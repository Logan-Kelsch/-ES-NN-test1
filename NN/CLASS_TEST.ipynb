{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTED FEATURES: \n",
      "Index(['FullK', 'diffKD', 'OB', 'OS', 'vol', 's15', 's30', 's60', 'ToD',\n",
      "       'Inertias', 'percBB', 'spreadRSI', 'ADX', 'RSI', 'Wpercent', 'acc'],\n",
      "      dtype='object')\n",
      "TESTING FOR: \n",
      "bull15\n",
      "OCCURANCES IN RAW DATA FOR bull15: \n",
      "{'in': 137027, 'up': 15476}\n",
      "ins -\t 137027 \n",
      "insMatch -\t 137027 \n",
      "non-ins -\t 15476\n",
      "PERCENT & WEIGHTS:\n",
      "INS\t-\t55.647062257803206 %\n",
      "Non-INS\t-\t492.70806409925046 %\n",
      "OCCURANCES IN RAW DATA FOR bull15: \n",
      "{'in': 137027, 'up': 15476}\n"
     ]
    }
   ],
   "source": [
    "#JJ McCauley + LOGAN KELSCH \n",
    "#TEST NN 1\n",
    "\n",
    "#IMPORT LIBRARIES-------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "#hahaha dont turn this on with high epoch or else\n",
    "#tf.config.experimental.set_memory_growth\n",
    "\n",
    "#LOAD DATA FROM CSV-------------------------------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "#data = pd.read_csv('ES7-26-22_to_9-18-24.csv')\n",
    "data = pd.read_csv('ES7-26-22_to_9-18-24.csv')\n",
    "\n",
    "#testing random feature drops\n",
    "data = data.drop(columns='FT')\n",
    "#data = data.drop(columns='FullK')\n",
    "#data = data.drop(columns='diffKD')\n",
    "#data = data.drop(columns='OB')\n",
    "#data = data.drop(columns='OS')\n",
    "#data = data.drop(columns='vol')\n",
    "#data = data.drop(columns='s15')\n",
    "#data = data.drop(columns='s30')\n",
    "#data = data.drop(columns='s60')\n",
    "#data = data.drop(columns='ToD')\n",
    "#data = data.drop(columns='Inertias')\n",
    "#data = data.drop(columns='percBB')\n",
    "#data = data.drop(columns='spreadRSI')\n",
    "#data = data.drop(columns='ADX')\n",
    "#data = data.drop(columns='RSI')\n",
    "#data = data.drop(columns='Wpercent')\n",
    "#data = data.drop(columns='acc')\n",
    "\n",
    "#TEMP DROP PRE-DUAL-OUTPUT NN\n",
    "\n",
    "#data = data.drop(columns='bull15')\n",
    "data = data.drop(columns='bear15')\n",
    "\n",
    "data = data.drop(columns='bull30')\n",
    "data = data.drop(columns='bear30')\n",
    "\n",
    "data = data.drop(columns='bull60')\n",
    "data = data.drop(columns='bear60')\n",
    "\n",
    "#confirming X and Y features post training\n",
    "Xfeatures = data.columns[:-1]\n",
    "Yfeatures = data.columns[-1]\n",
    "print(\"TESTED FEATURES: \")\n",
    "print(Xfeatures)\n",
    "print(\"TESTING FOR: \")\n",
    "print(Yfeatures)\n",
    "\n",
    "#DATA OPTIMIZATION------------------------------------------------------\n",
    "\n",
    "print(\"OCCURANCES IN RAW DATA FOR \", Yfeatures, \": \", sep='')\n",
    "unique, counts = np.unique(data.iloc[:, -1].values, return_counts=True)\n",
    "print(dict(zip(unique,counts)))\n",
    "\n",
    "NinRows = data.drop(data[data['bull15'] == 'in'].index)\n",
    "inRows = data.drop(data[data['bull15'] != 'in'].index)\n",
    "\n",
    "inRowsMatch = inRows#.loc[0:2740]\n",
    "\n",
    "print('ins -\\t',inRows.index.size,'\\ninsMatch -\\t',\\\n",
    "      inRowsMatch.index.size,'\\nnon-ins -\\t',NinRows.index.size)\n",
    "\n",
    "optData = pd.concat([NinRows, inRowsMatch],axis=0)\n",
    "\n",
    "percIn = data.size/(inRows.size*2)\n",
    "percNin = data.size/(NinRows.size*2)\n",
    "weight_for_0 = percIn\n",
    "weight_for_1 = percNin\n",
    "cw = {0: weight_for_1, 1: weight_for_0}\n",
    "\n",
    "print(\"PERCENT & WEIGHTS:\\nINS\\t-\\t\",percIn*100,\" %\\nNon-INS\\t-\\t\",percNin*100,\" %\",sep='')\n",
    "\n",
    "print(\"OCCURANCES IN RAW DATA FOR \", Yfeatures, \": \", sep='')\n",
    "unique, counts = np.unique(optData.iloc[:, -1].values, return_counts=True)\n",
    "print(dict(zip(unique,counts)))\n",
    "\n",
    "optData = optData.drop(optData[optData['ToD'] > 955].index)\n",
    "optData = optData.drop(optData[optData['ToD'] < 455].index)\n",
    "optData = optData.drop(optData[optData['s60'] <0].index)\n",
    "optData = optData.drop(optData[optData['OB'] == 1].index)\n",
    "\n",
    "optData = optData.drop(columns='s60')\n",
    "optData = optData.drop(columns='ToD')\n",
    "optData = optData.drop(columns='OB')\n",
    "\n",
    "#PROCESS THE DATA-------------------------------------------------------\n",
    "\n",
    "# Separate features and target\n",
    "X = optData.iloc[:, :-1].values\n",
    "y = optData.iloc[:, -1].values\n",
    "\n",
    "\n",
    "\n",
    "#Encoding data\n",
    "labelencoder = LabelBinarizer()\n",
    "y = labelencoder.fit_transform(y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "        \n",
    "        # Standard binary cross-entropy\n",
    "        bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        \n",
    "        # Define penalties for false negatives (y_true = 1, y_pred = 0)\n",
    "        false_negatives_penalty = 0.0  # Penalty for false negatives\n",
    "        false_positives_penalty = 5.0  # Penalty for false positives\n",
    "        \n",
    "        # Define reward for true positives (y_true = 1, y_pred = 1)\n",
    "        true_positives_reward = -2.0  # Negative value to reduce the loss when TP happens\n",
    "\n",
    "        # Calculate false negatives and false positives\n",
    "        false_negatives = y_true * (1 - y_pred)\n",
    "        false_positives = (1 - y_true) * y_pred\n",
    "        \n",
    "        # Calculate true positives\n",
    "        true_positives = y_true * y_pred\n",
    "        \n",
    "        # Apply penalties and rewards\n",
    "        penalties = false_negatives_penalty * false_negatives + false_positives_penalty * false_positives\n",
    "        rewards = true_positives_reward * true_positives\n",
    "        \n",
    "        # Return combined loss (penalize FNs and FPs, reward TPs)\n",
    "        return bce + penalties + rewards\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('modData1.keras')#,custom_objects={\"custom_loss\":custom_loss})\n",
    "met = ['Accuracy','AUC','Precision','Recall','TrueNegatives','TruePositives','FalsePositives','FalseNegatives']\n",
    "loaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=met)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the test set results\n",
    "threshold = 0.01\n",
    "y_pred = loaded_model.predict(X)\n",
    "y_pred = (y_pred > threshold)\n",
    "\n",
    "#making a confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "\n",
    "#PRINTS OUT ALL GUESSES\n",
    "#[print(x) for x in y_pred]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
