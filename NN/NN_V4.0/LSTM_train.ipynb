{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JJ McCauley + LOGAN KELSCH \n",
    "#TEST NN 1\n",
    "\n",
    "#IMPORT LIBRARIES-------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#hahaha dont turn this on with high epoch or else\n",
    "#tf.config.experimental.set_memory_growth\n",
    "\n",
    "#LOAD DATA FROM CSV-------------------------------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('catted_1-8.csv')\n",
    "\n",
    "#data = data[:1000]\n",
    "\n",
    "#      'Dr1' 'Dr3' 'Mr1' 'Mr3' \n",
    "testFor = 'r30'\n",
    "timeSteps = 10\n",
    "tType = testFor[0]\n",
    "#testing random feature drops\n",
    "#TREND\n",
    "\n",
    "data = data.drop(columns=['FT','FT.1'])\n",
    "#data = data.drop(columns=['FT'])\n",
    "#--------------------------------------\n",
    "#targets-------------------------------\n",
    "#r----  1   2   3   5   10  15  30  60\n",
    "match testFor:\n",
    "    case 'r1':\n",
    "        data = data.drop(columns=['r2','r3','r5','r10','r15','r30','r60'])\n",
    "    case 'r2':\n",
    "        data = data.drop(columns=['r1','r3','r5','r10','r15','r30','r60'])\n",
    "    case 'r3':\n",
    "        data = data.drop(columns=['r1','r2','r5','r10','r15','r30','r60'])\n",
    "    case 'r5':\n",
    "        data = data.drop(columns=['r1','r2','r3','r10','r15','r30','r60'])\n",
    "    case 'r10':\n",
    "        data = data.drop(columns=['r1','r2','r3','r5','r15','r30','r60'])\n",
    "    case 'r15':\n",
    "        data = data.drop(columns=['r1','r2','r3','r5','r10','r30','r60'])\n",
    "    case 'r30':\n",
    "        data = data.drop(columns=['r1','r2','r3','r5','r10','r15','r60'])\n",
    "    case 'r60':\n",
    "        data = data.drop(columns=['r1','r2','r3','r5','r10','r15','r30'])\n",
    "#data['Dr3_Model'] = 0\n",
    "#confirming X and Y features post training\n",
    "Xfeatures = data.columns[:-1]\n",
    "Yfeatures = data.columns[-1]\n",
    "print(\"TESTED FEATURES: \")\n",
    "print(Xfeatures)\n",
    "print(\"TESTING FOR: \")\n",
    "print(Yfeatures)\n",
    "#PROCESS THE DATA-------------------------------------------------------\n",
    "\n",
    "# Separate features and target\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "#setting data for LSTM\n",
    "def reformat_to_lstm(X, time_steps=timeSteps):\n",
    "    X_lstm, y_lstm = [], []\n",
    "    \n",
    "    for i in range(time_steps, len(X)):\n",
    "        # Collect previous time_steps rows for X\n",
    "        X_lstm.append(X[i-time_steps:i])  \n",
    "        # The corresponding y value for the last time step in the sequence\n",
    "    \n",
    "    X_lstm = np.array(X_lstm)\n",
    "    \n",
    "    return X_lstm\n",
    "# Standardize the features\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = RobustScaler()\n",
    "scaler3 = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "#test size that will be used in training\n",
    "test_size = 0.2\n",
    "#scale all data to that of the projected training set datapoints\n",
    "X_fit = X[:int(len(X)*(1-test_size))]\n",
    "\n",
    "scaler1.fit(X_fit)\n",
    "X = scaler1.transform(X)\n",
    "\n",
    "X = reformat_to_lstm(X, timeSteps)\n",
    "\n",
    "y = y[timeSteps:]\n",
    "y = np.array(y)\n",
    "\n",
    "print('\\nX shape == {}.'.format(X.shape))\n",
    "print('y shape == {}.\\n'.format(y.shape))\n",
    "\n",
    "def remove_zero_mo_samples(X, y):\n",
    "    # Get the 'MO' column (index 34 for 0-based indexing) for all time steps and samples\n",
    "    non_zero_indices = (X[:, timeSteps-1, len(Xfeatures)-1] >= 0)\n",
    "    # Filter X and y using these indices\n",
    "    X_filtered = X[non_zero_indices]\n",
    "    y_filtered = y[non_zero_indices]\n",
    "    return X_filtered, y_filtered\n",
    "\n",
    "t0930 = -0.32007092\n",
    "t1045 = -0.141503587\n",
    "t1200 = 0.03706375\n",
    "\n",
    "def remove_extra_filter(X, y):\n",
    "    indices = (X[:, timeSteps-1, len(Xfeatures)-3] >= t0930)#-3 is ToD, this value is 9:30am\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "    indices = (X[:, timeSteps-1, len(Xfeatures)-3] <= t1200)#-3 is ToD, this value is 12:00pm\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "    return X, y\n",
    "print(f'Raw Sample Count:\\t{len(X)}')\n",
    "X, y = remove_zero_mo_samples(X, y)\n",
    "X, y = remove_extra_filter(X, y)\n",
    "print(f'Remaining Sample Count:\\t{len(X)}')\n",
    "\n",
    "#mos = X[:, timeSteps-1, len(Xfeatures)-1].mean()\n",
    "#print(mos)\n",
    "#print(len(X))\n",
    "#print(X[0])\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "\n",
    "#to remove overlapping values that were left from training set\n",
    "X_test = X_test[timeSteps:]\n",
    "y_test = y_test[timeSteps:]\n",
    "\n",
    "print('\\nX_train shape == {}.'.format(X_train.shape))\n",
    "print('y_train shape == {}.'.format(y_train.shape))\n",
    "print('X_test shape == {}.'.format(X_test.shape))\n",
    "print('y_test shape == {}.\\n'.format(y_test.shape))\n",
    "\n",
    "\n",
    "#LEARNING RATES____________________________________________________________________________________________\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "lr_schedule = ExponentialDecay(\n",
    "    #good rough val to start, .25, good val to end at .0015.\n",
    "    #5k epoch should be: .25, 8565, .9995, true\n",
    "    0.01,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.997,\n",
    "    staircase=True)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    factor=0.95, \n",
    "    patience=10, \n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "#LOSS FUNCTION\n",
    "from keras.saving import get_custom_objects\n",
    "from keras.saving import register_keras_serializable\n",
    "get_custom_objects().clear()\n",
    "#CUSTOM LOSS 1_______________________________________________________________________________________________\n",
    "from keras.src import ops\n",
    "from keras.src.losses.loss import squeeze_or_expand_to_same_rank\n",
    "@register_keras_serializable(name=\"skew_loss\")\n",
    "def skew_loss(y_true,y_pred,sFact=4):\n",
    "    #return ops.mean(ops.square((y_pred-y_true)*(1+sFact*tf.cast(((y_true>0 & y_pred<y_true) | (y_true<0 & y_pred>y_true)),tf.float32))),axis=-1)\n",
    "    y_pred = ops.convert_to_tensor(y_pred)\n",
    "    y_true = ops.convert_to_tensor(y_true, dtype=y_pred.dtype)\n",
    "    #y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n",
    "    error = ops.subtract(y_pred, y_true)\n",
    "    a = ops.convert_to_tensor(ops.cast(y_pred > 0,tf.float32), dtype=tf.float32)\n",
    "    b = ops.convert_to_tensor(ops.cast(y_pred < 0,tf.float32), dtype=tf.float32)\n",
    "    c = ops.convert_to_tensor(ops.cast(y_true >= y_pred*.9,tf.float32), dtype=tf.float32)\n",
    "    d = ops.convert_to_tensor(ops.cast(y_true <= y_pred*.9,tf.float32), dtype=tf.float32)\n",
    "    #e = ops.convert_to_tensor(ops.cast(y_true >= 0.05,tf.float32), dtype=tf.float32)\n",
    "    #f = ops.convert_to_tensor(ops.cast(y_true <= -0.05,tf.float32), dtype=tf.float32)\n",
    "    h = ops.convert_to_tensor(0.5, dtype=error.dtype)\n",
    "    return ops.mean(\n",
    "        ops.where(\n",
    "            a*c+b*d==1,# or (b and d),\n",
    "            h*ops.square(error),\n",
    "            ops.square(error)\n",
    "        ))\n",
    "\n",
    "opt1 = SGD(learning_rate=0.01)\n",
    "opt2  = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "opt3 = SGD(learning_rate=lr_schedule)\n",
    "opt4 = SGD(learning_rate=0.0025, momentum=0.9)\n",
    "opt5 = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#BUILD AND LOAD MODEL__________________________________________________________________________________________\n",
    "\n",
    "\n",
    "#print(X_train.shape[0]/time_steps)\n",
    "#X_train = np.reshape(X_train,((X_train.shape[0]//time_steps), time_steps, 35))  # Reshape to (batch_size, 5 time steps, 35 features)\n",
    "#y_train = y.reshape(1,-1)\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def build_LSTM_model():\n",
    "    #time_steps=5\n",
    "    n_features=len(Xfeatures)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(X_train.shape[1],X_train.shape[2])),\n",
    "        tf.keras.layers.LSTM(128, activation='tanh', recurrent_dropout=0.3, return_sequences=True),#, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        tf.keras.layers.LSTM(64, activation='tanh', recurrent_dropout=0.2, return_sequences=False),#, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),#,kernel_initializer='he_normal',kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=opt5,\n",
    "                  loss='mse'\n",
    "                  ,metrics=['R2Score','root_mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "def load_model():\n",
    "    #loaded_model = tf.keras.models.load_model('tupleTrain.keras', custom_objects={'custom_loss':custom_loss})\n",
    "    loaded_model = tf.keras.models.load_model('r30_10s_LSTM_8.keras')\n",
    "    loaded_model.compile(optimizer=opt4,\n",
    "                         loss=skew_loss\n",
    "                         , metrics=['R2Score','root_mean_squared_error'])\n",
    "    return loaded_model\n",
    "\n",
    "#TRAIN THE MODEL WITH CUSTOMIZABLE EPOCHS-------------------------------------------------------\n",
    "\n",
    "epochs = 2000\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=42, mode='min', restore_best_weights=True)\n",
    "\n",
    "cmp = 'C'\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    cmp = 'G'\n",
    "    pass\n",
    "with tf.device('/'+cmp+'PU:0'):\n",
    "    print('Running on: '+cmp+'PU\\n')\n",
    "    model = build_LSTM_model()\n",
    "    loaded_model = load_model()\n",
    "    used_model = loaded_model\n",
    "    history = used_model.fit(X_train, y_train, epochs=epochs,\\\n",
    "                        shuffle=False, verbose=1, validation_data=(X_test, y_test),\\\n",
    "                        batch_size=64,callbacks=[reduce_lr, early_stopping])\n",
    "\n",
    "#EVALUATE THE MODEL AND VISUALIZE RESULTS-------------------------------------------------------\n",
    "\n",
    "# LOSS\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, history.history['loss'], 'y', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "# ACCURACY\n",
    "\n",
    "plt.plot(epochs, history.history['R2Score'], 'y', label='Training R2')\n",
    "plt.plot(epochs, history.history['val_R2Score'], 'r', label='Validation R2')\n",
    "plt.title('Training and Validation R2Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R2Score')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = used_model.predict(X_test) \n",
    "\n",
    "\n",
    "plt.scatter(y_pred, y_test, s=1)\n",
    "plt.axis('tight')\n",
    "plt.title('Testing Outputs')\n",
    "plt.xlabel('y_pred')\n",
    "plt.xlim(-.25,.25)\n",
    "plt.ylim(-.25,.25)\n",
    "plt.ylabel('y_test')\n",
    "ax = plt.gca()\n",
    "x_vals = np.array(ax.get_xlim())\n",
    "y_vals = x_vals  # Since y = x\n",
    "plt.plot(x_vals, y_vals, '-', color='black', label='y = x', linewidth=0.5)\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.axvline(0,color='black',linewidth=0.5)\n",
    "plt.show()\n",
    "\n",
    "#SCATTERPLOT #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  \n",
    "plt.scatter(y_pred, y_test, s=1)\n",
    "plt.grid()\n",
    "plt.axis('tight')\n",
    "plt.title('Testing Outputs')\n",
    "plt.xlabel('y_pred')\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-1,1)\n",
    "plt.ylabel('y_test')\n",
    "ax = plt.gca()\n",
    "x_vals = np.array(ax.get_xlim())\n",
    "y_vals = x_vals  # Since y = x\n",
    "plt.plot(x_vals, y_vals, '-', color='black', label='y = x', linewidth=0.5)\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.axvline(0,color='black',linewidth=0.5)\n",
    "plt.show()\n",
    "#DIRECTIONAL ACCURACY #DIRECTIONAL ACCURACY  #DIRECTIONAL ACCURACY  #DIRECTIONAL ACCURACY  #DIRECTIONAL ACCURACY  \n",
    "tp, fp, tn, fn = 0, 0, 0, 0\n",
    "tp5, fp5, tn5, fn5 = 0, 0, 0, 0\n",
    "for i in range(len(y_pred)):\n",
    "    if(y_pred[i]>0):\n",
    "        if(y_test[i]>0):\n",
    "            tp+=1\n",
    "        if(y_test[i]<0):\n",
    "            fp+=1\n",
    "        if(y_pred[i]>=5):\n",
    "            if(y_test[i]>0):\n",
    "                tp5+=1\n",
    "            if(y_test[i]<0):\n",
    "                fp5+=1\n",
    "    if(y_pred[i]<0):\n",
    "        if(y_test[i]<0):\n",
    "            tn+=1\n",
    "        if(y_test[i]>0):\n",
    "            fn+=1\n",
    "        if(y_pred[i]<=-5):\n",
    "            if(y_test[i]<0):\n",
    "                tn5+=1\n",
    "            if(y_test[i]>0):\n",
    "                fn5+=1\n",
    "directionalAccuracy = ((tp+tn)/(tp+fp+tn+fn))*10000//1/100\n",
    "print('Directional Accuracy:\\t\\t',directionalAccuracy)\n",
    "directionalAccuracy5guess = ((tp5+tn5)/(tp5+fp5+tn5+fn5))*10000//1/100\n",
    "print('Directional Accuracy >(+/-)5:\\t',directionalAccuracy5guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_model.save('r30_10s_LSTM_16.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3019, 48, 31) \n",
      "y shape: (3019,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=LSTM_testtest.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m y_vals \u001b[38;5;241m=\u001b[39m y_test\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX shape:\u001b[39m\u001b[38;5;124m'\u001b[39m,X_vals\u001b[38;5;241m.\u001b[39mshape,\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124my shape:\u001b[39m\u001b[38;5;124m'\u001b[39m,y_vals\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 56\u001b[0m scores \u001b[38;5;241m=\u001b[39m walk_forward_validation(X_test, y_test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM_testtest.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     57\u001b[0m avgScore \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m score \u001b[38;5;129;01min\u001b[39;00m scores:\n",
      "Cell \u001b[1;32mIn[78], line 33\u001b[0m, in \u001b[0;36mwalk_forward_validation\u001b[1;34m(X, y, model, n_splits, test_size)\u001b[0m\n\u001b[0;32m     30\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y[:train_end], y[train_end:train_end \u001b[38;5;241m+\u001b[39m test_set_size]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Ensure that your model is recompiled and retrained in each fold\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m model_copy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(model)\n\u001b[0;32m     34\u001b[0m model_copy\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Assuming MSE for regression\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Fit the model on the current training set\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\logan\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:193\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    190\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m    191\u001b[0m     )\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m     )\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    211\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: File not found: filepath=LSTM_testtest.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def walk_forward_validation(X, y, model, n_splits=20, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Perform walk-forward validation for an LSTM model.\n",
    "\n",
    "    Parameters:\n",
    "    X (np.ndarray): 3D array of features with shape (n_samples, time_steps, n_features)\n",
    "    y (np.ndarray): 1D array of labels with shape (n_samples,)\n",
    "    model (tf.keras.Model): Compiled LSTM model\n",
    "    n_splits (int): Number of walk-forward splits\n",
    "    test_size (float): Proportion of the data to use as the test set in each split\n",
    "\n",
    "    Returns:\n",
    "    list: MSE scores for each split\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    test_set_size = int(test_size * n_samples)\n",
    "    \n",
    "    mse_scores = []\n",
    "\n",
    "    # Split the data into n_splits segments\n",
    "    for i in range(n_splits):\n",
    "        # Define the index range for the training set (everything before the test set)\n",
    "        train_end = int((i + 1) * (n_samples - test_set_size) / n_splits)\n",
    "\n",
    "        # Define the test set\n",
    "        X_train, X_test = X[:train_end], X[train_end:train_end + test_set_size]\n",
    "        y_train, y_test = y[:train_end], y[train_end:train_end + test_set_size]\n",
    "\n",
    "        # Ensure that your model is recompiled and retrained in each fold\n",
    "        model_copy = tf.keras.models.load_model(model)\n",
    "        model_copy.compile(optimizer='adam', loss='mse')  # Assuming MSE for regression\n",
    "\n",
    "        # Fit the model on the current training set\n",
    "        model_copy.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = model_copy.predict(X_test)\n",
    "\n",
    "        # Calculate the mean squared error for this fold\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "        print(f'Fold {i+1}/{n_splits}, MSE: {mse}')\n",
    "\n",
    "    return mse_scores\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have already defined `X`, `y`, and compiled your LSTM model\n",
    "# mse_scores = walk_forward_validation(X, y, lstm_model, n_splits=5, test_size=0.2)\n",
    "X_vals = X_test\n",
    "y_vals = y_test\n",
    "print('X shape:',X_vals.shape,'\\ny shape:',y_vals.shape)\n",
    "scores = walk_forward_validation(X_test, y_test, 'LSTM_testtest.keras')\n",
    "avgScore = 0\n",
    "for score in scores:\n",
    "    avgScore+=score\n",
    "avgScore/=len(scores)\n",
    "\n",
    "print('Average MSE:',avgScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vel5</th>\n",
       "      <th>vel10</th>\n",
       "      <th>vel15</th>\n",
       "      <th>vel30</th>\n",
       "      <th>vel60</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc10</th>\n",
       "      <th>acc15</th>\n",
       "      <th>acc30</th>\n",
       "      <th>acc60</th>\n",
       "      <th>...</th>\n",
       "      <th>volD60</th>\n",
       "      <th>vpm5</th>\n",
       "      <th>vpm10</th>\n",
       "      <th>vpm15</th>\n",
       "      <th>vpm30</th>\n",
       "      <th>vpm60</th>\n",
       "      <th>ToD</th>\n",
       "      <th>DoW</th>\n",
       "      <th>MO</th>\n",
       "      <th>Dr1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vel5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.696269</td>\n",
       "      <td>0.566629</td>\n",
       "      <td>0.404792</td>\n",
       "      <td>0.292516</td>\n",
       "      <td>0.717757</td>\n",
       "      <td>0.488963</td>\n",
       "      <td>0.396644</td>\n",
       "      <td>0.279971</td>\n",
       "      <td>0.209327</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040104</td>\n",
       "      <td>0.399169</td>\n",
       "      <td>0.295397</td>\n",
       "      <td>0.252108</td>\n",
       "      <td>0.187244</td>\n",
       "      <td>0.122011</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>-0.006288</td>\n",
       "      <td>-0.005597</td>\n",
       "      <td>-0.030087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vel10</th>\n",
       "      <td>0.696269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806148</td>\n",
       "      <td>0.574039</td>\n",
       "      <td>0.409941</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.715761</td>\n",
       "      <td>0.566122</td>\n",
       "      <td>0.401907</td>\n",
       "      <td>0.289201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056399</td>\n",
       "      <td>0.261988</td>\n",
       "      <td>0.431247</td>\n",
       "      <td>0.351803</td>\n",
       "      <td>0.258081</td>\n",
       "      <td>0.170056</td>\n",
       "      <td>0.010114</td>\n",
       "      <td>-0.008862</td>\n",
       "      <td>-0.006926</td>\n",
       "      <td>-0.030580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vel15</th>\n",
       "      <td>0.566629</td>\n",
       "      <td>0.806148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702885</td>\n",
       "      <td>0.499764</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.289400</td>\n",
       "      <td>0.711311</td>\n",
       "      <td>0.494297</td>\n",
       "      <td>0.351262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063678</td>\n",
       "      <td>0.211814</td>\n",
       "      <td>0.339981</td>\n",
       "      <td>0.446810</td>\n",
       "      <td>0.313587</td>\n",
       "      <td>0.208718</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>-0.010801</td>\n",
       "      <td>-0.006752</td>\n",
       "      <td>-0.021263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vel30</th>\n",
       "      <td>0.404792</td>\n",
       "      <td>0.574039</td>\n",
       "      <td>0.702885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.706232</td>\n",
       "      <td>0.007091</td>\n",
       "      <td>0.011623</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.707956</td>\n",
       "      <td>0.498343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069082</td>\n",
       "      <td>0.146675</td>\n",
       "      <td>0.227690</td>\n",
       "      <td>0.295953</td>\n",
       "      <td>0.459010</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.017696</td>\n",
       "      <td>-0.015124</td>\n",
       "      <td>-0.005017</td>\n",
       "      <td>-0.009727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vel60</th>\n",
       "      <td>0.292516</td>\n",
       "      <td>0.409941</td>\n",
       "      <td>0.499764</td>\n",
       "      <td>0.706232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009827</td>\n",
       "      <td>0.012296</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.702112</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040721</td>\n",
       "      <td>0.105265</td>\n",
       "      <td>0.158133</td>\n",
       "      <td>0.204836</td>\n",
       "      <td>0.309917</td>\n",
       "      <td>0.452845</td>\n",
       "      <td>0.025193</td>\n",
       "      <td>-0.019204</td>\n",
       "      <td>-0.009746</td>\n",
       "      <td>-0.002594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc5</th>\n",
       "      <td>0.717757</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007091</td>\n",
       "      <td>0.009827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013115</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001119</td>\n",
       "      <td>0.301999</td>\n",
       "      <td>-0.006754</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.010539</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.001095</td>\n",
       "      <td>-0.012246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc10</th>\n",
       "      <td>0.488963</td>\n",
       "      <td>0.715761</td>\n",
       "      <td>0.289400</td>\n",
       "      <td>0.011623</td>\n",
       "      <td>0.012296</td>\n",
       "      <td>-0.013115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.395404</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014793</td>\n",
       "      <td>0.191872</td>\n",
       "      <td>0.320990</td>\n",
       "      <td>0.125447</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>-0.004608</td>\n",
       "      <td>-0.026688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc15</th>\n",
       "      <td>0.396644</td>\n",
       "      <td>0.566122</td>\n",
       "      <td>0.711311</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.395404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004650</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021239</td>\n",
       "      <td>0.152865</td>\n",
       "      <td>0.253008</td>\n",
       "      <td>0.335755</td>\n",
       "      <td>-0.012689</td>\n",
       "      <td>-0.000914</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.004520</td>\n",
       "      <td>-0.020336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc30</th>\n",
       "      <td>0.279971</td>\n",
       "      <td>0.401907</td>\n",
       "      <td>0.494297</td>\n",
       "      <td>0.707956</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>-0.004650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056943</td>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.163888</td>\n",
       "      <td>0.213747</td>\n",
       "      <td>0.339243</td>\n",
       "      <td>-0.030884</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>-0.002206</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>-0.011194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc60</th>\n",
       "      <td>0.209327</td>\n",
       "      <td>0.289201</td>\n",
       "      <td>0.351262</td>\n",
       "      <td>0.498343</td>\n",
       "      <td>0.702112</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031837</td>\n",
       "      <td>0.072164</td>\n",
       "      <td>0.108224</td>\n",
       "      <td>0.140920</td>\n",
       "      <td>0.214447</td>\n",
       "      <td>0.323144</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>-0.001878</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stoch12</th>\n",
       "      <td>0.377976</td>\n",
       "      <td>0.478170</td>\n",
       "      <td>0.541923</td>\n",
       "      <td>0.635179</td>\n",
       "      <td>0.636602</td>\n",
       "      <td>0.062749</td>\n",
       "      <td>0.099823</td>\n",
       "      <td>0.134281</td>\n",
       "      <td>0.262216</td>\n",
       "      <td>0.451728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065496</td>\n",
       "      <td>0.302808</td>\n",
       "      <td>0.408260</td>\n",
       "      <td>0.475668</td>\n",
       "      <td>0.566148</td>\n",
       "      <td>0.538376</td>\n",
       "      <td>0.012769</td>\n",
       "      <td>-0.014696</td>\n",
       "      <td>-0.010189</td>\n",
       "      <td>-0.007544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stochDiff6012</th>\n",
       "      <td>0.400457</td>\n",
       "      <td>0.507834</td>\n",
       "      <td>0.565856</td>\n",
       "      <td>0.607925</td>\n",
       "      <td>0.442418</td>\n",
       "      <td>0.065284</td>\n",
       "      <td>0.129730</td>\n",
       "      <td>0.194854</td>\n",
       "      <td>0.417469</td>\n",
       "      <td>0.403139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091359</td>\n",
       "      <td>0.251414</td>\n",
       "      <td>0.350791</td>\n",
       "      <td>0.411406</td>\n",
       "      <td>0.479059</td>\n",
       "      <td>0.379592</td>\n",
       "      <td>0.012056</td>\n",
       "      <td>-0.008342</td>\n",
       "      <td>-0.010490</td>\n",
       "      <td>-0.009730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSIhl_diff</th>\n",
       "      <td>0.029998</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>0.014242</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.030880</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>0.019105</td>\n",
       "      <td>0.023221</td>\n",
       "      <td>0.026310</td>\n",
       "      <td>-0.011032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.592633</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>0.023544</td>\n",
       "      <td>0.025213</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.180068</td>\n",
       "      <td>-0.020364</td>\n",
       "      <td>-0.138535</td>\n",
       "      <td>-0.006143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSIhl_diffROC</th>\n",
       "      <td>0.035536</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>-0.002526</td>\n",
       "      <td>-0.000746</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.005933</td>\n",
       "      <td>-0.002836</td>\n",
       "      <td>-0.001631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268701</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>-0.001552</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>-0.004357</td>\n",
       "      <td>-0.002434</td>\n",
       "      <td>0.005355</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>-0.010908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol</th>\n",
       "      <td>-0.034446</td>\n",
       "      <td>-0.061487</td>\n",
       "      <td>-0.072707</td>\n",
       "      <td>-0.096548</td>\n",
       "      <td>-0.092960</td>\n",
       "      <td>0.011658</td>\n",
       "      <td>-0.008032</td>\n",
       "      <td>-0.006791</td>\n",
       "      <td>-0.043577</td>\n",
       "      <td>-0.028476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402226</td>\n",
       "      <td>-0.020267</td>\n",
       "      <td>-0.025863</td>\n",
       "      <td>-0.031096</td>\n",
       "      <td>-0.041812</td>\n",
       "      <td>-0.050274</td>\n",
       "      <td>0.037538</td>\n",
       "      <td>0.037112</td>\n",
       "      <td>0.546729</td>\n",
       "      <td>-0.012484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol10</th>\n",
       "      <td>-0.024375</td>\n",
       "      <td>-0.050011</td>\n",
       "      <td>-0.068859</td>\n",
       "      <td>-0.097354</td>\n",
       "      <td>-0.098282</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.039403</td>\n",
       "      <td>-0.031610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294425</td>\n",
       "      <td>-0.019573</td>\n",
       "      <td>-0.025661</td>\n",
       "      <td>-0.031523</td>\n",
       "      <td>-0.043353</td>\n",
       "      <td>-0.052847</td>\n",
       "      <td>0.043069</td>\n",
       "      <td>0.039122</td>\n",
       "      <td>0.573243</td>\n",
       "      <td>-0.011404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol15</th>\n",
       "      <td>-0.019875</td>\n",
       "      <td>-0.039884</td>\n",
       "      <td>-0.059506</td>\n",
       "      <td>-0.094437</td>\n",
       "      <td>-0.101208</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>0.016860</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>-0.032366</td>\n",
       "      <td>-0.032690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211861</td>\n",
       "      <td>-0.019550</td>\n",
       "      <td>-0.025131</td>\n",
       "      <td>-0.031419</td>\n",
       "      <td>-0.044165</td>\n",
       "      <td>-0.054638</td>\n",
       "      <td>0.048250</td>\n",
       "      <td>0.040585</td>\n",
       "      <td>0.591939</td>\n",
       "      <td>-0.010286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol30</th>\n",
       "      <td>-0.015631</td>\n",
       "      <td>-0.028293</td>\n",
       "      <td>-0.040582</td>\n",
       "      <td>-0.079453</td>\n",
       "      <td>-0.105122</td>\n",
       "      <td>0.005635</td>\n",
       "      <td>0.012062</td>\n",
       "      <td>0.021460</td>\n",
       "      <td>-0.007295</td>\n",
       "      <td>-0.033583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>-0.019288</td>\n",
       "      <td>-0.024235</td>\n",
       "      <td>-0.030175</td>\n",
       "      <td>-0.044407</td>\n",
       "      <td>-0.057573</td>\n",
       "      <td>0.062838</td>\n",
       "      <td>0.043465</td>\n",
       "      <td>0.622879</td>\n",
       "      <td>-0.011967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol60</th>\n",
       "      <td>-0.016707</td>\n",
       "      <td>-0.027100</td>\n",
       "      <td>-0.036276</td>\n",
       "      <td>-0.061492</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.005914</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>-0.019555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050688</td>\n",
       "      <td>-0.021449</td>\n",
       "      <td>-0.026577</td>\n",
       "      <td>-0.031855</td>\n",
       "      <td>-0.043558</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>0.091407</td>\n",
       "      <td>0.046908</td>\n",
       "      <td>0.642290</td>\n",
       "      <td>-0.013805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volD10</th>\n",
       "      <td>-0.045696</td>\n",
       "      <td>-0.039452</td>\n",
       "      <td>-0.031596</td>\n",
       "      <td>-0.020902</td>\n",
       "      <td>-0.009628</td>\n",
       "      <td>-0.025341</td>\n",
       "      <td>-0.032221</td>\n",
       "      <td>-0.023755</td>\n",
       "      <td>-0.019910</td>\n",
       "      <td>-0.006221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545014</td>\n",
       "      <td>-0.035195</td>\n",
       "      <td>-0.014472</td>\n",
       "      <td>-0.019168</td>\n",
       "      <td>-0.013615</td>\n",
       "      <td>-0.008109</td>\n",
       "      <td>-0.044984</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.018263</td>\n",
       "      <td>0.002834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volD15</th>\n",
       "      <td>-0.046466</td>\n",
       "      <td>-0.054973</td>\n",
       "      <td>-0.045964</td>\n",
       "      <td>-0.031205</td>\n",
       "      <td>-0.013122</td>\n",
       "      <td>-0.011361</td>\n",
       "      <td>-0.042100</td>\n",
       "      <td>-0.033771</td>\n",
       "      <td>-0.030971</td>\n",
       "      <td>-0.009095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701749</td>\n",
       "      <td>-0.036479</td>\n",
       "      <td>-0.028739</td>\n",
       "      <td>-0.026636</td>\n",
       "      <td>-0.019305</td>\n",
       "      <td>-0.012053</td>\n",
       "      <td>-0.060366</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.019381</td>\n",
       "      <td>0.000511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volD30</th>\n",
       "      <td>-0.045175</td>\n",
       "      <td>-0.061389</td>\n",
       "      <td>-0.065355</td>\n",
       "      <td>-0.053528</td>\n",
       "      <td>-0.022932</td>\n",
       "      <td>-0.003340</td>\n",
       "      <td>-0.025325</td>\n",
       "      <td>-0.038965</td>\n",
       "      <td>-0.052715</td>\n",
       "      <td>-0.017033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894664</td>\n",
       "      <td>-0.034789</td>\n",
       "      <td>-0.036498</td>\n",
       "      <td>-0.042076</td>\n",
       "      <td>-0.034900</td>\n",
       "      <td>-0.024396</td>\n",
       "      <td>-0.088542</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.026703</td>\n",
       "      <td>0.001492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volD60</th>\n",
       "      <td>-0.040104</td>\n",
       "      <td>-0.056399</td>\n",
       "      <td>-0.063678</td>\n",
       "      <td>-0.069082</td>\n",
       "      <td>-0.040721</td>\n",
       "      <td>-0.001119</td>\n",
       "      <td>-0.014793</td>\n",
       "      <td>-0.021239</td>\n",
       "      <td>-0.056943</td>\n",
       "      <td>-0.031837</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034729</td>\n",
       "      <td>-0.040941</td>\n",
       "      <td>-0.049075</td>\n",
       "      <td>-0.054675</td>\n",
       "      <td>-0.046031</td>\n",
       "      <td>-0.136767</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.055587</td>\n",
       "      <td>-0.002607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vpm5</th>\n",
       "      <td>0.399169</td>\n",
       "      <td>0.261988</td>\n",
       "      <td>0.211814</td>\n",
       "      <td>0.146675</td>\n",
       "      <td>0.105265</td>\n",
       "      <td>0.301999</td>\n",
       "      <td>0.191872</td>\n",
       "      <td>0.152865</td>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.072164</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.599395</td>\n",
       "      <td>0.477815</td>\n",
       "      <td>0.329781</td>\n",
       "      <td>0.207445</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>-0.007764</td>\n",
       "      <td>-0.019992</td>\n",
       "      <td>-0.005129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vpm10</th>\n",
       "      <td>0.295397</td>\n",
       "      <td>0.431247</td>\n",
       "      <td>0.339981</td>\n",
       "      <td>0.227690</td>\n",
       "      <td>0.158133</td>\n",
       "      <td>-0.006754</td>\n",
       "      <td>0.320990</td>\n",
       "      <td>0.253008</td>\n",
       "      <td>0.163888</td>\n",
       "      <td>0.108224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040941</td>\n",
       "      <td>0.599395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.739195</td>\n",
       "      <td>0.474857</td>\n",
       "      <td>0.292856</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>-0.009220</td>\n",
       "      <td>-0.024274</td>\n",
       "      <td>-0.003280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vpm15</th>\n",
       "      <td>0.252108</td>\n",
       "      <td>0.351803</td>\n",
       "      <td>0.446810</td>\n",
       "      <td>0.295953</td>\n",
       "      <td>0.204836</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.125447</td>\n",
       "      <td>0.335755</td>\n",
       "      <td>0.213747</td>\n",
       "      <td>0.140920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049075</td>\n",
       "      <td>0.477815</td>\n",
       "      <td>0.739195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612409</td>\n",
       "      <td>0.383153</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>-0.010489</td>\n",
       "      <td>-0.029213</td>\n",
       "      <td>-0.003253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vpm30</th>\n",
       "      <td>0.187244</td>\n",
       "      <td>0.258081</td>\n",
       "      <td>0.313587</td>\n",
       "      <td>0.459010</td>\n",
       "      <td>0.309917</td>\n",
       "      <td>0.010539</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>-0.012689</td>\n",
       "      <td>0.339243</td>\n",
       "      <td>0.214447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054675</td>\n",
       "      <td>0.329781</td>\n",
       "      <td>0.474857</td>\n",
       "      <td>0.612409</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.598460</td>\n",
       "      <td>0.012997</td>\n",
       "      <td>-0.012419</td>\n",
       "      <td>-0.039529</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vpm60</th>\n",
       "      <td>0.122011</td>\n",
       "      <td>0.170056</td>\n",
       "      <td>0.208718</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.452845</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>-0.000914</td>\n",
       "      <td>-0.030884</td>\n",
       "      <td>0.323144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046031</td>\n",
       "      <td>0.207445</td>\n",
       "      <td>0.292856</td>\n",
       "      <td>0.383153</td>\n",
       "      <td>0.598460</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024778</td>\n",
       "      <td>-0.013850</td>\n",
       "      <td>-0.050378</td>\n",
       "      <td>-0.003207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ToD</th>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.010114</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.017696</td>\n",
       "      <td>0.025193</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136767</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.012997</td>\n",
       "      <td>0.024778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.044723</td>\n",
       "      <td>0.006287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoW</th>\n",
       "      <td>-0.006288</td>\n",
       "      <td>-0.008862</td>\n",
       "      <td>-0.010801</td>\n",
       "      <td>-0.015124</td>\n",
       "      <td>-0.019204</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.002206</td>\n",
       "      <td>-0.001878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>-0.007764</td>\n",
       "      <td>-0.009220</td>\n",
       "      <td>-0.010489</td>\n",
       "      <td>-0.012419</td>\n",
       "      <td>-0.013850</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>-0.000859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MO</th>\n",
       "      <td>-0.005597</td>\n",
       "      <td>-0.006926</td>\n",
       "      <td>-0.006752</td>\n",
       "      <td>-0.005017</td>\n",
       "      <td>-0.009746</td>\n",
       "      <td>-0.001095</td>\n",
       "      <td>-0.004608</td>\n",
       "      <td>-0.004520</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055587</td>\n",
       "      <td>-0.019992</td>\n",
       "      <td>-0.024274</td>\n",
       "      <td>-0.029213</td>\n",
       "      <td>-0.039529</td>\n",
       "      <td>-0.050378</td>\n",
       "      <td>0.044723</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr1</th>\n",
       "      <td>-0.030087</td>\n",
       "      <td>-0.030580</td>\n",
       "      <td>-0.021263</td>\n",
       "      <td>-0.009727</td>\n",
       "      <td>-0.002594</td>\n",
       "      <td>-0.012246</td>\n",
       "      <td>-0.026688</td>\n",
       "      <td>-0.020336</td>\n",
       "      <td>-0.011194</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002607</td>\n",
       "      <td>-0.005129</td>\n",
       "      <td>-0.003280</td>\n",
       "      <td>-0.003253</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.003207</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>-0.000859</td>\n",
       "      <td>-0.005728</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   vel5     vel10     vel15     vel30     vel60      acc5  \\\n",
       "vel5           1.000000  0.696269  0.566629  0.404792  0.292516  0.717757   \n",
       "vel10          0.696269  1.000000  0.806148  0.574039  0.409941 -0.000033   \n",
       "vel15          0.566629  0.806148  1.000000  0.702885  0.499764  0.007407   \n",
       "vel30          0.404792  0.574039  0.702885  1.000000  0.706232  0.007091   \n",
       "vel60          0.292516  0.409941  0.499764  0.706232  1.000000  0.009827   \n",
       "acc5           0.717757 -0.000033  0.007407  0.007091  0.009827  1.000000   \n",
       "acc10          0.488963  0.715761  0.289400  0.011623  0.012296 -0.013115   \n",
       "acc15          0.396644  0.566122  0.711311  0.000013  0.004736  0.003432   \n",
       "acc30          0.279971  0.401907  0.494297  0.707956 -0.000029  0.000202   \n",
       "acc60          0.209327  0.289201  0.351262  0.498343  0.702112  0.011057   \n",
       "stoch12        0.377976  0.478170  0.541923  0.635179  0.636602  0.062749   \n",
       "stochDiff6012  0.400457  0.507834  0.565856  0.607925  0.442418  0.065284   \n",
       "RSIhl_diff     0.029998  0.018920  0.014242 -0.003205 -0.030880  0.023451   \n",
       "RSIhl_diffROC  0.035536  0.002013  0.002452 -0.002526 -0.000746  0.047545   \n",
       "vol           -0.034446 -0.061487 -0.072707 -0.096548 -0.092960  0.011658   \n",
       "vol10         -0.024375 -0.050011 -0.068859 -0.097354 -0.098282  0.014531   \n",
       "vol15         -0.019875 -0.039884 -0.059506 -0.094437 -0.101208  0.010969   \n",
       "vol30         -0.015631 -0.028293 -0.040582 -0.079453 -0.105122  0.005635   \n",
       "vol60         -0.016707 -0.027100 -0.036276 -0.061492 -0.100000  0.002979   \n",
       "volD10        -0.045696 -0.039452 -0.031596 -0.020902 -0.009628 -0.025341   \n",
       "volD15        -0.046466 -0.054973 -0.045964 -0.031205 -0.013122 -0.011361   \n",
       "volD30        -0.045175 -0.061389 -0.065355 -0.053528 -0.022932 -0.003340   \n",
       "volD60        -0.040104 -0.056399 -0.063678 -0.069082 -0.040721 -0.001119   \n",
       "vpm5           0.399169  0.261988  0.211814  0.146675  0.105265  0.301999   \n",
       "vpm10          0.295397  0.431247  0.339981  0.227690  0.158133 -0.006754   \n",
       "vpm15          0.252108  0.351803  0.446810  0.295953  0.204836  0.009999   \n",
       "vpm30          0.187244  0.258081  0.313587  0.459010  0.309917  0.010539   \n",
       "vpm60          0.122011  0.170056  0.208718  0.297900  0.452845  0.005033   \n",
       "ToD            0.007345  0.010114  0.012498  0.017696  0.025193  0.000411   \n",
       "DoW           -0.006288 -0.008862 -0.010801 -0.015124 -0.019204 -0.000164   \n",
       "MO            -0.005597 -0.006926 -0.006752 -0.005017 -0.009746 -0.001095   \n",
       "Dr1           -0.030087 -0.030580 -0.021263 -0.009727 -0.002594 -0.012246   \n",
       "\n",
       "                  acc10     acc15     acc30     acc60  ...    volD60  \\\n",
       "vel5           0.488963  0.396644  0.279971  0.209327  ... -0.040104   \n",
       "vel10          0.715761  0.566122  0.401907  0.289201  ... -0.056399   \n",
       "vel15          0.289400  0.711311  0.494297  0.351262  ... -0.063678   \n",
       "vel30          0.011623  0.000013  0.707956  0.498343  ... -0.069082   \n",
       "vel60          0.012296  0.004736 -0.000029  0.702112  ... -0.040721   \n",
       "acc5          -0.013115  0.003432  0.000202  0.011057  ... -0.001119   \n",
       "acc10          1.000000  0.395404  0.004165  0.011784  ... -0.014793   \n",
       "acc15          0.395404  1.000000 -0.004650  0.001396  ... -0.021239   \n",
       "acc30          0.004165 -0.004650  1.000000  0.003486  ... -0.056943   \n",
       "acc60          0.011784  0.001396  0.003486  1.000000  ... -0.031837   \n",
       "stoch12        0.099823  0.134281  0.262216  0.451728  ... -0.065496   \n",
       "stochDiff6012  0.129730  0.194854  0.417469  0.403139  ... -0.091359   \n",
       "RSIhl_diff     0.019105  0.023221  0.026310 -0.011032  ... -0.592633   \n",
       "RSIhl_diffROC  0.004153  0.005933 -0.002836 -0.001631  ... -0.268701   \n",
       "vol           -0.008032 -0.006791 -0.043577 -0.028476  ...  0.402226   \n",
       "vol10          0.006932 -0.000592 -0.039403 -0.031610  ...  0.294425   \n",
       "vol15          0.016860  0.009675 -0.032366 -0.032690  ...  0.211861   \n",
       "vol30          0.012062  0.021460 -0.007295 -0.033583  ...  0.074166   \n",
       "vol60          0.005914  0.009768  0.012955 -0.019555  ... -0.050688   \n",
       "volD10        -0.032221 -0.023755 -0.019910 -0.006221  ...  0.545014   \n",
       "volD15        -0.042100 -0.033771 -0.030971 -0.009095  ...  0.701749   \n",
       "volD30        -0.025325 -0.038965 -0.052715 -0.017033  ...  0.894664   \n",
       "volD60        -0.014793 -0.021239 -0.056943 -0.031837  ...  1.000000   \n",
       "vpm5           0.191872  0.152865  0.102190  0.072164  ... -0.034729   \n",
       "vpm10          0.320990  0.253008  0.163888  0.108224  ... -0.040941   \n",
       "vpm15          0.125447  0.335755  0.213747  0.140920  ... -0.049075   \n",
       "vpm30          0.007287 -0.012689  0.339243  0.214447  ... -0.054675   \n",
       "vpm60          0.002171 -0.000914 -0.030884  0.323144  ... -0.046031   \n",
       "ToD            0.000022  0.000070 -0.000141  0.000812  ... -0.136767   \n",
       "DoW           -0.000255 -0.000236 -0.002206 -0.001878  ...  0.002594   \n",
       "MO            -0.004608 -0.004520  0.002634  0.000152  ...  0.055587   \n",
       "Dr1           -0.026688 -0.020336 -0.011194  0.000266  ... -0.002607   \n",
       "\n",
       "                   vpm5     vpm10     vpm15     vpm30     vpm60       ToD  \\\n",
       "vel5           0.399169  0.295397  0.252108  0.187244  0.122011  0.007345   \n",
       "vel10          0.261988  0.431247  0.351803  0.258081  0.170056  0.010114   \n",
       "vel15          0.211814  0.339981  0.446810  0.313587  0.208718  0.012498   \n",
       "vel30          0.146675  0.227690  0.295953  0.459010  0.297900  0.017696   \n",
       "vel60          0.105265  0.158133  0.204836  0.309917  0.452845  0.025193   \n",
       "acc5           0.301999 -0.006754  0.009999  0.010539  0.005033  0.000411   \n",
       "acc10          0.191872  0.320990  0.125447  0.007287  0.002171  0.000022   \n",
       "acc15          0.152865  0.253008  0.335755 -0.012689 -0.000914  0.000070   \n",
       "acc30          0.102190  0.163888  0.213747  0.339243 -0.030884 -0.000141   \n",
       "acc60          0.072164  0.108224  0.140920  0.214447  0.323144  0.000812   \n",
       "stoch12        0.302808  0.408260  0.475668  0.566148  0.538376  0.012769   \n",
       "stochDiff6012  0.251414  0.350791  0.411406  0.479059  0.379592  0.012056   \n",
       "RSIhl_diff     0.023018  0.023544  0.025213  0.017613  0.001776  0.180068   \n",
       "RSIhl_diffROC  0.008598 -0.001552  0.000344 -0.004357 -0.002434  0.005355   \n",
       "vol           -0.020267 -0.025863 -0.031096 -0.041812 -0.050274  0.037538   \n",
       "vol10         -0.019573 -0.025661 -0.031523 -0.043353 -0.052847  0.043069   \n",
       "vol15         -0.019550 -0.025131 -0.031419 -0.044165 -0.054638  0.048250   \n",
       "vol30         -0.019288 -0.024235 -0.030175 -0.044407 -0.057573  0.062838   \n",
       "vol60         -0.021449 -0.026577 -0.031855 -0.043558 -0.058607  0.091407   \n",
       "volD10        -0.035195 -0.014472 -0.019168 -0.013615 -0.008109 -0.044984   \n",
       "volD15        -0.036479 -0.028739 -0.026636 -0.019305 -0.012053 -0.060366   \n",
       "volD30        -0.034789 -0.036498 -0.042076 -0.034900 -0.024396 -0.088542   \n",
       "volD60        -0.034729 -0.040941 -0.049075 -0.054675 -0.046031 -0.136767   \n",
       "vpm5           1.000000  0.599395  0.477815  0.329781  0.207445  0.004742   \n",
       "vpm10          0.599395  1.000000  0.739195  0.474857  0.292856  0.003320   \n",
       "vpm15          0.477815  0.739195  1.000000  0.612409  0.383153  0.007189   \n",
       "vpm30          0.329781  0.474857  0.612409  1.000000  0.598460  0.012997   \n",
       "vpm60          0.207445  0.292856  0.383153  0.598460  1.000000  0.024778   \n",
       "ToD            0.004742  0.003320  0.007189  0.012997  0.024778  1.000000   \n",
       "DoW           -0.007764 -0.009220 -0.010489 -0.012419 -0.013850  0.000294   \n",
       "MO            -0.019992 -0.024274 -0.029213 -0.039529 -0.050378  0.044723   \n",
       "Dr1           -0.005129 -0.003280 -0.003253  0.000037 -0.003207  0.006287   \n",
       "\n",
       "                    DoW        MO       Dr1  \n",
       "vel5          -0.006288 -0.005597 -0.030087  \n",
       "vel10         -0.008862 -0.006926 -0.030580  \n",
       "vel15         -0.010801 -0.006752 -0.021263  \n",
       "vel30         -0.015124 -0.005017 -0.009727  \n",
       "vel60         -0.019204 -0.009746 -0.002594  \n",
       "acc5          -0.000164 -0.001095 -0.012246  \n",
       "acc10         -0.000255 -0.004608 -0.026688  \n",
       "acc15         -0.000236 -0.004520 -0.020336  \n",
       "acc30         -0.002206  0.002634 -0.011194  \n",
       "acc60         -0.001878  0.000152  0.000266  \n",
       "stoch12       -0.014696 -0.010189 -0.007544  \n",
       "stochDiff6012 -0.008342 -0.010490 -0.009730  \n",
       "RSIhl_diff    -0.020364 -0.138535 -0.006143  \n",
       "RSIhl_diffROC  0.000161  0.001681 -0.010908  \n",
       "vol            0.037112  0.546729 -0.012484  \n",
       "vol10          0.039122  0.573243 -0.011404  \n",
       "vol15          0.040585  0.591939 -0.010286  \n",
       "vol30          0.043465  0.622879 -0.011967  \n",
       "vol60          0.046908  0.642290 -0.013805  \n",
       "volD10         0.000776  0.018263  0.002834  \n",
       "volD15         0.001110  0.019381  0.000511  \n",
       "volD30         0.001874  0.026703  0.001492  \n",
       "volD60         0.002594  0.055587 -0.002607  \n",
       "vpm5          -0.007764 -0.019992 -0.005129  \n",
       "vpm10         -0.009220 -0.024274 -0.003280  \n",
       "vpm15         -0.010489 -0.029213 -0.003253  \n",
       "vpm30         -0.012419 -0.039529  0.000037  \n",
       "vpm60         -0.013850 -0.050378 -0.003207  \n",
       "ToD            0.000294  0.044723  0.006287  \n",
       "DoW            1.000000  0.001395 -0.000859  \n",
       "MO             0.001395  1.000000 -0.005728  \n",
       "Dr1           -0.000859 -0.005728  1.000000  \n",
       "\n",
       "[32 rows x 32 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
