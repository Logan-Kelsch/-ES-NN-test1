{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTED FEATURES: \n",
      "Index(['vel5', 'vel10', 'vel15', 'vel30', 'vel60', 'acc5', 'acc10', 'acc15',\n",
      "       'acc30', 'acc60', 'stoch12', 'stochDiff6012', 'RSIhl_diff',\n",
      "       'RSIhl_diffROC', 'HLdiff', 'HL2', 'H2L', 'HLdiff12', 'HLdiff21', 'vol',\n",
      "       'vol10', 'vol15', 'vol30', 'vol60', 'volD10', 'volD15', 'volD30',\n",
      "       'volD60', 'vpm5', 'vpm10', 'vpm15', 'vpm30', 'vpm60', 'ToD', 'DoW',\n",
      "       'mo'],\n",
      "      dtype='object')\n",
      "TESTING FOR: \n",
      "r30\n",
      "X shape == (6830, 10, 36).\n",
      "y shape == (6830,).\n",
      "0.01042251031828126\n",
      "1.555336881662674\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not locate function 'skew_loss'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'builtins', 'class_name': 'function', 'config': 'skew_loss', 'registered_name': 'function'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 185\u001b[0m\n\u001b[1;32m    182\u001b[0m mos \u001b[38;5;241m=\u001b[39m X[:, timeSteps\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(Xfeatures)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mprint\u001b[39m(mos)\n\u001b[0;32m--> 185\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr30_10s_LSTM_5.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#----------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    187\u001b[0m                   loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    188\u001b[0m                   ,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR2Score\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m#predicting the test set results\u001b[39;00m\n",
      "File \u001b[0;32m~/-ES-NN-test1/venv/lib/python3.12/site-packages/keras/src/saving/saving_api.py:189\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    186\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir \u001b[38;5;129;01mor\u001b[39;00m is_hf:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[1;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[1;32m    198\u001b[0m     )\n",
      "File \u001b[0;32m~/-ES-NN-test1/venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:365\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    361\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m     )\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/-ES-NN-test1/venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:442\u001b[0m, in \u001b[0;36m_load_model_from_fileobj\u001b[0;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zf\u001b[38;5;241m.\u001b[39mopen(_CONFIG_FILENAME, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    440\u001b[0m     config_json \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 442\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43m_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m    447\u001b[0m extract_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/-ES-NN-test1/venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:431\u001b[0m, in \u001b[0;36m_model_from_config\u001b[0;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 431\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/-ES-NN-test1/venv/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m     compile_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompile_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compile_config:\n\u001b[0;32m--> 734\u001b[0m         \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompile_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m         instance\u001b[38;5;241m.\u001b[39mcompiled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[0;32m~/-ES-NN-test1/venv/lib/python3.12/site-packages/keras/src/trainers/trainer.py:949\u001b[0m, in \u001b[0;36mTrainer.compile_from_config\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    938\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`compile()` was not called as part of model loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbecause the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms `compile()` method is custom. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    947\u001b[0m     )\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 949\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;66;03m# Create optimizer variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/-ES-NN-test1/venv/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:595\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m--> 595\u001b[0m         key: \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    599\u001b[0m     }\n\u001b[1;32m    601\u001b[0m class_name \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    602\u001b[0m inner_config \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[0;32m~/-ES-NN-test1/venv/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:678\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    677\u001b[0m     fn_name \u001b[38;5;241m=\u001b[39m inner_config\n\u001b[0;32m--> 678\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;66;03m# Below, handling of all classes.\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;66;03m# First, is it a shared object?\u001b[39;00m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[0;32m~/-ES-NN-test1/venv/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:812\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[0;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    810\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 812\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not locate function 'skew_loss'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'builtins', 'class_name': 'function', 'config': 'skew_loss', 'registered_name': 'function'}"
     ]
    }
   ],
   "source": [
    "#JJ McCauley + LOGAN KELSCH \n",
    "#TEST NN 1\n",
    "\n",
    "#IMPORT LIBRARIES-------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#hahaha dont turn this on with high epoch or else\n",
    "#tf.config.experimental.set_memory_growth\n",
    "\n",
    "#LOAD DATA FROM CSV-------------------------------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('d1_test_.csv')\n",
    "dataTRAIN = pd.read_csv('catted_1-8.csv')\n",
    "\n",
    "#      'Dr1' 'Dr3' 'Mr1' 'Mr3' \n",
    "testFor = 'r30'\n",
    "timeSteps = 10\n",
    "tType = testFor[0]\n",
    "\n",
    "data = data.drop(columns=['FT'])#,'FT.1'])\n",
    "dataTRAIN = dataTRAIN.drop(columns=['FT','FT.1'])\n",
    "#CALENDAR\n",
    "#--------------------------------------\n",
    "#SOLUTION------------------------------\n",
    "match testFor:\n",
    "    case 'r1':\n",
    "        data = data.drop(columns=['r2','r3','r5','r10','r15','r30','r60'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r2','r3','r5','r10','r15','r30','r60'])\n",
    "    case 'r2':\n",
    "        data = data.drop(columns=['r1','r3','r5','r10','r15','r30','r60'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r1','r3','r5','r10','r15','r30','r60'])\n",
    "    case 'r3':\n",
    "        data = data.drop(columns=['r1','r2','r5','r10','r15','r30','r60'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r1','r2','r5','r10','r15','r30','r60'])\n",
    "    case 'r5':\n",
    "        data = data.drop(columns=['r1','r2','r3','r10','r15','r30','r60'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r1','r2','r3','r10','r15','r30','r60'])\n",
    "    case 'r10':\n",
    "        data = data.drop(columns=['r1','r2','r3','r5','r15','r30','r60'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r1','r2','r3','r5','r15','r30','r60'])\n",
    "    case 'r15':\n",
    "        data = data.drop(columns=['r1','r2','r3','r5','r10','r30','r60'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r1','r2','r3','r5','r10','r30','r60'])\n",
    "    case 'r30':\n",
    "        data = data.drop(columns=['r1','r2','r3','r5','r10','r15','r60'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r1','r2','r3','r5','r10','r15','r60'])\n",
    "    case 'r60':\n",
    "        data = data.drop(columns=['r1','r2','r3','r5','r10','r15','r30'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r1','r2','r3','r5','r10','r15','r30'])\n",
    "\n",
    "\n",
    "#confirming X and Y features post training\n",
    "Xfeatures = data.columns[:-1]\n",
    "Yfeatures = data.columns[-1]\n",
    "print(\"TESTED FEATURES: \")\n",
    "print(Xfeatures)\n",
    "print(\"TESTING FOR: \")\n",
    "print(Yfeatures)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "XTRAIN = dataTRAIN.iloc[:, :-1].values\n",
    "yTRAIN = dataTRAIN.iloc[:, -1].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = RobustScaler()\n",
    "scaler3 = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "percFit = 0.8\n",
    "fitSplit = len(X)//(1/(percFit))\n",
    "negFitSplit = len(X)//(1/(1-percFit))\n",
    "\n",
    "scaler1.fit(XTRAIN)\n",
    "XTRAIN = scaler1.transform(XTRAIN)\n",
    "#scaler2.fit(XTRAIN)\n",
    "#XTRAIN = scaler2.transform(XTRAIN)\n",
    "#scaler3.fit(XTRAIN)\n",
    "#XTRAIN = scaler3.transform(XTRAIN)\n",
    "X = scaler1.transform(X)\n",
    "#X = scaler2.transform(X)\n",
    "#X = scaler3.transform(X)\n",
    "#scaler3.fit(XTRAIN)\n",
    "\n",
    "\n",
    "#X = scaler3.transform(X)\n",
    "\n",
    "#setting data for LSTM\n",
    "def reformat_to_lstm(X, time_steps=timeSteps):\n",
    "    X_lstm, y_lstm = [], []\n",
    "    \n",
    "    for i in range(time_steps, len(X)):\n",
    "        # Collect previous time_steps rows for X\n",
    "        X_lstm.append(X[i-time_steps:i])  \n",
    "        # The corresponding y value for the last time step in the sequence\n",
    "    \n",
    "    X_lstm = np.array(X_lstm)\n",
    "    \n",
    "    return X_lstm\n",
    "\n",
    "X = reformat_to_lstm(X, timeSteps)\n",
    "y = y[timeSteps:]\n",
    "y = np.array(y)\n",
    "\n",
    "XTRAIN = reformat_to_lstm(XTRAIN, timeSteps)\n",
    "yTRAIN = yTRAIN[timeSteps:]\n",
    "yTRAIN = np.array(yTRAIN)\n",
    "\n",
    "print('X shape == {}.'.format(X.shape))\n",
    "print('y shape == {}.'.format(y.shape))\n",
    "\n",
    "\n",
    "mos = X[:, timeSteps-1, len(Xfeatures)-1].mean()\n",
    "print(mos)\n",
    "\n",
    "def remove_zero_mo_samples(X, y):\n",
    "    # Get the 'MO' column (index 34 for 0-based indexing) for all time steps and samples\n",
    "    non_zero_indices = (X[:, timeSteps-1, len(Xfeatures)-1] >= 0)\n",
    "    # Filter X and y using these indices\n",
    "    X_filtered = X[non_zero_indices]\n",
    "    y_filtered = y[non_zero_indices]\n",
    "    return X_filtered, y_filtered\n",
    "\n",
    "def remove_extra_filter(X, y):\n",
    "    indices = (X[:, timeSteps-1, len(Xfeatures)-3] >= -0.321405)#-3 is ToD, this value is 9:30am\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "    indices = (X[:, timeSteps-1, len(Xfeatures)-3] <= 0.0366699)#-3 is ToD, this value is 12:00pm\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "    return X, y\n",
    "\n",
    "X, y = remove_zero_mo_samples(X, y)\n",
    "X, y = remove_extra_filter(X, y)\n",
    "#XTRAIN, yTRAIN = remove_zero_mo_samples(XTRAIN, yTRAIN)\n",
    "\n",
    "from keras.saving import get_custom_objects\n",
    "from keras.saving import register_keras_serializable\n",
    "get_custom_objects().clear()\n",
    "#CUSTOM LOSS 1_______________________________________________________________________________________________\n",
    "from keras.src import ops\n",
    "from keras.src.losses.loss import squeeze_or_expand_to_same_rank\n",
    "#@register_keras_serializable(name=\"skew_loss\")\n",
    "def skew_loss(y_true,y_pred,sFact=4):\n",
    "    #return ops.mean(ops.square((y_pred-y_true)*(1+sFact*tf.cast(((y_true>0 & y_pred<y_true) | (y_true<0 & y_pred>y_true)),tf.float32))),axis=-1)\n",
    "    y_pred = ops.convert_to_tensor(y_pred)\n",
    "    y_true = ops.convert_to_tensor(y_true, dtype=y_pred.dtype)\n",
    "    #y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n",
    "    error = ops.subtract(y_pred, y_true)\n",
    "    a = ops.convert_to_tensor(ops.cast(y_pred > 0,tf.float32), dtype=tf.float32)\n",
    "    b = ops.convert_to_tensor(ops.cast(y_pred < 0,tf.float32), dtype=tf.float32)\n",
    "    c = ops.convert_to_tensor(ops.cast(y_true >= y_pred,tf.float32), dtype=tf.float32)\n",
    "    d = ops.convert_to_tensor(ops.cast(y_true <= y_pred,tf.float32), dtype=tf.float32)\n",
    "    h = ops.convert_to_tensor(0.1, dtype=error.dtype)\n",
    "    return ops.mean(\n",
    "        ops.where(\n",
    "            a*c+b*d==1,# or (b and d),\n",
    "            h*ops.square(error),\n",
    "            ops.square(error)\n",
    "        ))\n",
    "\n",
    "mos = X[:, timeSteps-1, len(Xfeatures)-1].mean()\n",
    "print(mos)\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('r30_10s_LSTM_5.keras')#----------------------------------------------------------------------\n",
    "loaded_model.compile(optimizer='adam',\n",
    "                  loss='mse'\n",
    "                  ,metrics=['R2Score','root_mean_squared_error'])\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = loaded_model.predict(X) \n",
    "\n",
    "s_kws = {'s':2,'color':'maroon'}\n",
    "l_kws = {'lw':1,'color':'maroon'}\n",
    "\n",
    "import seaborn as sns\n",
    "y_pred = np.squeeze(y_pred)\n",
    "y = np.squeeze(y)\n",
    "ys = pd.DataFrame({\"y_pred\":y_pred,\"y_true\":y})\n",
    "#data.insert(1, \"y_pred\", y_pred, True)\n",
    "# plot 1 with axes level-plot\n",
    "g = sns.lmplot(data=ys,x=\"y_pred\", y=\"y_true\", scatter_kws=s_kws,line_kws=l_kws)#, hue=\"MO\")\n",
    "\n",
    "#plt.scatter(y_pred, y, s=1)\n",
    "plt.axis('tight')\n",
    "plt.grid()\n",
    "plt.title('Testing Outputs')\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel(testFor)\n",
    "\n",
    "\n",
    "plt.xlim(-.25,.25)\n",
    "plt.ylim(-.25,.25)\n",
    "plt.show()\n",
    "\n",
    "g = sns.lmplot(data=ys,x=\"y_pred\", y=\"y_true\", scatter_kws=s_kws, line_kws=l_kws)#,hue=\"MO\")\n",
    "plt.title('Zoomed in graph')\n",
    "plt.grid()\n",
    "y_min, y_max = ys['y_true'].min(), ys['y_true'].max()\n",
    "plt.ylim(y_min, y_max)\n",
    "x_center = np.mean(ys['y_pred'])\n",
    "y_range = y_max - y_min\n",
    "x_min = x_center - y_range / 2\n",
    "x_max = x_center + y_range / 2\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.show()\n",
    "\n",
    "#DIRECTIONAL ACCURACY #DIRECTIONAL ACCURACY  #DIRECTIONAL ACCURACY  #DIRECTIONAL ACCURACY  #DIRECTIONAL ACCURACY  \n",
    "specGuess = 0.25\n",
    "frac = 100\n",
    "fracf = 1/frac\n",
    "specAcc, locSpecAcc = [], []\n",
    "valCount, locValCount = [], []\n",
    "locMean = []\n",
    "locStd = []\n",
    "sameDirAvg, sameDirMax, sameDirMin = [], [], []\n",
    "diffDirAvg, diffDirMax, diffDirMin = [], [], []\n",
    "locSameDirAvg, locSameDirMax, locSameDirMin = [], [], []\n",
    "locDiffDirAvg, locDiffDirMax, locDiffDirMin = [], [], []\n",
    "for v in range(0,int(specGuess*frac)):\n",
    "    tp, fp, tn, fn, tpL, fpL, tnL, fnL = 0, 0, 0, 0, 0, 0, 0, 0\n",
    "    valCnt = 0\n",
    "    locValCnt = 0\n",
    "    allTmp = []\n",
    "    sameTmp, diffTmp = [], []\n",
    "    locSameTmp, locDiffTmp = [], []\n",
    "    y_pred = ys['y_pred']\n",
    "    y_test = ys['y_true']\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i]>=(v/frac)):\n",
    "            valCnt+=1\n",
    "            if(y_test[i]>0):\n",
    "                tp+=1\n",
    "                sameTmp.append(abs(y_test[i]))\n",
    "            if(y_test[i]<0):\n",
    "                fp+=1\n",
    "                diffTmp.append(abs(y_test[i]))\n",
    "            if(y_pred[i]<(v/frac)+(1/frac)):\n",
    "                locValCnt+=1\n",
    "                if(y_test[i]>0):\n",
    "                    tpL+=1\n",
    "                    locSameTmp.append(abs(y_test[i]))\n",
    "                if(y_test[i]<0):\n",
    "                    fpL+=1\n",
    "                    locDiffTmp.append(abs(y_test[i]))\n",
    "        if(y_pred[i]<=-(v/frac)):\n",
    "            valCnt+=1\n",
    "            if(y_test[i]<0):\n",
    "                tn+=1\n",
    "                sameTmp.append(abs(y_test[i]))\n",
    "            if(y_test[i]>0):\n",
    "                fn+=1\n",
    "                diffTmp.append(abs(y_test[i]))\n",
    "            if(y_pred[i]>-(v/frac)-(1/frac)):\n",
    "                locValCnt+=1\n",
    "                if(y_test[i]<0):\n",
    "                    tnL+=1\n",
    "                    locSameTmp.append(abs(y_test[i]))\n",
    "                if(y_test[i]>0):\n",
    "                    fnL+=1\n",
    "                    locDiffTmp.append(abs(y_test[i]))\n",
    "    if((tp+fp+tn+fn)<1):\n",
    "        break\n",
    "    \n",
    "\n",
    "    if(len(sameTmp)>0 and len(diffTmp)>0):\n",
    "        allTmp = locSameTmp\n",
    "        for i in range(len(locDiffTmp)):\n",
    "            allTmp.append(locDiffTmp[i])\n",
    "        locMean.append(np.average(allTmp))\n",
    "        locStd.append(np.std(allTmp))\n",
    "    else:\n",
    "        locMean.append(locMean[-1])\n",
    "        locStd.append(locStd[-1])\n",
    "\n",
    "    if(len(sameTmp)!=0):\n",
    "        sameDirAvg.append(np.average(sameTmp))\n",
    "        sameDirMax.append(np.max(sameTmp))\n",
    "        sameDirMin.append(np.min(sameTmp))\n",
    "        locSameDirAvg.append(np.average(sameTmp))\n",
    "        locSameDirMax.append(np.max(sameTmp))\n",
    "        locSameDirMin.append(np.min(sameTmp))\n",
    "    else:\n",
    "        sameDirAvg.append(0.1)\n",
    "        sameDirMax.append(0.1)\n",
    "        sameDirMin.append(0.1)\n",
    "        locSameDirAvg.append(0.1)\n",
    "        locSameDirMax.append(0.1)\n",
    "        locSameDirMin.append(0.1)\n",
    "    if(len(diffTmp)!=0):\n",
    "        diffDirAvg.append(np.average(diffTmp))\n",
    "        diffDirMax.append(np.max(diffTmp))\n",
    "        diffDirMin.append(np.min(diffTmp))\n",
    "        locDiffDirAvg.append(np.average(diffTmp))\n",
    "        locDiffDirMax.append(np.max(diffTmp))\n",
    "        locDiffDirMin.append(np.min(diffTmp))\n",
    "    else:\n",
    "        diffDirAvg.append(0.1)\n",
    "        diffDirMax.append(0.1)\n",
    "        diffDirMin.append(0.1)\n",
    "        locDiffDirAvg.append(0.1)\n",
    "        locDiffDirMax.append(0.1)\n",
    "        locDiffDirMin.append(0.1)\n",
    "    directionalAccuracy = ((tp+tn)/(tp+fp+tn+fn))*10000//1/100\n",
    "    specAcc.append(directionalAccuracy)\n",
    "    valCount.append(valCnt)\n",
    "    if((tpL+fpL+tnL+fnL) > 0):\n",
    "        localDirectionalAccuracy = ((tpL+tnL)/(tpL+fpL+tnL+fnL))*10000//1/100\n",
    "        locSpecAcc.append(localDirectionalAccuracy)\n",
    "        locValCount.append(locValCnt)\n",
    "    else:\n",
    "        locSpecAcc.append(locSpecAcc[-1])\n",
    "        locValCount.append(0)\n",
    "    #print(f'Directional Accuracy >(+/-){v/2}:\\t',directionalAccuracy5guess)\n",
    "#print('Directional Accuracy:\\t\\t',directionalAccuracy)\n",
    "valCount = [x / valCount[0] * 100 for x in valCount]\n",
    "locValCount = [x / locValCount[0] * 100 for x in locValCount]\n",
    "plt.figure(figsize=(18, 9))\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), specAcc, 'maroon', label='Directional Accuracy')\n",
    "plt.scatter(np.arange(0,(1/frac)*len(specAcc),(1/frac)), specAcc, s=5, color='maroon')\n",
    "plt.plot(np.arange(0,(1/frac)*len(locSpecAcc),(1/frac)), locSpecAcc, 'red', label='Directional Accuracy')\n",
    "plt.scatter(np.arange(0,(1/frac)*len(locSpecAcc),(1/frac)), locSpecAcc, s=5, color='red')\n",
    "plt.title(f'Directional Accuracy Percentage Outside of given Predicted Value\\n(With Percentage of {len(X)} Samples)')\n",
    "plt.xlabel('> (+/-) Prediction Value')\n",
    "plt.ylabel('Percent')\n",
    "plt.grid()\n",
    "plt.legend(['Directional Accuracy','S- Samples\\nA- Accuracy','Local Directional Accuracy'], loc='upper left')\n",
    "for x, y in zip(np.arange(0,(1/frac)*len(specAcc),(1/frac)), specAcc):\n",
    "    plt.annotate(f'{float(valCount[int(x*frac)]*10//1/10)}%S\\n{float(specAcc[int(x*frac)])}%A', color='black', xy=(x, y-2), fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Average Move by Directional Accuracy')\n",
    "plt.xlabel('> (+/-) Prediction Value')\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), sameDirAvg, 'maroon', label='Directional Accuracy')\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), diffDirAvg, 'purple', label='Directional Accuracy')\n",
    "plt.grid()\n",
    "plt.legend(['Accurate','Inaccurate'], loc='upper left')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('P/L Ratio')\n",
    "plt.xlabel('> (+/-) Prediction Value')\n",
    "plt.grid()\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)),np.divide(sameDirAvg,diffDirAvg), 'blue')\n",
    "plt.legend(['P/L Ratio'], loc='upper left')\n",
    "plt.ylim(0,6)\n",
    "plt.show()\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Highest and Lowest of\\nDirectionally Accurate Moves')\n",
    "plt.xlabel('> (+/-) Prediction Value')\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), sameDirMax, 'maroon', label='Directional Accuracy')\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), sameDirMin, 'maroon', label='Directional Accuracy')\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Highest and Lowest of\\nDirectionally Inaccurate Moves')\n",
    "plt.xlabel('> (+/-) Prediction Value')\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), diffDirMax, 'purple', label='Directional Accuracy')\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), diffDirMin, 'purple', label='Directional Accuracy')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "std2 = np.multiply(locStd, 2)\n",
    "std0 = np.multiply(locStd, 0)\n",
    "yerr = [std2,std0]\n",
    "plt.title('Mean Move and Standard Deviations per Predicted Value')\n",
    "plt.xlabel('> (+/-) Prediction Value')\n",
    "plt.errorbar(np.arange(0,(1/frac)*len(specAcc),(1/frac)), locMean, yerr=yerr, capsize=3, ecolor = \"gray\", elinewidth=1, markeredgewidth='1',markersize=2)\n",
    "plt.errorbar(np.arange(0,(1/frac)*len(specAcc),(1/frac)), locMean, locStd, capsize=3, ecolor = \"black\", elinewidth=1, markeredgewidth='1',markersize=2)\n",
    "plt.axhline(0,color='black')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()\n",
    "#print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2.084353\n",
      "1       0.025369\n",
      "2       7.009391\n",
      "3       6.450147\n",
      "4       3.973774\n",
      "          ...   \n",
      "3333    3.246205\n",
      "3334    4.664523\n",
      "3335    2.991430\n",
      "3336    4.215136\n",
      "3337    3.782758\n",
      "Name: y_pred, Length: 3338, dtype: float32\n",
      "(3338,)\n",
      "<class 'pandas.core.series.Series'>\n",
      "                 FT    vel5   vel10   vel15   vel30   vel60    acc5   acc10  \\\n",
      "3339  1729642500000  0.0127 -0.0064 -0.0141 -0.0028  0.0060  0.0382  0.0064   \n",
      "3340  1729642800000 -0.0085  0.0021 -0.0071 -0.0064  0.0021 -0.0212  0.0297   \n",
      "3341  1729643100000  0.0085  0.0000  0.0042 -0.0064  0.0025  0.0170  0.0064   \n",
      "3342  1729643400000 -0.0127 -0.0021 -0.0042 -0.0092 -0.0004 -0.0212 -0.0042   \n",
      "3343  1729643700000 -0.0127 -0.0127 -0.0057 -0.0064 -0.0011 -0.0000 -0.0127   \n",
      "\n",
      "       acc15   acc30  ...   MO  Dc1  Dc3   Dr1   Dr3  Mc1  Mc3     Mr1  \\\n",
      "3339 -0.0226 -0.0177  ...  0.0   dn   dn -0.50 -0.75   nm   nm  0.4773   \n",
      "3340 -0.0014 -0.0170  ...  0.0   up   dn  0.50 -1.00   nm   nm  0.5178   \n",
      "3341  0.0212 -0.0177  ...  0.0   dn   dn -0.75 -2.50   nm   mv  0.7768   \n",
      "3342  0.0099 -0.0177  ...  0.0   dn   dn -0.75 -1.00   nm   nm  0.8074   \n",
      "3343  0.0014 -0.0106  ...  0.0   dn   dn -1.00 -1.50   mv   mv  1.2921   \n",
      "\n",
      "         Mr3  Dr3_Model  \n",
      "3339  0.4516   4.664523  \n",
      "3340  0.5828   2.991430  \n",
      "3341  1.4577   4.215136  \n",
      "3342  0.5757   3.782758  \n",
      "3343  0.8521        NaN  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "catReform = pd.read_csv('catted_12day.csv')\n",
    "print(y_pred)\n",
    "print((y_pred.shape))\n",
    "#y_pred = y_pred.to_numpy()\n",
    "print(type(y_pred))\n",
    "y_pred = np.insert(y_pred, 0, 0, axis=0)\n",
    "y_pred = np.insert(y_pred, 0, 0, axis=0)\n",
    "y_pred = np.insert(y_pred, 0, 0, axis=0)\n",
    "y_pred = np.insert(y_pred, 0, 0, axis=0)\n",
    "y_pred = np.insert(y_pred, 0, 0, axis=0)\n",
    "#y_pred = np.append(y_pred, -1, 0, axis=0)\n",
    "y_pred = pd.Series(y_pred)\n",
    "catReform['Dr3_Model'] = y_pred\n",
    "print(catReform.tail(5))\n",
    "catReform.to_csv('catted_12day_Dr3Model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  FT    vel5   vel10   vel15   vel30   vel60    acc5   acc10  \\\n",
      "100899  1.728075e+12 -0.0043  0.0043 -0.0043 -0.0101 -0.0061 -0.0173  0.0280   \n",
      "100900  1.728252e+12  0.1596  0.0776  0.0561  0.0201  0.0093  0.1639  0.0820   \n",
      "100901  1.728252e+12  0.0301  0.0949  0.0618  0.0252  0.0093 -0.1295  0.0906   \n",
      "100902  1.728253e+12  0.0172  0.0237  0.0690  0.0323  0.0108 -0.0129 -0.0540   \n",
      "100903  1.728253e+12 -0.0043  0.0065  0.0144  0.0352  0.0122 -0.0215 -0.0884   \n",
      "\n",
      "         acc15   acc30  ...   MO  Dc1  Dc3   Dr1    Dr3  Mc1  Mc3      Mr1  \\\n",
      "100899  0.0115 -0.0079  ...  0.0   up   up  9.25  12.00   mv   mv  11.3884   \n",
      "100900  0.0719  0.0216  ...  0.0   up   up  1.75   2.50   nm   nm   0.4739   \n",
      "100901  0.0733  0.0316  ...  0.0   up   dn  1.00  -1.25   nm   nm   0.2733   \n",
      "100902  0.0733  0.0431  ...  0.0   dn   dn -0.25   0.00   nm   nm   0.0728   \n",
      "100903 -0.0417  0.0460  ...  0.0   dn   dn -2.00  -4.00   mv   mv   0.6062   \n",
      "\n",
      "           Mr3  Dr3_Model  \n",
      "100899  3.4622   4.053635  \n",
      "100900  0.7543   8.216476  \n",
      "100901  0.3196   5.777864  \n",
      "100902  0.0000   5.399108  \n",
      "100903  0.9081        NaN  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "y_pred = pd.Series(y_pred)\n",
    "catReform['Dr3_Model'] = y_pred\n",
    "print(catReform.tail(5))\n",
    "catReform.to_csv('catted_1_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "catReform.to_csv('catted_12day_Dr3Model.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPolish = pd.read_csv('catted_12day_Dr3Model.csv')\n",
    "cols = ['FT','vel5','vel10','vel15','vel30','vel60','acc5','acc10','acc15','acc30','acc60','stoch12','stochDiff6012','RSIhl_diff','RSIhl_diffROC','vol','vol10','vol15','vol30','vol60','volD10','volD15','volD30','volD60','vpm5','vpm10','vpm15','vpm30','vpm60','ToD','DoW','MO','Dr3_Model','Dr3','Dc1','Dc3','Dr1','Mc1','Mc3','Mr1','Mr3']\n",
    "dataPolish = dataPolish.reindex(columns=cols)\n",
    "#dataPolish = dataPolish.drop(columns=['YM_diff','NQ_diff','volNQdiff','volYMdiff'])\n",
    "dataPolish.to_csv('catted_12day_Dr3Model.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
