{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTED FEATURES: \n",
      "Index(['vel5', 'vel10', 'vel15', 'vel30', 'vel60', 'acc5', 'acc10', 'acc15',\n",
      "       'acc30', 'acc60', 'stoch12', 'stochDiff6012', 'RSIhl_diff',\n",
      "       'RSIhl_diffROC', 'YM_diff', 'NQ_diff', 'vol', 'ToD', 'DoW', 'MO'],\n",
      "      dtype='object')\n",
      "TESTING FOR: \n",
      "MOVE\n",
      "OCCURANCES IN RAW DATA FOR MOVE: \n",
      "{'mv': 12736, 'nm': 12743}\n",
      "Smallest Class Size: 3335 \n",
      "\n",
      "OCCURANCES IN OPT DATA FOR MOVE: \n",
      "{'mv': 3335, 'nm': 3335}\n",
      "Epoch 1/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5437 - loss: 23.8957 - precision: 0.5280 - recall: 0.5099\n",
      "Epoch 1 - Train Recall: 0.5480 - Val Recall: 0.8861\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5435 - loss: 23.3152 - precision: 0.5293 - recall: 0.5137 - val_accuracy: 0.5345 - val_loss: 8.8480 - val_precision: 0.5202 - val_recall: 0.8861\n",
      "Epoch 2/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5319 - loss: 6.8716 - precision: 0.5245 - recall: 0.3580\n",
      "Epoch 2 - Train Recall: 0.3771 - Val Recall: 0.7811\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5324 - loss: 6.6390 - precision: 0.5284 - recall: 0.3607 - val_accuracy: 0.5772 - val_loss: 3.1701 - val_precision: 0.5548 - val_recall: 0.7811\n",
      "Epoch 3/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5248 - loss: 2.3366 - precision: 0.5123 - recall: 0.2514\n",
      "Epoch 3 - Train Recall: 0.2556 - Val Recall: 0.1169\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5235 - loss: 2.2892 - precision: 0.5138 - recall: 0.2518 - val_accuracy: 0.4925 - val_loss: 1.6977 - val_precision: 0.4699 - val_recall: 0.1169\n",
      "Epoch 4/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5250 - loss: 0.7587 - precision: 0.5108 - recall: 0.8604\n",
      "Epoch 4 - Train Recall: 0.8969 - Val Recall: 1.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5264 - loss: 0.7440 - precision: 0.5121 - recall: 0.8644 - val_accuracy: 0.5000 - val_loss: 0.6335 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 5/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5631 - loss: 0.5368 - precision: 0.5688 - recall: 0.5518\n",
      "Epoch 5 - Train Recall: 0.5210 - Val Recall: 0.2519\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5621 - loss: 0.5341 - precision: 0.5677 - recall: 0.5484 - val_accuracy: 0.5030 - val_loss: 0.8800 - val_precision: 0.5060 - val_recall: 0.2519\n",
      "Epoch 6/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5290 - loss: 0.3041 - precision: 0.5142 - recall: 0.8680\n",
      "Epoch 6 - Train Recall: 0.8958 - Val Recall: 0.9160\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5293 - loss: 0.3024 - precision: 0.5147 - recall: 0.8704 - val_accuracy: 0.5150 - val_loss: 0.4934 - val_precision: 0.5083 - val_recall: 0.9160\n",
      "Epoch 7/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5210 - loss: 0.4092 - precision: 0.5249 - recall: 0.5618\n",
      "Epoch 7 - Train Recall: 0.5435 - Val Recall: 0.4633\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5222 - loss: 0.4091 - precision: 0.5256 - recall: 0.5600 - val_accuracy: 0.5667 - val_loss: 0.7855 - val_precision: 0.5841 - val_recall: 0.4633\n",
      "Epoch 8/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5631 - loss: 0.3608 - precision: 0.5515 - recall: 0.7018\n",
      "Epoch 8 - Train Recall: 0.6829 - Val Recall: 0.6417\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5618 - loss: 0.3609 - precision: 0.5503 - recall: 0.7003 - val_accuracy: 0.5570 - val_loss: 0.6565 - val_precision: 0.5487 - val_recall: 0.6417\n",
      "Epoch 9/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5573 - loss: 0.3850 - precision: 0.5520 - recall: 0.5995\n",
      "Epoch 9 - Train Recall: 0.6053 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5572 - loss: 0.3851 - precision: 0.5519 - recall: 0.5996 - val_accuracy: 0.5615 - val_loss: 0.6975 - val_precision: 0.5526 - val_recall: 0.6462\n",
      "Epoch 10/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5595 - loss: 0.4089 - precision: 0.5610 - recall: 0.5481\n",
      "Epoch 10 - Train Recall: 0.5588 - Val Recall: 0.7571\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5598 - loss: 0.4088 - precision: 0.5611 - recall: 0.5490 - val_accuracy: 0.5742 - val_loss: 0.7449 - val_precision: 0.5543 - val_recall: 0.7571\n",
      "Epoch 11/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5387 - loss: 0.4579 - precision: 0.5550 - recall: 0.4197\n",
      "Epoch 11 - Train Recall: 0.3834 - Val Recall: 0.6252\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5381 - loss: 0.4590 - precision: 0.5541 - recall: 0.4162 - val_accuracy: 0.5937 - val_loss: 0.8327 - val_precision: 0.5882 - val_recall: 0.6252\n",
      "Epoch 12/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5192 - loss: 0.5327 - precision: 0.5574 - recall: 0.2891\n",
      "Epoch 12 - Train Recall: 0.2672 - Val Recall: 0.4003\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5202 - loss: 0.5325 - precision: 0.5573 - recall: 0.2863 - val_accuracy: 0.5652 - val_loss: 0.9152 - val_precision: 0.5973 - val_recall: 0.4003\n",
      "Epoch 13/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5409 - loss: 0.5168 - precision: 0.5605 - recall: 0.3189\n",
      "Epoch 13 - Train Recall: 0.3145 - Val Recall: 0.5547\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5401 - loss: 0.5157 - precision: 0.5603 - recall: 0.3182 - val_accuracy: 0.5960 - val_loss: 1.2964 - val_precision: 0.6046 - val_recall: 0.5547\n",
      "Epoch 14/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5457 - loss: 0.5730 - precision: 0.6033 - recall: 0.2694\n",
      "Epoch 14 - Train Recall: 0.2271 - Val Recall: 0.1319\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5453 - loss: 0.5725 - precision: 0.6027 - recall: 0.2681 - val_accuracy: 0.5315 - val_loss: 1.0171 - val_precision: 0.6567 - val_recall: 0.1319\n",
      "Epoch 15/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5514 - loss: 0.3184 - precision: 0.5389 - recall: 0.8108\n",
      "Epoch 15 - Train Recall: 0.8261 - Val Recall: 0.9595\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5513 - loss: 0.3182 - precision: 0.5388 - recall: 0.8113 - val_accuracy: 0.5202 - val_loss: 0.5316 - val_precision: 0.5108 - val_recall: 0.9595\n",
      "Epoch 16/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5516 - loss: 0.4372 - precision: 0.5589 - recall: 0.4646\n",
      "Epoch 16 - Train Recall: 0.4666 - Val Recall: 0.5727\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5517 - loss: 0.4370 - precision: 0.5592 - recall: 0.4646 - val_accuracy: 0.6027 - val_loss: 0.8766 - val_precision: 0.6093 - val_recall: 0.5727\n",
      "Epoch 17/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5599 - loss: 0.4355 - precision: 0.5897 - recall: 0.4823\n",
      "Epoch 17 - Train Recall: 0.4322 - Val Recall: 0.3613\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5591 - loss: 0.4360 - precision: 0.5875 - recall: 0.4773 - val_accuracy: 0.5060 - val_loss: 1.0740 - val_precision: 0.5084 - val_recall: 0.3613\n",
      "Epoch 18/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5525 - loss: 0.3682 - precision: 0.5487 - recall: 0.6997\n",
      "Epoch 18 - Train Recall: 0.6837 - Val Recall: 0.7826\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5526 - loss: 0.3679 - precision: 0.5480 - recall: 0.6981 - val_accuracy: 0.5645 - val_loss: 0.7736 - val_precision: 0.5449 - val_recall: 0.7826\n",
      "Epoch 19/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5557 - loss: 0.4222 - precision: 0.5607 - recall: 0.5505\n",
      "Epoch 19 - Train Recall: 0.5142 - Val Recall: 0.7496\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5557 - loss: 0.4222 - precision: 0.5607 - recall: 0.5473 - val_accuracy: 0.5667 - val_loss: 0.8456 - val_precision: 0.5488 - val_recall: 0.7496\n",
      "Epoch 20/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5538 - loss: 0.4670 - precision: 0.5800 - recall: 0.3760\n",
      "Epoch 20 - Train Recall: 0.3328 - Val Recall: 0.1004\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5518 - loss: 0.4685 - precision: 0.5784 - recall: 0.3709 - val_accuracy: 0.4925 - val_loss: 0.8631 - val_precision: 0.4653 - val_recall: 0.1004\n",
      "Epoch 21/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5111 - loss: 0.2171 - precision: 0.5068 - recall: 0.9028    \n",
      "Epoch 21 - Train Recall: 0.9524 - Val Recall: 1.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5107 - loss: 0.2162 - precision: 0.5066 - recall: 0.9075 - val_accuracy: 0.5000 - val_loss: 0.4046 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 22/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5424 - loss: 0.4126 - precision: 0.5262 - recall: 0.6269\n",
      "Epoch 22 - Train Recall: 0.5877 - Val Recall: 0.9685\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5429 - loss: 0.4122 - precision: 0.5279 - recall: 0.6226 - val_accuracy: 0.5195 - val_loss: 0.8565 - val_precision: 0.5103 - val_recall: 0.9685\n",
      "Epoch 23/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5241 - loss: 0.5300 - precision: 0.5516 - recall: 0.2873\n",
      "Epoch 23 - Train Recall: 0.2403 - Val Recall: 0.7046\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5240 - loss: 0.5297 - precision: 0.5518 - recall: 0.2851 - val_accuracy: 0.5420 - val_loss: 1.0924 - val_precision: 0.5317 - val_recall: 0.7046\n",
      "Epoch 24/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4863 - loss: 0.7088 - precision: 0.4517 - recall: 0.0434\n",
      "Epoch 24 - Train Recall: 0.0371 - Val Recall: 0.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4872 - loss: 0.7079 - precision: 0.4538 - recall: 0.0429 - val_accuracy: 0.5000 - val_loss: 1.4580 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5551 - loss: 0.4406 - precision: 0.5645 - recall: 0.4799    \n",
      "Epoch 25 - Train Recall: 0.5079 - Val Recall: 0.6762\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5550 - loss: 0.4390 - precision: 0.5641 - recall: 0.4819 - val_accuracy: 0.5645 - val_loss: 0.7314 - val_precision: 0.5527 - val_recall: 0.6762\n",
      "Epoch 26/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5509 - loss: 0.4470 - precision: 0.5711 - recall: 0.4189\n",
      "Epoch 26 - Train Recall: 0.3767 - Val Recall: 0.0645\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5506 - loss: 0.4469 - precision: 0.5710 - recall: 0.4167 - val_accuracy: 0.4933 - val_loss: 0.8243 - val_precision: 0.4526 - val_recall: 0.0645\n",
      "Epoch 27/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4997 - loss: 0.1613 - precision: 0.5056 - recall: 0.9396\n",
      "Epoch 27 - Train Recall: 0.9813 - Val Recall: 1.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5000 - loss: 0.1605 - precision: 0.5054 - recall: 0.9423 - val_accuracy: 0.5000 - val_loss: 0.2547 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 28/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5431 - loss: 0.4017 - precision: 0.5377 - recall: 0.6152\n",
      "Epoch 28 - Train Recall: 0.5911 - Val Recall: 0.8321\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5444 - loss: 0.4005 - precision: 0.5391 - recall: 0.6124 - val_accuracy: 0.5975 - val_loss: 0.7122 - val_precision: 0.5663 - val_recall: 0.8321\n",
      "Epoch 29/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5431 - loss: 0.4536 - precision: 0.5887 - recall: 0.4048\n",
      "Epoch 29 - Train Recall: 0.3321 - Val Recall: 0.4948\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5434 - loss: 0.4533 - precision: 0.5880 - recall: 0.3964 - val_accuracy: 0.5892 - val_loss: 0.8648 - val_precision: 0.6100 - val_recall: 0.4948\n",
      "Epoch 30/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5348 - loss: 0.4643 - precision: 0.5595 - recall: 0.2740\n",
      "Epoch 30 - Train Recall: 0.2732 - Val Recall: 0.1889\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5349 - loss: 0.4639 - precision: 0.5612 - recall: 0.2743 - val_accuracy: 0.5352 - val_loss: 0.9335 - val_precision: 0.6146 - val_recall: 0.1889\n",
      "Epoch 31/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5562 - loss: 0.3184 - precision: 0.5400 - recall: 0.6685\n",
      "Epoch 31 - Train Recall: 0.7474 - Val Recall: 0.3388\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5564 - loss: 0.3183 - precision: 0.5402 - recall: 0.6717 - val_accuracy: 0.5367 - val_loss: 0.6319 - val_precision: 0.5608 - val_recall: 0.3388\n",
      "Epoch 32/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5356 - loss: 0.2449 - precision: 0.5132 - recall: 0.8625\n",
      "Epoch 32 - Train Recall: 0.9164 - Val Recall: 1.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5349 - loss: 0.2448 - precision: 0.5136 - recall: 0.8689 - val_accuracy: 0.5022 - val_loss: 0.5018 - val_precision: 0.5011 - val_recall: 1.0000\n",
      "Epoch 33/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5561 - loss: 0.3953 - precision: 0.5527 - recall: 0.5797\n",
      "Epoch 33 - Train Recall: 0.5738 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5567 - loss: 0.3952 - precision: 0.5535 - recall: 0.5789 - val_accuracy: 0.5480 - val_loss: 0.9007 - val_precision: 0.5364 - val_recall: 0.7061\n",
      "Epoch 34/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5522 - loss: 0.4211 - precision: 0.5592 - recall: 0.4619\n",
      "Epoch 34 - Train Recall: 0.4531 - Val Recall: 0.7826\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5528 - loss: 0.4206 - precision: 0.5607 - recall: 0.4611 - val_accuracy: 0.5525 - val_loss: 0.9303 - val_precision: 0.5359 - val_recall: 0.7826\n",
      "Epoch 35/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5280 - loss: 0.4983 - precision: 0.5665 - recall: 0.2198\n",
      "Epoch 35 - Train Recall: 0.1653 - Val Recall: 0.0630\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5276 - loss: 0.4982 - precision: 0.5665 - recall: 0.2175 - val_accuracy: 0.5090 - val_loss: 1.1533 - val_precision: 0.5833 - val_recall: 0.0630\n",
      "Epoch 36/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5432 - loss: 0.2464 - precision: 0.5139 - recall: 0.8134    \n",
      "Epoch 36 - Train Recall: 0.9205 - Val Recall: 0.9655\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5425 - loss: 0.2454 - precision: 0.5144 - recall: 0.8227 - val_accuracy: 0.5105 - val_loss: 0.4228 - val_precision: 0.5055 - val_recall: 0.9655\n",
      "Epoch 37/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5663 - loss: 0.3905 - precision: 0.5589 - recall: 0.6143\n",
      "Epoch 37 - Train Recall: 0.5742 - Val Recall: 0.7241\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5659 - loss: 0.3906 - precision: 0.5590 - recall: 0.6107 - val_accuracy: 0.5787 - val_loss: 0.7214 - val_precision: 0.5610 - val_recall: 0.7241\n",
      "Epoch 38/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5545 - loss: 0.4248 - precision: 0.5726 - recall: 0.4652\n",
      "Epoch 38 - Train Recall: 0.4284 - Val Recall: 0.0765\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5544 - loss: 0.4246 - precision: 0.5724 - recall: 0.4627 - val_accuracy: 0.5202 - val_loss: 0.8639 - val_precision: 0.6800 - val_recall: 0.0765\n",
      "Epoch 39/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5068 - loss: 0.1634 - precision: 0.5033 - recall: 0.9227    \n",
      "Epoch 39 - Train Recall: 0.9816 - Val Recall: 1.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5066 - loss: 0.1614 - precision: 0.5033 - recall: 0.9304 - val_accuracy: 0.5000 - val_loss: 0.2694 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 40/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5539 - loss: 0.3752 - precision: 0.5423 - recall: 0.6319\n",
      "Epoch 40 - Train Recall: 0.6252 - Val Recall: 0.5892\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5544 - loss: 0.3750 - precision: 0.5430 - recall: 0.6316 - val_accuracy: 0.5480 - val_loss: 0.7435 - val_precision: 0.5443 - val_recall: 0.5892\n",
      "Epoch 41/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5712 - loss: 0.3584 - precision: 0.5658 - recall: 0.6978\n",
      "Epoch 41 - Train Recall: 0.6852 - Val Recall: 0.3088\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5708 - loss: 0.3585 - precision: 0.5648 - recall: 0.6969 - val_accuracy: 0.5772 - val_loss: 0.7534 - val_precision: 0.6667 - val_recall: 0.3088\n",
      "Epoch 42/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5546 - loss: 0.2462 - precision: 0.5330 - recall: 0.8833\n",
      "Epoch 42 - Train Recall: 0.9337 - Val Recall: 0.8921\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5516 - loss: 0.2460 - precision: 0.5310 - recall: 0.8896 - val_accuracy: 0.5157 - val_loss: 0.4732 - val_precision: 0.5090 - val_recall: 0.8921\n",
      "Epoch 43/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5695 - loss: 0.3586 - precision: 0.5576 - recall: 0.7457\n",
      "Epoch 43 - Train Recall: 0.7069 - Val Recall: 0.7886\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5688 - loss: 0.3587 - precision: 0.5568 - recall: 0.7431 - val_accuracy: 0.5607 - val_loss: 0.7013 - val_precision: 0.5417 - val_recall: 0.7886\n",
      "Epoch 44/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5757 - loss: 0.3953 - precision: 0.5800 - recall: 0.5724\n",
      "Epoch 44 - Train Recall: 0.5540 - Val Recall: 0.2789\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5754 - loss: 0.3954 - precision: 0.5796 - recall: 0.5718 - val_accuracy: 0.5600 - val_loss: 0.8572 - val_precision: 0.6370 - val_recall: 0.2789\n",
      "Epoch 45/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5420 - loss: 0.2625 - precision: 0.5312 - recall: 0.8398\n",
      "Epoch 45 - Train Recall: 0.8924 - Val Recall: 1.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5411 - loss: 0.2621 - precision: 0.5300 - recall: 0.8448 - val_accuracy: 0.5045 - val_loss: 0.4995 - val_precision: 0.5023 - val_recall: 1.0000\n",
      "Epoch 46/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5437 - loss: 0.3997 - precision: 0.5358 - recall: 0.5781\n",
      "Epoch 46 - Train Recall: 0.5731 - Val Recall: 0.3433\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5445 - loss: 0.3994 - precision: 0.5370 - recall: 0.5780 - val_accuracy: 0.5787 - val_loss: 0.8082 - val_precision: 0.6487 - val_recall: 0.3433\n",
      "Epoch 47/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5403 - loss: 0.2857 - precision: 0.5277 - recall: 0.8268\n",
      "Epoch 47 - Train Recall: 0.8737 - Val Recall: 0.9850\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5404 - loss: 0.2855 - precision: 0.5277 - recall: 0.8285 - val_accuracy: 0.5045 - val_loss: 0.5462 - val_precision: 0.5023 - val_recall: 0.9850\n",
      "Epoch 48/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5815 - loss: 0.3860 - precision: 0.5866 - recall: 0.6469\n",
      "Epoch 48 - Train Recall: 0.5821 - Val Recall: 0.1919\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5814 - loss: 0.3860 - precision: 0.5864 - recall: 0.6462 - val_accuracy: 0.4648 - val_loss: 0.7720 - val_precision: 0.4224 - val_recall: 0.1919\n",
      "Epoch 49/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5088 - loss: 0.2072 - precision: 0.5003 - recall: 0.9398\n",
      "Epoch 49 - Train Recall: 0.9734 - Val Recall: 1.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5090 - loss: 0.2068 - precision: 0.5007 - recall: 0.9426 - val_accuracy: 0.5007 - val_loss: 0.3715 - val_precision: 0.5004 - val_recall: 1.0000\n",
      "Epoch 50/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5456 - loss: 0.3737 - precision: 0.5406 - recall: 0.6625\n",
      "Epoch 50 - Train Recall: 0.6226 - Val Recall: 0.6252\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5458 - loss: 0.3736 - precision: 0.5408 - recall: 0.6601 - val_accuracy: 0.5885 - val_loss: 0.8131 - val_precision: 0.5824 - val_recall: 0.6252\n",
      "Epoch 51/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5607 - loss: 0.3678 - precision: 0.5548 - recall: 0.6461\n",
      "Epoch 51 - Train Recall: 0.6424 - Val Recall: 0.6297\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5609 - loss: 0.3677 - precision: 0.5547 - recall: 0.6456 - val_accuracy: 0.5675 - val_loss: 0.7341 - val_precision: 0.5600 - val_recall: 0.6297\n",
      "Epoch 52/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5575 - loss: 0.3613 - precision: 0.5470 - recall: 0.6216\n",
      "Epoch 52 - Train Recall: 0.6402 - Val Recall: 0.7001\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5583 - loss: 0.3612 - precision: 0.5479 - recall: 0.6231 - val_accuracy: 0.5757 - val_loss: 0.7221 - val_precision: 0.5606 - val_recall: 0.7001\n",
      "Epoch 53/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5705 - loss: 0.3785 - precision: 0.5644 - recall: 0.5848\n",
      "Epoch 53 - Train Recall: 0.5772 - Val Recall: 0.3763\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5704 - loss: 0.3786 - precision: 0.5644 - recall: 0.5846 - val_accuracy: 0.5802 - val_loss: 0.7325 - val_precision: 0.6354 - val_recall: 0.3763\n",
      "Epoch 54/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5546 - loss: 0.2928 - precision: 0.5328 - recall: 0.7686\n",
      "Epoch 54 - Train Recall: 0.8205 - Val Recall: 0.8396\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5544 - loss: 0.2928 - precision: 0.5330 - recall: 0.7732 - val_accuracy: 0.5802 - val_loss: 0.5544 - val_precision: 0.5528 - val_recall: 0.8396\n",
      "Epoch 55/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5698 - loss: 0.3668 - precision: 0.5669 - recall: 0.6162\n",
      "Epoch 55 - Train Recall: 0.5978 - Val Recall: 0.6132\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5691 - loss: 0.3671 - precision: 0.5660 - recall: 0.6140 - val_accuracy: 0.5397 - val_loss: 0.7212 - val_precision: 0.5346 - val_recall: 0.6132\n",
      "Epoch 56/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5817 - loss: 0.3698 - precision: 0.5829 - recall: 0.6260\n",
      "Epoch 56 - Train Recall: 0.6057 - Val Recall: 0.7601\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5811 - loss: 0.3698 - precision: 0.5821 - recall: 0.6252 - val_accuracy: 0.5847 - val_loss: 0.7096 - val_precision: 0.5627 - val_recall: 0.7601\n",
      "Epoch 57/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5477 - loss: 0.4085 - precision: 0.5475 - recall: 0.4314\n",
      "Epoch 57 - Train Recall: 0.4295 - Val Recall: 0.5562\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5483 - loss: 0.4084 - precision: 0.5498 - recall: 0.4312 - val_accuracy: 0.6012 - val_loss: 0.8800 - val_precision: 0.6112 - val_recall: 0.5562\n",
      "Epoch 58/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5585 - loss: 0.4171 - precision: 0.5900 - recall: 0.4357\n",
      "Epoch 58 - Train Recall: 0.3887 - Val Recall: 0.1064\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5580 - loss: 0.4172 - precision: 0.5889 - recall: 0.4319 - val_accuracy: 0.5285 - val_loss: 0.9041 - val_precision: 0.6827 - val_recall: 0.1064\n",
      "Epoch 59/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5364 - loss: 0.1939 - precision: 0.5195 - recall: 0.8995\n",
      "Epoch 59 - Train Recall: 0.9708 - Val Recall: 0.9700\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5341 - loss: 0.1930 - precision: 0.5184 - recall: 0.9070 - val_accuracy: 0.4970 - val_loss: 0.3577 - val_precision: 0.4985 - val_recall: 0.9700\n",
      "Epoch 60/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5511 - loss: 0.3693 - precision: 0.5438 - recall: 0.7145\n",
      "Epoch 60 - Train Recall: 0.6585 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5525 - loss: 0.3689 - precision: 0.5449 - recall: 0.7094 - val_accuracy: 0.5832 - val_loss: 0.7485 - val_precision: 0.5770 - val_recall: 0.6237\n",
      "Epoch 61/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5889 - loss: 0.3522 - precision: 0.5772 - recall: 0.7129\n",
      "Epoch 61 - Train Recall: 0.6908 - Val Recall: 0.6897\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5879 - loss: 0.3525 - precision: 0.5759 - recall: 0.7108 - val_accuracy: 0.5547 - val_loss: 0.7283 - val_precision: 0.5431 - val_recall: 0.6897\n",
      "Epoch 62/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5706 - loss: 0.3680 - precision: 0.5667 - recall: 0.6162\n",
      "Epoch 62 - Train Recall: 0.5993 - Val Recall: 0.3628\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5706 - loss: 0.3677 - precision: 0.5669 - recall: 0.6145 - val_accuracy: 0.5472 - val_loss: 0.7958 - val_precision: 0.5748 - val_recall: 0.3628\n",
      "Epoch 63/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5404 - loss: 0.2846 - precision: 0.5218 - recall: 0.8154\n",
      "Epoch 63 - Train Recall: 0.8666 - Val Recall: 0.9415\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5407 - loss: 0.2843 - precision: 0.5223 - recall: 0.8208 - val_accuracy: 0.5210 - val_loss: 0.5349 - val_precision: 0.5114 - val_recall: 0.9415\n",
      "Epoch 64/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5617 - loss: 0.3787 - precision: 0.5587 - recall: 0.5745\n",
      "Epoch 64 - Train Recall: 0.5457 - Val Recall: 0.4633\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5616 - loss: 0.3787 - precision: 0.5588 - recall: 0.5740 - val_accuracy: 0.5705 - val_loss: 0.7550 - val_precision: 0.5897 - val_recall: 0.4633\n",
      "Epoch 65/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5517 - loss: 0.3382 - precision: 0.5378 - recall: 0.6448\n",
      "Epoch 65 - Train Recall: 0.7103 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5529 - loss: 0.3377 - precision: 0.5390 - recall: 0.6508 - val_accuracy: 0.6012 - val_loss: 0.6390 - val_precision: 0.5866 - val_recall: 0.6852\n",
      "Epoch 66/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5694 - loss: 0.3541 - precision: 0.5639 - recall: 0.6623\n",
      "Epoch 66 - Train Recall: 0.6398 - Val Recall: 0.7046\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5692 - loss: 0.3542 - precision: 0.5634 - recall: 0.6599 - val_accuracy: 0.5825 - val_loss: 0.6776 - val_precision: 0.5663 - val_recall: 0.7046\n",
      "Epoch 67/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5463 - loss: 0.3809 - precision: 0.5575 - recall: 0.5078\n",
      "Epoch 67 - Train Recall: 0.5154 - Val Recall: 0.6177\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5476 - loss: 0.3807 - precision: 0.5581 - recall: 0.5082 - val_accuracy: 0.5652 - val_loss: 0.7493 - val_precision: 0.5590 - val_recall: 0.6177\n",
      "Epoch 68/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5483 - loss: 0.4002 - precision: 0.5596 - recall: 0.4980\n",
      "Epoch 68 - Train Recall: 0.4591 - Val Recall: 0.7211\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5484 - loss: 0.3998 - precision: 0.5598 - recall: 0.4920 - val_accuracy: 0.6019 - val_loss: 0.7538 - val_precision: 0.5823 - val_recall: 0.7211\n",
      "Epoch 69/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5465 - loss: 0.4484 - precision: 0.5916 - recall: 0.2452\n",
      "Epoch 69 - Train Recall: 0.2328 - Val Recall: 0.2594\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5461 - loss: 0.4485 - precision: 0.5932 - recall: 0.2441 - val_accuracy: 0.5555 - val_loss: 0.9157 - val_precision: 0.6360 - val_recall: 0.2594\n",
      "Epoch 70/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5537 - loss: 0.3896 - precision: 0.5762 - recall: 0.4134\n",
      "Epoch 70 - Train Recall: 0.4535 - Val Recall: 0.5802\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5551 - loss: 0.3891 - precision: 0.5769 - recall: 0.4186 - val_accuracy: 0.5892 - val_loss: 0.7733 - val_precision: 0.5908 - val_recall: 0.5802\n",
      "Epoch 71/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5482 - loss: 0.4135 - precision: 0.5661 - recall: 0.3935\n",
      "Epoch 71 - Train Recall: 0.3696 - Val Recall: 0.4783\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5481 - loss: 0.4134 - precision: 0.5669 - recall: 0.3913 - val_accuracy: 0.5937 - val_loss: 0.7988 - val_precision: 0.6218 - val_recall: 0.4783\n",
      "Epoch 72/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5627 - loss: 0.4099 - precision: 0.5849 - recall: 0.3874\n",
      "Epoch 72 - Train Recall: 0.3756 - Val Recall: 0.1124\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5621 - loss: 0.4100 - precision: 0.5855 - recall: 0.3864 - val_accuracy: 0.5315 - val_loss: 0.8311 - val_precision: 0.6944 - val_recall: 0.1124\n",
      "Epoch 73/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5243 - loss: 0.2042 - precision: 0.5173 - recall: 0.8998\n",
      "Epoch 73 - Train Recall: 0.9666 - Val Recall: 1.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5242 - loss: 0.2041 - precision: 0.5172 - recall: 0.9002 - val_accuracy: 0.5000 - val_loss: 0.3628 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 74/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5609 - loss: 0.3707 - precision: 0.5517 - recall: 0.6423\n",
      "Epoch 74 - Train Recall: 0.6188 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5615 - loss: 0.3705 - precision: 0.5524 - recall: 0.6412 - val_accuracy: 0.5975 - val_loss: 0.7044 - val_precision: 0.5853 - val_recall: 0.6687\n",
      "Epoch 75/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5717 - loss: 0.3721 - precision: 0.5646 - recall: 0.4803\n",
      "Epoch 75 - Train Recall: 0.5296 - Val Recall: 0.6702\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5724 - loss: 0.3722 - precision: 0.5674 - recall: 0.4874 - val_accuracy: 0.6034 - val_loss: 0.7198 - val_precision: 0.5913 - val_recall: 0.6702\n",
      "Epoch 76/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5508 - loss: 0.4011 - precision: 0.5771 - recall: 0.4222\n",
      "Epoch 76 - Train Recall: 0.3962 - Val Recall: 0.4843\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5513 - loss: 0.4012 - precision: 0.5777 - recall: 0.4201 - val_accuracy: 0.5870 - val_loss: 0.7693 - val_precision: 0.6094 - val_recall: 0.4843\n",
      "Epoch 77/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5738 - loss: 0.3925 - precision: 0.6090 - recall: 0.4197\n",
      "Epoch 77 - Train Recall: 0.3999 - Val Recall: 0.6222\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5729 - loss: 0.3927 - precision: 0.6077 - recall: 0.4172 - val_accuracy: 0.5915 - val_loss: 0.7650 - val_precision: 0.5862 - val_recall: 0.6222\n",
      "Epoch 78/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5486 - loss: 0.4399 - precision: 0.6149 - recall: 0.3262\n",
      "Epoch 78 - Train Recall: 0.2219 - Val Recall: 0.3178\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5472 - loss: 0.4401 - precision: 0.6127 - recall: 0.3149 - val_accuracy: 0.5277 - val_loss: 0.8829 - val_precision: 0.5478 - val_recall: 0.3178\n",
      "Epoch 79/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5467 - loss: 0.4265 - precision: 0.6080 - recall: 0.2474\n",
      "Epoch 79 - Train Recall: 0.2429 - Val Recall: 0.2264\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5459 - loss: 0.4267 - precision: 0.6064 - recall: 0.2471 - val_accuracy: 0.5525 - val_loss: 0.8163 - val_precision: 0.6509 - val_recall: 0.2264\n",
      "Epoch 80/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5750 - loss: 0.3483 - precision: 0.5724 - recall: 0.5488\n",
      "Epoch 80 - Train Recall: 0.5738 - Val Recall: 0.0870\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 0.3482 - precision: 0.5733 - recall: 0.5527 - val_accuracy: 0.5225 - val_loss: 0.6898 - val_precision: 0.6744 - val_recall: 0.0870\n",
      "Epoch 81/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5225 - loss: 0.1417 - precision: 0.5201 - recall: 0.9410\n",
      "Epoch 81 - Train Recall: 0.9888 - Val Recall: 1.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5204 - loss: 0.1404 - precision: 0.5182 - recall: 0.9464 - val_accuracy: 0.5000 - val_loss: 0.2379 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 82/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5610 - loss: 0.3687 - precision: 0.5554 - recall: 0.6583\n",
      "Epoch 82 - Train Recall: 0.6053 - Val Recall: 0.3553\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5618 - loss: 0.3683 - precision: 0.5562 - recall: 0.6543 - val_accuracy: 0.5615 - val_loss: 0.6952 - val_precision: 0.6046 - val_recall: 0.3553\n",
      "Epoch 83/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5430 - loss: 0.2751 - precision: 0.5234 - recall: 0.8286\n",
      "Epoch 83 - Train Recall: 0.8834 - Val Recall: 0.8516\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5438 - loss: 0.2747 - precision: 0.5240 - recall: 0.8340 - val_accuracy: 0.5517 - val_loss: 0.5243 - val_precision: 0.5323 - val_recall: 0.8516\n",
      "Epoch 84/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5684 - loss: 0.3524 - precision: 0.5561 - recall: 0.7248\n",
      "Epoch 84 - Train Recall: 0.6762 - Val Recall: 0.4723\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5681 - loss: 0.3525 - precision: 0.5557 - recall: 0.7194 - val_accuracy: 0.5577 - val_loss: 0.7021 - val_precision: 0.5696 - val_recall: 0.4723\n",
      "Epoch 85/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5694 - loss: 0.2997 - precision: 0.5464 - recall: 0.8089\n",
      "Epoch 85 - Train Recall: 0.8287 - Val Recall: 0.7436\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5683 - loss: 0.2997 - precision: 0.5456 - recall: 0.8107 - val_accuracy: 0.5892 - val_loss: 0.6153 - val_precision: 0.5682 - val_recall: 0.7436\n",
      "Epoch 86/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5836 - loss: 0.3366 - precision: 0.5667 - recall: 0.7717\n",
      "Epoch 86 - Train Recall: 0.7507 - Val Recall: 0.5217\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5822 - loss: 0.3366 - precision: 0.5652 - recall: 0.7692 - val_accuracy: 0.5727 - val_loss: 0.6740 - val_precision: 0.5810 - val_recall: 0.5217\n",
      "Epoch 87/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5761 - loss: 0.2942 - precision: 0.5510 - recall: 0.8171\n",
      "Epoch 87 - Train Recall: 0.8632 - Val Recall: 0.7091\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5748 - loss: 0.2941 - precision: 0.5499 - recall: 0.8238 - val_accuracy: 0.5922 - val_loss: 0.5967 - val_precision: 0.5747 - val_recall: 0.7091\n",
      "Epoch 88/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5619 - loss: 0.3209 - precision: 0.5409 - recall: 0.7819\n",
      "Epoch 88 - Train Recall: 0.7901 - Val Recall: 0.7841\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5616 - loss: 0.3210 - precision: 0.5408 - recall: 0.7829 - val_accuracy: 0.6117 - val_loss: 0.6161 - val_precision: 0.5831 - val_recall: 0.7841\n",
      "Epoch 89/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5692 - loss: 0.3550 - precision: 0.5584 - recall: 0.7317\n",
      "Epoch 89 - Train Recall: 0.6942 - Val Recall: 0.6942\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5693 - loss: 0.3551 - precision: 0.5582 - recall: 0.7272 - val_accuracy: 0.5487 - val_loss: 0.7135 - val_precision: 0.5377 - val_recall: 0.6942\n",
      "Epoch 90/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5792 - loss: 0.3581 - precision: 0.5598 - recall: 0.6360\n",
      "Epoch 90 - Train Recall: 0.6263 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5781 - loss: 0.3584 - precision: 0.5603 - recall: 0.6353 - val_accuracy: 0.5735 - val_loss: 0.7047 - val_precision: 0.5643 - val_recall: 0.6447\n",
      "Epoch 91/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5791 - loss: 0.3616 - precision: 0.5768 - recall: 0.6349\n",
      "Epoch 91 - Train Recall: 0.5858 - Val Recall: 0.5742\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5778 - loss: 0.3617 - precision: 0.5753 - recall: 0.6273 - val_accuracy: 0.5742 - val_loss: 0.7108 - val_precision: 0.5742 - val_recall: 0.5742\n",
      "Epoch 92/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5729 - loss: 0.3548 - precision: 0.5632 - recall: 0.5854\n",
      "Epoch 92 - Train Recall: 0.6012 - Val Recall: 0.7571\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5723 - loss: 0.3548 - precision: 0.5630 - recall: 0.5871 - val_accuracy: 0.5502 - val_loss: 0.7087 - val_precision: 0.5355 - val_recall: 0.7571\n",
      "Epoch 93/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5733 - loss: 0.3987 - precision: 0.5836 - recall: 0.4965\n",
      "Epoch 93 - Train Recall: 0.4175 - Val Recall: 0.4108\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5710 - loss: 0.3991 - precision: 0.5827 - recall: 0.4854 - val_accuracy: 0.5517 - val_loss: 0.8093 - val_precision: 0.5720 - val_recall: 0.4108\n",
      "Epoch 94/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5650 - loss: 0.3576 - precision: 0.5649 - recall: 0.5603\n",
      "Epoch 94 - Train Recall: 0.5600 - Val Recall: 0.7271\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5653 - loss: 0.3574 - precision: 0.5652 - recall: 0.5604 - val_accuracy: 0.5772 - val_loss: 0.7008 - val_precision: 0.5594 - val_recall: 0.7271\n",
      "Epoch 95/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5576 - loss: 0.4097 - precision: 0.5884 - recall: 0.3983\n",
      "Epoch 95 - Train Recall: 0.3613 - Val Recall: 0.2369\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5573 - loss: 0.4096 - precision: 0.5886 - recall: 0.3948 - val_accuracy: 0.5510 - val_loss: 0.8036 - val_precision: 0.6371 - val_recall: 0.2369\n",
      "Epoch 96/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5614 - loss: 0.2933 - precision: 0.5310 - recall: 0.7181\n",
      "Epoch 96 - Train Recall: 0.8156 - Val Recall: 0.7046\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5606 - loss: 0.2931 - precision: 0.5314 - recall: 0.7276 - val_accuracy: 0.5960 - val_loss: 0.5727 - val_precision: 0.5788 - val_recall: 0.7046\n",
      "Epoch 97/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5895 - loss: 0.3296 - precision: 0.5706 - recall: 0.7286\n",
      "Epoch 97 - Train Recall: 0.7114 - Val Recall: 0.7751\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5880 - loss: 0.3297 - precision: 0.5695 - recall: 0.7268 - val_accuracy: 0.5840 - val_loss: 0.6432 - val_precision: 0.5607 - val_recall: 0.7751\n",
      "Epoch 98/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5782 - loss: 0.3723 - precision: 0.5774 - recall: 0.6048\n",
      "Epoch 98 - Train Recall: 0.5499 - Val Recall: 0.7391\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5768 - loss: 0.3722 - precision: 0.5764 - recall: 0.5984 - val_accuracy: 0.5735 - val_loss: 0.7467 - val_precision: 0.5552 - val_recall: 0.7391\n",
      "Epoch 99/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5692 - loss: 0.4117 - precision: 0.6087 - recall: 0.3503\n",
      "Epoch 99 - Train Recall: 0.3253 - Val Recall: 0.4798\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5676 - loss: 0.4118 - precision: 0.6075 - recall: 0.3472 - val_accuracy: 0.5795 - val_loss: 0.8066 - val_precision: 0.5993 - val_recall: 0.4798\n",
      "Epoch 100/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5528 - loss: 0.4314 - precision: 0.6167 - recall: 0.2943\n",
      "Epoch 100 - Train Recall: 0.2605 - Val Recall: 0.4048\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5517 - loss: 0.4314 - precision: 0.6152 - recall: 0.2891 - val_accuracy: 0.5727 - val_loss: 0.8443 - val_precision: 0.6095 - val_recall: 0.4048\n",
      "Epoch 101/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5461 - loss: 0.4391 - precision: 0.6098 - recall: 0.2490\n",
      "Epoch 101 - Train Recall: 0.2118 - Val Recall: 0.4108\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5454 - loss: 0.4393 - precision: 0.6098 - recall: 0.2456 - val_accuracy: 0.5712 - val_loss: 0.8696 - val_precision: 0.6049 - val_recall: 0.4108\n",
      "Epoch 102/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5148 - loss: 0.4869 - precision: 0.6102 - recall: 0.1139\n",
      "Epoch 102 - Train Recall: 0.0990 - Val Recall: 0.2789\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5150 - loss: 0.4869 - precision: 0.6093 - recall: 0.1130 - val_accuracy: 0.5637 - val_loss: 0.9875 - val_precision: 0.6481 - val_recall: 0.2789\n",
      "Epoch 103/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5061 - loss: 0.5664 - precision: 0.6037 - recall: 0.0242\n",
      "Epoch 103 - Train Recall: 0.0214 - Val Recall: 0.0135\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5061 - loss: 0.5664 - precision: 0.6040 - recall: 0.0242 - val_accuracy: 0.5007 - val_loss: 1.1024 - val_precision: 0.5294 - val_recall: 0.0135\n",
      "Epoch 104/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5600 - loss: 0.3066 - precision: 0.5529 - recall: 0.5840   \n",
      "Epoch 104 - Train Recall: 0.7136 - Val Recall: 0.7766\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5603 - loss: 0.3063 - precision: 0.5529 - recall: 0.5879 - val_accuracy: 0.5802 - val_loss: 0.5539 - val_precision: 0.5576 - val_recall: 0.7766\n",
      "Epoch 105/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5614 - loss: 0.3767 - precision: 0.5652 - recall: 0.4856\n",
      "Epoch 105 - Train Recall: 0.4618 - Val Recall: 0.8141\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5621 - loss: 0.3764 - precision: 0.5672 - recall: 0.4827 - val_accuracy: 0.6034 - val_loss: 0.7288 - val_precision: 0.5728 - val_recall: 0.8141\n",
      "Epoch 106/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5323 - loss: 0.4691 - precision: 0.5965 - recall: 0.1778\n",
      "Epoch 106 - Train Recall: 0.1548 - Val Recall: 0.0390\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5322 - loss: 0.4692 - precision: 0.5966 - recall: 0.1775 - val_accuracy: 0.5030 - val_loss: 0.9045 - val_precision: 0.5417 - val_recall: 0.0390\n",
      "Epoch 107/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5041 - loss: 0.1934 - precision: 0.5107 - recall: 0.8835\n",
      "Epoch 107 - Train Recall: 0.9693 - Val Recall: 1.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5038 - loss: 0.1918 - precision: 0.5095 - recall: 0.8931 - val_accuracy: 0.5000 - val_loss: 0.3256 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 108/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5600 - loss: 0.3716 - precision: 0.5628 - recall: 0.5905\n",
      "Epoch 108 - Train Recall: 0.5266 - Val Recall: 0.2744\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5603 - loss: 0.3711 - precision: 0.5635 - recall: 0.5839 - val_accuracy: 0.5547 - val_loss: 0.7266 - val_precision: 0.6246 - val_recall: 0.2744\n",
      "Epoch 109/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5495 - loss: 0.2595 - precision: 0.5275 - recall: 0.8040\n",
      "Epoch 109 - Train Recall: 0.8947 - Val Recall: 0.8771\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5492 - loss: 0.2593 - precision: 0.5275 - recall: 0.8094 - val_accuracy: 0.5652 - val_loss: 0.5043 - val_precision: 0.5402 - val_recall: 0.8771\n",
      "Epoch 110/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5867 - loss: 0.3505 - precision: 0.5768 - recall: 0.7093\n",
      "Epoch 110 - Train Recall: 0.6346 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5853 - loss: 0.3508 - precision: 0.5756 - recall: 0.7021 - val_accuracy: 0.5900 - val_loss: 0.6823 - val_precision: 0.5798 - val_recall: 0.6537\n",
      "Epoch 111/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 0.3618 - precision: 0.5677 - recall: 0.5818\n",
      "Epoch 111 - Train Recall: 0.6102 - Val Recall: 0.6267\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5763 - loss: 0.3615 - precision: 0.5692 - recall: 0.5854 - val_accuracy: 0.5922 - val_loss: 0.7019 - val_precision: 0.5863 - val_recall: 0.6267\n",
      "Epoch 112/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5721 - loss: 0.3598 - precision: 0.5801 - recall: 0.5957\n",
      "Epoch 112 - Train Recall: 0.5600 - Val Recall: 0.5217\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5722 - loss: 0.3599 - precision: 0.5795 - recall: 0.5912 - val_accuracy: 0.5855 - val_loss: 0.6984 - val_precision: 0.5979 - val_recall: 0.5217\n",
      "Epoch 113/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5808 - loss: 0.3429 - precision: 0.5740 - recall: 0.6701\n",
      "Epoch 113 - Train Recall: 0.6653 - Val Recall: 0.5397\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5805 - loss: 0.3429 - precision: 0.5731 - recall: 0.6695 - val_accuracy: 0.5945 - val_loss: 0.6825 - val_precision: 0.6061 - val_recall: 0.5397\n",
      "Epoch 114/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5697 - loss: 0.3163 - precision: 0.5495 - recall: 0.7247\n",
      "Epoch 114 - Train Recall: 0.7519 - Val Recall: 0.5757\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5690 - loss: 0.3164 - precision: 0.5493 - recall: 0.7277 - val_accuracy: 0.5877 - val_loss: 0.6346 - val_precision: 0.5899 - val_recall: 0.5757\n",
      "Epoch 115/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5714 - loss: 0.3068 - precision: 0.5474 - recall: 0.7846\n",
      "Epoch 115 - Train Recall: 0.8118 - Val Recall: 0.6987\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5712 - loss: 0.3068 - precision: 0.5475 - recall: 0.7872 - val_accuracy: 0.6064 - val_loss: 0.6594 - val_precision: 0.5899 - val_recall: 0.6987\n",
      "Epoch 116/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5605 - loss: 0.3275 - precision: 0.5473 - recall: 0.7807\n",
      "Epoch 116 - Train Recall: 0.7676 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5609 - loss: 0.3275 - precision: 0.5471 - recall: 0.7785 - val_accuracy: 0.6117 - val_loss: 0.6311 - val_precision: 0.5971 - val_recall: 0.6867\n",
      "Epoch 117/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5880 - loss: 0.3308 - precision: 0.5678 - recall: 0.7295\n",
      "Epoch 117 - Train Recall: 0.7478 - Val Recall: 0.8396\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5861 - loss: 0.3312 - precision: 0.5660 - recall: 0.7313 - val_accuracy: 0.5817 - val_loss: 0.6525 - val_precision: 0.5539 - val_recall: 0.8396\n",
      "Epoch 118/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5734 - loss: 0.3757 - precision: 0.5635 - recall: 0.6257\n",
      "Epoch 118 - Train Recall: 0.5607 - Val Recall: 0.4438\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5729 - loss: 0.3757 - precision: 0.5639 - recall: 0.6202 - val_accuracy: 0.5690 - val_loss: 0.7287 - val_precision: 0.5920 - val_recall: 0.4438\n",
      "Epoch 119/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5885 - loss: 0.3142 - precision: 0.5630 - recall: 0.7280\n",
      "Epoch 119 - Train Recall: 0.7744 - Val Recall: 0.8141\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5881 - loss: 0.3142 - precision: 0.5627 - recall: 0.7294 - val_accuracy: 0.5967 - val_loss: 0.6100 - val_precision: 0.5674 - val_recall: 0.8141\n",
      "Epoch 120/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5653 - loss: 0.3653 - precision: 0.5623 - recall: 0.6483\n",
      "Epoch 120 - Train Recall: 0.6087 - Val Recall: 0.5652\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5663 - loss: 0.3651 - precision: 0.5630 - recall: 0.6441 - val_accuracy: 0.5832 - val_loss: 0.7174 - val_precision: 0.5863 - val_recall: 0.5652\n",
      "Epoch 121/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5858 - loss: 0.3414 - precision: 0.5700 - recall: 0.7089\n",
      "Epoch 121 - Train Recall: 0.6795 - Val Recall: 0.7781\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5853 - loss: 0.3415 - precision: 0.5698 - recall: 0.7061 - val_accuracy: 0.6094 - val_loss: 0.6568 - val_precision: 0.5818 - val_recall: 0.7781\n",
      "Epoch 122/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5726 - loss: 0.3773 - precision: 0.5692 - recall: 0.5142\n",
      "Epoch 122 - Train Recall: 0.5022 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5721 - loss: 0.3775 - precision: 0.5700 - recall: 0.5137 - val_accuracy: 0.5570 - val_loss: 0.7591 - val_precision: 0.5458 - val_recall: 0.6792\n",
      "Epoch 123/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5519 - loss: 0.4086 - precision: 0.5824 - recall: 0.3470\n",
      "Epoch 123 - Train Recall: 0.3430 - Val Recall: 0.3538\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5519 - loss: 0.4086 - precision: 0.5831 - recall: 0.3466 - val_accuracy: 0.5465 - val_loss: 0.7995 - val_precision: 0.5756 - val_recall: 0.3538\n",
      "Epoch 124/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5779 - loss: 0.3612 - precision: 0.5952 - recall: 0.5248\n",
      "Epoch 124 - Train Recall: 0.5555 - Val Recall: 0.4003\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5782 - loss: 0.3612 - precision: 0.5942 - recall: 0.5281 - val_accuracy: 0.5907 - val_loss: 0.7084 - val_precision: 0.6465 - val_recall: 0.4003\n",
      "Epoch 125/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5826 - loss: 0.3018 - precision: 0.5648 - recall: 0.7245\n",
      "Epoch 125 - Train Recall: 0.7957 - Val Recall: 0.7676\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5812 - loss: 0.3018 - precision: 0.5633 - recall: 0.7298 - val_accuracy: 0.5645 - val_loss: 0.5933 - val_precision: 0.5458 - val_recall: 0.7676\n",
      "Epoch 126/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5602 - loss: 0.3481 - precision: 0.5478 - recall: 0.7203\n",
      "Epoch 126 - Train Recall: 0.6852 - Val Recall: 0.8891\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5617 - loss: 0.3480 - precision: 0.5490 - recall: 0.7166 - val_accuracy: 0.5577 - val_loss: 0.7045 - val_precision: 0.5347 - val_recall: 0.8891\n",
      "Epoch 127/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5649 - loss: 0.4052 - precision: 0.5800 - recall: 0.4713\n",
      "Epoch 127 - Train Recall: 0.4168 - Val Recall: 0.5382\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5648 - loss: 0.4052 - precision: 0.5803 - recall: 0.4697 - val_accuracy: 0.5435 - val_loss: 0.8051 - val_precision: 0.5439 - val_recall: 0.5382\n",
      "Epoch 128/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5770 - loss: 0.4009 - precision: 0.6245 - recall: 0.4065\n",
      "Epoch 128 - Train Recall: 0.3594 - Val Recall: 0.3793\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5756 - loss: 0.4012 - precision: 0.6226 - recall: 0.4024 - val_accuracy: 0.5622 - val_loss: 0.7791 - val_precision: 0.5981 - val_recall: 0.3793\n",
      "Epoch 129/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5668 - loss: 0.3629 - precision: 0.5784 - recall: 0.5185\n",
      "Epoch 129 - Train Recall: 0.5060 - Val Recall: 0.5787\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5668 - loss: 0.3631 - precision: 0.5781 - recall: 0.5172 - val_accuracy: 0.5802 - val_loss: 0.7438 - val_precision: 0.5805 - val_recall: 0.5787\n",
      "Epoch 130/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5740 - loss: 0.3803 - precision: 0.5885 - recall: 0.4377\n",
      "Epoch 130 - Train Recall: 0.4340 - Val Recall: 0.6777\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5739 - loss: 0.3802 - precision: 0.5889 - recall: 0.4375 - val_accuracy: 0.5922 - val_loss: 0.7682 - val_precision: 0.5787 - val_recall: 0.6777\n",
      "Epoch 131/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5320 - loss: 0.4426 - precision: 0.5540 - recall: 0.1940\n",
      "Epoch 131 - Train Recall: 0.1975 - Val Recall: 0.1904\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5325 - loss: 0.4424 - precision: 0.5619 - recall: 0.1946 - val_accuracy: 0.5427 - val_loss: 0.8512 - val_precision: 0.6447 - val_recall: 0.1904\n",
      "Epoch 132/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5850 - loss: 0.3517 - precision: 0.6103 - recall: 0.5546\n",
      "Epoch 132 - Train Recall: 0.5540 - Val Recall: 0.4588\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5839 - loss: 0.3517 - precision: 0.6064 - recall: 0.5552 - val_accuracy: 0.5990 - val_loss: 0.6804 - val_precision: 0.6375 - val_recall: 0.4588\n",
      "Epoch 133/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5845 - loss: 0.3226 - precision: 0.5785 - recall: 0.6451\n",
      "Epoch 133 - Train Recall: 0.6923 - Val Recall: 0.8261\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5842 - loss: 0.3226 - precision: 0.5772 - recall: 0.6499 - val_accuracy: 0.5675 - val_loss: 0.6272 - val_precision: 0.5445 - val_recall: 0.8261\n",
      "Epoch 134/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5799 - loss: 0.3854 - precision: 0.5942 - recall: 0.5051\n",
      "Epoch 134 - Train Recall: 0.4633 - Val Recall: 0.4948\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5796 - loss: 0.3855 - precision: 0.5947 - recall: 0.5009 - val_accuracy: 0.5945 - val_loss: 0.9032 - val_precision: 0.6180 - val_recall: 0.4948\n",
      "Epoch 135/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5796 - loss: 0.3684 - precision: 0.5847 - recall: 0.5746\n",
      "Epoch 135 - Train Recall: 0.5379 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5786 - loss: 0.3685 - precision: 0.5835 - recall: 0.5711 - val_accuracy: 0.5742 - val_loss: 0.7303 - val_precision: 0.5606 - val_recall: 0.6867\n",
      "Epoch 136/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5616 - loss: 0.4021 - precision: 0.5951 - recall: 0.3488\n",
      "Epoch 136 - Train Recall: 0.3340 - Val Recall: 0.4033\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5603 - loss: 0.4020 - precision: 0.5944 - recall: 0.3467 - val_accuracy: 0.5577 - val_loss: 0.7750 - val_precision: 0.5835 - val_recall: 0.4033\n",
      "Epoch 137/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5781 - loss: 0.3879 - precision: 0.6015 - recall: 0.4556\n",
      "Epoch 137 - Train Recall: 0.4048 - Val Recall: 0.3943\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5767 - loss: 0.3882 - precision: 0.6006 - recall: 0.4505 - val_accuracy: 0.5577 - val_loss: 0.7600 - val_precision: 0.5857 - val_recall: 0.3943\n",
      "Epoch 138/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5833 - loss: 0.3509 - precision: 0.5804 - recall: 0.5637\n",
      "Epoch 138 - Train Recall: 0.5828 - Val Recall: 0.5337\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5823 - loss: 0.3509 - precision: 0.5797 - recall: 0.5652 - val_accuracy: 0.5952 - val_loss: 0.6975 - val_precision: 0.6085 - val_recall: 0.5337\n",
      "Epoch 139/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5928 - loss: 0.3362 - precision: 0.5767 - recall: 0.6683\n",
      "Epoch 139 - Train Recall: 0.6690 - Val Recall: 0.7226\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5911 - loss: 0.3366 - precision: 0.5754 - recall: 0.6680 - val_accuracy: 0.5915 - val_loss: 0.7370 - val_precision: 0.5724 - val_recall: 0.7226\n",
      "Epoch 140/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5726 - loss: 0.3702 - precision: 0.5686 - recall: 0.5902\n",
      "Epoch 140 - Train Recall: 0.5697 - Val Recall: 0.6762\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5729 - loss: 0.3698 - precision: 0.5698 - recall: 0.5866 - val_accuracy: 0.6079 - val_loss: 0.7073 - val_precision: 0.5950 - val_recall: 0.6762\n",
      "Epoch 141/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5521 - loss: 0.3865 - precision: 0.5700 - recall: 0.4145\n",
      "Epoch 141 - Train Recall: 0.4168 - Val Recall: 0.4003\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5531 - loss: 0.3865 - precision: 0.5716 - recall: 0.4150 - val_accuracy: 0.5735 - val_loss: 0.7527 - val_precision: 0.6124 - val_recall: 0.4003\n",
      "Epoch 142/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5828 - loss: 0.3446 - precision: 0.5710 - recall: 0.6051\n",
      "Epoch 142 - Train Recall: 0.6211 - Val Recall: 0.5697\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5826 - loss: 0.3447 - precision: 0.5709 - recall: 0.6054 - val_accuracy: 0.5900 - val_loss: 0.6712 - val_precision: 0.5938 - val_recall: 0.5697\n",
      "Epoch 143/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5866 - loss: 0.3372 - precision: 0.5739 - recall: 0.6999\n",
      "Epoch 143 - Train Recall: 0.6949 - Val Recall: 0.7211\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5865 - loss: 0.3372 - precision: 0.5737 - recall: 0.6998 - val_accuracy: 0.5915 - val_loss: 0.6663 - val_precision: 0.5726 - val_recall: 0.7211\n",
      "Epoch 144/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 0.3614 - precision: 0.5678 - recall: 0.5964\n",
      "Epoch 144 - Train Recall: 0.5922 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5755 - loss: 0.3612 - precision: 0.5687 - recall: 0.5961 - val_accuracy: 0.6019 - val_loss: 0.6943 - val_precision: 0.6053 - val_recall: 0.5862\n",
      "Epoch 145/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5756 - loss: 0.3507 - precision: 0.5713 - recall: 0.6381\n",
      "Epoch 145 - Train Recall: 0.6106 - Val Recall: 0.7451\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5752 - loss: 0.3509 - precision: 0.5710 - recall: 0.6340 - val_accuracy: 0.6064 - val_loss: 0.6782 - val_precision: 0.5833 - val_recall: 0.7451\n",
      "Epoch 146/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5864 - loss: 0.3859 - precision: 0.6007 - recall: 0.4749\n",
      "Epoch 146 - Train Recall: 0.4419 - Val Recall: 0.4423\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5851 - loss: 0.3865 - precision: 0.6011 - recall: 0.4702 - val_accuracy: 0.5712 - val_loss: 0.7620 - val_precision: 0.5960 - val_recall: 0.4423\n",
      "Epoch 147/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5774 - loss: 0.3534 - precision: 0.5954 - recall: 0.5719\n",
      "Epoch 147 - Train Recall: 0.5637 - Val Recall: 0.5037\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5775 - loss: 0.3534 - precision: 0.5934 - recall: 0.5715 - val_accuracy: 0.6019 - val_loss: 0.6942 - val_precision: 0.6269 - val_recall: 0.5037\n",
      "Epoch 148/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5855 - loss: 0.3336 - precision: 0.5891 - recall: 0.5995\n",
      "Epoch 148 - Train Recall: 0.6585 - Val Recall: 0.7931\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5842 - loss: 0.3337 - precision: 0.5865 - recall: 0.6049 - val_accuracy: 0.5937 - val_loss: 0.6492 - val_precision: 0.5670 - val_recall: 0.7931\n",
      "Epoch 149/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5670 - loss: 0.3874 - precision: 0.5713 - recall: 0.5099\n",
      "Epoch 149 - Train Recall: 0.4876 - Val Recall: 0.2324\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5675 - loss: 0.3873 - precision: 0.5729 - recall: 0.5080 - val_accuracy: 0.5360 - val_loss: 0.7598 - val_precision: 0.5916 - val_recall: 0.2324\n",
      "Epoch 150/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5375 - loss: 0.2452 - precision: 0.5246 - recall: 0.8582\n",
      "Epoch 150 - Train Recall: 0.9265 - Val Recall: 0.9835\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5373 - loss: 0.2452 - precision: 0.5244 - recall: 0.8594 - val_accuracy: 0.5105 - val_loss: 0.4836 - val_precision: 0.5054 - val_recall: 0.9835\n",
      "Epoch 151/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5634 - loss: 0.3650 - precision: 0.5454 - recall: 0.6550\n",
      "Epoch 151 - Train Recall: 0.6181 - Val Recall: 0.6777\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5637 - loss: 0.3649 - precision: 0.5472 - recall: 0.6507 - val_accuracy: 0.6004 - val_loss: 0.7200 - val_precision: 0.5870 - val_recall: 0.6777\n",
      "Epoch 152/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5876 - loss: 0.3688 - precision: 0.5867 - recall: 0.5982\n",
      "Epoch 152 - Train Recall: 0.5720 - Val Recall: 0.3823\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5874 - loss: 0.3688 - precision: 0.5866 - recall: 0.5972 - val_accuracy: 0.5667 - val_loss: 0.7384 - val_precision: 0.6057 - val_recall: 0.3823\n",
      "Epoch 153/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5450 - loss: 0.2934 - precision: 0.5411 - recall: 0.8020\n",
      "Epoch 153 - Train Recall: 0.8366 - Val Recall: 0.8636\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5452 - loss: 0.2933 - precision: 0.5408 - recall: 0.8031 - val_accuracy: 0.5577 - val_loss: 0.5584 - val_precision: 0.5358 - val_recall: 0.8636\n",
      "Epoch 154/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5780 - loss: 0.3577 - precision: 0.5569 - recall: 0.6930\n",
      "Epoch 154 - Train Recall: 0.6732 - Val Recall: 0.8471\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5781 - loss: 0.3577 - precision: 0.5573 - recall: 0.6925 - val_accuracy: 0.5652 - val_loss: 0.7899 - val_precision: 0.5417 - val_recall: 0.8471\n",
      "Epoch 155/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5720 - loss: 0.3951 - precision: 0.5848 - recall: 0.5258\n",
      "Epoch 155 - Train Recall: 0.4588 - Val Recall: 0.6702\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5719 - loss: 0.3951 - precision: 0.5848 - recall: 0.5250 - val_accuracy: 0.5982 - val_loss: 0.7775 - val_precision: 0.5858 - val_recall: 0.6702\n",
      "Epoch 156/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5657 - loss: 0.4238 - precision: 0.6275 - recall: 0.3375\n",
      "Epoch 156 - Train Recall: 0.2620 - Val Recall: 0.1859\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5632 - loss: 0.4242 - precision: 0.6251 - recall: 0.3283 - val_accuracy: 0.5472 - val_loss: 0.8431 - val_precision: 0.6703 - val_recall: 0.1859\n",
      "Epoch 157/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5630 - loss: 0.3075 - precision: 0.5639 - recall: 0.6528\n",
      "Epoch 157 - Train Recall: 0.7631 - Val Recall: 0.8621\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5643 - loss: 0.3067 - precision: 0.5624 - recall: 0.6668 - val_accuracy: 0.5712 - val_loss: 0.5759 - val_precision: 0.5450 - val_recall: 0.8621\n",
      "Epoch 158/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5836 - loss: 0.3763 - precision: 0.5841 - recall: 0.6167\n",
      "Epoch 158 - Train Recall: 0.5240 - Val Recall: 0.4723\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5834 - loss: 0.3760 - precision: 0.5849 - recall: 0.6069 - val_accuracy: 0.5555 - val_loss: 0.7443 - val_precision: 0.5665 - val_recall: 0.4723\n",
      "Epoch 159/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5783 - loss: 0.3361 - precision: 0.5748 - recall: 0.6165\n",
      "Epoch 159 - Train Recall: 0.6507 - Val Recall: 0.5877\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5785 - loss: 0.3361 - precision: 0.5748 - recall: 0.6176 - val_accuracy: 0.5847 - val_loss: 0.6529 - val_precision: 0.5842 - val_recall: 0.5877\n",
      "Epoch 160/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5714 - loss: 0.3354 - precision: 0.5669 - recall: 0.6826\n",
      "Epoch 160 - Train Recall: 0.6987 - Val Recall: 0.5472\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5717 - loss: 0.3355 - precision: 0.5661 - recall: 0.6851 - val_accuracy: 0.5840 - val_loss: 0.6603 - val_precision: 0.5906 - val_recall: 0.5472\n",
      "Epoch 161/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5636 - loss: 0.3133 - precision: 0.5545 - recall: 0.7563\n",
      "Epoch 161 - Train Recall: 0.7785 - Val Recall: 0.8141\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5635 - loss: 0.3132 - precision: 0.5529 - recall: 0.7592 - val_accuracy: 0.5877 - val_loss: 0.6067 - val_precision: 0.5604 - val_recall: 0.8141\n",
      "Epoch 162/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5746 - loss: 0.3608 - precision: 0.5709 - recall: 0.6682\n",
      "Epoch 162 - Train Recall: 0.6229 - Val Recall: 0.5772\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5755 - loss: 0.3607 - precision: 0.5714 - recall: 0.6626 - val_accuracy: 0.5727 - val_loss: 0.7136 - val_precision: 0.5721 - val_recall: 0.5772\n",
      "Epoch 163/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5754 - loss: 0.3428 - precision: 0.5628 - recall: 0.6665\n",
      "Epoch 163 - Train Recall: 0.6709 - Val Recall: 0.9130\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5753 - loss: 0.3428 - precision: 0.5626 - recall: 0.6667 - val_accuracy: 0.5577 - val_loss: 0.6704 - val_precision: 0.5337 - val_recall: 0.9130\n",
      "Epoch 164/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5612 - loss: 0.4098 - precision: 0.5865 - recall: 0.4359\n",
      "Epoch 164 - Train Recall: 0.3313 - Val Recall: 0.1739\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5602 - loss: 0.4099 - precision: 0.5870 - recall: 0.4255 - val_accuracy: 0.5375 - val_loss: 0.8157 - val_precision: 0.6374 - val_recall: 0.1739\n",
      "Epoch 165/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5424 - loss: 0.2630 - precision: 0.5317 - recall: 0.7995\n",
      "Epoch 165 - Train Recall: 0.8939 - Val Recall: 1.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5428 - loss: 0.2619 - precision: 0.5309 - recall: 0.8121 - val_accuracy: 0.5000 - val_loss: 0.4974 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 166/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5725 - loss: 0.3753 - precision: 0.5646 - recall: 0.6305\n",
      "Epoch 166 - Train Recall: 0.5356 - Val Recall: 0.3718\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5731 - loss: 0.3751 - precision: 0.5669 - recall: 0.6196 - val_accuracy: 0.5510 - val_loss: 0.7257 - val_precision: 0.5794 - val_recall: 0.3718\n",
      "Epoch 167/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5796 - loss: 0.2914 - precision: 0.5496 - recall: 0.7827\n",
      "Epoch 167 - Train Recall: 0.8302 - Val Recall: 0.9025\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5787 - loss: 0.2915 - precision: 0.5494 - recall: 0.7883 - val_accuracy: 0.5360 - val_loss: 0.5717 - val_precision: 0.5208 - val_recall: 0.9025\n",
      "Epoch 168/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5790 - loss: 0.3654 - precision: 0.5692 - recall: 0.6354\n",
      "Epoch 168 - Train Recall: 0.6064 - Val Recall: 0.3613\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5792 - loss: 0.3654 - precision: 0.5701 - recall: 0.6326 - val_accuracy: 0.5472 - val_loss: 0.7264 - val_precision: 0.5752 - val_recall: 0.3613\n",
      "Epoch 169/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5473 - loss: 0.2737 - precision: 0.5230 - recall: 0.8359\n",
      "Epoch 169 - Train Recall: 0.8951 - Val Recall: 0.9565\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5467 - loss: 0.2735 - precision: 0.5232 - recall: 0.8426 - val_accuracy: 0.5165 - val_loss: 0.5221 - val_precision: 0.5088 - val_recall: 0.9565\n",
      "Epoch 170/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5644 - loss: 0.3657 - precision: 0.5583 - recall: 0.6683\n",
      "Epoch 170 - Train Recall: 0.5873 - Val Recall: 0.8111\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5647 - loss: 0.3656 - precision: 0.5589 - recall: 0.6633 - val_accuracy: 0.5892 - val_loss: 0.7158 - val_precision: 0.5618 - val_recall: 0.8111\n",
      "Epoch 171/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5626 - loss: 0.4108 - precision: 0.6051 - recall: 0.3457\n",
      "Epoch 171 - Train Recall: 0.2800 - Val Recall: 0.5727\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5603 - loss: 0.4112 - precision: 0.6036 - recall: 0.3357 - val_accuracy: 0.5982 - val_loss: 0.8042 - val_precision: 0.6035 - val_recall: 0.5727\n",
      "Epoch 172/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5104 - loss: 0.4936 - precision: 0.5900 - recall: 0.0794\n",
      "Epoch 172 - Train Recall: 0.0532 - Val Recall: 0.0255\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5102 - loss: 0.4936 - precision: 0.5922 - recall: 0.0771 - val_accuracy: 0.5015 - val_loss: 0.9595 - val_precision: 0.5312 - val_recall: 0.0255\n",
      "Epoch 173/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5566 - loss: 0.2592 - precision: 0.5444 - recall: 0.6915   \n",
      "Epoch 173 - Train Recall: 0.8587 - Val Recall: 1.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5558 - loss: 0.2587 - precision: 0.5433 - recall: 0.7014 - val_accuracy: 0.5007 - val_loss: 0.4733 - val_precision: 0.5004 - val_recall: 1.0000\n",
      "Epoch 174/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5764 - loss: 0.3847 - precision: 0.5884 - recall: 0.5669\n",
      "Epoch 174 - Train Recall: 0.4550 - Val Recall: 0.4978\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 0.3844 - precision: 0.5880 - recall: 0.5516 - val_accuracy: 0.5667 - val_loss: 0.7411 - val_precision: 0.5774 - val_recall: 0.4978\n",
      "Epoch 175/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5990 - loss: 0.3643 - precision: 0.6220 - recall: 0.4978\n",
      "Epoch 175 - Train Recall: 0.4963 - Val Recall: 0.3613\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5981 - loss: 0.3646 - precision: 0.6210 - recall: 0.4964 - val_accuracy: 0.5727 - val_loss: 0.7158 - val_precision: 0.6260 - val_recall: 0.3613\n",
      "Epoch 176/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5841 - loss: 0.3022 - precision: 0.5723 - recall: 0.7014\n",
      "Epoch 176 - Train Recall: 0.7500 - Val Recall: 0.8321\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5838 - loss: 0.3021 - precision: 0.5711 - recall: 0.7061 - val_accuracy: 0.6079 - val_loss: 0.5820 - val_precision: 0.5745 - val_recall: 0.8321\n",
      "Epoch 177/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5741 - loss: 0.3701 - precision: 0.5736 - recall: 0.5159\n",
      "Epoch 177 - Train Recall: 0.4918 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5727 - loss: 0.3703 - precision: 0.5739 - recall: 0.5115 - val_accuracy: 0.5982 - val_loss: 0.7332 - val_precision: 0.5916 - val_recall: 0.6342\n",
      "Epoch 178/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5615 - loss: 0.3978 - precision: 0.5915 - recall: 0.3862\n",
      "Epoch 178 - Train Recall: 0.3579 - Val Recall: 0.7091\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5620 - loss: 0.3978 - precision: 0.5933 - recall: 0.3835 - val_accuracy: 0.5922 - val_loss: 0.7876 - val_precision: 0.5747 - val_recall: 0.7091\n",
      "Epoch 179/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5202 - loss: 0.4868 - precision: 0.6321 - recall: 0.0974\n",
      "Epoch 179 - Train Recall: 0.0409 - Val Recall: 0.0135\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5184 - loss: 0.4869 - precision: 0.6301 - recall: 0.0889 - val_accuracy: 0.5015 - val_loss: 0.9632 - val_precision: 0.5625 - val_recall: 0.0135\n",
      "Epoch 180/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5194 - loss: 0.2244 - precision: 0.5256 - recall: 0.8038    \n",
      "Epoch 180 - Train Recall: 0.9457 - Val Recall: 1.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5179 - loss: 0.2223 - precision: 0.5231 - recall: 0.8213 - val_accuracy: 0.5000 - val_loss: 0.3853 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 181/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5629 - loss: 0.3706 - precision: 0.5500 - recall: 0.5845\n",
      "Epoch 181 - Train Recall: 0.5573 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5640 - loss: 0.3700 - precision: 0.5528 - recall: 0.5813 - val_accuracy: 0.5975 - val_loss: 0.7098 - val_precision: 0.5860 - val_recall: 0.6642\n",
      "Epoch 182/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5759 - loss: 0.3835 - precision: 0.6079 - recall: 0.4788\n",
      "Epoch 182 - Train Recall: 0.4359 - Val Recall: 0.3148\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5754 - loss: 0.3834 - precision: 0.6068 - recall: 0.4741 - val_accuracy: 0.5615 - val_loss: 0.7524 - val_precision: 0.6213 - val_recall: 0.3148\n",
      "Epoch 183/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5782 - loss: 0.3028 - precision: 0.5707 - recall: 0.6766\n",
      "Epoch 183 - Train Recall: 0.7537 - Val Recall: 0.8771\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5780 - loss: 0.3027 - precision: 0.5701 - recall: 0.6793 - val_accuracy: 0.5285 - val_loss: 0.5910 - val_precision: 0.5168 - val_recall: 0.8771\n",
      "Epoch 184/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5815 - loss: 0.3803 - precision: 0.5780 - recall: 0.5636\n",
      "Epoch 184 - Train Recall: 0.5019 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5812 - loss: 0.3802 - precision: 0.5791 - recall: 0.5582 - val_accuracy: 0.6072 - val_loss: 0.7358 - val_precision: 0.5927 - val_recall: 0.6852\n",
      "Epoch 185/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5776 - loss: 0.4075 - precision: 0.6036 - recall: 0.4104\n",
      "Epoch 185 - Train Recall: 0.3115 - Val Recall: 0.2264\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5749 - loss: 0.4078 - precision: 0.6034 - recall: 0.3984 - val_accuracy: 0.5435 - val_loss: 0.8021 - val_precision: 0.6189 - val_recall: 0.2264\n",
      "Epoch 186/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 0.3001 - precision: 0.5854 - recall: 0.7030\n",
      "Epoch 186 - Train Recall: 0.7680 - Val Recall: 0.8036\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5939 - loss: 0.3001 - precision: 0.5827 - recall: 0.7095 - val_accuracy: 0.5982 - val_loss: 0.5813 - val_precision: 0.5696 - val_recall: 0.8036\n",
      "Epoch 187/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5695 - loss: 0.3604 - precision: 0.5693 - recall: 0.6560\n",
      "Epoch 187 - Train Recall: 0.6151 - Val Recall: 0.7481\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5707 - loss: 0.3602 - precision: 0.5698 - recall: 0.6491 - val_accuracy: 0.5727 - val_loss: 0.7078 - val_precision: 0.5538 - val_recall: 0.7481\n",
      "Epoch 188/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5822 - loss: 0.3869 - precision: 0.6036 - recall: 0.4661\n",
      "Epoch 188 - Train Recall: 0.4235 - Val Recall: 0.5097\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5813 - loss: 0.3869 - precision: 0.6033 - recall: 0.4621 - val_accuracy: 0.5300 - val_loss: 0.7819 - val_precision: 0.5312 - val_recall: 0.5097\n",
      "Epoch 189/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5666 - loss: 0.3887 - precision: 0.5865 - recall: 0.4365\n",
      "Epoch 189 - Train Recall: 0.4164 - Val Recall: 0.5067\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5666 - loss: 0.3885 - precision: 0.5876 - recall: 0.4337 - val_accuracy: 0.5705 - val_loss: 0.7622 - val_precision: 0.5808 - val_recall: 0.5067\n",
      "Epoch 190/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5655 - loss: 0.3887 - precision: 0.5897 - recall: 0.4615\n",
      "Epoch 190 - Train Recall: 0.4145 - Val Recall: 0.4393\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5660 - loss: 0.3886 - precision: 0.5907 - recall: 0.4558 - val_accuracy: 0.5810 - val_loss: 0.7677 - val_precision: 0.6130 - val_recall: 0.4393\n",
      "Epoch 191/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5967 - loss: 0.3591 - precision: 0.6258 - recall: 0.5433\n",
      "Epoch 191 - Train Recall: 0.5240 - Val Recall: 0.4963\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5948 - loss: 0.3595 - precision: 0.6217 - recall: 0.5403 - val_accuracy: 0.5877 - val_loss: 0.7053 - val_precision: 0.6073 - val_recall: 0.4963\n",
      "Epoch 192/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5718 - loss: 0.3420 - precision: 0.5643 - recall: 0.5909\n",
      "Epoch 192 - Train Recall: 0.6406 - Val Recall: 0.4168\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5721 - loss: 0.3420 - precision: 0.5645 - recall: 0.5921 - val_accuracy: 0.5720 - val_loss: 0.6753 - val_precision: 0.6043 - val_recall: 0.4168\n",
      "Epoch 193/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5817 - loss: 0.2815 - precision: 0.5641 - recall: 0.7721\n",
      "Epoch 193 - Train Recall: 0.8208 - Val Recall: 0.8381\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5801 - loss: 0.2815 - precision: 0.5620 - recall: 0.7770 - val_accuracy: 0.5667 - val_loss: 0.5470 - val_precision: 0.5432 - val_recall: 0.8381\n",
      "Epoch 194/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5816 - loss: 0.3530 - precision: 0.5674 - recall: 0.6987\n",
      "Epoch 194 - Train Recall: 0.6683 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5817 - loss: 0.3530 - precision: 0.5674 - recall: 0.6985 - val_accuracy: 0.5885 - val_loss: 0.7095 - val_precision: 0.5870 - val_recall: 0.5967\n",
      "Epoch 195/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5798 - loss: 0.3306 - precision: 0.5561 - recall: 0.6718\n",
      "Epoch 195 - Train Recall: 0.6837 - Val Recall: 0.7676\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5796 - loss: 0.3308 - precision: 0.5570 - recall: 0.6733 - val_accuracy: 0.5975 - val_loss: 0.6502 - val_precision: 0.5727 - val_recall: 0.7676\n",
      "Epoch 196/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5594 - loss: 0.3729 - precision: 0.5519 - recall: 0.5816\n",
      "Epoch 196 - Train Recall: 0.5337 - Val Recall: 0.5592\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5598 - loss: 0.3728 - precision: 0.5537 - recall: 0.5759 - val_accuracy: 0.5795 - val_loss: 0.7559 - val_precision: 0.5828 - val_recall: 0.5592\n",
      "Epoch 197/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5806 - loss: 0.3618 - precision: 0.6018 - recall: 0.5289\n",
      "Epoch 197 - Train Recall: 0.5435 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5810 - loss: 0.3615 - precision: 0.6007 - recall: 0.5305 - val_accuracy: 0.5705 - val_loss: 0.7193 - val_precision: 0.5620 - val_recall: 0.6387\n",
      "Epoch 198/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5747 - loss: 0.3792 - precision: 0.5907 - recall: 0.4930\n",
      "Epoch 198 - Train Recall: 0.4603 - Val Recall: 0.4498\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5744 - loss: 0.3793 - precision: 0.5907 - recall: 0.4898 - val_accuracy: 0.5960 - val_loss: 0.7457 - val_precision: 0.6356 - val_recall: 0.4498\n",
      "Epoch 199/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5895 - loss: 0.3472 - precision: 0.5992 - recall: 0.5647\n",
      "Epoch 199 - Train Recall: 0.6004 - Val Recall: 0.5382\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5889 - loss: 0.3474 - precision: 0.5973 - recall: 0.5690 - val_accuracy: 0.5937 - val_loss: 0.6751 - val_precision: 0.6054 - val_recall: 0.5382\n",
      "Epoch 200/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6017 - loss: 0.3298 - precision: 0.6021 - recall: 0.6958\n",
      "Epoch 200 - Train Recall: 0.6893 - Val Recall: 0.7391\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5989 - loss: 0.3301 - precision: 0.5973 - recall: 0.6946 - val_accuracy: 0.5862 - val_loss: 0.6549 - val_precision: 0.5660 - val_recall: 0.7391\n",
      "Epoch 201/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5823 - loss: 0.3617 - precision: 0.5869 - recall: 0.6581\n",
      "Epoch 201 - Train Recall: 0.5926 - Val Recall: 0.3718\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5823 - loss: 0.3617 - precision: 0.5866 - recall: 0.6548 - val_accuracy: 0.5172 - val_loss: 0.7386 - val_precision: 0.5243 - val_recall: 0.3718\n",
      "Epoch 202/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5561 - loss: 0.2817 - precision: 0.5345 - recall: 0.7736\n",
      "Epoch 202 - Train Recall: 0.8358 - Val Recall: 0.8051\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5562 - loss: 0.2816 - precision: 0.5346 - recall: 0.7765 - val_accuracy: 0.5922 - val_loss: 0.5424 - val_precision: 0.5647 - val_recall: 0.8051\n",
      "Epoch 203/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5825 - loss: 0.3442 - precision: 0.5657 - recall: 0.7804\n",
      "Epoch 203 - Train Recall: 0.7151 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5824 - loss: 0.3443 - precision: 0.5657 - recall: 0.7715 - val_accuracy: 0.5840 - val_loss: 0.6957 - val_precision: 0.5805 - val_recall: 0.6057\n",
      "Epoch 204/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5753 - loss: 0.3259 - precision: 0.5474 - recall: 0.6802\n",
      "Epoch 204 - Train Recall: 0.7328 - Val Recall: 0.8186\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5760 - loss: 0.3257 - precision: 0.5489 - recall: 0.6851 - val_accuracy: 0.5870 - val_loss: 0.6264 - val_precision: 0.5594 - val_recall: 0.8186\n",
      "Epoch 205/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5779 - loss: 0.3713 - precision: 0.5716 - recall: 0.6442\n",
      "Epoch 205 - Train Recall: 0.5675 - Val Recall: 0.4228\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5780 - loss: 0.3714 - precision: 0.5726 - recall: 0.6351 - val_accuracy: 0.5697 - val_loss: 0.7311 - val_precision: 0.5987 - val_recall: 0.4228\n",
      "Epoch 206/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5854 - loss: 0.3039 - precision: 0.5728 - recall: 0.7609\n",
      "Epoch 206 - Train Recall: 0.7995 - Val Recall: 0.8591\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5840 - loss: 0.3038 - precision: 0.5702 - recall: 0.7658 - val_accuracy: 0.5802 - val_loss: 0.5931 - val_precision: 0.5515 - val_recall: 0.8591\n",
      "Epoch 207/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5804 - loss: 0.3621 - precision: 0.5811 - recall: 0.6189\n",
      "Epoch 207 - Train Recall: 0.5847 - Val Recall: 0.5007\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5803 - loss: 0.3623 - precision: 0.5808 - recall: 0.6145 - val_accuracy: 0.5832 - val_loss: 0.7138 - val_precision: 0.5996 - val_recall: 0.5007\n",
      "Epoch 208/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5755 - loss: 0.3263 - precision: 0.5620 - recall: 0.6499\n",
      "Epoch 208 - Train Recall: 0.7024 - Val Recall: 0.7481\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5757 - loss: 0.3263 - precision: 0.5622 - recall: 0.6512 - val_accuracy: 0.5750 - val_loss: 0.6465 - val_precision: 0.5557 - val_recall: 0.7481\n",
      "Epoch 209/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5591 - loss: 0.3647 - precision: 0.5535 - recall: 0.6229\n",
      "Epoch 209 - Train Recall: 0.6106 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5603 - loss: 0.3646 - precision: 0.5547 - recall: 0.6218 - val_accuracy: 0.5787 - val_loss: 0.7192 - val_precision: 0.5695 - val_recall: 0.6447\n",
      "Epoch 210/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5734 - loss: 0.3615 - precision: 0.5695 - recall: 0.5883\n",
      "Epoch 210 - Train Recall: 0.5963 - Val Recall: 0.5112\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5734 - loss: 0.3615 - precision: 0.5695 - recall: 0.5883 - val_accuracy: 0.5810 - val_loss: 0.7035 - val_precision: 0.5941 - val_recall: 0.5112\n",
      "Epoch 211/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5880 - loss: 0.3238 - precision: 0.5751 - recall: 0.7210\n",
      "Epoch 211 - Train Recall: 0.7399 - Val Recall: 0.6972\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5876 - loss: 0.3239 - precision: 0.5738 - recall: 0.7232 - val_accuracy: 0.5892 - val_loss: 0.6322 - val_precision: 0.5734 - val_recall: 0.6972\n",
      "Epoch 212/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5768 - loss: 0.3414 - precision: 0.5643 - recall: 0.7341\n",
      "Epoch 212 - Train Recall: 0.7005 - Val Recall: 0.5037\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5774 - loss: 0.3413 - precision: 0.5644 - recall: 0.7317 - val_accuracy: 0.5682 - val_loss: 0.6820 - val_precision: 0.5783 - val_recall: 0.5037\n",
      "Epoch 213/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5703 - loss: 0.2961 - precision: 0.5514 - recall: 0.7382\n",
      "Epoch 213 - Train Recall: 0.8036 - Val Recall: 0.8816\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5701 - loss: 0.2961 - precision: 0.5508 - recall: 0.7456 - val_accuracy: 0.5502 - val_loss: 0.5803 - val_precision: 0.5302 - val_recall: 0.8816\n",
      "Epoch 214/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5706 - loss: 0.3675 - precision: 0.5557 - recall: 0.6172\n",
      "Epoch 214 - Train Recall: 0.5742 - Val Recall: 0.5622\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5709 - loss: 0.3674 - precision: 0.5579 - recall: 0.6106 - val_accuracy: 0.5990 - val_loss: 0.7571 - val_precision: 0.6068 - val_recall: 0.5622\n",
      "Epoch 215/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5815 - loss: 0.3473 - precision: 0.5688 - recall: 0.6473\n",
      "Epoch 215 - Train Recall: 0.6675 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5816 - loss: 0.3473 - precision: 0.5688 - recall: 0.6476 - val_accuracy: 0.5540 - val_loss: 0.7052 - val_precision: 0.5442 - val_recall: 0.6642\n",
      "Epoch 216/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5871 - loss: 0.3511 - precision: 0.5759 - recall: 0.7081\n",
      "Epoch 216 - Train Recall: 0.6829 - Val Recall: 0.6012\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5868 - loss: 0.3508 - precision: 0.5752 - recall: 0.7053 - val_accuracy: 0.6057 - val_loss: 0.6895 - val_precision: 0.6067 - val_recall: 0.6012\n",
      "Epoch 217/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5943 - loss: 0.3267 - precision: 0.5667 - recall: 0.7264\n",
      "Epoch 217 - Train Recall: 0.7440 - Val Recall: 0.7181\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5936 - loss: 0.3268 - precision: 0.5666 - recall: 0.7280 - val_accuracy: 0.5832 - val_loss: 0.6436 - val_precision: 0.5655 - val_recall: 0.7181\n",
      "Epoch 218/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6001 - loss: 0.3408 - precision: 0.5764 - recall: 0.7104\n",
      "Epoch 218 - Train Recall: 0.6949 - Val Recall: 0.7901\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5994 - loss: 0.3409 - precision: 0.5761 - recall: 0.7098 - val_accuracy: 0.5870 - val_loss: 0.6723 - val_precision: 0.5618 - val_recall: 0.7901\n",
      "Epoch 219/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5906 - loss: 0.3698 - precision: 0.5820 - recall: 0.6431\n",
      "Epoch 219 - Train Recall: 0.5802 - Val Recall: 0.4963\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5902 - loss: 0.3701 - precision: 0.5825 - recall: 0.6373 - val_accuracy: 0.5922 - val_loss: 0.7346 - val_precision: 0.6141 - val_recall: 0.4963\n",
      "Epoch 220/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5896 - loss: 0.3221 - precision: 0.5724 - recall: 0.6389\n",
      "Epoch 220 - Train Recall: 0.7020 - Val Recall: 0.8531\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 0.3221 - precision: 0.5724 - recall: 0.6464 - val_accuracy: 0.5802 - val_loss: 0.6324 - val_precision: 0.5519 - val_recall: 0.8531\n",
      "Epoch 221/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5830 - loss: 0.3835 - precision: 0.5919 - recall: 0.5682\n",
      "Epoch 221 - Train Recall: 0.4693 - Val Recall: 0.3313\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5816 - loss: 0.3838 - precision: 0.5916 - recall: 0.5577 - val_accuracy: 0.5645 - val_loss: 0.7665 - val_precision: 0.6208 - val_recall: 0.3313\n",
      "Epoch 222/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5757 - loss: 0.2969 - precision: 0.5627 - recall: 0.7101\n",
      "Epoch 222 - Train Recall: 0.7811 - Val Recall: 0.7316\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5738 - loss: 0.2966 - precision: 0.5598 - recall: 0.7200 - val_accuracy: 0.6049 - val_loss: 0.5982 - val_precision: 0.5837 - val_recall: 0.7316\n",
      "Epoch 223/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5809 - loss: 0.3398 - precision: 0.5603 - recall: 0.7566\n",
      "Epoch 223 - Train Recall: 0.7256 - Val Recall: 0.5832\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5815 - loss: 0.3397 - precision: 0.5612 - recall: 0.7528 - val_accuracy: 0.5930 - val_loss: 0.6553 - val_precision: 0.5948 - val_recall: 0.5832\n",
      "Epoch 224/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5935 - loss: 0.3107 - precision: 0.5719 - recall: 0.7359\n",
      "Epoch 224 - Train Recall: 0.7792 - Val Recall: 0.7286\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5916 - loss: 0.3109 - precision: 0.5699 - recall: 0.7405 - val_accuracy: 0.5990 - val_loss: 0.6111 - val_precision: 0.5786 - val_recall: 0.7286\n",
      "Epoch 225/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5812 - loss: 0.3358 - precision: 0.5602 - recall: 0.7248\n",
      "Epoch 225 - Train Recall: 0.7170 - Val Recall: 0.8336\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5807 - loss: 0.3359 - precision: 0.5600 - recall: 0.7234 - val_accuracy: 0.5982 - val_loss: 0.6842 - val_precision: 0.5668 - val_recall: 0.8336\n",
      "Epoch 226/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5900 - loss: 0.3748 - precision: 0.5804 - recall: 0.6201\n",
      "Epoch 226 - Train Recall: 0.5341 - Val Recall: 0.4708\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5873 - loss: 0.3752 - precision: 0.5801 - recall: 0.6068 - val_accuracy: 0.5652 - val_loss: 0.7620 - val_precision: 0.5804 - val_recall: 0.4708\n",
      "Epoch 227/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5819 - loss: 0.3312 - precision: 0.5763 - recall: 0.6378\n",
      "Epoch 227 - Train Recall: 0.6930 - Val Recall: 0.7256\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5820 - loss: 0.3311 - precision: 0.5762 - recall: 0.6391 - val_accuracy: 0.5817 - val_loss: 0.6501 - val_precision: 0.5634 - val_recall: 0.7256\n",
      "Epoch 228/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5842 - loss: 0.3590 - precision: 0.5699 - recall: 0.7005\n",
      "Epoch 228 - Train Recall: 0.6323 - Val Recall: 0.5787\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5844 - loss: 0.3590 - precision: 0.5709 - recall: 0.6927 - val_accuracy: 0.5735 - val_loss: 0.7093 - val_precision: 0.5727 - val_recall: 0.5787\n",
      "Epoch 229/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5724 - loss: 0.3376 - precision: 0.5598 - recall: 0.6468\n",
      "Epoch 229 - Train Recall: 0.6833 - Val Recall: 0.6837\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5725 - loss: 0.3375 - precision: 0.5600 - recall: 0.6475 - val_accuracy: 0.5960 - val_loss: 0.6587 - val_precision: 0.5816 - val_recall: 0.6837\n",
      "Epoch 230/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5686 - loss: 0.3508 - precision: 0.5636 - recall: 0.6276\n",
      "Epoch 230 - Train Recall: 0.6481 - Val Recall: 0.5292\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5701 - loss: 0.3507 - precision: 0.5647 - recall: 0.6300 - val_accuracy: 0.5862 - val_loss: 0.6937 - val_precision: 0.5973 - val_recall: 0.5292\n",
      "Epoch 231/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5827 - loss: 0.3173 - precision: 0.5792 - recall: 0.7587\n",
      "Epoch 231 - Train Recall: 0.7710 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5817 - loss: 0.3172 - precision: 0.5760 - recall: 0.7608 - val_accuracy: 0.5877 - val_loss: 0.6155 - val_precision: 0.5785 - val_recall: 0.6462\n",
      "Epoch 232/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5710 - loss: 0.3211 - precision: 0.5542 - recall: 0.7167\n",
      "Epoch 232 - Train Recall: 0.7567 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5724 - loss: 0.3208 - precision: 0.5549 - recall: 0.7212 - val_accuracy: 0.5705 - val_loss: 0.6407 - val_precision: 0.5572 - val_recall: 0.6867\n",
      "Epoch 233/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5725 - loss: 0.3366 - precision: 0.5526 - recall: 0.7731\n",
      "Epoch 233 - Train Recall: 0.7627 - Val Recall: 0.7271\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5728 - loss: 0.3364 - precision: 0.5528 - recall: 0.7722 - val_accuracy: 0.5922 - val_loss: 0.6544 - val_precision: 0.5726 - val_recall: 0.7271\n",
      "Epoch 234/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5885 - loss: 0.3410 - precision: 0.5733 - recall: 0.7123\n",
      "Epoch 234 - Train Recall: 0.6897 - Val Recall: 0.7571\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5884 - loss: 0.3410 - precision: 0.5731 - recall: 0.7096 - val_accuracy: 0.5840 - val_loss: 0.6687 - val_precision: 0.5624 - val_recall: 0.7571\n",
      "Epoch 235/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5856 - loss: 0.3657 - precision: 0.5866 - recall: 0.6223\n",
      "Epoch 235 - Train Recall: 0.5618 - Val Recall: 0.6012\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5854 - loss: 0.3658 - precision: 0.5864 - recall: 0.6191 - val_accuracy: 0.5877 - val_loss: 0.7186 - val_precision: 0.5854 - val_recall: 0.6012\n",
      "Epoch 236/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5887 - loss: 0.3581 - precision: 0.5973 - recall: 0.5571\n",
      "Epoch 236 - Train Recall: 0.5412 - Val Recall: 0.6567\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5876 - loss: 0.3584 - precision: 0.5958 - recall: 0.5552 - val_accuracy: 0.5787 - val_loss: 0.7076 - val_precision: 0.5681 - val_recall: 0.6567\n",
      "Epoch 237/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5928 - loss: 0.3809 - precision: 0.6129 - recall: 0.5374\n",
      "Epoch 237 - Train Recall: 0.4659 - Val Recall: 0.4843\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5908 - loss: 0.3812 - precision: 0.6114 - recall: 0.5274 - val_accuracy: 0.5780 - val_loss: 0.7535 - val_precision: 0.5959 - val_recall: 0.4843\n",
      "Epoch 238/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5888 - loss: 0.3565 - precision: 0.5949 - recall: 0.5396\n",
      "Epoch 238 - Train Recall: 0.5540 - Val Recall: 0.6042\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5884 - loss: 0.3565 - precision: 0.5944 - recall: 0.5411 - val_accuracy: 0.5907 - val_loss: 0.7015 - val_precision: 0.5883 - val_recall: 0.6042\n",
      "Epoch 239/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5865 - loss: 0.3661 - precision: 0.6035 - recall: 0.5656\n",
      "Epoch 239 - Train Recall: 0.5180 - Val Recall: 0.4573\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5864 - loss: 0.3661 - precision: 0.6032 - recall: 0.5606 - val_accuracy: 0.5742 - val_loss: 0.7190 - val_precision: 0.5969 - val_recall: 0.4573\n",
      "Epoch 240/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5529 - loss: 0.3322 - precision: 0.5544 - recall: 0.5738\n",
      "Epoch 240 - Train Recall: 0.6612 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5546 - loss: 0.3318 - precision: 0.5549 - recall: 0.5848 - val_accuracy: 0.5915 - val_loss: 0.6642 - val_precision: 0.5905 - val_recall: 0.5967\n",
      "Epoch 241/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5925 - loss: 0.3312 - precision: 0.5912 - recall: 0.6619\n",
      "Epoch 241 - Train Recall: 0.6769 - Val Recall: 0.5457\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5918 - loss: 0.3313 - precision: 0.5890 - recall: 0.6643 - val_accuracy: 0.5900 - val_loss: 0.6665 - val_precision: 0.5987 - val_recall: 0.5457\n",
      "Epoch 242/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5816 - loss: 0.3151 - precision: 0.5700 - recall: 0.7345\n",
      "Epoch 242 - Train Recall: 0.7624 - Val Recall: 0.7466\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5817 - loss: 0.3150 - precision: 0.5688 - recall: 0.7379 - val_accuracy: 0.5900 - val_loss: 0.6145 - val_precision: 0.5685 - val_recall: 0.7466\n",
      "Epoch 243/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5919 - loss: 0.3428 - precision: 0.5717 - recall: 0.6656\n",
      "Epoch 243 - Train Recall: 0.6496 - Val Recall: 0.7436\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5917 - loss: 0.3428 - precision: 0.5719 - recall: 0.6651 - val_accuracy: 0.5930 - val_loss: 0.6807 - val_precision: 0.5714 - val_recall: 0.7436\n",
      "Epoch 244/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5936 - loss: 0.3723 - precision: 0.6040 - recall: 0.5228\n",
      "Epoch 244 - Train Recall: 0.4644 - Val Recall: 0.5292\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5916 - loss: 0.3725 - precision: 0.6037 - recall: 0.5156 - val_accuracy: 0.5877 - val_loss: 0.7290 - val_precision: 0.5993 - val_recall: 0.5292\n",
      "Epoch 245/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5842 - loss: 0.3731 - precision: 0.5974 - recall: 0.4460\n",
      "Epoch 245 - Train Recall: 0.4663 - Val Recall: 0.3928\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5838 - loss: 0.3732 - precision: 0.5986 - recall: 0.4490 - val_accuracy: 0.5720 - val_loss: 0.7270 - val_precision: 0.6121 - val_recall: 0.3928\n",
      "Epoch 246/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5670 - loss: 0.3237 - precision: 0.5635 - recall: 0.6676\n",
      "Epoch 246 - Train Recall: 0.7133 - Val Recall: 0.8126\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5678 - loss: 0.3235 - precision: 0.5630 - recall: 0.6722 - val_accuracy: 0.5825 - val_loss: 0.6334 - val_precision: 0.5565 - val_recall: 0.8126\n",
      "Epoch 247/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5689 - loss: 0.3734 - precision: 0.5752 - recall: 0.5526\n",
      "Epoch 247 - Train Recall: 0.5056 - Val Recall: 0.4588\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5700 - loss: 0.3733 - precision: 0.5770 - recall: 0.5471 - val_accuracy: 0.5870 - val_loss: 0.7334 - val_precision: 0.6169 - val_recall: 0.4588\n",
      "Epoch 248/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 0.3310 - precision: 0.5863 - recall: 0.6548\n",
      "Epoch 248 - Train Recall: 0.6739 - Val Recall: 0.6612\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5879 - loss: 0.3312 - precision: 0.5836 - recall: 0.6571 - val_accuracy: 0.5915 - val_loss: 0.6523 - val_precision: 0.5803 - val_recall: 0.6612\n",
      "Epoch 249/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5842 - loss: 0.3447 - precision: 0.5798 - recall: 0.7012\n",
      "Epoch 249 - Train Recall: 0.6570 - Val Recall: 0.5877\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5840 - loss: 0.3447 - precision: 0.5790 - recall: 0.6965 - val_accuracy: 0.6057 - val_loss: 0.6757 - val_precision: 0.6096 - val_recall: 0.5877\n",
      "Epoch 250/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5905 - loss: 0.3289 - precision: 0.5809 - recall: 0.6707\n",
      "Epoch 250 - Train Recall: 0.7155 - Val Recall: 0.7796\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5890 - loss: 0.3290 - precision: 0.5785 - recall: 0.6763 - val_accuracy: 0.5517 - val_loss: 0.6682 - val_precision: 0.5355 - val_recall: 0.7796\n",
      "Epoch 251/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5876 - loss: 0.3642 - precision: 0.5890 - recall: 0.5633\n",
      "Epoch 251 - Train Recall: 0.5229 - Val Recall: 0.1754\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5872 - loss: 0.3642 - precision: 0.5891 - recall: 0.5611 - val_accuracy: 0.5457 - val_loss: 0.7506 - val_precision: 0.6763 - val_recall: 0.1754\n",
      "Epoch 252/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5076 - loss: 0.2109 - precision: 0.5050 - recall: 0.8859\n",
      "Epoch 252 - Train Recall: 0.9685 - Val Recall: 1.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5075 - loss: 0.2096 - precision: 0.5048 - recall: 0.8955 - val_accuracy: 0.5000 - val_loss: 0.3746 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 253/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5731 - loss: 0.3626 - precision: 0.5540 - recall: 0.8067\n",
      "Epoch 253 - Train Recall: 0.6889 - Val Recall: 0.5547\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5734 - loss: 0.3619 - precision: 0.5548 - recall: 0.7927 - val_accuracy: 0.5765 - val_loss: 0.6994 - val_precision: 0.5799 - val_recall: 0.5547\n",
      "Epoch 254/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5806 - loss: 0.3131 - precision: 0.5663 - recall: 0.7460\n",
      "Epoch 254 - Train Recall: 0.7822 - Val Recall: 0.8381\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5806 - loss: 0.3131 - precision: 0.5662 - recall: 0.7462 - val_accuracy: 0.5690 - val_loss: 0.6119 - val_precision: 0.5448 - val_recall: 0.8381\n",
      "Epoch 255/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5714 - loss: 0.3623 - precision: 0.5701 - recall: 0.6741\n",
      "Epoch 255 - Train Recall: 0.6034 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5729 - loss: 0.3621 - precision: 0.5713 - recall: 0.6670 - val_accuracy: 0.6057 - val_loss: 0.7131 - val_precision: 0.5939 - val_recall: 0.6687\n",
      "Epoch 256/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5799 - loss: 0.3665 - precision: 0.6103 - recall: 0.4881\n",
      "Epoch 256 - Train Recall: 0.4813 - Val Recall: 0.7211\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5798 - loss: 0.3666 - precision: 0.6086 - recall: 0.4874 - val_accuracy: 0.6012 - val_loss: 0.7325 - val_precision: 0.5816 - val_recall: 0.7211\n",
      "Epoch 257/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5494 - loss: 0.4226 - precision: 0.5975 - recall: 0.2814\n",
      "Epoch 257 - Train Recall: 0.1945 - Val Recall: 0.3643\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5479 - loss: 0.4227 - precision: 0.5974 - recall: 0.2737 - val_accuracy: 0.5810 - val_loss: 0.8386 - val_precision: 0.6429 - val_recall: 0.3643\n",
      "Epoch 258/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5463 - loss: 0.4657 - precision: 0.6743 - recall: 0.1531\n",
      "Epoch 258 - Train Recall: 0.0956 - Val Recall: 0.0000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5456 - loss: 0.4659 - precision: 0.6737 - recall: 0.1514 - val_accuracy: 0.5000 - val_loss: 0.9142 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 259/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5721 - loss: 0.3560 - precision: 0.5967 - recall: 0.3762    \n",
      "Epoch 259 - Train Recall: 0.4873 - Val Recall: 0.5487\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5726 - loss: 0.3556 - precision: 0.5962 - recall: 0.3892 - val_accuracy: 0.5765 - val_loss: 0.6955 - val_precision: 0.5810 - val_recall: 0.5487\n",
      "Epoch 260/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5823 - loss: 0.3717 - precision: 0.5977 - recall: 0.4842\n",
      "Epoch 260 - Train Recall: 0.4625 - Val Recall: 0.2474\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5819 - loss: 0.3716 - precision: 0.5985 - recall: 0.4814 - val_accuracy: 0.5232 - val_loss: 0.7294 - val_precision: 0.5518 - val_recall: 0.2474\n",
      "Epoch 261/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5692 - loss: 0.2597 - precision: 0.5598 - recall: 0.7956\n",
      "Epoch 261 - Train Recall: 0.8864 - Val Recall: 0.8756\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5648 - loss: 0.2593 - precision: 0.5547 - recall: 0.8074 - val_accuracy: 0.5705 - val_loss: 0.5042 - val_precision: 0.5438 - val_recall: 0.8756\n",
      "Epoch 262/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5793 - loss: 0.3489 - precision: 0.5596 - recall: 0.7299\n",
      "Epoch 262 - Train Recall: 0.6582 - Val Recall: 0.6417\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5793 - loss: 0.3488 - precision: 0.5598 - recall: 0.7291 - val_accuracy: 0.6094 - val_loss: 0.6996 - val_precision: 0.6028 - val_recall: 0.6417\n",
      "Epoch 263/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 0.3444 - precision: 0.5750 - recall: 0.6677\n",
      "Epoch 263 - Train Recall: 0.6713 - Val Recall: 0.6417\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5898 - loss: 0.3444 - precision: 0.5759 - recall: 0.6674 - val_accuracy: 0.6057 - val_loss: 0.6740 - val_precision: 0.5986 - val_recall: 0.6417\n",
      "Epoch 264/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5977 - loss: 0.3415 - precision: 0.5869 - recall: 0.6934\n",
      "Epoch 264 - Train Recall: 0.6780 - Val Recall: 0.5907\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5977 - loss: 0.3415 - precision: 0.5868 - recall: 0.6933 - val_accuracy: 0.5885 - val_loss: 0.6696 - val_precision: 0.5881 - val_recall: 0.5907\n",
      "Epoch 265/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5836 - loss: 0.3261 - precision: 0.5665 - recall: 0.6734\n",
      "Epoch 265 - Train Recall: 0.6882 - Val Recall: 0.8306\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5836 - loss: 0.3261 - precision: 0.5665 - recall: 0.6737 - val_accuracy: 0.6064 - val_loss: 0.6360 - val_precision: 0.5735 - val_recall: 0.8306\n",
      "Epoch 266/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5785 - loss: 0.3832 - precision: 0.5797 - recall: 0.5632\n",
      "Epoch 266 - Train Recall: 0.4861 - Val Recall: 0.5832\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5790 - loss: 0.3831 - precision: 0.5818 - recall: 0.5553 - val_accuracy: 0.5967 - val_loss: 0.7585 - val_precision: 0.5994 - val_recall: 0.5832\n",
      "Epoch 267/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5758 - loss: 0.3819 - precision: 0.6326 - recall: 0.4303\n",
      "Epoch 267 - Train Recall: 0.3951 - Val Recall: 0.4678\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5753 - loss: 0.3819 - precision: 0.6302 - recall: 0.4263 - val_accuracy: 0.5960 - val_loss: 0.7820 - val_precision: 0.6290 - val_recall: 0.4678\n",
      "Epoch 268/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5748 - loss: 0.3779 - precision: 0.5890 - recall: 0.4619\n",
      "Epoch 268 - Train Recall: 0.4535 - Val Recall: 0.3793\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5748 - loss: 0.3780 - precision: 0.5891 - recall: 0.4618 - val_accuracy: 0.5675 - val_loss: 0.7428 - val_precision: 0.6082 - val_recall: 0.3793\n",
      "Epoch 269/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5736 - loss: 0.3245 - precision: 0.5855 - recall: 0.5582\n",
      "Epoch 269 - Train Recall: 0.6417 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5743 - loss: 0.3242 - precision: 0.5845 - recall: 0.5652 - val_accuracy: 0.6049 - val_loss: 0.6201 - val_precision: 0.6039 - val_recall: 0.6102\n",
      "Epoch 270/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6002 - loss: 0.3384 - precision: 0.5892 - recall: 0.6305\n",
      "Epoch 270 - Train Recall: 0.6477 - Val Recall: 0.6222\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6002 - loss: 0.3383 - precision: 0.5897 - recall: 0.6328 - val_accuracy: 0.5937 - val_loss: 0.6694 - val_precision: 0.5887 - val_recall: 0.6222\n",
      "Epoch 271/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5898 - loss: 0.3388 - precision: 0.5895 - recall: 0.6229\n",
      "Epoch 271 - Train Recall: 0.6196 - Val Recall: 0.7196\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5890 - loss: 0.3391 - precision: 0.5880 - recall: 0.6228 - val_accuracy: 0.5660 - val_loss: 0.6777 - val_precision: 0.5505 - val_recall: 0.7196\n",
      "Epoch 272/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5788 - loss: 0.3720 - precision: 0.6109 - recall: 0.4972\n",
      "Epoch 272 - Train Recall: 0.4738 - Val Recall: 0.5157\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5785 - loss: 0.3722 - precision: 0.6099 - recall: 0.4959 - val_accuracy: 0.5952 - val_loss: 0.7395 - val_precision: 0.6132 - val_recall: 0.5157\n",
      "Epoch 273/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5711 - loss: 0.3671 - precision: 0.5959 - recall: 0.4644\n",
      "Epoch 273 - Train Recall: 0.4891 - Val Recall: 0.4573\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5722 - loss: 0.3668 - precision: 0.5962 - recall: 0.4674 - val_accuracy: 0.5742 - val_loss: 0.7115 - val_precision: 0.5969 - val_recall: 0.4573\n",
      "Epoch 274/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5871 - loss: 0.3367 - precision: 0.5822 - recall: 0.5777\n",
      "Epoch 274 - Train Recall: 0.6166 - Val Recall: 0.7331\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5873 - loss: 0.3367 - precision: 0.5825 - recall: 0.5825 - val_accuracy: 0.5990 - val_loss: 0.6610 - val_precision: 0.5780 - val_recall: 0.7331\n",
      "Epoch 275/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5820 - loss: 0.3780 - precision: 0.5962 - recall: 0.5081\n",
      "Epoch 275 - Train Recall: 0.4816 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5816 - loss: 0.3783 - precision: 0.5965 - recall: 0.5053 - val_accuracy: 0.5802 - val_loss: 0.7585 - val_precision: 0.5757 - val_recall: 0.6102\n",
      "Epoch 276/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5683 - loss: 0.3909 - precision: 0.6025 - recall: 0.4191\n",
      "Epoch 276 - Train Recall: 0.4022 - Val Recall: 0.2609\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5684 - loss: 0.3910 - precision: 0.6026 - recall: 0.4175 - val_accuracy: 0.5442 - val_loss: 0.7723 - val_precision: 0.6021 - val_recall: 0.2609\n",
      "Epoch 277/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5753 - loss: 0.2842 - precision: 0.5547 - recall: 0.6332\n",
      "Epoch 277 - Train Recall: 0.7766 - Val Recall: 0.8936\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5742 - loss: 0.2840 - precision: 0.5538 - recall: 0.6489 - val_accuracy: 0.5667 - val_loss: 0.5436 - val_precision: 0.5403 - val_recall: 0.8936\n",
      "Epoch 278/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5804 - loss: 0.3769 - precision: 0.5724 - recall: 0.6985\n",
      "Epoch 278 - Train Recall: 0.5813 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5808 - loss: 0.3767 - precision: 0.5737 - recall: 0.6844 - val_accuracy: 0.6049 - val_loss: 0.7467 - val_precision: 0.5986 - val_recall: 0.6372\n",
      "Epoch 279/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5941 - loss: 0.3654 - precision: 0.6051 - recall: 0.5305\n",
      "Epoch 279 - Train Recall: 0.5232 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5937 - loss: 0.3654 - precision: 0.6048 - recall: 0.5301 - val_accuracy: 0.5900 - val_loss: 0.7198 - val_precision: 0.5763 - val_recall: 0.6792\n",
      "Epoch 280/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5765 - loss: 0.3934 - precision: 0.6076 - recall: 0.4081\n",
      "Epoch 280 - Train Recall: 0.3504 - Val Recall: 0.4993\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5764 - loss: 0.3934 - precision: 0.6076 - recall: 0.4077 - val_accuracy: 0.5975 - val_loss: 0.7739 - val_precision: 0.6213 - val_recall: 0.4993\n",
      "Epoch 281/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5441 - loss: 0.4142 - precision: 0.6172 - recall: 0.3022\n",
      "Epoch 281 - Train Recall: 0.2751 - Val Recall: 0.2324\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5443 - loss: 0.4142 - precision: 0.6174 - recall: 0.3019 - val_accuracy: 0.5420 - val_loss: 0.8508 - val_precision: 0.6102 - val_recall: 0.2324\n",
      "Epoch 282/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5805 - loss: 0.3247 - precision: 0.5881 - recall: 0.5437\n",
      "Epoch 282 - Train Recall: 0.6244 - Val Recall: 0.5832\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5803 - loss: 0.3245 - precision: 0.5864 - recall: 0.5525 - val_accuracy: 0.5855 - val_loss: 0.6390 - val_precision: 0.5858 - val_recall: 0.5832\n",
      "Epoch 283/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5967 - loss: 0.3367 - precision: 0.5844 - recall: 0.6600\n",
      "Epoch 283 - Train Recall: 0.6406 - Val Recall: 0.7121\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5958 - loss: 0.3369 - precision: 0.5837 - recall: 0.6577 - val_accuracy: 0.6064 - val_loss: 0.6654 - val_precision: 0.5879 - val_recall: 0.7121\n",
      "Epoch 284/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5761 - loss: 0.3675 - precision: 0.5851 - recall: 0.5186\n",
      "Epoch 284 - Train Recall: 0.4955 - Val Recall: 0.4933\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5765 - loss: 0.3675 - precision: 0.5863 - recall: 0.5165 - val_accuracy: 0.5877 - val_loss: 0.7181 - val_precision: 0.6081 - val_recall: 0.4933\n",
      "Epoch 285/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5925 - loss: 0.3471 - precision: 0.6145 - recall: 0.5558\n",
      "Epoch 285 - Train Recall: 0.5596 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5917 - loss: 0.3472 - precision: 0.6118 - recall: 0.5561 - val_accuracy: 0.5990 - val_loss: 0.6755 - val_precision: 0.5994 - val_recall: 0.5967\n",
      "Epoch 286/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5912 - loss: 0.3583 - precision: 0.6039 - recall: 0.5768\n",
      "Epoch 286 - Train Recall: 0.5525 - Val Recall: 0.5307\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5910 - loss: 0.3583 - precision: 0.6033 - recall: 0.5752 - val_accuracy: 0.5787 - val_loss: 0.7075 - val_precision: 0.5871 - val_recall: 0.5307\n",
      "Epoch 287/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5915 - loss: 0.3406 - precision: 0.5896 - recall: 0.5536\n",
      "Epoch 287 - Train Recall: 0.5870 - Val Recall: 0.6762\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5915 - loss: 0.3406 - precision: 0.5897 - recall: 0.5545 - val_accuracy: 0.5622 - val_loss: 0.6734 - val_precision: 0.5507 - val_recall: 0.6762\n",
      "Epoch 288/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5582 - loss: 0.3764 - precision: 0.5668 - recall: 0.5488\n",
      "Epoch 288 - Train Recall: 0.4940 - Val Recall: 0.5037\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5597 - loss: 0.3763 - precision: 0.5689 - recall: 0.5428 - val_accuracy: 0.5855 - val_loss: 0.7340 - val_precision: 0.6022 - val_recall: 0.5037\n",
      "Epoch 289/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5715 - loss: 0.3526 - precision: 0.5761 - recall: 0.5162\n",
      "Epoch 289 - Train Recall: 0.5603 - Val Recall: 0.5892\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5719 - loss: 0.3527 - precision: 0.5764 - recall: 0.5205 - val_accuracy: 0.6012 - val_loss: 0.6913 - val_precision: 0.6037 - val_recall: 0.5892\n",
      "Epoch 290/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5822 - loss: 0.3561 - precision: 0.5793 - recall: 0.5352\n",
      "Epoch 290 - Train Recall: 0.5461 - Val Recall: 0.3703\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5828 - loss: 0.3561 - precision: 0.5813 - recall: 0.5368 - val_accuracy: 0.5727 - val_loss: 0.7278 - val_precision: 0.6222 - val_recall: 0.3703\n",
      "Epoch 291/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.2861 - precision: 0.5815 - recall: 0.6971\n",
      "Epoch 291 - Train Recall: 0.7804 - Val Recall: 0.8591\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5938 - loss: 0.2862 - precision: 0.5779 - recall: 0.7073 - val_accuracy: 0.5607 - val_loss: 0.5705 - val_precision: 0.5380 - val_recall: 0.8591\n",
      "Epoch 292/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5793 - loss: 0.3675 - precision: 0.5653 - recall: 0.6323\n",
      "Epoch 292 - Train Recall: 0.5513 - Val Recall: 0.5772\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5789 - loss: 0.3674 - precision: 0.5668 - recall: 0.6232 - val_accuracy: 0.5892 - val_loss: 0.7177 - val_precision: 0.5914 - val_recall: 0.5772\n",
      "Epoch 293/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5773 - loss: 0.3558 - precision: 0.5803 - recall: 0.6031\n",
      "Epoch 293 - Train Recall: 0.5633 - Val Recall: 0.4333\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5772 - loss: 0.3558 - precision: 0.5802 - recall: 0.6022 - val_accuracy: 0.5607 - val_loss: 0.7084 - val_precision: 0.5815 - val_recall: 0.4333\n",
      "Epoch 294/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5938 - loss: 0.3060 - precision: 0.5818 - recall: 0.6937\n",
      "Epoch 294 - Train Recall: 0.7710 - Val Recall: 0.9265\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5925 - loss: 0.3059 - precision: 0.5790 - recall: 0.7042 - val_accuracy: 0.5285 - val_loss: 0.6025 - val_precision: 0.5159 - val_recall: 0.9265\n",
      "Epoch 295/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5862 - loss: 0.3817 - precision: 0.5828 - recall: 0.6301\n",
      "Epoch 295 - Train Recall: 0.4993 - Val Recall: 0.3748\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5849 - loss: 0.3818 - precision: 0.5840 - recall: 0.6124 - val_accuracy: 0.5735 - val_loss: 0.7469 - val_precision: 0.6219 - val_recall: 0.3748\n",
      "Epoch 296/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5844 - loss: 0.3045 - precision: 0.5715 - recall: 0.6754\n",
      "Epoch 296 - Train Recall: 0.7601 - Val Recall: 0.8486\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5842 - loss: 0.3043 - precision: 0.5702 - recall: 0.6835 - val_accuracy: 0.5210 - val_loss: 0.6052 - val_precision: 0.5127 - val_recall: 0.8486\n",
      "Epoch 297/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5754 - loss: 0.3707 - precision: 0.5606 - recall: 0.6378\n",
      "Epoch 297 - Train Recall: 0.5412 - Val Recall: 0.4573\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5757 - loss: 0.3704 - precision: 0.5635 - recall: 0.6262 - val_accuracy: 0.5810 - val_loss: 0.7289 - val_precision: 0.6076 - val_recall: 0.4573\n",
      "Epoch 298/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5877 - loss: 0.3199 - precision: 0.5787 - recall: 0.6534\n",
      "Epoch 298 - Train Recall: 0.6968 - Val Recall: 0.8456\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5871 - loss: 0.3200 - precision: 0.5771 - recall: 0.6577 - val_accuracy: 0.5787 - val_loss: 0.6257 - val_precision: 0.5513 - val_recall: 0.8456\n",
      "Epoch 299/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5744 - loss: 0.3821 - precision: 0.5763 - recall: 0.6060\n",
      "Epoch 299 - Train Recall: 0.4933 - Val Recall: 0.4393\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5745 - loss: 0.3822 - precision: 0.5783 - recall: 0.5897 - val_accuracy: 0.5900 - val_loss: 0.7548 - val_precision: 0.6288 - val_recall: 0.4393\n",
      "Epoch 300/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5898 - loss: 0.3276 - precision: 0.5693 - recall: 0.6330\n",
      "Epoch 300 - Train Recall: 0.6859 - Val Recall: 0.7316\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5896 - loss: 0.3277 - precision: 0.5693 - recall: 0.6346 - val_accuracy: 0.5952 - val_loss: 0.6385 - val_precision: 0.5748 - val_recall: 0.7316\n",
      "Epoch 301/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5732 - loss: 0.3597 - precision: 0.5616 - recall: 0.6154\n",
      "Epoch 301 - Train Recall: 0.5671 - Val Recall: 0.5052\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5736 - loss: 0.3596 - precision: 0.5639 - recall: 0.6090 - val_accuracy: 0.5585 - val_loss: 0.7624 - val_precision: 0.5654 - val_recall: 0.5052\n",
      "Epoch 302/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5817 - loss: 0.3293 - precision: 0.5664 - recall: 0.6843\n",
      "Epoch 302 - Train Recall: 0.7275 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5816 - loss: 0.3293 - precision: 0.5663 - recall: 0.6848 - val_accuracy: 0.5877 - val_loss: 0.6477 - val_precision: 0.5732 - val_recall: 0.6867\n",
      "Epoch 303/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5798 - loss: 0.3387 - precision: 0.5553 - recall: 0.6962\n",
      "Epoch 303 - Train Recall: 0.7084 - Val Recall: 0.6882\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5798 - loss: 0.3386 - precision: 0.5554 - recall: 0.6963 - val_accuracy: 0.5982 - val_loss: 0.6578 - val_precision: 0.5832 - val_recall: 0.6882\n",
      "Epoch 304/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5929 - loss: 0.3434 - precision: 0.5784 - recall: 0.7109\n",
      "Epoch 304 - Train Recall: 0.6874 - Val Recall: 0.7331\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5926 - loss: 0.3433 - precision: 0.5781 - recall: 0.7077 - val_accuracy: 0.5780 - val_loss: 0.6794 - val_precision: 0.5595 - val_recall: 0.7331\n",
      "Epoch 305/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5917 - loss: 0.3574 - precision: 0.5825 - recall: 0.6226\n",
      "Epoch 305 - Train Recall: 0.6072 - Val Recall: 0.5292\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5907 - loss: 0.3576 - precision: 0.5822 - recall: 0.6197 - val_accuracy: 0.5855 - val_loss: 0.7282 - val_precision: 0.5963 - val_recall: 0.5292\n",
      "Epoch 306/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5934 - loss: 0.3243 - precision: 0.5740 - recall: 0.6958\n",
      "Epoch 306 - Train Recall: 0.7275 - Val Recall: 0.7331\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5932 - loss: 0.3244 - precision: 0.5738 - recall: 0.6970 - val_accuracy: 0.5997 - val_loss: 0.6327 - val_precision: 0.5787 - val_recall: 0.7331\n",
      "Epoch 307/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5864 - loss: 0.3500 - precision: 0.5724 - recall: 0.7017\n",
      "Epoch 307 - Train Recall: 0.6882 - Val Recall: 0.7541\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5860 - loss: 0.3501 - precision: 0.5720 - recall: 0.6999 - val_accuracy: 0.5765 - val_loss: 0.6858 - val_precision: 0.5564 - val_recall: 0.7541\n",
      "Epoch 308/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5989 - loss: 0.3610 - precision: 0.5864 - recall: 0.6701\n",
      "Epoch 308 - Train Recall: 0.6061 - Val Recall: 0.5772\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5988 - loss: 0.3610 - precision: 0.5864 - recall: 0.6694 - val_accuracy: 0.5690 - val_loss: 0.7193 - val_precision: 0.5678 - val_recall: 0.5772\n",
      "Epoch 309/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5797 - loss: 0.3414 - precision: 0.5756 - recall: 0.6430\n",
      "Epoch 309 - Train Recall: 0.6863 - Val Recall: 0.7301\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5803 - loss: 0.3411 - precision: 0.5749 - recall: 0.6490 - val_accuracy: 0.5652 - val_loss: 0.6720 - val_precision: 0.5490 - val_recall: 0.7301\n",
      "Epoch 310/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5988 - loss: 0.3560 - precision: 0.5935 - recall: 0.6105\n",
      "Epoch 310 - Train Recall: 0.5802 - Val Recall: 0.6612\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.3562 - precision: 0.5938 - recall: 0.6081 - val_accuracy: 0.5982 - val_loss: 0.6985 - val_precision: 0.5872 - val_recall: 0.6612\n",
      "Epoch 311/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5983 - loss: 0.3669 - precision: 0.6031 - recall: 0.5338\n",
      "Epoch 311 - Train Recall: 0.5037 - Val Recall: 0.3073\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5956 - loss: 0.3674 - precision: 0.6015 - recall: 0.5304 - val_accuracy: 0.5562 - val_loss: 0.7355 - val_precision: 0.6119 - val_recall: 0.3073\n",
      "Epoch 312/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5838 - loss: 0.2742 - precision: 0.5692 - recall: 0.7497\n",
      "Epoch 312 - Train Recall: 0.8415 - Val Recall: 0.9265\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5832 - loss: 0.2741 - precision: 0.5684 - recall: 0.7524 - val_accuracy: 0.5562 - val_loss: 0.5317 - val_precision: 0.5323 - val_recall: 0.9265\n",
      "Epoch 313/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5835 - loss: 0.3665 - precision: 0.5688 - recall: 0.7143\n",
      "Epoch 313 - Train Recall: 0.6042 - Val Recall: 0.7046\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5833 - loss: 0.3665 - precision: 0.5694 - recall: 0.7072 - val_accuracy: 0.5922 - val_loss: 0.7265 - val_precision: 0.5753 - val_recall: 0.7046\n",
      "Epoch 314/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5797 - loss: 0.3743 - precision: 0.6092 - recall: 0.5096\n",
      "Epoch 314 - Train Recall: 0.4696 - Val Recall: 0.3523\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5796 - loss: 0.3743 - precision: 0.6088 - recall: 0.5082 - val_accuracy: 0.5780 - val_loss: 0.7389 - val_precision: 0.6421 - val_recall: 0.3523\n",
      "Epoch 315/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5827 - loss: 0.3051 - precision: 0.5712 - recall: 0.7116\n",
      "Epoch 315 - Train Recall: 0.7687 - Val Recall: 0.7901\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5827 - loss: 0.3051 - precision: 0.5711 - recall: 0.7119 - val_accuracy: 0.5832 - val_loss: 0.5934 - val_precision: 0.5589 - val_recall: 0.7901\n",
      "Epoch 316/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5781 - loss: 0.3533 - precision: 0.5593 - recall: 0.7185\n",
      "Epoch 316 - Train Recall: 0.6848 - Val Recall: 0.7316\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5784 - loss: 0.3531 - precision: 0.5600 - recall: 0.7136 - val_accuracy: 0.5855 - val_loss: 0.6902 - val_precision: 0.5661 - val_recall: 0.7316\n",
      "Epoch 317/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5891 - loss: 0.3591 - precision: 0.5796 - recall: 0.6810\n",
      "Epoch 317 - Train Recall: 0.6282 - Val Recall: 0.4168\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5893 - loss: 0.3590 - precision: 0.5803 - recall: 0.6745 - val_accuracy: 0.5720 - val_loss: 0.7089 - val_precision: 0.6043 - val_recall: 0.4168\n",
      "Epoch 318/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5637 - loss: 0.2882 - precision: 0.5565 - recall: 0.7764\n",
      "Epoch 318 - Train Recall: 0.8370 - Val Recall: 0.8171\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5635 - loss: 0.2875 - precision: 0.5546 - recall: 0.7840 - val_accuracy: 0.5952 - val_loss: 0.5504 - val_precision: 0.5659 - val_recall: 0.8171\n",
      "Epoch 319/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5906 - loss: 0.3415 - precision: 0.5747 - recall: 0.7524\n",
      "Epoch 319 - Train Recall: 0.7001 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5904 - loss: 0.3417 - precision: 0.5743 - recall: 0.7483 - val_accuracy: 0.6004 - val_loss: 0.6697 - val_precision: 0.5905 - val_recall: 0.6552\n",
      "Epoch 320/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6060 - loss: 0.3336 - precision: 0.5940 - recall: 0.7023\n",
      "Epoch 320 - Train Recall: 0.7043 - Val Recall: 0.7406\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6056 - loss: 0.3337 - precision: 0.5935 - recall: 0.7024 - val_accuracy: 0.6057 - val_loss: 0.6541 - val_precision: 0.5832 - val_recall: 0.7406\n",
      "Epoch 321/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5917 - loss: 0.3539 - precision: 0.5822 - recall: 0.6596\n",
      "Epoch 321 - Train Recall: 0.6357 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5917 - loss: 0.3539 - precision: 0.5822 - recall: 0.6595 - val_accuracy: 0.5825 - val_loss: 0.7021 - val_precision: 0.5821 - val_recall: 0.5847\n",
      "Epoch 322/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5796 - loss: 0.3329 - precision: 0.5752 - recall: 0.6886\n",
      "Epoch 322 - Train Recall: 0.7185 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5797 - loss: 0.3329 - precision: 0.5740 - recall: 0.6916 - val_accuracy: 0.5847 - val_loss: 0.6572 - val_precision: 0.5845 - val_recall: 0.5862\n",
      "Epoch 323/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5806 - loss: 0.3145 - precision: 0.5599 - recall: 0.7498\n",
      "Epoch 323 - Train Recall: 0.7564 - Val Recall: 0.8351\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5809 - loss: 0.3144 - precision: 0.5601 - recall: 0.7501 - val_accuracy: 0.5660 - val_loss: 0.6172 - val_precision: 0.5429 - val_recall: 0.8351\n",
      "Epoch 324/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5989 - loss: 0.3621 - precision: 0.5832 - recall: 0.7105\n",
      "Epoch 324 - Train Recall: 0.6267 - Val Recall: 0.5337\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5988 - loss: 0.3622 - precision: 0.5832 - recall: 0.7100 - val_accuracy: 0.5975 - val_loss: 0.7134 - val_precision: 0.6117 - val_recall: 0.5337\n",
      "Epoch 325/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5967 - loss: 0.3205 - precision: 0.5899 - recall: 0.6030\n",
      "Epoch 325 - Train Recall: 0.6859 - Val Recall: 0.8471\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5963 - loss: 0.3205 - precision: 0.5892 - recall: 0.6064 - val_accuracy: 0.5697 - val_loss: 0.6290 - val_precision: 0.5448 - val_recall: 0.8471\n",
      "Epoch 326/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5794 - loss: 0.3842 - precision: 0.5867 - recall: 0.6191\n",
      "Epoch 326 - Train Recall: 0.4936 - Val Recall: 0.4243\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5792 - loss: 0.3843 - precision: 0.5873 - recall: 0.6030 - val_accuracy: 0.5787 - val_loss: 0.7590 - val_precision: 0.6139 - val_recall: 0.4243\n",
      "Epoch 327/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5761 - loss: 0.3226 - precision: 0.5832 - recall: 0.5885\n",
      "Epoch 327 - Train Recall: 0.6668 - Val Recall: 0.7196\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5762 - loss: 0.3226 - precision: 0.5831 - recall: 0.5895 - val_accuracy: 0.5915 - val_loss: 0.6297 - val_precision: 0.5728 - val_recall: 0.7196\n",
      "Epoch 328/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5773 - loss: 0.3616 - precision: 0.5748 - recall: 0.6030\n",
      "Epoch 328 - Train Recall: 0.5776 - Val Recall: 0.5322\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5792 - loss: 0.3613 - precision: 0.5775 - recall: 0.5998 - val_accuracy: 0.6019 - val_loss: 0.7513 - val_precision: 0.6185 - val_recall: 0.5322\n",
      "Epoch 329/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5916 - loss: 0.3335 - precision: 0.5809 - recall: 0.6286\n",
      "Epoch 329 - Train Recall: 0.6540 - Val Recall: 0.7931\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5916 - loss: 0.3335 - precision: 0.5809 - recall: 0.6293 - val_accuracy: 0.5900 - val_loss: 0.6527 - val_precision: 0.5640 - val_recall: 0.7931\n",
      "Epoch 330/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5766 - loss: 0.3837 - precision: 0.5820 - recall: 0.5667\n",
      "Epoch 330 - Train Recall: 0.4790 - Val Recall: 0.3493\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5766 - loss: 0.3837 - precision: 0.5821 - recall: 0.5662 - val_accuracy: 0.5495 - val_loss: 0.7488 - val_precision: 0.5825 - val_recall: 0.3493\n",
      "Epoch 331/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5880 - loss: 0.2995 - precision: 0.5786 - recall: 0.6471\n",
      "Epoch 331 - Train Recall: 0.7590 - Val Recall: 0.8486\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5873 - loss: 0.2994 - precision: 0.5773 - recall: 0.6536 - val_accuracy: 0.5810 - val_loss: 0.5911 - val_precision: 0.5527 - val_recall: 0.8486\n",
      "Epoch 332/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5674 - loss: 0.3716 - precision: 0.5608 - recall: 0.6787\n",
      "Epoch 332 - Train Recall: 0.5967 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5681 - loss: 0.3713 - precision: 0.5620 - recall: 0.6700 - val_accuracy: 0.6064 - val_loss: 0.7349 - val_precision: 0.6113 - val_recall: 0.5847\n",
      "Epoch 333/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5989 - loss: 0.3430 - precision: 0.5876 - recall: 0.5913\n",
      "Epoch 333 - Train Recall: 0.6323 - Val Recall: 0.5742\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.3430 - precision: 0.5882 - recall: 0.5974 - val_accuracy: 0.5892 - val_loss: 0.6781 - val_precision: 0.5920 - val_recall: 0.5742\n",
      "Epoch 334/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5976 - loss: 0.3296 - precision: 0.5940 - recall: 0.6431\n",
      "Epoch 334 - Train Recall: 0.6458 - Val Recall: 0.6942\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5962 - loss: 0.3298 - precision: 0.5917 - recall: 0.6435 - val_accuracy: 0.5892 - val_loss: 0.6497 - val_precision: 0.5737 - val_recall: 0.6942\n",
      "Epoch 335/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5986 - loss: 0.3590 - precision: 0.5917 - recall: 0.6423\n",
      "Epoch 335 - Train Recall: 0.5746 - Val Recall: 0.5337\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5977 - loss: 0.3590 - precision: 0.5921 - recall: 0.6337 - val_accuracy: 0.5772 - val_loss: 0.7124 - val_precision: 0.5846 - val_recall: 0.5337\n",
      "Epoch 336/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5944 - loss: 0.3352 - precision: 0.5843 - recall: 0.5961\n",
      "Epoch 336 - Train Recall: 0.6567 - Val Recall: 0.8246\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5937 - loss: 0.3352 - precision: 0.5835 - recall: 0.6022 - val_accuracy: 0.5877 - val_loss: 0.6576 - val_precision: 0.5595 - val_recall: 0.8246\n",
      "Epoch 337/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5682 - loss: 0.3922 - precision: 0.5814 - recall: 0.5125\n",
      "Epoch 337 - Train Recall: 0.4232 - Val Recall: 0.4198\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5682 - loss: 0.3921 - precision: 0.5815 - recall: 0.5115 - val_accuracy: 0.5697 - val_loss: 0.7622 - val_precision: 0.5996 - val_recall: 0.4198\n",
      "Epoch 338/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 0.3466 - precision: 0.6018 - recall: 0.4882\n",
      "Epoch 338 - Train Recall: 0.5562 - Val Recall: 0.5532\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5758 - loss: 0.3465 - precision: 0.6003 - recall: 0.4949 - val_accuracy: 0.5847 - val_loss: 0.6913 - val_precision: 0.5904 - val_recall: 0.5532\n",
      "Epoch 339/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5909 - loss: 0.3456 - precision: 0.5879 - recall: 0.5830\n",
      "Epoch 339 - Train Recall: 0.6087 - Val Recall: 0.5682\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5904 - loss: 0.3458 - precision: 0.5872 - recall: 0.5869 - val_accuracy: 0.5990 - val_loss: 0.6822 - val_precision: 0.6054 - val_recall: 0.5682\n",
      "Epoch 340/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5819 - loss: 0.3357 - precision: 0.5813 - recall: 0.6734\n",
      "Epoch 340 - Train Recall: 0.6769 - Val Recall: 0.6957\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5822 - loss: 0.3356 - precision: 0.5801 - recall: 0.6740 - val_accuracy: 0.5810 - val_loss: 0.6589 - val_precision: 0.5659 - val_recall: 0.6957\n",
      "Epoch 341/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5891 - loss: 0.3507 - precision: 0.5719 - recall: 0.6245\n",
      "Epoch 341 - Train Recall: 0.6049 - Val Recall: 0.7301\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5884 - loss: 0.3507 - precision: 0.5729 - recall: 0.6221 - val_accuracy: 0.6027 - val_loss: 0.6866 - val_precision: 0.5818 - val_recall: 0.7301\n",
      "Epoch 342/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5878 - loss: 0.3763 - precision: 0.5958 - recall: 0.5278\n",
      "Epoch 342 - Train Recall: 0.4644 - Val Recall: 0.5397\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5867 - loss: 0.3768 - precision: 0.5966 - recall: 0.5192 - val_accuracy: 0.6049 - val_loss: 0.7469 - val_precision: 0.6207 - val_recall: 0.5397\n",
      "Epoch 343/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5792 - loss: 0.3728 - precision: 0.6065 - recall: 0.4751\n",
      "Epoch 343 - Train Recall: 0.4629 - Val Recall: 0.3283\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5792 - loss: 0.3728 - precision: 0.6064 - recall: 0.4745 - val_accuracy: 0.5787 - val_loss: 0.7274 - val_precision: 0.6577 - val_recall: 0.3283\n",
      "Epoch 344/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5754 - loss: 0.2965 - precision: 0.5650 - recall: 0.6532\n",
      "Epoch 344 - Train Recall: 0.7594 - Val Recall: 0.6957\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5754 - loss: 0.2964 - precision: 0.5649 - recall: 0.6544 - val_accuracy: 0.6012 - val_loss: 0.5837 - val_precision: 0.5851 - val_recall: 0.6957\n",
      "Epoch 345/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5850 - loss: 0.3321 - precision: 0.5587 - recall: 0.7771\n",
      "Epoch 345 - Train Recall: 0.7451 - Val Recall: 0.7931\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5841 - loss: 0.3323 - precision: 0.5584 - recall: 0.7734 - val_accuracy: 0.5795 - val_loss: 0.6535 - val_precision: 0.5557 - val_recall: 0.7931\n",
      "Epoch 346/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5748 - loss: 0.3577 - precision: 0.5656 - recall: 0.6878\n",
      "Epoch 346 - Train Recall: 0.6267 - Val Recall: 0.5592\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5763 - loss: 0.3575 - precision: 0.5673 - recall: 0.6802 - val_accuracy: 0.5847 - val_loss: 0.7024 - val_precision: 0.5893 - val_recall: 0.5592\n",
      "Epoch 347/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5982 - loss: 0.3252 - precision: 0.5854 - recall: 0.6931\n",
      "Epoch 347 - Train Recall: 0.7118 - Val Recall: 0.7796\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5976 - loss: 0.3255 - precision: 0.5840 - recall: 0.6963 - val_accuracy: 0.5750 - val_loss: 0.6471 - val_precision: 0.5532 - val_recall: 0.7796\n",
      "Epoch 348/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6042 - loss: 0.3586 - precision: 0.5967 - recall: 0.6428\n",
      "Epoch 348 - Train Recall: 0.5881 - Val Recall: 0.5382\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6040 - loss: 0.3587 - precision: 0.5966 - recall: 0.6419 - val_accuracy: 0.5877 - val_loss: 0.7151 - val_precision: 0.5973 - val_recall: 0.5382\n",
      "Epoch 349/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5889 - loss: 0.3330 - precision: 0.5763 - recall: 0.5781\n",
      "Epoch 349 - Train Recall: 0.6698 - Val Recall: 0.7481\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5888 - loss: 0.3330 - precision: 0.5763 - recall: 0.5786 - val_accuracy: 0.5757 - val_loss: 0.6494 - val_precision: 0.5563 - val_recall: 0.7481\n",
      "Epoch 350/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5797 - loss: 0.3661 - precision: 0.5766 - recall: 0.5983\n",
      "Epoch 350 - Train Recall: 0.5244 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5797 - loss: 0.3661 - precision: 0.5767 - recall: 0.5975 - val_accuracy: 0.6012 - val_loss: 0.7103 - val_precision: 0.6021 - val_recall: 0.5967\n",
      "Epoch 351/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5995 - loss: 0.3677 - precision: 0.6168 - recall: 0.5538\n",
      "Epoch 351 - Train Recall: 0.5109 - Val Recall: 0.5307\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5994 - loss: 0.3677 - precision: 0.6167 - recall: 0.5533 - val_accuracy: 0.6019 - val_loss: 0.7254 - val_precision: 0.6189 - val_recall: 0.5307\n",
      "Epoch 352/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5828 - loss: 0.3545 - precision: 0.6019 - recall: 0.5305\n",
      "Epoch 352 - Train Recall: 0.5457 - Val Recall: 0.6087\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5833 - loss: 0.3545 - precision: 0.6010 - recall: 0.5323 - val_accuracy: 0.5900 - val_loss: 0.6933 - val_precision: 0.5867 - val_recall: 0.6087\n",
      "Epoch 353/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5675 - loss: 0.3657 - precision: 0.5721 - recall: 0.4770\n",
      "Epoch 353 - Train Recall: 0.4888 - Val Recall: 0.5367\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5676 - loss: 0.3657 - precision: 0.5723 - recall: 0.4771 - val_accuracy: 0.5997 - val_loss: 0.7159 - val_precision: 0.6141 - val_recall: 0.5367\n",
      "Epoch 354/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5960 - loss: 0.3600 - precision: 0.6255 - recall: 0.5246\n",
      "Epoch 354 - Train Recall: 0.5120 - Val Recall: 0.5457\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5957 - loss: 0.3601 - precision: 0.6245 - recall: 0.5240 - val_accuracy: 0.6012 - val_loss: 0.7168 - val_precision: 0.6138 - val_recall: 0.5457\n",
      "Epoch 355/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5914 - loss: 0.3558 - precision: 0.6143 - recall: 0.4788\n",
      "Epoch 355 - Train Recall: 0.4921 - Val Recall: 0.5907\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5906 - loss: 0.3561 - precision: 0.6131 - recall: 0.4796 - val_accuracy: 0.6057 - val_loss: 0.6948 - val_precision: 0.6090 - val_recall: 0.5907\n",
      "Epoch 356/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5789 - loss: 0.3779 - precision: 0.5978 - recall: 0.4968\n",
      "Epoch 356 - Train Recall: 0.4490 - Val Recall: 0.3058\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5788 - loss: 0.3779 - precision: 0.5980 - recall: 0.4953 - val_accuracy: 0.5765 - val_loss: 0.8123 - val_precision: 0.6667 - val_recall: 0.3058\n",
      "Epoch 357/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5796 - loss: 0.2919 - precision: 0.5695 - recall: 0.6594\n",
      "Epoch 357 - Train Recall: 0.7717 - Val Recall: 0.7211\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5800 - loss: 0.2911 - precision: 0.5684 - recall: 0.6747 - val_accuracy: 0.5885 - val_loss: 0.5803 - val_precision: 0.5699 - val_recall: 0.7211\n",
      "Epoch 358/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5794 - loss: 0.3361 - precision: 0.5588 - recall: 0.7970\n",
      "Epoch 358 - Train Recall: 0.7485 - Val Recall: 0.6222\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5792 - loss: 0.3361 - precision: 0.5586 - recall: 0.7914 - val_accuracy: 0.5952 - val_loss: 0.6557 - val_precision: 0.5903 - val_recall: 0.6222\n",
      "Epoch 359/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5983 - loss: 0.3121 - precision: 0.5833 - recall: 0.7523\n",
      "Epoch 359 - Train Recall: 0.7635 - Val Recall: 0.9175\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5965 - loss: 0.3124 - precision: 0.5805 - recall: 0.7535 - val_accuracy: 0.5472 - val_loss: 0.6217 - val_precision: 0.5271 - val_recall: 0.9175\n",
      "Epoch 360/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5870 - loss: 0.3765 - precision: 0.5839 - recall: 0.6007\n",
      "Epoch 360 - Train Recall: 0.5019 - Val Recall: 0.5022\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5867 - loss: 0.3766 - precision: 0.5847 - recall: 0.5949 - val_accuracy: 0.5630 - val_loss: 0.7510 - val_precision: 0.5717 - val_recall: 0.5022\n",
      "Epoch 361/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5836 - loss: 0.3481 - precision: 0.5821 - recall: 0.5549\n",
      "Epoch 361 - Train Recall: 0.5982 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5840 - loss: 0.3481 - precision: 0.5823 - recall: 0.5613 - val_accuracy: 0.5765 - val_loss: 0.6841 - val_precision: 0.5735 - val_recall: 0.5967\n",
      "Epoch 362/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5971 - loss: 0.3437 - precision: 0.5888 - recall: 0.6377\n",
      "Epoch 362 - Train Recall: 0.6391 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5965 - loss: 0.3439 - precision: 0.5885 - recall: 0.6377 - val_accuracy: 0.5900 - val_loss: 0.6911 - val_precision: 0.5870 - val_recall: 0.6072\n",
      "Epoch 363/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5972 - loss: 0.3364 - precision: 0.5855 - recall: 0.6292\n",
      "Epoch 363 - Train Recall: 0.6387 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5959 - loss: 0.3366 - precision: 0.5846 - recall: 0.6313 - val_accuracy: 0.5802 - val_loss: 0.6700 - val_precision: 0.5641 - val_recall: 0.7061\n",
      "Epoch 364/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6038 - loss: 0.3610 - precision: 0.6095 - recall: 0.5511\n",
      "Epoch 364 - Train Recall: 0.5499 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6018 - loss: 0.3613 - precision: 0.6081 - recall: 0.5510 - val_accuracy: 0.5667 - val_loss: 0.7261 - val_precision: 0.5675 - val_recall: 0.5607\n",
      "Epoch 365/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5981 - loss: 0.3455 - precision: 0.6020 - recall: 0.5671\n",
      "Epoch 365 - Train Recall: 0.5746 - Val Recall: 0.7031\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5964 - loss: 0.3460 - precision: 0.6002 - recall: 0.5674 - val_accuracy: 0.5907 - val_loss: 0.6829 - val_precision: 0.5741 - val_recall: 0.7031\n",
      "Epoch 366/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5717 - loss: 0.3832 - precision: 0.5885 - recall: 0.4790\n",
      "Epoch 366 - Train Recall: 0.4599 - Val Recall: 0.4003\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5725 - loss: 0.3832 - precision: 0.5900 - recall: 0.4772 - val_accuracy: 0.5690 - val_loss: 0.7529 - val_precision: 0.6041 - val_recall: 0.4003\n",
      "Epoch 367/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5697 - loss: 0.3254 - precision: 0.5550 - recall: 0.5819\n",
      "Epoch 367 - Train Recall: 0.6795 - Val Recall: 0.7871\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5716 - loss: 0.3252 - precision: 0.5571 - recall: 0.5947 - val_accuracy: 0.5802 - val_loss: 0.6405 - val_precision: 0.5567 - val_recall: 0.7871\n",
      "Epoch 368/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5793 - loss: 0.3742 - precision: 0.5846 - recall: 0.6216\n",
      "Epoch 368 - Train Recall: 0.5304 - Val Recall: 0.5247\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5793 - loss: 0.3742 - precision: 0.5847 - recall: 0.6205 - val_accuracy: 0.5885 - val_loss: 0.7371 - val_precision: 0.6014 - val_recall: 0.5247\n",
      "Epoch 369/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5873 - loss: 0.3456 - precision: 0.6088 - recall: 0.5071\n",
      "Epoch 369 - Train Recall: 0.5765 - Val Recall: 0.4123\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5884 - loss: 0.3455 - precision: 0.6078 - recall: 0.5165 - val_accuracy: 0.5690 - val_loss: 0.6833 - val_precision: 0.6004 - val_recall: 0.4123\n",
      "Epoch 370/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5849 - loss: 0.2939 - precision: 0.5742 - recall: 0.7061\n",
      "Epoch 370 - Train Recall: 0.7961 - Val Recall: 0.8231\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5837 - loss: 0.2938 - precision: 0.5713 - recall: 0.7173 - val_accuracy: 0.5990 - val_loss: 0.5677 - val_precision: 0.5683 - val_recall: 0.8231\n",
      "Epoch 371/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5875 - loss: 0.3527 - precision: 0.5740 - recall: 0.7681\n",
      "Epoch 371 - Train Recall: 0.7005 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5873 - loss: 0.3527 - precision: 0.5736 - recall: 0.7636 - val_accuracy: 0.6087 - val_loss: 0.6936 - val_precision: 0.6061 - val_recall: 0.6207\n",
      "Epoch 372/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5871 - loss: 0.3260 - precision: 0.5739 - recall: 0.6411\n",
      "Epoch 372 - Train Recall: 0.6960 - Val Recall: 0.6912\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5872 - loss: 0.3260 - precision: 0.5738 - recall: 0.6479 - val_accuracy: 0.5997 - val_loss: 0.6343 - val_precision: 0.5843 - val_recall: 0.6912\n",
      "Epoch 373/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5992 - loss: 0.3421 - precision: 0.5780 - recall: 0.7077\n",
      "Epoch 373 - Train Recall: 0.6953 - Val Recall: 0.7331\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5988 - loss: 0.3422 - precision: 0.5778 - recall: 0.7074 - val_accuracy: 0.5997 - val_loss: 0.6748 - val_precision: 0.5787 - val_recall: 0.7331\n",
      "Epoch 374/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5759 - loss: 0.3540 - precision: 0.5648 - recall: 0.6357\n",
      "Epoch 374 - Train Recall: 0.6031 - Val Recall: 0.7016\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5760 - loss: 0.3540 - precision: 0.5649 - recall: 0.6355 - val_accuracy: 0.5900 - val_loss: 0.7081 - val_precision: 0.5735 - val_recall: 0.7016\n",
      "Epoch 375/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5873 - loss: 0.3734 - precision: 0.5838 - recall: 0.6186\n",
      "Epoch 375 - Train Recall: 0.5281 - Val Recall: 0.4363\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5865 - loss: 0.3735 - precision: 0.5846 - recall: 0.6074 - val_accuracy: 0.5787 - val_loss: 0.7336 - val_precision: 0.6101 - val_recall: 0.4363\n",
      "Epoch 376/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5843 - loss: 0.3167 - precision: 0.5772 - recall: 0.6891\n",
      "Epoch 376 - Train Recall: 0.7406 - Val Recall: 0.8321\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5841 - loss: 0.3167 - precision: 0.5766 - recall: 0.6906 - val_accuracy: 0.5750 - val_loss: 0.6167 - val_precision: 0.5495 - val_recall: 0.8321\n",
      "Epoch 377/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6036 - loss: 0.3639 - precision: 0.5917 - recall: 0.6819\n",
      "Epoch 377 - Train Recall: 0.6016 - Val Recall: 0.5742\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6020 - loss: 0.3642 - precision: 0.5912 - recall: 0.6731 - val_accuracy: 0.5997 - val_loss: 0.7207 - val_precision: 0.6051 - val_recall: 0.5742\n",
      "Epoch 378/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5790 - loss: 0.3402 - precision: 0.5723 - recall: 0.6284\n",
      "Epoch 378 - Train Recall: 0.6466 - Val Recall: 0.6312\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5794 - loss: 0.3401 - precision: 0.5725 - recall: 0.6298 - val_accuracy: 0.5832 - val_loss: 0.6910 - val_precision: 0.5759 - val_recall: 0.6312\n",
      "Epoch 379/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5734 - loss: 0.3424 - precision: 0.5553 - recall: 0.6779\n",
      "Epoch 379 - Train Recall: 0.6874 - Val Recall: 0.7271\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5744 - loss: 0.3423 - precision: 0.5566 - recall: 0.6786 - val_accuracy: 0.5885 - val_loss: 0.6706 - val_precision: 0.5692 - val_recall: 0.7271\n",
      "Epoch 380/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5792 - loss: 0.3572 - precision: 0.5588 - recall: 0.6795\n",
      "Epoch 380 - Train Recall: 0.6481 - Val Recall: 0.5142\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5797 - loss: 0.3572 - precision: 0.5602 - recall: 0.6770 - val_accuracy: 0.5825 - val_loss: 0.6988 - val_precision: 0.5955 - val_recall: 0.5142\n",
      "Epoch 381/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5820 - loss: 0.3061 - precision: 0.5667 - recall: 0.7140\n",
      "Epoch 381 - Train Recall: 0.7680 - Val Recall: 0.8321\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5819 - loss: 0.3061 - precision: 0.5664 - recall: 0.7156 - val_accuracy: 0.5757 - val_loss: 0.6027 - val_precision: 0.5500 - val_recall: 0.8321\n",
      "Epoch 382/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5987 - loss: 0.3587 - precision: 0.5857 - recall: 0.7291\n",
      "Epoch 382 - Train Recall: 0.6304 - Val Recall: 0.6177\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5984 - loss: 0.3588 - precision: 0.5856 - recall: 0.7256 - val_accuracy: 0.5900 - val_loss: 0.7152 - val_precision: 0.5852 - val_recall: 0.6177\n",
      "Epoch 383/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5951 - loss: 0.3415 - precision: 0.5992 - recall: 0.6002\n",
      "Epoch 383 - Train Recall: 0.6304 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5938 - loss: 0.3416 - precision: 0.5963 - recall: 0.6034 - val_accuracy: 0.5967 - val_loss: 0.6756 - val_precision: 0.5830 - val_recall: 0.6792\n",
      "Epoch 384/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5940 - loss: 0.3577 - precision: 0.5852 - recall: 0.6612\n",
      "Epoch 384 - Train Recall: 0.6008 - Val Recall: 0.4108\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5939 - loss: 0.3578 - precision: 0.5852 - recall: 0.6608 - val_accuracy: 0.5720 - val_loss: 0.7098 - val_precision: 0.6062 - val_recall: 0.4108\n",
      "Epoch 385/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5826 - loss: 0.2889 - precision: 0.5632 - recall: 0.7088\n",
      "Epoch 385 - Train Recall: 0.8013 - Val Recall: 0.8846\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5820 - loss: 0.2885 - precision: 0.5622 - recall: 0.7205 - val_accuracy: 0.5720 - val_loss: 0.5625 - val_precision: 0.5443 - val_recall: 0.8846\n",
      "Epoch 386/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5905 - loss: 0.3647 - precision: 0.5706 - recall: 0.7302\n",
      "Epoch 386 - Train Recall: 0.6391 - Val Recall: 0.5892\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5897 - loss: 0.3646 - precision: 0.5718 - recall: 0.7176 - val_accuracy: 0.5952 - val_loss: 0.7157 - val_precision: 0.5964 - val_recall: 0.5892\n",
      "Epoch 387/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5872 - loss: 0.3337 - precision: 0.5859 - recall: 0.6664\n",
      "Epoch 387 - Train Recall: 0.7076 - Val Recall: 0.6837\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5872 - loss: 0.3337 - precision: 0.5854 - recall: 0.6679 - val_accuracy: 0.6004 - val_loss: 0.6520 - val_precision: 0.5861 - val_recall: 0.6837\n",
      "Epoch 388/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5815 - loss: 0.3386 - precision: 0.5599 - recall: 0.7018\n",
      "Epoch 388 - Train Recall: 0.6728 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5816 - loss: 0.3386 - precision: 0.5602 - recall: 0.7011 - val_accuracy: 0.5952 - val_loss: 0.6658 - val_precision: 0.5906 - val_recall: 0.6207\n",
      "Epoch 389/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5922 - loss: 0.3307 - precision: 0.5704 - recall: 0.6618\n",
      "Epoch 389 - Train Recall: 0.6957 - Val Recall: 0.7781\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5922 - loss: 0.3307 - precision: 0.5704 - recall: 0.6624 - val_accuracy: 0.5862 - val_loss: 0.6477 - val_precision: 0.5623 - val_recall: 0.7781\n",
      "Epoch 390/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5881 - loss: 0.3639 - precision: 0.5810 - recall: 0.6010\n",
      "Epoch 390 - Train Recall: 0.5244 - Val Recall: 0.4768\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5872 - loss: 0.3641 - precision: 0.5832 - recall: 0.5893 - val_accuracy: 0.5780 - val_loss: 0.7166 - val_precision: 0.5977 - val_recall: 0.4768\n",
      "Epoch 391/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5895 - loss: 0.3290 - precision: 0.5878 - recall: 0.6185\n",
      "Epoch 391 - Train Recall: 0.6728 - Val Recall: 0.7436\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5887 - loss: 0.3292 - precision: 0.5852 - recall: 0.6259 - val_accuracy: 0.6004 - val_loss: 0.6463 - val_precision: 0.5781 - val_recall: 0.7436\n",
      "Epoch 392/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5820 - loss: 0.3647 - precision: 0.5716 - recall: 0.6502\n",
      "Epoch 392 - Train Recall: 0.5911 - Val Recall: 0.5682\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5821 - loss: 0.3647 - precision: 0.5722 - recall: 0.6469 - val_accuracy: 0.5900 - val_loss: 0.7168 - val_precision: 0.5940 - val_recall: 0.5682\n",
      "Epoch 393/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5846 - loss: 0.3378 - precision: 0.5869 - recall: 0.5678\n",
      "Epoch 393 - Train Recall: 0.6177 - Val Recall: 0.5487\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5854 - loss: 0.3379 - precision: 0.5870 - recall: 0.5739 - val_accuracy: 0.5885 - val_loss: 0.6673 - val_precision: 0.5961 - val_recall: 0.5487\n",
      "Epoch 394/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5793 - loss: 0.3268 - precision: 0.5772 - recall: 0.6308\n",
      "Epoch 394 - Train Recall: 0.6799 - Val Recall: 0.8396\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5795 - loss: 0.3267 - precision: 0.5763 - recall: 0.6367 - val_accuracy: 0.5682 - val_loss: 0.6424 - val_precision: 0.5442 - val_recall: 0.8396\n",
      "Epoch 395/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5903 - loss: 0.3843 - precision: 0.6014 - recall: 0.5777\n",
      "Epoch 395 - Train Recall: 0.4756 - Val Recall: 0.5007\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5891 - loss: 0.3843 - precision: 0.6020 - recall: 0.5635 - val_accuracy: 0.5817 - val_loss: 0.7778 - val_precision: 0.5975 - val_recall: 0.5007\n",
      "Epoch 396/2000\n",
      "\u001b[1m141/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5874 - loss: 0.3536 - precision: 0.6295 - recall: 0.4605\n",
      "Epoch 396 - Train Recall: 0.4948 - Val Recall: 0.7136\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5872 - loss: 0.3537 - precision: 0.6259 - recall: 0.4658 - val_accuracy: 0.5772 - val_loss: 0.7011 - val_precision: 0.5607 - val_recall: 0.7136\n",
      "Epoch 397/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5873 - loss: 0.4114 - precision: 0.6385 - recall: 0.4210\n",
      "Epoch 397 - Train Recall: 0.3152 - Val Recall: 0.2789\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5848 - loss: 0.4115 - precision: 0.6379 - recall: 0.4085 - val_accuracy: 0.5525 - val_loss: 0.8321 - val_precision: 0.6159 - val_recall: 0.2789\n",
      "Epoch 398/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5702 - loss: 0.3320 - precision: 0.6116 - recall: 0.4597\n",
      "Epoch 398 - Train Recall: 0.5720 - Val Recall: 0.7751\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5707 - loss: 0.3317 - precision: 0.6095 - recall: 0.4668 - val_accuracy: 0.5847 - val_loss: 0.6398 - val_precision: 0.5613 - val_recall: 0.7751\n",
      "Epoch 399/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5745 - loss: 0.4048 - precision: 0.5966 - recall: 0.4699\n",
      "Epoch 399 - Train Recall: 0.3771 - Val Recall: 0.3298\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5736 - loss: 0.4045 - precision: 0.5980 - recall: 0.4602 - val_accuracy: 0.5682 - val_loss: 0.7922 - val_precision: 0.6304 - val_recall: 0.3298\n",
      "Epoch 400/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5845 - loss: 0.3265 - precision: 0.6125 - recall: 0.5149\n",
      "Epoch 400 - Train Recall: 0.6012 - Val Recall: 0.5952\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5841 - loss: 0.3264 - precision: 0.6082 - recall: 0.5248 - val_accuracy: 0.5945 - val_loss: 0.6395 - val_precision: 0.5943 - val_recall: 0.5952\n",
      "Epoch 401/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5962 - loss: 0.3429 - precision: 0.5891 - recall: 0.5821\n",
      "Epoch 401 - Train Recall: 0.5990 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5961 - loss: 0.3430 - precision: 0.5898 - recall: 0.5842 - val_accuracy: 0.6034 - val_loss: 0.6746 - val_precision: 0.5945 - val_recall: 0.6507\n",
      "Epoch 402/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5941 - loss: 0.3588 - precision: 0.5999 - recall: 0.5391\n",
      "Epoch 402 - Train Recall: 0.5075 - Val Recall: 0.4993\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5940 - loss: 0.3588 - precision: 0.5999 - recall: 0.5385 - val_accuracy: 0.5772 - val_loss: 0.7108 - val_precision: 0.5915 - val_recall: 0.4993\n",
      "Epoch 403/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5976 - loss: 0.3396 - precision: 0.6026 - recall: 0.5745\n",
      "Epoch 403 - Train Recall: 0.5907 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5970 - loss: 0.3399 - precision: 0.6015 - recall: 0.5757 - val_accuracy: 0.5990 - val_loss: 0.6706 - val_precision: 0.5844 - val_recall: 0.6852\n",
      "Epoch 404/2000\n",
      "\u001b[1m141/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5988 - loss: 0.3702 - precision: 0.5992 - recall: 0.6081\n",
      "Epoch 404 - Train Recall: 0.5292 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5972 - loss: 0.3705 - precision: 0.5987 - recall: 0.5973 - val_accuracy: 0.5982 - val_loss: 0.7283 - val_precision: 0.6062 - val_recall: 0.5607\n",
      "Epoch 405/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5909 - loss: 0.3549 - precision: 0.6071 - recall: 0.5849\n",
      "Epoch 405 - Train Recall: 0.5652 - Val Recall: 0.3343\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5911 - loss: 0.3549 - precision: 0.6069 - recall: 0.5842 - val_accuracy: 0.5412 - val_loss: 0.7160 - val_precision: 0.5703 - val_recall: 0.3343\n",
      "Epoch 406/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5757 - loss: 0.2704 - precision: 0.5666 - recall: 0.7171\n",
      "Epoch 406 - Train Recall: 0.8313 - Val Recall: 0.8891\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5745 - loss: 0.2698 - precision: 0.5639 - recall: 0.7300 - val_accuracy: 0.5847 - val_loss: 0.5160 - val_precision: 0.5527 - val_recall: 0.8891\n",
      "Epoch 407/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5748 - loss: 0.3603 - precision: 0.5542 - recall: 0.7451\n",
      "Epoch 407 - Train Recall: 0.6807 - Val Recall: 0.5457\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5750 - loss: 0.3603 - precision: 0.5546 - recall: 0.7439 - val_accuracy: 0.6004 - val_loss: 0.7036 - val_precision: 0.6128 - val_recall: 0.5457\n",
      "Epoch 408/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5873 - loss: 0.3094 - precision: 0.5748 - recall: 0.6871\n",
      "Epoch 408 - Train Recall: 0.7376 - Val Recall: 0.8366\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5870 - loss: 0.3094 - precision: 0.5743 - recall: 0.6889 - val_accuracy: 0.5772 - val_loss: 0.6065 - val_precision: 0.5508 - val_recall: 0.8366\n",
      "Epoch 409/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5788 - loss: 0.3692 - precision: 0.5672 - recall: 0.6599\n",
      "Epoch 409 - Train Recall: 0.5862 - Val Recall: 0.6897\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5789 - loss: 0.3692 - precision: 0.5674 - recall: 0.6591 - val_accuracy: 0.5877 - val_loss: 0.7419 - val_precision: 0.5729 - val_recall: 0.6897\n",
      "Epoch 410/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5809 - loss: 0.3766 - precision: 0.6049 - recall: 0.4742\n",
      "Epoch 410 - Train Recall: 0.4749 - Val Recall: 0.5037\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5812 - loss: 0.3765 - precision: 0.6052 - recall: 0.4744 - val_accuracy: 0.6012 - val_loss: 0.7281 - val_precision: 0.6257 - val_recall: 0.5037\n",
      "Epoch 411/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6043 - loss: 0.3554 - precision: 0.6281 - recall: 0.5301\n",
      "Epoch 411 - Train Recall: 0.5199 - Val Recall: 0.5322\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6025 - loss: 0.3555 - precision: 0.6251 - recall: 0.5286 - val_accuracy: 0.5772 - val_loss: 0.7105 - val_precision: 0.5848 - val_recall: 0.5322\n",
      "Epoch 412/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5827 - loss: 0.3501 - precision: 0.5970 - recall: 0.5596\n",
      "Epoch 412 - Train Recall: 0.5686 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5828 - loss: 0.3501 - precision: 0.5970 - recall: 0.5597 - val_accuracy: 0.6034 - val_loss: 0.6846 - val_precision: 0.6021 - val_recall: 0.6102\n",
      "Epoch 413/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5912 - loss: 0.3582 - precision: 0.5974 - recall: 0.6078\n",
      "Epoch 413 - Train Recall: 0.5783 - Val Recall: 0.4828\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5909 - loss: 0.3582 - precision: 0.5968 - recall: 0.6057 - val_accuracy: 0.5772 - val_loss: 0.7001 - val_precision: 0.5952 - val_recall: 0.4828\n",
      "Epoch 414/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5854 - loss: 0.3147 - precision: 0.5912 - recall: 0.6585\n",
      "Epoch 414 - Train Recall: 0.7369 - Val Recall: 0.7526\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5844 - loss: 0.3148 - precision: 0.5873 - recall: 0.6684 - val_accuracy: 0.6034 - val_loss: 0.6190 - val_precision: 0.5797 - val_recall: 0.7526\n",
      "Epoch 415/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5845 - loss: 0.3472 - precision: 0.5690 - recall: 0.6354\n",
      "Epoch 415 - Train Recall: 0.6252 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5855 - loss: 0.3473 - precision: 0.5709 - recall: 0.6343 - val_accuracy: 0.5877 - val_loss: 0.6885 - val_precision: 0.5785 - val_recall: 0.6462\n",
      "Epoch 416/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5889 - loss: 0.3489 - precision: 0.5943 - recall: 0.6139\n",
      "Epoch 416 - Train Recall: 0.5937 - Val Recall: 0.4648\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5888 - loss: 0.3490 - precision: 0.5939 - recall: 0.6129 - val_accuracy: 0.5780 - val_loss: 0.7001 - val_precision: 0.6008 - val_recall: 0.4648\n",
      "Epoch 417/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5845 - loss: 0.3073 - precision: 0.5736 - recall: 0.6581\n",
      "Epoch 417 - Train Recall: 0.7358 - Val Recall: 0.8276\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5848 - loss: 0.3071 - precision: 0.5725 - recall: 0.6681 - val_accuracy: 0.5952 - val_loss: 0.5925 - val_precision: 0.5650 - val_recall: 0.8276\n",
      "Epoch 418/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5828 - loss: 0.3671 - precision: 0.5745 - recall: 0.7059\n",
      "Epoch 418 - Train Recall: 0.6207 - Val Recall: 0.5742\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5829 - loss: 0.3670 - precision: 0.5748 - recall: 0.6996 - val_accuracy: 0.5952 - val_loss: 0.7224 - val_precision: 0.5994 - val_recall: 0.5742\n",
      "Epoch 419/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5921 - loss: 0.3324 - precision: 0.5916 - recall: 0.5808\n",
      "Epoch 419 - Train Recall: 0.6338 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5920 - loss: 0.3324 - precision: 0.5915 - recall: 0.5814 - val_accuracy: 0.5937 - val_loss: 0.6501 - val_precision: 0.5798 - val_recall: 0.6807\n",
      "Epoch 420/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5996 - loss: 0.3545 - precision: 0.5832 - recall: 0.6214\n",
      "Epoch 420 - Train Recall: 0.5806 - Val Recall: 0.5907\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5978 - loss: 0.3551 - precision: 0.5841 - recall: 0.6158 - val_accuracy: 0.5900 - val_loss: 0.7081 - val_precision: 0.5898 - val_recall: 0.5907\n",
      "Epoch 421/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5876 - loss: 0.3472 - precision: 0.5970 - recall: 0.5451\n",
      "Epoch 421 - Train Recall: 0.5611 - Val Recall: 0.5322\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5876 - loss: 0.3472 - precision: 0.5970 - recall: 0.5453 - val_accuracy: 0.5825 - val_loss: 0.6987 - val_precision: 0.5917 - val_recall: 0.5322\n",
      "Epoch 422/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5837 - loss: 0.3374 - precision: 0.5807 - recall: 0.6014\n",
      "Epoch 422 - Train Recall: 0.6064 - Val Recall: 0.6582\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5837 - loss: 0.3374 - precision: 0.5807 - recall: 0.6015 - val_accuracy: 0.5997 - val_loss: 0.6588 - val_precision: 0.5893 - val_recall: 0.6582\n",
      "Epoch 423/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.3585 - precision: 0.5950 - recall: 0.5943\n",
      "Epoch 423 - Train Recall: 0.5499 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5963 - loss: 0.3586 - precision: 0.5952 - recall: 0.5911 - val_accuracy: 0.5975 - val_loss: 0.7110 - val_precision: 0.5890 - val_recall: 0.6447\n",
      "Epoch 424/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5879 - loss: 0.3724 - precision: 0.5992 - recall: 0.5064\n",
      "Epoch 424 - Train Recall: 0.4880 - Val Recall: 0.4798\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5868 - loss: 0.3727 - precision: 0.5995 - recall: 0.5028 - val_accuracy: 0.5862 - val_loss: 0.7469 - val_precision: 0.6095 - val_recall: 0.4798\n",
      "Epoch 425/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5840 - loss: 0.3451 - precision: 0.5994 - recall: 0.5720\n",
      "Epoch 425 - Train Recall: 0.5918 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5849 - loss: 0.3448 - precision: 0.5988 - recall: 0.5742 - val_accuracy: 0.5960 - val_loss: 0.6715 - val_precision: 0.5982 - val_recall: 0.5847\n",
      "Epoch 426/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5814 - loss: 0.3425 - precision: 0.5744 - recall: 0.5437\n",
      "Epoch 426 - Train Recall: 0.5813 - Val Recall: 0.6402\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5815 - loss: 0.3425 - precision: 0.5745 - recall: 0.5441 - val_accuracy: 0.5877 - val_loss: 0.6723 - val_precision: 0.5794 - val_recall: 0.6402\n",
      "Epoch 427/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5875 - loss: 0.3620 - precision: 0.5917 - recall: 0.5292\n",
      "Epoch 427 - Train Recall: 0.5322 - Val Recall: 0.4873\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5877 - loss: 0.3621 - precision: 0.5932 - recall: 0.5294 - val_accuracy: 0.5780 - val_loss: 0.7142 - val_precision: 0.5952 - val_recall: 0.4873\n",
      "Epoch 428/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6005 - loss: 0.3284 - precision: 0.6008 - recall: 0.5891\n",
      "Epoch 428 - Train Recall: 0.6259 - Val Recall: 0.7571\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5996 - loss: 0.3286 - precision: 0.5993 - recall: 0.5920 - val_accuracy: 0.6042 - val_loss: 0.6492 - val_precision: 0.5798 - val_recall: 0.7571\n",
      "Epoch 429/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5863 - loss: 0.3767 - precision: 0.5895 - recall: 0.5997\n",
      "Epoch 429 - Train Recall: 0.5124 - Val Recall: 0.4873\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5862 - loss: 0.3768 - precision: 0.5896 - recall: 0.5981 - val_accuracy: 0.5915 - val_loss: 0.7538 - val_precision: 0.6155 - val_recall: 0.4873\n",
      "Epoch 430/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5929 - loss: 0.3384 - precision: 0.6002 - recall: 0.5255\n",
      "Epoch 430 - Train Recall: 0.5858 - Val Recall: 0.7736\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5916 - loss: 0.3384 - precision: 0.5981 - recall: 0.5322 - val_accuracy: 0.5982 - val_loss: 0.6655 - val_precision: 0.5727 - val_recall: 0.7736\n",
      "Epoch 431/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.3930 - precision: 0.6114 - recall: 0.5901\n",
      "Epoch 431 - Train Recall: 0.4531 - Val Recall: 0.2624\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5966 - loss: 0.3932 - precision: 0.6116 - recall: 0.5732 - val_accuracy: 0.5630 - val_loss: 0.7768 - val_precision: 0.6579 - val_recall: 0.2624\n",
      "Epoch 432/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5555 - loss: 0.2758 - precision: 0.5693 - recall: 0.6595\n",
      "Epoch 432 - Train Recall: 0.8010 - Val Recall: 0.9010\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5560 - loss: 0.2750 - precision: 0.5674 - recall: 0.6695 - val_accuracy: 0.5622 - val_loss: 0.5146 - val_precision: 0.5371 - val_recall: 0.9010\n",
      "Epoch 433/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5775 - loss: 0.3717 - precision: 0.5570 - recall: 0.7463\n",
      "Epoch 433 - Train Recall: 0.6668 - Val Recall: 0.4738\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5777 - loss: 0.3716 - precision: 0.5574 - recall: 0.7444 - val_accuracy: 0.5907 - val_loss: 0.7163 - val_precision: 0.6184 - val_recall: 0.4738\n",
      "Epoch 434/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5921 - loss: 0.2945 - precision: 0.5852 - recall: 0.7159\n",
      "Epoch 434 - Train Recall: 0.7995 - Val Recall: 0.7991\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5901 - loss: 0.2941 - precision: 0.5810 - recall: 0.7271 - val_accuracy: 0.5832 - val_loss: 0.5696 - val_precision: 0.5581 - val_recall: 0.7991\n",
      "Epoch 435/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5913 - loss: 0.3449 - precision: 0.5635 - recall: 0.7599\n",
      "Epoch 435 - Train Recall: 0.7103 - Val Recall: 0.7526\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5913 - loss: 0.3449 - precision: 0.5637 - recall: 0.7591 - val_accuracy: 0.5817 - val_loss: 0.6814 - val_precision: 0.5609 - val_recall: 0.7526\n",
      "Epoch 436/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5856 - loss: 0.3543 - precision: 0.5803 - recall: 0.6396\n",
      "Epoch 436 - Train Recall: 0.6049 - Val Recall: 0.5907\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5856 - loss: 0.3543 - precision: 0.5804 - recall: 0.6393 - val_accuracy: 0.5975 - val_loss: 0.7017 - val_precision: 0.5988 - val_recall: 0.5907\n",
      "Epoch 437/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6049 - loss: 0.3373 - precision: 0.5980 - recall: 0.6487\n",
      "Epoch 437 - Train Recall: 0.6443 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6039 - loss: 0.3376 - precision: 0.5968 - recall: 0.6483 - val_accuracy: 0.6019 - val_loss: 0.6707 - val_precision: 0.5929 - val_recall: 0.6507\n",
      "Epoch 438/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5873 - loss: 0.3454 - precision: 0.5741 - recall: 0.6584\n",
      "Epoch 438 - Train Recall: 0.6368 - Val Recall: 0.5802\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5865 - loss: 0.3456 - precision: 0.5738 - recall: 0.6556 - val_accuracy: 0.6027 - val_loss: 0.6844 - val_precision: 0.6075 - val_recall: 0.5802\n",
      "Epoch 439/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5872 - loss: 0.3301 - precision: 0.5776 - recall: 0.6440\n",
      "Epoch 439 - Train Recall: 0.6912 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5870 - loss: 0.3302 - precision: 0.5770 - recall: 0.6491 - val_accuracy: 0.6019 - val_loss: 0.6501 - val_precision: 0.5934 - val_recall: 0.6477\n",
      "Epoch 440/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5793 - loss: 0.3353 - precision: 0.5644 - recall: 0.7059\n",
      "Epoch 440 - Train Recall: 0.7245 - Val Recall: 0.8156\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5798 - loss: 0.3352 - precision: 0.5645 - recall: 0.7076 - val_accuracy: 0.5772 - val_loss: 0.6569 - val_precision: 0.5523 - val_recall: 0.8156\n",
      "Epoch 441/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5956 - loss: 0.3649 - precision: 0.5926 - recall: 0.6524\n",
      "Epoch 441 - Train Recall: 0.5663 - Val Recall: 0.4228\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5945 - loss: 0.3652 - precision: 0.5925 - recall: 0.6415 - val_accuracy: 0.5855 - val_loss: 0.7182 - val_precision: 0.6267 - val_recall: 0.4228\n",
      "Epoch 442/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6048 - loss: 0.2986 - precision: 0.5954 - recall: 0.6409\n",
      "Epoch 442 - Train Recall: 0.7260 - Val Recall: 0.8231\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.2986 - precision: 0.5944 - recall: 0.6439 - val_accuracy: 0.5862 - val_loss: 0.5839 - val_precision: 0.5585 - val_recall: 0.8231\n",
      "Epoch 443/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5780 - loss: 0.3684 - precision: 0.5706 - recall: 0.6531\n",
      "Epoch 443 - Train Recall: 0.5656 - Val Recall: 0.5112\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5778 - loss: 0.3684 - precision: 0.5710 - recall: 0.6480 - val_accuracy: 0.5885 - val_loss: 0.7183 - val_precision: 0.6046 - val_recall: 0.5112\n",
      "Epoch 444/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5856 - loss: 0.3292 - precision: 0.5951 - recall: 0.5445\n",
      "Epoch 444 - Train Recall: 0.6271 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5863 - loss: 0.3291 - precision: 0.5938 - recall: 0.5547 - val_accuracy: 0.5892 - val_loss: 0.6455 - val_precision: 0.5814 - val_recall: 0.6372\n",
      "Epoch 445/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5860 - loss: 0.3475 - precision: 0.5742 - recall: 0.6757\n",
      "Epoch 445 - Train Recall: 0.6241 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5860 - loss: 0.3475 - precision: 0.5742 - recall: 0.6751 - val_accuracy: 0.5847 - val_loss: 0.6852 - val_precision: 0.5779 - val_recall: 0.6282\n",
      "Epoch 446/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6024 - loss: 0.3443 - precision: 0.6007 - recall: 0.6355\n",
      "Epoch 446 - Train Recall: 0.6297 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 0.3445 - precision: 0.5992 - recall: 0.6345 - val_accuracy: 0.5892 - val_loss: 0.6831 - val_precision: 0.5805 - val_recall: 0.6432\n",
      "Epoch 447/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5989 - loss: 0.3445 - precision: 0.5902 - recall: 0.6364\n",
      "Epoch 447 - Train Recall: 0.6383 - Val Recall: 0.4438\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5984 - loss: 0.3448 - precision: 0.5897 - recall: 0.6365 - val_accuracy: 0.5727 - val_loss: 0.6882 - val_precision: 0.5980 - val_recall: 0.4438\n",
      "Epoch 448/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5943 - loss: 0.2863 - precision: 0.5661 - recall: 0.6897\n",
      "Epoch 448 - Train Recall: 0.7860 - Val Recall: 0.8516\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5927 - loss: 0.2865 - precision: 0.5652 - recall: 0.7024 - val_accuracy: 0.5855 - val_loss: 0.5599 - val_precision: 0.5558 - val_recall: 0.8516\n",
      "Epoch 449/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5846 - loss: 0.3594 - precision: 0.5728 - recall: 0.7295\n",
      "Epoch 449 - Train Recall: 0.6391 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5847 - loss: 0.3594 - precision: 0.5729 - recall: 0.7274 - val_accuracy: 0.5930 - val_loss: 0.7042 - val_precision: 0.5912 - val_recall: 0.6027\n",
      "Epoch 450/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5883 - loss: 0.3346 - precision: 0.5857 - recall: 0.5974\n",
      "Epoch 450 - Train Recall: 0.6229 - Val Recall: 0.5187\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5895 - loss: 0.3345 - precision: 0.5865 - recall: 0.6015 - val_accuracy: 0.5900 - val_loss: 0.6755 - val_precision: 0.6049 - val_recall: 0.5187\n",
      "Epoch 451/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5935 - loss: 0.3143 - precision: 0.5756 - recall: 0.7203\n",
      "Epoch 451 - Train Recall: 0.7459 - Val Recall: 0.8441\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5935 - loss: 0.3143 - precision: 0.5755 - recall: 0.7209 - val_accuracy: 0.5652 - val_loss: 0.6196 - val_precision: 0.5419 - val_recall: 0.8441\n",
      "Epoch 452/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5890 - loss: 0.3667 - precision: 0.5800 - recall: 0.6850\n",
      "Epoch 452 - Train Recall: 0.5930 - Val Recall: 0.5127\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5881 - loss: 0.3668 - precision: 0.5798 - recall: 0.6750 - val_accuracy: 0.5937 - val_loss: 0.7150 - val_precision: 0.6118 - val_recall: 0.5127\n",
      "Epoch 453/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.3188 - precision: 0.5886 - recall: 0.6321\n",
      "Epoch 453 - Train Recall: 0.7046 - Val Recall: 0.7661\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5930 - loss: 0.3191 - precision: 0.5862 - recall: 0.6416 - val_accuracy: 0.5922 - val_loss: 0.6303 - val_precision: 0.5684 - val_recall: 0.7661\n",
      "Epoch 454/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5915 - loss: 0.3588 - precision: 0.5754 - recall: 0.6178\n",
      "Epoch 454 - Train Recall: 0.5547 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5907 - loss: 0.3589 - precision: 0.5771 - recall: 0.6101 - val_accuracy: 0.5922 - val_loss: 0.7066 - val_precision: 0.5853 - val_recall: 0.6327\n",
      "Epoch 455/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6006 - loss: 0.3654 - precision: 0.6120 - recall: 0.5406\n",
      "Epoch 455 - Train Recall: 0.5116 - Val Recall: 0.5277\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5997 - loss: 0.3655 - precision: 0.6120 - recall: 0.5373 - val_accuracy: 0.5855 - val_loss: 0.7254 - val_precision: 0.5966 - val_recall: 0.5277\n",
      "Epoch 456/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5835 - loss: 0.3506 - precision: 0.5854 - recall: 0.5486\n",
      "Epoch 456 - Train Recall: 0.5656 - Val Recall: 0.5502\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5845 - loss: 0.3506 - precision: 0.5866 - recall: 0.5499 - val_accuracy: 0.5855 - val_loss: 0.6860 - val_precision: 0.5919 - val_recall: 0.5502\n",
      "Epoch 457/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5940 - loss: 0.3384 - precision: 0.5908 - recall: 0.6124\n",
      "Epoch 457 - Train Recall: 0.6169 - Val Recall: 0.5877\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5940 - loss: 0.3384 - precision: 0.5908 - recall: 0.6124 - val_accuracy: 0.5825 - val_loss: 0.6829 - val_precision: 0.5816 - val_recall: 0.5877\n",
      "Epoch 458/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5849 - loss: 0.3388 - precision: 0.5679 - recall: 0.6135\n",
      "Epoch 458 - Train Recall: 0.6432 - Val Recall: 0.6837\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5851 - loss: 0.3387 - precision: 0.5683 - recall: 0.6142 - val_accuracy: 0.5967 - val_loss: 0.6597 - val_precision: 0.5824 - val_recall: 0.6837\n",
      "Epoch 459/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5908 - loss: 0.3529 - precision: 0.5803 - recall: 0.6128\n",
      "Epoch 459 - Train Recall: 0.5937 - Val Recall: 0.4843\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5913 - loss: 0.3530 - precision: 0.5822 - recall: 0.6101 - val_accuracy: 0.5652 - val_loss: 0.7086 - val_precision: 0.5778 - val_recall: 0.4843\n",
      "Epoch 460/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6079 - loss: 0.3107 - precision: 0.5860 - recall: 0.6701\n",
      "Epoch 460 - Train Recall: 0.7129 - Val Recall: 0.7736\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6066 - loss: 0.3108 - precision: 0.5852 - recall: 0.6760 - val_accuracy: 0.6004 - val_loss: 0.6098 - val_precision: 0.5746 - val_recall: 0.7736\n",
      "Epoch 461/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6004 - loss: 0.3585 - precision: 0.5906 - recall: 0.6974\n",
      "Epoch 461 - Train Recall: 0.6323 - Val Recall: 0.6597\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6000 - loss: 0.3586 - precision: 0.5903 - recall: 0.6928 - val_accuracy: 0.5922 - val_loss: 0.7069 - val_precision: 0.5812 - val_recall: 0.6597\n",
      "Epoch 462/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.3496 - precision: 0.5917 - recall: 0.5868\n",
      "Epoch 462 - Train Recall: 0.5967 - Val Recall: 0.6402\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5971 - loss: 0.3498 - precision: 0.5911 - recall: 0.5883 - val_accuracy: 0.6027 - val_loss: 0.6924 - val_precision: 0.5955 - val_recall: 0.6402\n",
      "Epoch 463/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5805 - loss: 0.3582 - precision: 0.5857 - recall: 0.5752\n",
      "Epoch 463 - Train Recall: 0.5495 - Val Recall: 0.4633\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5807 - loss: 0.3581 - precision: 0.5859 - recall: 0.5740 - val_accuracy: 0.5892 - val_loss: 0.7003 - val_precision: 0.6192 - val_recall: 0.4633\n",
      "Epoch 464/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5943 - loss: 0.3180 - precision: 0.5890 - recall: 0.6060\n",
      "Epoch 464 - Train Recall: 0.6758 - Val Recall: 0.8546\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5934 - loss: 0.3180 - precision: 0.5870 - recall: 0.6133 - val_accuracy: 0.5817 - val_loss: 0.6260 - val_precision: 0.5529 - val_recall: 0.8546\n",
      "Epoch 465/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5929 - loss: 0.3897 - precision: 0.5921 - recall: 0.5980\n",
      "Epoch 465 - Train Recall: 0.4955 - Val Recall: 0.4468\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5926 - loss: 0.3896 - precision: 0.5929 - recall: 0.5926 - val_accuracy: 0.5757 - val_loss: 0.7664 - val_precision: 0.6020 - val_recall: 0.4468\n",
      "Epoch 466/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5946 - loss: 0.3296 - precision: 0.6051 - recall: 0.5420\n",
      "Epoch 466 - Train Recall: 0.6334 - Val Recall: 0.6882\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5948 - loss: 0.3294 - precision: 0.6031 - recall: 0.5551 - val_accuracy: 0.5817 - val_loss: 0.6461 - val_precision: 0.5674 - val_recall: 0.6882\n",
      "Epoch 467/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5924 - loss: 0.3584 - precision: 0.5864 - recall: 0.6070\n",
      "Epoch 467 - Train Recall: 0.5768 - Val Recall: 0.4408\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5925 - loss: 0.3584 - precision: 0.5879 - recall: 0.6030 - val_accuracy: 0.5802 - val_loss: 0.7081 - val_precision: 0.6112 - val_recall: 0.4408\n",
      "Epoch 468/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6008 - loss: 0.3026 - precision: 0.5842 - recall: 0.6433\n",
      "Epoch 468 - Train Recall: 0.7283 - Val Recall: 0.8921\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5999 - loss: 0.3024 - precision: 0.5830 - recall: 0.6535 - val_accuracy: 0.5810 - val_loss: 0.5878 - val_precision: 0.5499 - val_recall: 0.8921\n",
      "Epoch 469/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5811 - loss: 0.3834 - precision: 0.5828 - recall: 0.6358\n",
      "Epoch 469 - Train Recall: 0.5120 - Val Recall: 0.3853\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5808 - loss: 0.3833 - precision: 0.5830 - recall: 0.6307 - val_accuracy: 0.5705 - val_loss: 0.7645 - val_precision: 0.6119 - val_recall: 0.3853\n",
      "Epoch 470/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5908 - loss: 0.3019 - precision: 0.5850 - recall: 0.6141\n",
      "Epoch 470 - Train Recall: 0.7290 - Val Recall: 0.7541\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5908 - loss: 0.3017 - precision: 0.5835 - recall: 0.6260 - val_accuracy: 0.5982 - val_loss: 0.5840 - val_precision: 0.5749 - val_recall: 0.7541\n",
      "Epoch 471/2000\n",
      "\u001b[1m141/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6012 - loss: 0.3484 - precision: 0.5786 - recall: 0.7431\n",
      "Epoch 471 - Train Recall: 0.6499 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6003 - loss: 0.3486 - precision: 0.5793 - recall: 0.7290 - val_accuracy: 0.5997 - val_loss: 0.6902 - val_precision: 0.5912 - val_recall: 0.6462\n",
      "Epoch 472/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5979 - loss: 0.3426 - precision: 0.5989 - recall: 0.6432\n",
      "Epoch 472 - Train Recall: 0.6323 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5973 - loss: 0.3427 - precision: 0.5974 - recall: 0.6423 - val_accuracy: 0.5907 - val_loss: 0.6736 - val_precision: 0.5787 - val_recall: 0.6672\n",
      "Epoch 473/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5864 - loss: 0.3531 - precision: 0.5941 - recall: 0.6073\n",
      "Epoch 473 - Train Recall: 0.5885 - Val Recall: 0.4858\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5872 - loss: 0.3531 - precision: 0.5935 - recall: 0.6048 - val_accuracy: 0.5870 - val_loss: 0.6973 - val_precision: 0.6090 - val_recall: 0.4858\n",
      "Epoch 474/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5973 - loss: 0.3134 - precision: 0.5878 - recall: 0.6733\n",
      "Epoch 474 - Train Recall: 0.7129 - Val Recall: 0.7646\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5969 - loss: 0.3134 - precision: 0.5872 - recall: 0.6744 - val_accuracy: 0.6049 - val_loss: 0.6059 - val_precision: 0.5795 - val_recall: 0.7646\n",
      "Epoch 475/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5881 - loss: 0.3581 - precision: 0.5702 - recall: 0.6296\n",
      "Epoch 475 - Train Recall: 0.5787 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5881 - loss: 0.3581 - precision: 0.5715 - recall: 0.6259 - val_accuracy: 0.6102 - val_loss: 0.7040 - val_precision: 0.6099 - val_recall: 0.6117\n",
      "Epoch 476/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5980 - loss: 0.3530 - precision: 0.6073 - recall: 0.5612\n",
      "Epoch 476 - Train Recall: 0.5431 - Val Recall: 0.6222\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5979 - loss: 0.3530 - precision: 0.6071 - recall: 0.5610 - val_accuracy: 0.5982 - val_loss: 0.6985 - val_precision: 0.5937 - val_recall: 0.6222\n",
      "Epoch 477/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6007 - loss: 0.3652 - precision: 0.6074 - recall: 0.5012\n",
      "Epoch 477 - Train Recall: 0.4753 - Val Recall: 0.5562\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5989 - loss: 0.3656 - precision: 0.6076 - recall: 0.4983 - val_accuracy: 0.5832 - val_loss: 0.7318 - val_precision: 0.5880 - val_recall: 0.5562\n",
      "Epoch 478/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5818 - loss: 0.3733 - precision: 0.6096 - recall: 0.4561\n",
      "Epoch 478 - Train Recall: 0.4453 - Val Recall: 0.3973\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5819 - loss: 0.3733 - precision: 0.6098 - recall: 0.4558 - val_accuracy: 0.5600 - val_loss: 0.7406 - val_precision: 0.5889 - val_recall: 0.3973\n",
      "Epoch 479/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5806 - loss: 0.3271 - precision: 0.5698 - recall: 0.5774\n",
      "Epoch 479 - Train Recall: 0.6503 - Val Recall: 0.6777\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5810 - loss: 0.3271 - precision: 0.5702 - recall: 0.5816 - val_accuracy: 0.5952 - val_loss: 0.6401 - val_precision: 0.5817 - val_recall: 0.6777\n",
      "Epoch 480/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5967 - loss: 0.3496 - precision: 0.5837 - recall: 0.6489\n",
      "Epoch 480 - Train Recall: 0.6038 - Val Recall: 0.4828\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5966 - loss: 0.3496 - precision: 0.5837 - recall: 0.6483 - val_accuracy: 0.5840 - val_loss: 0.6874 - val_precision: 0.6053 - val_recall: 0.4828\n",
      "Epoch 481/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5981 - loss: 0.3074 - precision: 0.5864 - recall: 0.6883\n",
      "Epoch 481 - Train Recall: 0.7380 - Val Recall: 0.8336\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5980 - loss: 0.3074 - precision: 0.5862 - recall: 0.6889 - val_accuracy: 0.5690 - val_loss: 0.6086 - val_precision: 0.5451 - val_recall: 0.8336\n",
      "Epoch 482/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5866 - loss: 0.3678 - precision: 0.5825 - recall: 0.6547\n",
      "Epoch 482 - Train Recall: 0.5723 - Val Recall: 0.5097\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5867 - loss: 0.3678 - precision: 0.5827 - recall: 0.6537 - val_accuracy: 0.6019 - val_loss: 0.7164 - val_precision: 0.6250 - val_recall: 0.5097\n",
      "Epoch 483/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5878 - loss: 0.3262 - precision: 0.6001 - recall: 0.5595\n",
      "Epoch 483 - Train Recall: 0.6038 - Val Recall: 0.6972\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5879 - loss: 0.3263 - precision: 0.5993 - recall: 0.5625 - val_accuracy: 0.5975 - val_loss: 0.6391 - val_precision: 0.5813 - val_recall: 0.6972\n",
      "Epoch 484/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5883 - loss: 0.3698 - precision: 0.5931 - recall: 0.5743\n",
      "Epoch 484 - Train Recall: 0.5221 - Val Recall: 0.5562\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5882 - loss: 0.3698 - precision: 0.5931 - recall: 0.5734 - val_accuracy: 0.5862 - val_loss: 0.7307 - val_precision: 0.5917 - val_recall: 0.5562\n",
      "Epoch 485/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5871 - loss: 0.3546 - precision: 0.5928 - recall: 0.4783\n",
      "Epoch 485 - Train Recall: 0.5195 - Val Recall: 0.5127\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5868 - loss: 0.3547 - precision: 0.5935 - recall: 0.4835 - val_accuracy: 0.5735 - val_loss: 0.6980 - val_precision: 0.5836 - val_recall: 0.5127\n",
      "Epoch 486/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5818 - loss: 0.3426 - precision: 0.5894 - recall: 0.5811\n",
      "Epoch 486 - Train Recall: 0.5937 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5822 - loss: 0.3425 - precision: 0.5893 - recall: 0.5819 - val_accuracy: 0.5810 - val_loss: 0.6748 - val_precision: 0.5844 - val_recall: 0.5607\n",
      "Epoch 487/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5907 - loss: 0.3346 - precision: 0.5868 - recall: 0.6255\n",
      "Epoch 487 - Train Recall: 0.6533 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5907 - loss: 0.3346 - precision: 0.5865 - recall: 0.6267 - val_accuracy: 0.6027 - val_loss: 0.6615 - val_precision: 0.5961 - val_recall: 0.6372\n",
      "Epoch 488/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5820 - loss: 0.3404 - precision: 0.5721 - recall: 0.6073\n",
      "Epoch 488 - Train Recall: 0.6229 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5821 - loss: 0.3404 - precision: 0.5722 - recall: 0.6074 - val_accuracy: 0.5930 - val_loss: 0.6685 - val_precision: 0.5859 - val_recall: 0.6342\n",
      "Epoch 489/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5881 - loss: 0.3472 - precision: 0.5895 - recall: 0.6508\n",
      "Epoch 489 - Train Recall: 0.6424 - Val Recall: 0.5412\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5886 - loss: 0.3472 - precision: 0.5886 - recall: 0.6501 - val_accuracy: 0.5885 - val_loss: 0.6822 - val_precision: 0.5977 - val_recall: 0.5412\n",
      "Epoch 490/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5868 - loss: 0.3160 - precision: 0.5689 - recall: 0.6620\n",
      "Epoch 490 - Train Recall: 0.7226 - Val Recall: 0.8426\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5869 - loss: 0.3160 - precision: 0.5688 - recall: 0.6698 - val_accuracy: 0.5877 - val_loss: 0.6272 - val_precision: 0.5581 - val_recall: 0.8426\n",
      "Epoch 491/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5920 - loss: 0.3699 - precision: 0.5841 - recall: 0.6557\n",
      "Epoch 491 - Train Recall: 0.5517 - Val Recall: 0.5232\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5918 - loss: 0.3699 - precision: 0.5844 - recall: 0.6527 - val_accuracy: 0.5825 - val_loss: 0.7289 - val_precision: 0.5935 - val_recall: 0.5232\n",
      "Epoch 492/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5826 - loss: 0.3349 - precision: 0.5803 - recall: 0.5736\n",
      "Epoch 492 - Train Recall: 0.5971 - Val Recall: 0.7406\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5826 - loss: 0.3349 - precision: 0.5802 - recall: 0.5753 - val_accuracy: 0.5982 - val_loss: 0.6621 - val_precision: 0.5764 - val_recall: 0.7406\n",
      "Epoch 493/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5844 - loss: 0.3826 - precision: 0.5807 - recall: 0.5068\n",
      "Epoch 493 - Train Recall: 0.4625 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5843 - loss: 0.3826 - precision: 0.5811 - recall: 0.5060 - val_accuracy: 0.6042 - val_loss: 0.7568 - val_precision: 0.5894 - val_recall: 0.6867\n",
      "Epoch 494/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5680 - loss: 0.4165 - precision: 0.6137 - recall: 0.3844\n",
      "Epoch 494 - Train Recall: 0.3047 - Val Recall: 0.2399\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5679 - loss: 0.4165 - precision: 0.6139 - recall: 0.3835 - val_accuracy: 0.5525 - val_loss: 0.8268 - val_precision: 0.6400 - val_recall: 0.2399\n",
      "Epoch 495/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5739 - loss: 0.3142 - precision: 0.5974 - recall: 0.4974\n",
      "Epoch 495 - Train Recall: 0.6424 - Val Recall: 0.7346\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5745 - loss: 0.3138 - precision: 0.5959 - recall: 0.5066 - val_accuracy: 0.5922 - val_loss: 0.5999 - val_precision: 0.5718 - val_recall: 0.7346\n",
      "Epoch 496/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5976 - loss: 0.3657 - precision: 0.5885 - recall: 0.6392\n",
      "Epoch 496 - Train Recall: 0.5780 - Val Recall: 0.4813\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5974 - loss: 0.3658 - precision: 0.5887 - recall: 0.6370 - val_accuracy: 0.5802 - val_loss: 0.7230 - val_precision: 0.6000 - val_recall: 0.4813\n",
      "Epoch 497/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5906 - loss: 0.3134 - precision: 0.5797 - recall: 0.6208\n",
      "Epoch 497 - Train Recall: 0.6825 - Val Recall: 0.7541\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5906 - loss: 0.3134 - precision: 0.5796 - recall: 0.6219 - val_accuracy: 0.5937 - val_loss: 0.6205 - val_precision: 0.5709 - val_recall: 0.7541\n",
      "Epoch 498/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6064 - loss: 0.3598 - precision: 0.6018 - recall: 0.6810\n",
      "Epoch 498 - Train Recall: 0.6173 - Val Recall: 0.5427\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6063 - loss: 0.3599 - precision: 0.6017 - recall: 0.6806 - val_accuracy: 0.5855 - val_loss: 0.7122 - val_precision: 0.5934 - val_recall: 0.5427\n",
      "Epoch 499/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5997 - loss: 0.3240 - precision: 0.6068 - recall: 0.6159\n",
      "Epoch 499 - Train Recall: 0.6653 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5984 - loss: 0.3240 - precision: 0.6031 - recall: 0.6224 - val_accuracy: 0.6034 - val_loss: 0.6330 - val_precision: 0.5887 - val_recall: 0.6867\n",
      "Epoch 500/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 0.3480 - precision: 0.5974 - recall: 0.6836\n",
      "Epoch 500 - Train Recall: 0.6331 - Val Recall: 0.5667\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6010 - loss: 0.3481 - precision: 0.5965 - recall: 0.6804 - val_accuracy: 0.5915 - val_loss: 0.6878 - val_precision: 0.5962 - val_recall: 0.5667\n",
      "Epoch 501/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5933 - loss: 0.3248 - precision: 0.5904 - recall: 0.6506\n",
      "Epoch 501 - Train Recall: 0.6709 - Val Recall: 0.7436\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5932 - loss: 0.3248 - precision: 0.5901 - recall: 0.6512 - val_accuracy: 0.5862 - val_loss: 0.6391 - val_precision: 0.5656 - val_recall: 0.7436\n",
      "Epoch 502/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5858 - loss: 0.3609 - precision: 0.5824 - recall: 0.6125\n",
      "Epoch 502 - Train Recall: 0.5840 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5860 - loss: 0.3609 - precision: 0.5828 - recall: 0.6113 - val_accuracy: 0.5945 - val_loss: 0.7184 - val_precision: 0.5877 - val_recall: 0.6327\n",
      "Epoch 503/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5719 - loss: 0.3609 - precision: 0.5798 - recall: 0.5073\n",
      "Epoch 503 - Train Recall: 0.5277 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5721 - loss: 0.3608 - precision: 0.5800 - recall: 0.5077 - val_accuracy: 0.5870 - val_loss: 0.7084 - val_precision: 0.5918 - val_recall: 0.5607\n",
      "Epoch 504/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5888 - loss: 0.3555 - precision: 0.5968 - recall: 0.5397\n",
      "Epoch 504 - Train Recall: 0.5439 - Val Recall: 0.4663\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5889 - loss: 0.3555 - precision: 0.5971 - recall: 0.5401 - val_accuracy: 0.5847 - val_loss: 0.7028 - val_precision: 0.6110 - val_recall: 0.4663\n",
      "Epoch 505/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5849 - loss: 0.3193 - precision: 0.5743 - recall: 0.6675\n",
      "Epoch 505 - Train Recall: 0.7065 - Val Recall: 0.8021\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5848 - loss: 0.3192 - precision: 0.5741 - recall: 0.6689 - val_accuracy: 0.5825 - val_loss: 0.6265 - val_precision: 0.5573 - val_recall: 0.8021\n",
      "Epoch 506/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5874 - loss: 0.3649 - precision: 0.5829 - recall: 0.5831\n",
      "Epoch 506 - Train Recall: 0.5270 - Val Recall: 0.4183\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5874 - loss: 0.3649 - precision: 0.5831 - recall: 0.5825 - val_accuracy: 0.5645 - val_loss: 0.7271 - val_precision: 0.5911 - val_recall: 0.4183\n",
      "Epoch 507/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5858 - loss: 0.3095 - precision: 0.5885 - recall: 0.6579\n",
      "Epoch 507 - Train Recall: 0.7249 - Val Recall: 0.7136\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5858 - loss: 0.3094 - precision: 0.5876 - recall: 0.6606 - val_accuracy: 0.5990 - val_loss: 0.6003 - val_precision: 0.5805 - val_recall: 0.7136\n",
      "Epoch 508/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 0.3411 - precision: 0.5735 - recall: 0.7340\n",
      "Epoch 508 - Train Recall: 0.6990 - Val Recall: 0.7076\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5893 - loss: 0.3411 - precision: 0.5734 - recall: 0.7320 - val_accuracy: 0.5795 - val_loss: 0.6777 - val_precision: 0.5632 - val_recall: 0.7076\n",
      "Epoch 509/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5944 - loss: 0.3450 - precision: 0.5859 - recall: 0.6657\n",
      "Epoch 509 - Train Recall: 0.6417 - Val Recall: 0.7166\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 0.3450 - precision: 0.5859 - recall: 0.6643 - val_accuracy: 0.5862 - val_loss: 0.6818 - val_precision: 0.5684 - val_recall: 0.7166\n",
      "Epoch 510/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5899 - loss: 0.3626 - precision: 0.5885 - recall: 0.5754\n",
      "Epoch 510 - Train Recall: 0.5289 - Val Recall: 0.5172\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5898 - loss: 0.3626 - precision: 0.5886 - recall: 0.5743 - val_accuracy: 0.5877 - val_loss: 0.7212 - val_precision: 0.6021 - val_recall: 0.5172\n",
      "Epoch 511/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5959 - loss: 0.3386 - precision: 0.5976 - recall: 0.6090\n",
      "Epoch 511 - Train Recall: 0.6353 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5957 - loss: 0.3386 - precision: 0.5971 - recall: 0.6102 - val_accuracy: 0.6019 - val_loss: 0.6662 - val_precision: 0.5899 - val_recall: 0.6687\n",
      "Epoch 512/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 0.3507 - precision: 0.6097 - recall: 0.6370\n",
      "Epoch 512 - Train Recall: 0.5915 - Val Recall: 0.6417\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6022 - loss: 0.3508 - precision: 0.6085 - recall: 0.6346 - val_accuracy: 0.5840 - val_loss: 0.6962 - val_precision: 0.5753 - val_recall: 0.6417\n",
      "Epoch 513/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5765 - loss: 0.3550 - precision: 0.5826 - recall: 0.5366\n",
      "Epoch 513 - Train Recall: 0.5371 - Val Recall: 0.5802\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5769 - loss: 0.3554 - precision: 0.5834 - recall: 0.5363 - val_accuracy: 0.6072 - val_loss: 0.6981 - val_precision: 0.6133 - val_recall: 0.5802\n",
      "Epoch 514/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 0.3559 - precision: 0.6163 - recall: 0.5625\n",
      "Epoch 514 - Train Recall: 0.5499 - Val Recall: 0.5382\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 0.3560 - precision: 0.6154 - recall: 0.5618 - val_accuracy: 0.5652 - val_loss: 0.7170 - val_precision: 0.5689 - val_recall: 0.5382\n",
      "Epoch 515/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5957 - loss: 0.3400 - precision: 0.5891 - recall: 0.6191\n",
      "Epoch 515 - Train Recall: 0.6151 - Val Recall: 0.6927\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5950 - loss: 0.3403 - precision: 0.5885 - recall: 0.6187 - val_accuracy: 0.6034 - val_loss: 0.6683 - val_precision: 0.5878 - val_recall: 0.6927\n",
      "Epoch 516/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5861 - loss: 0.3671 - precision: 0.5848 - recall: 0.5548\n",
      "Epoch 516 - Train Recall: 0.5409 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5860 - loss: 0.3670 - precision: 0.5852 - recall: 0.5541 - val_accuracy: 0.6094 - val_loss: 0.7156 - val_precision: 0.6034 - val_recall: 0.6387\n",
      "Epoch 517/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5981 - loss: 0.3696 - precision: 0.6114 - recall: 0.5241\n",
      "Epoch 517 - Train Recall: 0.5056 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5979 - loss: 0.3697 - precision: 0.6113 - recall: 0.5238 - val_accuracy: 0.5990 - val_loss: 0.7363 - val_precision: 0.6071 - val_recall: 0.5607\n",
      "Epoch 518/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5897 - loss: 0.3612 - precision: 0.6001 - recall: 0.5027\n",
      "Epoch 518 - Train Recall: 0.5210 - Val Recall: 0.4693\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5896 - loss: 0.3613 - precision: 0.6001 - recall: 0.5030 - val_accuracy: 0.5892 - val_loss: 0.7112 - val_precision: 0.6174 - val_recall: 0.4693\n",
      "Epoch 519/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5782 - loss: 0.3285 - precision: 0.5706 - recall: 0.5781\n",
      "Epoch 519 - Train Recall: 0.6563 - Val Recall: 0.7106\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5782 - loss: 0.3285 - precision: 0.5706 - recall: 0.5786 - val_accuracy: 0.5945 - val_loss: 0.6411 - val_precision: 0.5766 - val_recall: 0.7106\n",
      "Epoch 520/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.3541 - precision: 0.5853 - recall: 0.6194\n",
      "Epoch 520 - Train Recall: 0.5720 - Val Recall: 0.5457\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5942 - loss: 0.3541 - precision: 0.5854 - recall: 0.6188 - val_accuracy: 0.5922 - val_loss: 0.6993 - val_precision: 0.6017 - val_recall: 0.5457\n",
      "Epoch 521/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5993 - loss: 0.3338 - precision: 0.5994 - recall: 0.6371\n",
      "Epoch 521 - Train Recall: 0.6477 - Val Recall: 0.6252\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5989 - loss: 0.3339 - precision: 0.5986 - recall: 0.6376 - val_accuracy: 0.5877 - val_loss: 0.6688 - val_precision: 0.5816 - val_recall: 0.6252\n",
      "Epoch 522/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6082 - loss: 0.3348 - precision: 0.5922 - recall: 0.6851\n",
      "Epoch 522 - Train Recall: 0.6844 - Val Recall: 0.6957\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6071 - loss: 0.3351 - precision: 0.5915 - recall: 0.6851 - val_accuracy: 0.6057 - val_loss: 0.6652 - val_precision: 0.5896 - val_recall: 0.6957\n",
      "Epoch 523/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5895 - loss: 0.3459 - precision: 0.5774 - recall: 0.6778\n",
      "Epoch 523 - Train Recall: 0.6316 - Val Recall: 0.6012\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5899 - loss: 0.3459 - precision: 0.5784 - recall: 0.6721 - val_accuracy: 0.5952 - val_loss: 0.6800 - val_precision: 0.5941 - val_recall: 0.6012\n",
      "Epoch 524/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6033 - loss: 0.3343 - precision: 0.6066 - recall: 0.6391\n",
      "Epoch 524 - Train Recall: 0.6428 - Val Recall: 0.6597\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6032 - loss: 0.3343 - precision: 0.6065 - recall: 0.6391 - val_accuracy: 0.5930 - val_loss: 0.6609 - val_precision: 0.5820 - val_recall: 0.6597\n",
      "Epoch 525/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5778 - loss: 0.3482 - precision: 0.5844 - recall: 0.6292\n",
      "Epoch 525 - Train Recall: 0.6259 - Val Recall: 0.5187\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5786 - loss: 0.3483 - precision: 0.5834 - recall: 0.6293 - val_accuracy: 0.5817 - val_loss: 0.6939 - val_precision: 0.5935 - val_recall: 0.5187\n",
      "Epoch 526/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5853 - loss: 0.3140 - precision: 0.5678 - recall: 0.6432\n",
      "Epoch 526 - Train Recall: 0.7279 - Val Recall: 0.6987\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5857 - loss: 0.3138 - precision: 0.5681 - recall: 0.6549 - val_accuracy: 0.6034 - val_loss: 0.6169 - val_precision: 0.5869 - val_recall: 0.6987\n",
      "Epoch 527/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5845 - loss: 0.3378 - precision: 0.5679 - recall: 0.7218\n",
      "Epoch 527 - Train Recall: 0.7121 - Val Recall: 0.6357\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5847 - loss: 0.3378 - precision: 0.5680 - recall: 0.7215 - val_accuracy: 0.6049 - val_loss: 0.6613 - val_precision: 0.5989 - val_recall: 0.6357\n",
      "Epoch 528/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5964 - loss: 0.3247 - precision: 0.5877 - recall: 0.7186\n",
      "Epoch 528 - Train Recall: 0.7170 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5952 - loss: 0.3248 - precision: 0.5853 - recall: 0.7183 - val_accuracy: 0.5945 - val_loss: 0.6401 - val_precision: 0.5808 - val_recall: 0.6792\n",
      "Epoch 529/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5939 - loss: 0.3336 - precision: 0.5754 - recall: 0.6909\n",
      "Epoch 529 - Train Recall: 0.6788 - Val Recall: 0.7496\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5940 - loss: 0.3336 - precision: 0.5757 - recall: 0.6904 - val_accuracy: 0.5862 - val_loss: 0.6651 - val_precision: 0.5650 - val_recall: 0.7496\n",
      "Epoch 530/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.3616 - precision: 0.5944 - recall: 0.6371\n",
      "Epoch 530 - Train Recall: 0.6151 - Val Recall: 0.5742\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5967 - loss: 0.3616 - precision: 0.5943 - recall: 0.6367 - val_accuracy: 0.5915 - val_loss: 0.7121 - val_precision: 0.5947 - val_recall: 0.5742\n",
      "Epoch 531/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5854 - loss: 0.3332 - precision: 0.5829 - recall: 0.5725\n",
      "Epoch 531 - Train Recall: 0.6192 - Val Recall: 0.6612\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5869 - loss: 0.3330 - precision: 0.5840 - recall: 0.5791 - val_accuracy: 0.5885 - val_loss: 0.6571 - val_precision: 0.5772 - val_recall: 0.6612\n",
      "Epoch 532/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5898 - loss: 0.3543 - precision: 0.5900 - recall: 0.6216\n",
      "Epoch 532 - Train Recall: 0.5817 - Val Recall: 0.5982\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5901 - loss: 0.3543 - precision: 0.5905 - recall: 0.6161 - val_accuracy: 0.6057 - val_loss: 0.7015 - val_precision: 0.6073 - val_recall: 0.5982\n",
      "Epoch 533/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5999 - loss: 0.3469 - precision: 0.5971 - recall: 0.5567\n",
      "Epoch 533 - Train Recall: 0.5892 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 0.3470 - precision: 0.5968 - recall: 0.5601 - val_accuracy: 0.6057 - val_loss: 0.6825 - val_precision: 0.5946 - val_recall: 0.6642\n",
      "Epoch 534/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5927 - loss: 0.3642 - precision: 0.5869 - recall: 0.5763\n",
      "Epoch 534 - Train Recall: 0.5652 - Val Recall: 0.5787\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5927 - loss: 0.3642 - precision: 0.5871 - recall: 0.5761 - val_accuracy: 0.6012 - val_loss: 0.7189 - val_precision: 0.6060 - val_recall: 0.5787\n",
      "Epoch 535/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5930 - loss: 0.3484 - precision: 0.5960 - recall: 0.5761\n",
      "Epoch 535 - Train Recall: 0.5765 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5934 - loss: 0.3484 - precision: 0.5964 - recall: 0.5760 - val_accuracy: 0.6102 - val_loss: 0.6821 - val_precision: 0.6034 - val_recall: 0.6432\n",
      "Epoch 536/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.3605 - precision: 0.5976 - recall: 0.5584\n",
      "Epoch 536 - Train Recall: 0.5296 - Val Recall: 0.4378\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5965 - loss: 0.3605 - precision: 0.5976 - recall: 0.5577 - val_accuracy: 0.5757 - val_loss: 0.7307 - val_precision: 0.6046 - val_recall: 0.4378\n",
      "Epoch 537/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6054 - loss: 0.3123 - precision: 0.5959 - recall: 0.6479\n",
      "Epoch 537 - Train Recall: 0.7080 - Val Recall: 0.8006\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6045 - loss: 0.3124 - precision: 0.5945 - recall: 0.6514 - val_accuracy: 0.6049 - val_loss: 0.6128 - val_precision: 0.5754 - val_recall: 0.8006\n",
      "Epoch 538/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5791 - loss: 0.3665 - precision: 0.5696 - recall: 0.6535\n",
      "Epoch 538 - Train Recall: 0.5738 - Val Recall: 0.5142\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5797 - loss: 0.3664 - precision: 0.5710 - recall: 0.6458 - val_accuracy: 0.5847 - val_loss: 0.7174 - val_precision: 0.5986 - val_recall: 0.5142\n",
      "Epoch 539/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5931 - loss: 0.3248 - precision: 0.5896 - recall: 0.5849\n",
      "Epoch 539 - Train Recall: 0.6499 - Val Recall: 0.7676\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5936 - loss: 0.3249 - precision: 0.5894 - recall: 0.5923 - val_accuracy: 0.5975 - val_loss: 0.6362 - val_precision: 0.5727 - val_recall: 0.7676\n",
      "Epoch 540/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6003 - loss: 0.3732 - precision: 0.5895 - recall: 0.6579\n",
      "Epoch 540 - Train Recall: 0.5600 - Val Recall: 0.3958\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5996 - loss: 0.3732 - precision: 0.5901 - recall: 0.6492 - val_accuracy: 0.5667 - val_loss: 0.7373 - val_precision: 0.6014 - val_recall: 0.3958\n",
      "Epoch 541/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5950 - loss: 0.2920 - precision: 0.5850 - recall: 0.6312\n",
      "Epoch 541 - Train Recall: 0.7286 - Val Recall: 0.8411\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5950 - loss: 0.2920 - precision: 0.5849 - recall: 0.6318 - val_accuracy: 0.5870 - val_loss: 0.5639 - val_precision: 0.5577 - val_recall: 0.8411\n",
      "Epoch 542/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5675 - loss: 0.3780 - precision: 0.5525 - recall: 0.6955\n",
      "Epoch 542 - Train Recall: 0.5847 - Val Recall: 0.6087\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5703 - loss: 0.3769 - precision: 0.5571 - recall: 0.6804 - val_accuracy: 0.6064 - val_loss: 0.7195 - val_precision: 0.6060 - val_recall: 0.6087\n",
      "Epoch 543/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6022 - loss: 0.3467 - precision: 0.6084 - recall: 0.5787\n",
      "Epoch 543 - Train Recall: 0.5712 - Val Recall: 0.4903\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6017 - loss: 0.3469 - precision: 0.6078 - recall: 0.5785 - val_accuracy: 0.5855 - val_loss: 0.6972 - val_precision: 0.6056 - val_recall: 0.4903\n",
      "Epoch 544/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5993 - loss: 0.3175 - precision: 0.5922 - recall: 0.6306\n",
      "Epoch 544 - Train Recall: 0.6615 - Val Recall: 0.7856\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5986 - loss: 0.3176 - precision: 0.5907 - recall: 0.6345 - val_accuracy: 0.5922 - val_loss: 0.6285 - val_precision: 0.5665 - val_recall: 0.7856\n",
      "Epoch 545/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 0.3746 - precision: 0.5966 - recall: 0.6336\n",
      "Epoch 545 - Train Recall: 0.5525 - Val Recall: 0.5412\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5952 - loss: 0.3745 - precision: 0.5969 - recall: 0.6280 - val_accuracy: 0.5817 - val_loss: 0.7419 - val_precision: 0.5889 - val_recall: 0.5412\n",
      "Epoch 546/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5810 - loss: 0.3430 - precision: 0.5957 - recall: 0.5377\n",
      "Epoch 546 - Train Recall: 0.5761 - Val Recall: 0.6162\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5817 - loss: 0.3429 - precision: 0.5958 - recall: 0.5395 - val_accuracy: 0.6079 - val_loss: 0.6697 - val_precision: 0.6062 - val_recall: 0.6162\n",
      "Epoch 547/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5946 - loss: 0.3535 - precision: 0.6097 - recall: 0.6009\n",
      "Epoch 547 - Train Recall: 0.5645 - Val Recall: 0.5457\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5947 - loss: 0.3535 - precision: 0.6095 - recall: 0.6001 - val_accuracy: 0.5945 - val_loss: 0.7056 - val_precision: 0.6047 - val_recall: 0.5457\n",
      "Epoch 548/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5985 - loss: 0.3369 - precision: 0.6028 - recall: 0.5661\n",
      "Epoch 548 - Train Recall: 0.5873 - Val Recall: 0.5157\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5983 - loss: 0.3369 - precision: 0.6025 - recall: 0.5668 - val_accuracy: 0.5870 - val_loss: 0.6693 - val_precision: 0.6014 - val_recall: 0.5157\n",
      "Epoch 549/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5965 - loss: 0.3218 - precision: 0.5902 - recall: 0.6625\n",
      "Epoch 549 - Train Recall: 0.6825 - Val Recall: 0.6267\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5964 - loss: 0.3218 - precision: 0.5899 - recall: 0.6629 - val_accuracy: 0.5960 - val_loss: 0.6366 - val_precision: 0.5904 - val_recall: 0.6267\n",
      "Epoch 550/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5927 - loss: 0.3290 - precision: 0.5787 - recall: 0.6672\n",
      "Epoch 550 - Train Recall: 0.6698 - Val Recall: 0.6822\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5919 - loss: 0.3293 - precision: 0.5782 - recall: 0.6670 - val_accuracy: 0.6012 - val_loss: 0.6466 - val_precision: 0.5871 - val_recall: 0.6822\n",
      "Epoch 551/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5980 - loss: 0.3456 - precision: 0.5951 - recall: 0.6447\n",
      "Epoch 551 - Train Recall: 0.6049 - Val Recall: 0.5277\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5978 - loss: 0.3456 - precision: 0.5948 - recall: 0.6428 - val_accuracy: 0.5967 - val_loss: 0.6821 - val_precision: 0.6122 - val_recall: 0.5277\n",
      "Epoch 552/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6010 - loss: 0.3179 - precision: 0.5795 - recall: 0.6359\n",
      "Epoch 552 - Train Recall: 0.6870 - Val Recall: 0.6927\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6004 - loss: 0.3181 - precision: 0.5795 - recall: 0.6400 - val_accuracy: 0.5997 - val_loss: 0.6270 - val_precision: 0.5841 - val_recall: 0.6927\n",
      "Epoch 553/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5883 - loss: 0.3457 - precision: 0.5756 - recall: 0.6535\n",
      "Epoch 553 - Train Recall: 0.6132 - Val Recall: 0.6702\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5882 - loss: 0.3457 - precision: 0.5758 - recall: 0.6520 - val_accuracy: 0.5982 - val_loss: 0.6763 - val_precision: 0.5858 - val_recall: 0.6702\n",
      "Epoch 554/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6089 - loss: 0.3556 - precision: 0.6118 - recall: 0.5964\n",
      "Epoch 554 - Train Recall: 0.5570 - Val Recall: 0.3703\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6062 - loss: 0.3561 - precision: 0.6097 - recall: 0.5915 - val_accuracy: 0.5795 - val_loss: 0.7068 - val_precision: 0.6366 - val_recall: 0.3703\n",
      "Epoch 555/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5945 - loss: 0.2833 - precision: 0.5760 - recall: 0.6919\n",
      "Epoch 555 - Train Recall: 0.7736 - Val Recall: 0.8096\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5944 - loss: 0.2832 - precision: 0.5758 - recall: 0.6928 - val_accuracy: 0.6094 - val_loss: 0.5482 - val_precision: 0.5782 - val_recall: 0.8096\n",
      "Epoch 556/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6046 - loss: 0.3503 - precision: 0.5872 - recall: 0.7563\n",
      "Epoch 556 - Train Recall: 0.6690 - Val Recall: 0.5442\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.3504 - precision: 0.5869 - recall: 0.7522 - val_accuracy: 0.5900 - val_loss: 0.6867 - val_precision: 0.5990 - val_recall: 0.5442\n",
      "Epoch 557/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5799 - loss: 0.3107 - precision: 0.5710 - recall: 0.6649\n",
      "Epoch 557 - Train Recall: 0.7136 - Val Recall: 0.7901\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5799 - loss: 0.3107 - precision: 0.5708 - recall: 0.6663 - val_accuracy: 0.5922 - val_loss: 0.6094 - val_precision: 0.5661 - val_recall: 0.7901\n",
      "Epoch 558/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5961 - loss: 0.3626 - precision: 0.5777 - recall: 0.6910\n",
      "Epoch 558 - Train Recall: 0.6207 - Val Recall: 0.5532\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5961 - loss: 0.3626 - precision: 0.5778 - recall: 0.6906 - val_accuracy: 0.5802 - val_loss: 0.7153 - val_precision: 0.5848 - val_recall: 0.5532\n",
      "Epoch 559/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 0.3252 - precision: 0.5856 - recall: 0.6303\n",
      "Epoch 559 - Train Recall: 0.6743 - Val Recall: 0.7316\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5953 - loss: 0.3252 - precision: 0.5852 - recall: 0.6335 - val_accuracy: 0.6019 - val_loss: 0.6423 - val_precision: 0.5810 - val_recall: 0.7316\n",
      "Epoch 560/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5877 - loss: 0.3571 - precision: 0.5768 - recall: 0.6511\n",
      "Epoch 560 - Train Recall: 0.6106 - Val Recall: 0.5697\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5878 - loss: 0.3571 - precision: 0.5770 - recall: 0.6503 - val_accuracy: 0.5892 - val_loss: 0.7085 - val_precision: 0.5928 - val_recall: 0.5697\n",
      "Epoch 561/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5927 - loss: 0.3306 - precision: 0.5820 - recall: 0.6347\n",
      "Epoch 561 - Train Recall: 0.6709 - Val Recall: 0.7166\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5932 - loss: 0.3306 - precision: 0.5824 - recall: 0.6392 - val_accuracy: 0.5892 - val_loss: 0.6576 - val_precision: 0.5711 - val_recall: 0.7166\n",
      "Epoch 562/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5987 - loss: 0.3567 - precision: 0.5819 - recall: 0.6734\n",
      "Epoch 562 - Train Recall: 0.6158 - Val Recall: 0.6357\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5985 - loss: 0.3567 - precision: 0.5820 - recall: 0.6721 - val_accuracy: 0.5922 - val_loss: 0.6971 - val_precision: 0.5848 - val_recall: 0.6357\n",
      "Epoch 563/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5972 - loss: 0.3464 - precision: 0.6123 - recall: 0.5387\n",
      "Epoch 563 - Train Recall: 0.5506 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5965 - loss: 0.3466 - precision: 0.6109 - recall: 0.5393 - val_accuracy: 0.6004 - val_loss: 0.6844 - val_precision: 0.5857 - val_recall: 0.6867\n",
      "Epoch 564/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5807 - loss: 0.3825 - precision: 0.5899 - recall: 0.4998\n",
      "Epoch 564 - Train Recall: 0.4501 - Val Recall: 0.5757\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5806 - loss: 0.3825 - precision: 0.5904 - recall: 0.4978 - val_accuracy: 0.5922 - val_loss: 0.7620 - val_precision: 0.5953 - val_recall: 0.5757\n",
      "Epoch 565/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5815 - loss: 0.3876 - precision: 0.6203 - recall: 0.4391\n",
      "Epoch 565 - Train Recall: 0.4340 - Val Recall: 0.4183\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5815 - loss: 0.3876 - precision: 0.6203 - recall: 0.4391 - val_accuracy: 0.5855 - val_loss: 0.7579 - val_precision: 0.6284 - val_recall: 0.4183\n",
      "Epoch 566/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5978 - loss: 0.3372 - precision: 0.6240 - recall: 0.5136\n",
      "Epoch 566 - Train Recall: 0.5641 - Val Recall: 0.3958\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5977 - loss: 0.3372 - precision: 0.6227 - recall: 0.5170 - val_accuracy: 0.5547 - val_loss: 0.6784 - val_precision: 0.5802 - val_recall: 0.3958\n",
      "Epoch 567/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5883 - loss: 0.2888 - precision: 0.5727 - recall: 0.6674\n",
      "Epoch 567 - Train Recall: 0.7410 - Val Recall: 0.8036\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5876 - loss: 0.2888 - precision: 0.5717 - recall: 0.6733 - val_accuracy: 0.6004 - val_loss: 0.5650 - val_precision: 0.5714 - val_recall: 0.8036\n",
      "Epoch 568/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5789 - loss: 0.3626 - precision: 0.5579 - recall: 0.7332\n",
      "Epoch 568 - Train Recall: 0.6301 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5800 - loss: 0.3622 - precision: 0.5608 - recall: 0.7204 - val_accuracy: 0.5945 - val_loss: 0.7038 - val_precision: 0.5908 - val_recall: 0.6147\n",
      "Epoch 569/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5945 - loss: 0.3378 - precision: 0.5871 - recall: 0.6070\n",
      "Epoch 569 - Train Recall: 0.6139 - Val Recall: 0.7781\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5944 - loss: 0.3378 - precision: 0.5871 - recall: 0.6071 - val_accuracy: 0.5922 - val_loss: 0.6696 - val_precision: 0.5672 - val_recall: 0.7781\n",
      "Epoch 570/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5869 - loss: 0.3859 - precision: 0.6064 - recall: 0.5216\n",
      "Epoch 570 - Train Recall: 0.4546 - Val Recall: 0.2354\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5864 - loss: 0.3859 - precision: 0.6062 - recall: 0.5174 - val_accuracy: 0.5262 - val_loss: 0.7761 - val_precision: 0.5627 - val_recall: 0.2354\n",
      "Epoch 571/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5918 - loss: 0.2559 - precision: 0.5964 - recall: 0.6946\n",
      "Epoch 571 - Train Recall: 0.8280 - Val Recall: 0.9805\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5910 - loss: 0.2557 - precision: 0.5948 - recall: 0.6985 - val_accuracy: 0.5112 - val_loss: 0.4795 - val_precision: 0.5058 - val_recall: 0.9805\n",
      "Epoch 572/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5951 - loss: 0.3774 - precision: 0.5821 - recall: 0.7556\n",
      "Epoch 572 - Train Recall: 0.5971 - Val Recall: 0.5082\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5949 - loss: 0.3773 - precision: 0.5824 - recall: 0.7482 - val_accuracy: 0.5937 - val_loss: 0.7340 - val_precision: 0.6130 - val_recall: 0.5082\n",
      "Epoch 573/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6119 - loss: 0.3162 - precision: 0.6139 - recall: 0.6199\n",
      "Epoch 573 - Train Recall: 0.6867 - Val Recall: 0.7346\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6098 - loss: 0.3164 - precision: 0.6098 - recall: 0.6284 - val_accuracy: 0.5967 - val_loss: 0.6221 - val_precision: 0.5758 - val_recall: 0.7346\n",
      "Epoch 574/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 0.3551 - precision: 0.5935 - recall: 0.6410\n",
      "Epoch 574 - Train Recall: 0.6072 - Val Recall: 0.5922\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6014 - loss: 0.3551 - precision: 0.5940 - recall: 0.6373 - val_accuracy: 0.6034 - val_loss: 0.6981 - val_precision: 0.6058 - val_recall: 0.5922\n",
      "Epoch 575/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5947 - loss: 0.3384 - precision: 0.5826 - recall: 0.6089\n",
      "Epoch 575 - Train Recall: 0.6331 - Val Recall: 0.7226\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5947 - loss: 0.3384 - precision: 0.5826 - recall: 0.6093 - val_accuracy: 0.6004 - val_loss: 0.6697 - val_precision: 0.5807 - val_recall: 0.7226\n",
      "Epoch 576/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5882 - loss: 0.3676 - precision: 0.5790 - recall: 0.6217\n",
      "Epoch 576 - Train Recall: 0.5802 - Val Recall: 0.6312\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5882 - loss: 0.3676 - precision: 0.5796 - recall: 0.6196 - val_accuracy: 0.5922 - val_loss: 0.7242 - val_precision: 0.5855 - val_recall: 0.6312\n",
      "Epoch 577/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5973 - loss: 0.3560 - precision: 0.5962 - recall: 0.5564\n",
      "Epoch 577 - Train Recall: 0.5439 - Val Recall: 0.5472\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5964 - loss: 0.3562 - precision: 0.5961 - recall: 0.5554 - val_accuracy: 0.5967 - val_loss: 0.7105 - val_precision: 0.6073 - val_recall: 0.5472\n",
      "Epoch 578/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5950 - loss: 0.3413 - precision: 0.5933 - recall: 0.5620\n",
      "Epoch 578 - Train Recall: 0.5971 - Val Recall: 0.6177\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5949 - loss: 0.3415 - precision: 0.5934 - recall: 0.5656 - val_accuracy: 0.5945 - val_loss: 0.6808 - val_precision: 0.5903 - val_recall: 0.6177\n",
      "Epoch 579/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6034 - loss: 0.3469 - precision: 0.5970 - recall: 0.6361\n",
      "Epoch 579 - Train Recall: 0.6139 - Val Recall: 0.5277\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6032 - loss: 0.3470 - precision: 0.5969 - recall: 0.6357 - val_accuracy: 0.5862 - val_loss: 0.6960 - val_precision: 0.5976 - val_recall: 0.5277\n",
      "Epoch 580/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5969 - loss: 0.3206 - precision: 0.5869 - recall: 0.6715\n",
      "Epoch 580 - Train Recall: 0.7241 - Val Recall: 0.7706\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5969 - loss: 0.3205 - precision: 0.5865 - recall: 0.6734 - val_accuracy: 0.5922 - val_loss: 0.6274 - val_precision: 0.5680 - val_recall: 0.7706\n",
      "Epoch 581/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5931 - loss: 0.3507 - precision: 0.5878 - recall: 0.6656\n",
      "Epoch 581 - Train Recall: 0.6001 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5927 - loss: 0.3509 - precision: 0.5876 - recall: 0.6606 - val_accuracy: 0.5810 - val_loss: 0.7009 - val_precision: 0.5716 - val_recall: 0.6462\n",
      "Epoch 582/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 0.3528 - precision: 0.6156 - recall: 0.5367\n",
      "Epoch 582 - Train Recall: 0.5274 - Val Recall: 0.6087\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5937 - loss: 0.3532 - precision: 0.6128 - recall: 0.5347 - val_accuracy: 0.6034 - val_loss: 0.6983 - val_precision: 0.6024 - val_recall: 0.6087\n",
      "Epoch 583/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 0.3659 - precision: 0.6161 - recall: 0.5494\n",
      "Epoch 583 - Train Recall: 0.5296 - Val Recall: 0.5337\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6023 - loss: 0.3659 - precision: 0.6158 - recall: 0.5488 - val_accuracy: 0.5772 - val_loss: 0.7297 - val_precision: 0.5846 - val_recall: 0.5337\n",
      "Epoch 584/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5789 - loss: 0.3458 - precision: 0.5813 - recall: 0.5516\n",
      "Epoch 584 - Train Recall: 0.5712 - Val Recall: 0.6717\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5793 - loss: 0.3458 - precision: 0.5817 - recall: 0.5522 - val_accuracy: 0.6042 - val_loss: 0.6739 - val_precision: 0.5918 - val_recall: 0.6717\n",
      "Epoch 585/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5818 - loss: 0.3734 - precision: 0.5851 - recall: 0.5759\n",
      "Epoch 585 - Train Recall: 0.5176 - Val Recall: 0.5007\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5820 - loss: 0.3734 - precision: 0.5859 - recall: 0.5725 - val_accuracy: 0.5787 - val_loss: 0.7337 - val_precision: 0.5933 - val_recall: 0.5007\n",
      "Epoch 586/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5826 - loss: 0.3404 - precision: 0.6019 - recall: 0.5237\n",
      "Epoch 586 - Train Recall: 0.5727 - Val Recall: 0.4828\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5830 - loss: 0.3403 - precision: 0.6014 - recall: 0.5260 - val_accuracy: 0.5945 - val_loss: 0.6656 - val_precision: 0.6216 - val_recall: 0.4828\n",
      "Epoch 587/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.3127 - precision: 0.5797 - recall: 0.6825\n",
      "Epoch 587 - Train Recall: 0.7189 - Val Recall: 0.7901\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5941 - loss: 0.3127 - precision: 0.5796 - recall: 0.6831 - val_accuracy: 0.6072 - val_loss: 0.6191 - val_precision: 0.5785 - val_recall: 0.7901\n",
      "Epoch 588/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5894 - loss: 0.3588 - precision: 0.5745 - recall: 0.6259\n",
      "Epoch 588 - Train Recall: 0.5768 - Val Recall: 0.5652\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5893 - loss: 0.3589 - precision: 0.5763 - recall: 0.6208 - val_accuracy: 0.6019 - val_loss: 0.7093 - val_precision: 0.6100 - val_recall: 0.5652\n",
      "Epoch 589/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5953 - loss: 0.3377 - precision: 0.5911 - recall: 0.5946\n",
      "Epoch 589 - Train Recall: 0.6008 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5952 - loss: 0.3377 - precision: 0.5911 - recall: 0.5948 - val_accuracy: 0.6057 - val_loss: 0.6656 - val_precision: 0.5972 - val_recall: 0.6492\n",
      "Epoch 590/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5993 - loss: 0.3558 - precision: 0.5924 - recall: 0.5953\n",
      "Epoch 590 - Train Recall: 0.5847 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5989 - loss: 0.3558 - precision: 0.5933 - recall: 0.5935 - val_accuracy: 0.6019 - val_loss: 0.7019 - val_precision: 0.5983 - val_recall: 0.6207\n",
      "Epoch 591/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5892 - loss: 0.3533 - precision: 0.6005 - recall: 0.5975\n",
      "Epoch 591 - Train Recall: 0.5787 - Val Recall: 0.5367\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5896 - loss: 0.3533 - precision: 0.6001 - recall: 0.5959 - val_accuracy: 0.5922 - val_loss: 0.6931 - val_precision: 0.6037 - val_recall: 0.5367\n",
      "Epoch 592/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5938 - loss: 0.3311 - precision: 0.5955 - recall: 0.5719\n",
      "Epoch 592 - Train Recall: 0.6046 - Val Recall: 0.5517\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5936 - loss: 0.3311 - precision: 0.5950 - recall: 0.5738 - val_accuracy: 0.5870 - val_loss: 0.6552 - val_precision: 0.5935 - val_recall: 0.5517\n",
      "Epoch 593/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5933 - loss: 0.3259 - precision: 0.5743 - recall: 0.6461\n",
      "Epoch 593 - Train Recall: 0.6481 - Val Recall: 0.8186\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5931 - loss: 0.3260 - precision: 0.5744 - recall: 0.6462 - val_accuracy: 0.5937 - val_loss: 0.6576 - val_precision: 0.5646 - val_recall: 0.8186\n",
      "Epoch 594/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5945 - loss: 0.3875 - precision: 0.5927 - recall: 0.5596\n",
      "Epoch 594 - Train Recall: 0.4801 - Val Recall: 0.4048\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 0.3875 - precision: 0.5930 - recall: 0.5577 - val_accuracy: 0.5652 - val_loss: 0.7604 - val_precision: 0.5960 - val_recall: 0.4048\n",
      "Epoch 595/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5790 - loss: 0.3197 - precision: 0.5809 - recall: 0.5644\n",
      "Epoch 595 - Train Recall: 0.6548 - Val Recall: 0.6987\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5795 - loss: 0.3195 - precision: 0.5804 - recall: 0.5712 - val_accuracy: 0.6049 - val_loss: 0.6185 - val_precision: 0.5884 - val_recall: 0.6987\n",
      "Epoch 596/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6115 - loss: 0.3515 - precision: 0.5941 - recall: 0.6651\n",
      "Epoch 596 - Train Recall: 0.6121 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6101 - loss: 0.3517 - precision: 0.5935 - recall: 0.6617 - val_accuracy: 0.5885 - val_loss: 0.6975 - val_precision: 0.5845 - val_recall: 0.6117\n",
      "Epoch 597/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5944 - loss: 0.3414 - precision: 0.5975 - recall: 0.5958\n",
      "Epoch 597 - Train Recall: 0.5993 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 0.3414 - precision: 0.5973 - recall: 0.5959 - val_accuracy: 0.5877 - val_loss: 0.6769 - val_precision: 0.5852 - val_recall: 0.6027\n",
      "Epoch 598/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5939 - loss: 0.3436 - precision: 0.5929 - recall: 0.6075\n",
      "Epoch 598 - Train Recall: 0.6064 - Val Recall: 0.5577\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5936 - loss: 0.3437 - precision: 0.5924 - recall: 0.6075 - val_accuracy: 0.5937 - val_loss: 0.6747 - val_precision: 0.6010 - val_recall: 0.5577\n",
      "Epoch 599/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5965 - loss: 0.3290 - precision: 0.5925 - recall: 0.6132\n",
      "Epoch 599 - Train Recall: 0.6379 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5966 - loss: 0.3291 - precision: 0.5923 - recall: 0.6152 - val_accuracy: 0.6057 - val_loss: 0.6440 - val_precision: 0.5922 - val_recall: 0.6792\n",
      "Epoch 600/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.3546 - precision: 0.5906 - recall: 0.6235\n",
      "Epoch 600 - Train Recall: 0.5791 - Val Recall: 0.7316\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5976 - loss: 0.3546 - precision: 0.5911 - recall: 0.6180 - val_accuracy: 0.5967 - val_loss: 0.7053 - val_precision: 0.5762 - val_recall: 0.7316\n",
      "Epoch 601/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5798 - loss: 0.3875 - precision: 0.6079 - recall: 0.4578\n",
      "Epoch 601 - Train Recall: 0.4340 - Val Recall: 0.5202\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5799 - loss: 0.3870 - precision: 0.6083 - recall: 0.4550 - val_accuracy: 0.6042 - val_loss: 0.7560 - val_precision: 0.6252 - val_recall: 0.5202\n",
      "Epoch 602/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5708 - loss: 0.3753 - precision: 0.6018 - recall: 0.4840\n",
      "Epoch 602 - Train Recall: 0.4711 - Val Recall: 0.3478\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5711 - loss: 0.3753 - precision: 0.6019 - recall: 0.4836 - val_accuracy: 0.5735 - val_loss: 0.7407 - val_precision: 0.6339 - val_recall: 0.3478\n",
      "Epoch 603/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5975 - loss: 0.2968 - precision: 0.5889 - recall: 0.6101\n",
      "Epoch 603 - Train Recall: 0.7024 - Val Recall: 0.8186\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5971 - loss: 0.2967 - precision: 0.5880 - recall: 0.6165 - val_accuracy: 0.5892 - val_loss: 0.5833 - val_precision: 0.5612 - val_recall: 0.8186\n",
      "Epoch 604/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5908 - loss: 0.3721 - precision: 0.5780 - recall: 0.6748\n",
      "Epoch 604 - Train Recall: 0.5761 - Val Recall: 0.5532\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5907 - loss: 0.3721 - precision: 0.5783 - recall: 0.6719 - val_accuracy: 0.5997 - val_loss: 0.7296 - val_precision: 0.6099 - val_recall: 0.5532\n",
      "Epoch 605/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5889 - loss: 0.3382 - precision: 0.5989 - recall: 0.5558\n",
      "Epoch 605 - Train Recall: 0.5971 - Val Recall: 0.6357\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5893 - loss: 0.3381 - precision: 0.5988 - recall: 0.5581 - val_accuracy: 0.5952 - val_loss: 0.6660 - val_precision: 0.5881 - val_recall: 0.6357\n",
      "Epoch 606/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5918 - loss: 0.3554 - precision: 0.5933 - recall: 0.5964\n",
      "Epoch 606 - Train Recall: 0.5858 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5919 - loss: 0.3554 - precision: 0.5934 - recall: 0.5960 - val_accuracy: 0.5892 - val_loss: 0.6997 - val_precision: 0.5797 - val_recall: 0.6492\n",
      "Epoch 607/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.3606 - precision: 0.6070 - recall: 0.5396\n",
      "Epoch 607 - Train Recall: 0.5142 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5966 - loss: 0.3606 - precision: 0.6069 - recall: 0.5390 - val_accuracy: 0.5885 - val_loss: 0.7140 - val_precision: 0.5891 - val_recall: 0.5847\n",
      "Epoch 608/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5958 - loss: 0.3631 - precision: 0.6073 - recall: 0.5302\n",
      "Epoch 608 - Train Recall: 0.5165 - Val Recall: 0.5652\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5955 - loss: 0.3631 - precision: 0.6070 - recall: 0.5298 - val_accuracy: 0.5825 - val_loss: 0.7232 - val_precision: 0.5854 - val_recall: 0.5652\n",
      "Epoch 609/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5866 - loss: 0.3582 - precision: 0.5943 - recall: 0.4952\n",
      "Epoch 609 - Train Recall: 0.5045 - Val Recall: 0.5352\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5866 - loss: 0.3582 - precision: 0.5946 - recall: 0.4955 - val_accuracy: 0.5877 - val_loss: 0.7085 - val_precision: 0.5980 - val_recall: 0.5352\n",
      "Epoch 610/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5903 - loss: 0.3525 - precision: 0.6102 - recall: 0.5670\n",
      "Epoch 610 - Train Recall: 0.5652 - Val Recall: 0.5412\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5903 - loss: 0.3525 - precision: 0.6083 - recall: 0.5672 - val_accuracy: 0.5892 - val_loss: 0.7005 - val_precision: 0.5987 - val_recall: 0.5412\n",
      "Epoch 611/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5919 - loss: 0.3361 - precision: 0.5845 - recall: 0.5691\n",
      "Epoch 611 - Train Recall: 0.5960 - Val Recall: 0.7076\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5917 - loss: 0.3361 - precision: 0.5846 - recall: 0.5702 - val_accuracy: 0.6094 - val_loss: 0.6582 - val_precision: 0.5915 - val_recall: 0.7076\n",
      "Epoch 612/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5780 - loss: 0.3754 - precision: 0.5749 - recall: 0.5636\n",
      "Epoch 612 - Train Recall: 0.5247 - Val Recall: 0.5592\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5781 - loss: 0.3754 - precision: 0.5752 - recall: 0.5629 - val_accuracy: 0.5877 - val_loss: 0.7319 - val_precision: 0.5930 - val_recall: 0.5592\n",
      "Epoch 613/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 0.3550 - precision: 0.5969 - recall: 0.5436\n",
      "Epoch 613 - Train Recall: 0.5506 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5890 - loss: 0.3551 - precision: 0.5966 - recall: 0.5440 - val_accuracy: 0.5862 - val_loss: 0.6983 - val_precision: 0.5865 - val_recall: 0.5847\n",
      "Epoch 614/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5966 - loss: 0.3508 - precision: 0.5957 - recall: 0.5900\n",
      "Epoch 614 - Train Recall: 0.5791 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5961 - loss: 0.3510 - precision: 0.5958 - recall: 0.5881 - val_accuracy: 0.5930 - val_loss: 0.6962 - val_precision: 0.5945 - val_recall: 0.5847\n",
      "Epoch 615/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5831 - loss: 0.3453 - precision: 0.5760 - recall: 0.5747\n",
      "Epoch 615 - Train Recall: 0.5761 - Val Recall: 0.5187\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5832 - loss: 0.3453 - precision: 0.5763 - recall: 0.5747 - val_accuracy: 0.5810 - val_loss: 0.6765 - val_precision: 0.5925 - val_recall: 0.5187\n",
      "Epoch 616/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5883 - loss: 0.3254 - precision: 0.5926 - recall: 0.6431\n",
      "Epoch 616 - Train Recall: 0.6578 - Val Recall: 0.7811\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5883 - loss: 0.3254 - precision: 0.5923 - recall: 0.6435 - val_accuracy: 0.5892 - val_loss: 0.6434 - val_precision: 0.5645 - val_recall: 0.7811\n",
      "Epoch 617/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5952 - loss: 0.3736 - precision: 0.5795 - recall: 0.6068\n",
      "Epoch 617 - Train Recall: 0.5386 - Val Recall: 0.5382\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.3737 - precision: 0.5818 - recall: 0.5977 - val_accuracy: 0.5945 - val_loss: 0.7296 - val_precision: 0.6064 - val_recall: 0.5382\n",
      "Epoch 618/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6025 - loss: 0.3408 - precision: 0.6128 - recall: 0.5687\n",
      "Epoch 618 - Train Recall: 0.5795 - Val Recall: 0.5487\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6022 - loss: 0.3408 - precision: 0.6120 - recall: 0.5695 - val_accuracy: 0.6019 - val_loss: 0.6935 - val_precision: 0.6141 - val_recall: 0.5487\n",
      "Epoch 619/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6041 - loss: 0.3312 - precision: 0.6028 - recall: 0.5869\n",
      "Epoch 619 - Train Recall: 0.6214 - Val Recall: 0.6612\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6030 - loss: 0.3315 - precision: 0.6015 - recall: 0.5911 - val_accuracy: 0.5990 - val_loss: 0.6555 - val_precision: 0.5880 - val_recall: 0.6612\n",
      "Epoch 620/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 0.3525 - precision: 0.6063 - recall: 0.6491\n",
      "Epoch 620 - Train Recall: 0.6079 - Val Recall: 0.4948\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6024 - loss: 0.3525 - precision: 0.6058 - recall: 0.6469 - val_accuracy: 0.5982 - val_loss: 0.7026 - val_precision: 0.6238 - val_recall: 0.4948\n",
      "Epoch 621/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5904 - loss: 0.3087 - precision: 0.5779 - recall: 0.5977\n",
      "Epoch 621 - Train Recall: 0.6769 - Val Recall: 0.8261\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5903 - loss: 0.3087 - precision: 0.5778 - recall: 0.6005 - val_accuracy: 0.5960 - val_loss: 0.6097 - val_precision: 0.5657 - val_recall: 0.8261\n",
      "Epoch 622/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5741 - loss: 0.3822 - precision: 0.5726 - recall: 0.5925\n",
      "Epoch 622 - Train Recall: 0.5150 - Val Recall: 0.4723\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5742 - loss: 0.3822 - precision: 0.5727 - recall: 0.5920 - val_accuracy: 0.5900 - val_loss: 0.7447 - val_precision: 0.6176 - val_recall: 0.4723\n",
      "Epoch 623/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.3296 - precision: 0.6174 - recall: 0.5741\n",
      "Epoch 623 - Train Recall: 0.6214 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5982 - loss: 0.3296 - precision: 0.6164 - recall: 0.5755 - val_accuracy: 0.6072 - val_loss: 0.6459 - val_precision: 0.6000 - val_recall: 0.6432\n",
      "Epoch 624/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5845 - loss: 0.3486 - precision: 0.5696 - recall: 0.6087\n",
      "Epoch 624 - Train Recall: 0.5963 - Val Recall: 0.5772\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5850 - loss: 0.3487 - precision: 0.5716 - recall: 0.6074 - val_accuracy: 0.6019 - val_loss: 0.6922 - val_precision: 0.6073 - val_recall: 0.5772\n",
      "Epoch 625/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5863 - loss: 0.3386 - precision: 0.5856 - recall: 0.6028\n",
      "Epoch 625 - Train Recall: 0.6064 - Val Recall: 0.6162\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5864 - loss: 0.3385 - precision: 0.5856 - recall: 0.6029 - val_accuracy: 0.5937 - val_loss: 0.6645 - val_precision: 0.5897 - val_recall: 0.6162\n",
      "Epoch 626/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5911 - loss: 0.3447 - precision: 0.5832 - recall: 0.6245\n",
      "Epoch 626 - Train Recall: 0.6023 - Val Recall: 0.5412\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5909 - loss: 0.3448 - precision: 0.5833 - recall: 0.6233 - val_accuracy: 0.5765 - val_loss: 0.6909 - val_precision: 0.5823 - val_recall: 0.5412\n",
      "Epoch 627/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5945 - loss: 0.3231 - precision: 0.5854 - recall: 0.6709\n",
      "Epoch 627 - Train Recall: 0.6784 - Val Recall: 0.6822\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5941 - loss: 0.3233 - precision: 0.5846 - recall: 0.6718 - val_accuracy: 0.5922 - val_loss: 0.6441 - val_precision: 0.5781 - val_recall: 0.6822\n",
      "Epoch 628/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5714 - loss: 0.3461 - precision: 0.5622 - recall: 0.6212\n",
      "Epoch 628 - Train Recall: 0.6211 - Val Recall: 0.7106\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5730 - loss: 0.3458 - precision: 0.5642 - recall: 0.6208 - val_accuracy: 0.5937 - val_loss: 0.6816 - val_precision: 0.5759 - val_recall: 0.7106\n",
      "Epoch 629/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5987 - loss: 0.3628 - precision: 0.6083 - recall: 0.5990\n",
      "Epoch 629 - Train Recall: 0.5573 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5986 - loss: 0.3629 - precision: 0.6082 - recall: 0.5985 - val_accuracy: 0.5975 - val_loss: 0.7253 - val_precision: 0.5997 - val_recall: 0.5862\n",
      "Epoch 630/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5872 - loss: 0.3504 - precision: 0.6021 - recall: 0.5448\n",
      "Epoch 630 - Train Recall: 0.5633 - Val Recall: 0.5022\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5877 - loss: 0.3504 - precision: 0.6020 - recall: 0.5462 - val_accuracy: 0.5990 - val_loss: 0.6908 - val_precision: 0.6227 - val_recall: 0.5022\n",
      "Epoch 631/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 0.3224 - precision: 0.6031 - recall: 0.6386\n",
      "Epoch 631 - Train Recall: 0.6589 - Val Recall: 0.6837\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 0.3224 - precision: 0.6029 - recall: 0.6389 - val_accuracy: 0.5922 - val_loss: 0.6403 - val_precision: 0.5779 - val_recall: 0.6837\n",
      "Epoch 632/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5977 - loss: 0.3485 - precision: 0.5923 - recall: 0.6613\n",
      "Epoch 632 - Train Recall: 0.6349 - Val Recall: 0.5232\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5972 - loss: 0.3485 - precision: 0.5914 - recall: 0.6589 - val_accuracy: 0.5712 - val_loss: 0.6944 - val_precision: 0.5788 - val_recall: 0.5232\n",
      "Epoch 633/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5936 - loss: 0.3116 - precision: 0.6014 - recall: 0.6556\n",
      "Epoch 633 - Train Recall: 0.7031 - Val Recall: 0.7166\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5926 - loss: 0.3116 - precision: 0.5984 - recall: 0.6597 - val_accuracy: 0.5900 - val_loss: 0.6135 - val_precision: 0.5718 - val_recall: 0.7166\n",
      "Epoch 634/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5997 - loss: 0.3460 - precision: 0.5880 - recall: 0.6854\n",
      "Epoch 634 - Train Recall: 0.6432 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5994 - loss: 0.3460 - precision: 0.5878 - recall: 0.6842 - val_accuracy: 0.5900 - val_loss: 0.6797 - val_precision: 0.5756 - val_recall: 0.6852\n",
      "Epoch 635/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6104 - loss: 0.3498 - precision: 0.6085 - recall: 0.6382\n",
      "Epoch 635 - Train Recall: 0.6008 - Val Recall: 0.5487\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6098 - loss: 0.3500 - precision: 0.6080 - recall: 0.6367 - val_accuracy: 0.5900 - val_loss: 0.7041 - val_precision: 0.5980 - val_recall: 0.5487\n",
      "Epoch 636/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5933 - loss: 0.3274 - precision: 0.5996 - recall: 0.6179\n",
      "Epoch 636 - Train Recall: 0.6627 - Val Recall: 0.7151\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5931 - loss: 0.3274 - precision: 0.5982 - recall: 0.6209 - val_accuracy: 0.5952 - val_loss: 0.6482 - val_precision: 0.5768 - val_recall: 0.7151\n",
      "Epoch 637/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5957 - loss: 0.3545 - precision: 0.5891 - recall: 0.6079\n",
      "Epoch 637 - Train Recall: 0.5933 - Val Recall: 0.5712\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5957 - loss: 0.3545 - precision: 0.5893 - recall: 0.6074 - val_accuracy: 0.6042 - val_loss: 0.7029 - val_precision: 0.6116 - val_recall: 0.5712\n",
      "Epoch 638/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5978 - loss: 0.3357 - precision: 0.5807 - recall: 0.5676\n",
      "Epoch 638 - Train Recall: 0.5836 - Val Recall: 0.6087\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5975 - loss: 0.3357 - precision: 0.5814 - recall: 0.5683 - val_accuracy: 0.6117 - val_loss: 0.6601 - val_precision: 0.6124 - val_recall: 0.6087\n",
      "Epoch 639/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5919 - loss: 0.3484 - precision: 0.5883 - recall: 0.5814\n",
      "Epoch 639 - Train Recall: 0.5697 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5917 - loss: 0.3485 - precision: 0.5883 - recall: 0.5811 - val_accuracy: 0.5960 - val_loss: 0.6893 - val_precision: 0.5909 - val_recall: 0.6237\n",
      "Epoch 640/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6065 - loss: 0.3570 - precision: 0.6056 - recall: 0.5881\n",
      "Epoch 640 - Train Recall: 0.5513 - Val Recall: 0.5697\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6052 - loss: 0.3571 - precision: 0.6053 - recall: 0.5837 - val_accuracy: 0.5930 - val_loss: 0.7066 - val_precision: 0.5975 - val_recall: 0.5697\n",
      "Epoch 641/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5927 - loss: 0.3464 - precision: 0.5878 - recall: 0.5667\n",
      "Epoch 641 - Train Recall: 0.5637 - Val Recall: 0.5547\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5927 - loss: 0.3465 - precision: 0.5880 - recall: 0.5667 - val_accuracy: 0.5930 - val_loss: 0.6878 - val_precision: 0.6006 - val_recall: 0.5547\n",
      "Epoch 642/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 0.3368 - precision: 0.5842 - recall: 0.6018\n",
      "Epoch 642 - Train Recall: 0.6218 - Val Recall: 0.7391\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6005 - loss: 0.3371 - precision: 0.5848 - recall: 0.6040 - val_accuracy: 0.6049 - val_loss: 0.6689 - val_precision: 0.5827 - val_recall: 0.7391\n",
      "Epoch 643/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5822 - loss: 0.3750 - precision: 0.5790 - recall: 0.5720\n",
      "Epoch 643 - Train Recall: 0.5124 - Val Recall: 0.4768\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5815 - loss: 0.3750 - precision: 0.5796 - recall: 0.5669 - val_accuracy: 0.5802 - val_loss: 0.7366 - val_precision: 0.6011 - val_recall: 0.4768\n",
      "Epoch 644/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5987 - loss: 0.3302 - precision: 0.5960 - recall: 0.5762\n",
      "Epoch 644 - Train Recall: 0.6248 - Val Recall: 0.7166\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5983 - loss: 0.3302 - precision: 0.5954 - recall: 0.5790 - val_accuracy: 0.5997 - val_loss: 0.6515 - val_precision: 0.5808 - val_recall: 0.7166\n",
      "Epoch 645/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.3670 - precision: 0.5892 - recall: 0.6305\n",
      "Epoch 645 - Train Recall: 0.5862 - Val Recall: 0.3823\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5981 - loss: 0.3670 - precision: 0.5895 - recall: 0.6279 - val_accuracy: 0.5622 - val_loss: 0.7269 - val_precision: 0.5972 - val_recall: 0.3823\n",
      "Epoch 646/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6007 - loss: 0.2814 - precision: 0.5913 - recall: 0.7038\n",
      "Epoch 646 - Train Recall: 0.7702 - Val Recall: 0.8366\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5991 - loss: 0.2812 - precision: 0.5889 - recall: 0.7081 - val_accuracy: 0.5825 - val_loss: 0.5434 - val_precision: 0.5547 - val_recall: 0.8366\n",
      "Epoch 647/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5760 - loss: 0.3621 - precision: 0.5502 - recall: 0.6947\n",
      "Epoch 647 - Train Recall: 0.6424 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5761 - loss: 0.3621 - precision: 0.5505 - recall: 0.6941 - val_accuracy: 0.6124 - val_loss: 0.7053 - val_precision: 0.6036 - val_recall: 0.6552\n",
      "Epoch 648/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5806 - loss: 0.3471 - precision: 0.5742 - recall: 0.6062\n",
      "Epoch 648 - Train Recall: 0.6057 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5807 - loss: 0.3471 - precision: 0.5744 - recall: 0.6062 - val_accuracy: 0.5795 - val_loss: 0.6875 - val_precision: 0.5634 - val_recall: 0.7061\n",
      "Epoch 649/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5847 - loss: 0.3720 - precision: 0.5898 - recall: 0.5813\n",
      "Epoch 649 - Train Recall: 0.5469 - Val Recall: 0.4963\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5853 - loss: 0.3718 - precision: 0.5907 - recall: 0.5783 - val_accuracy: 0.5915 - val_loss: 0.7288 - val_precision: 0.6130 - val_recall: 0.4963\n",
      "Epoch 650/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5980 - loss: 0.3283 - precision: 0.6015 - recall: 0.5745\n",
      "Epoch 650 - Train Recall: 0.6203 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5979 - loss: 0.3283 - precision: 0.6013 - recall: 0.5753 - val_accuracy: 0.5922 - val_loss: 0.6438 - val_precision: 0.5826 - val_recall: 0.6507\n",
      "Epoch 651/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5966 - loss: 0.3502 - precision: 0.5889 - recall: 0.6369\n",
      "Epoch 651 - Train Recall: 0.6173 - Val Recall: 0.6597\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5960 - loss: 0.3504 - precision: 0.5885 - recall: 0.6339 - val_accuracy: 0.6049 - val_loss: 0.6918 - val_precision: 0.5946 - val_recall: 0.6597\n",
      "Epoch 652/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5850 - loss: 0.3534 - precision: 0.5841 - recall: 0.6059\n",
      "Epoch 652 - Train Recall: 0.5948 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5851 - loss: 0.3534 - precision: 0.5841 - recall: 0.6057 - val_accuracy: 0.5982 - val_loss: 0.6965 - val_precision: 0.5956 - val_recall: 0.6117\n",
      "Epoch 653/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6023 - loss: 0.3454 - precision: 0.6028 - recall: 0.5749\n",
      "Epoch 653 - Train Recall: 0.5806 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6014 - loss: 0.3456 - precision: 0.6021 - recall: 0.5757 - val_accuracy: 0.5982 - val_loss: 0.6836 - val_precision: 0.5861 - val_recall: 0.6687\n",
      "Epoch 654/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5923 - loss: 0.3655 - precision: 0.6040 - recall: 0.5442\n",
      "Epoch 654 - Train Recall: 0.5097 - Val Recall: 0.5787\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5922 - loss: 0.3655 - precision: 0.6039 - recall: 0.5433 - val_accuracy: 0.5735 - val_loss: 0.7291 - val_precision: 0.5727 - val_recall: 0.5787\n",
      "Epoch 655/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5902 - loss: 0.3647 - precision: 0.6051 - recall: 0.5437\n",
      "Epoch 655 - Train Recall: 0.5349 - Val Recall: 0.5412\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5902 - loss: 0.3646 - precision: 0.6048 - recall: 0.5426 - val_accuracy: 0.5952 - val_loss: 0.7197 - val_precision: 0.6067 - val_recall: 0.5412\n",
      "Epoch 656/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5819 - loss: 0.3459 - precision: 0.5811 - recall: 0.5335\n",
      "Epoch 656 - Train Recall: 0.5536 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5822 - loss: 0.3459 - precision: 0.5819 - recall: 0.5350 - val_accuracy: 0.5802 - val_loss: 0.6835 - val_precision: 0.5699 - val_recall: 0.6537\n",
      "Epoch 657/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5859 - loss: 0.3736 - precision: 0.5889 - recall: 0.5488\n",
      "Epoch 657 - Train Recall: 0.5191 - Val Recall: 0.5412\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5859 - loss: 0.3736 - precision: 0.5892 - recall: 0.5481 - val_accuracy: 0.5892 - val_loss: 0.7374 - val_precision: 0.5987 - val_recall: 0.5412\n",
      "Epoch 658/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6056 - loss: 0.3496 - precision: 0.6279 - recall: 0.5758\n",
      "Epoch 658 - Train Recall: 0.5671 - Val Recall: 0.5757\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6038 - loss: 0.3498 - precision: 0.6240 - recall: 0.5750 - val_accuracy: 0.5795 - val_loss: 0.6940 - val_precision: 0.5801 - val_recall: 0.5757\n",
      "Epoch 659/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5921 - loss: 0.3418 - precision: 0.5998 - recall: 0.5585\n",
      "Epoch 659 - Train Recall: 0.5828 - Val Recall: 0.6042\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5918 - loss: 0.3421 - precision: 0.5990 - recall: 0.5606 - val_accuracy: 0.5877 - val_loss: 0.6828 - val_precision: 0.5849 - val_recall: 0.6042\n",
      "Epoch 660/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5932 - loss: 0.3493 - precision: 0.5923 - recall: 0.5858\n",
      "Epoch 660 - Train Recall: 0.5915 - Val Recall: 0.5817\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5932 - loss: 0.3493 - precision: 0.5923 - recall: 0.5860 - val_accuracy: 0.5945 - val_loss: 0.6880 - val_precision: 0.5969 - val_recall: 0.5817\n",
      "Epoch 661/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 0.3393 - precision: 0.6051 - recall: 0.6063\n",
      "Epoch 661 - Train Recall: 0.6192 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6015 - loss: 0.3393 - precision: 0.6050 - recall: 0.6064 - val_accuracy: 0.6087 - val_loss: 0.6655 - val_precision: 0.5943 - val_recall: 0.6852\n",
      "Epoch 662/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5846 - loss: 0.3615 - precision: 0.5925 - recall: 0.5530\n",
      "Epoch 662 - Train Recall: 0.5487 - Val Recall: 0.5772\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5850 - loss: 0.3614 - precision: 0.5929 - recall: 0.5528 - val_accuracy: 0.5960 - val_loss: 0.7166 - val_precision: 0.5997 - val_recall: 0.5772\n",
      "Epoch 663/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5921 - loss: 0.3505 - precision: 0.5766 - recall: 0.5835\n",
      "Epoch 663 - Train Recall: 0.5791 - Val Recall: 0.5307\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5920 - loss: 0.3505 - precision: 0.5769 - recall: 0.5834 - val_accuracy: 0.5750 - val_loss: 0.6985 - val_precision: 0.5822 - val_recall: 0.5307\n",
      "Epoch 664/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5796 - loss: 0.3301 - precision: 0.5694 - recall: 0.6113\n",
      "Epoch 664 - Train Recall: 0.6466 - Val Recall: 0.6312\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5800 - loss: 0.3301 - precision: 0.5698 - recall: 0.6126 - val_accuracy: 0.6049 - val_loss: 0.6440 - val_precision: 0.5997 - val_recall: 0.6312\n",
      "Epoch 665/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5876 - loss: 0.3390 - precision: 0.5720 - recall: 0.6556\n",
      "Epoch 665 - Train Recall: 0.6514 - Val Recall: 0.7661\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5884 - loss: 0.3389 - precision: 0.5735 - recall: 0.6550 - val_accuracy: 0.5990 - val_loss: 0.6694 - val_precision: 0.5742 - val_recall: 0.7661\n",
      "Epoch 666/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5973 - loss: 0.3720 - precision: 0.5918 - recall: 0.5857\n",
      "Epoch 666 - Train Recall: 0.5416 - Val Recall: 0.4078\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5973 - loss: 0.3720 - precision: 0.5924 - recall: 0.5839 - val_accuracy: 0.5675 - val_loss: 0.7367 - val_precision: 0.5991 - val_recall: 0.4078\n",
      "Epoch 667/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6092 - loss: 0.2968 - precision: 0.5991 - recall: 0.6334\n",
      "Epoch 667 - Train Recall: 0.6840 - Val Recall: 0.8081\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6089 - loss: 0.2968 - precision: 0.5986 - recall: 0.6352 - val_accuracy: 0.5802 - val_loss: 0.5858 - val_precision: 0.5551 - val_recall: 0.8081\n",
      "Epoch 668/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5938 - loss: 0.3752 - precision: 0.5840 - recall: 0.6720\n",
      "Epoch 668 - Train Recall: 0.5967 - Val Recall: 0.4513\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5936 - loss: 0.3751 - precision: 0.5844 - recall: 0.6673 - val_accuracy: 0.5900 - val_loss: 0.7283 - val_precision: 0.6245 - val_recall: 0.4513\n",
      "Epoch 669/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6059 - loss: 0.2964 - precision: 0.5995 - recall: 0.6068\n",
      "Epoch 669 - Train Recall: 0.6949 - Val Recall: 0.7631\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6032 - loss: 0.2967 - precision: 0.5957 - recall: 0.6163 - val_accuracy: 0.6027 - val_loss: 0.5878 - val_precision: 0.5778 - val_recall: 0.7631\n",
      "Epoch 670/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6041 - loss: 0.3581 - precision: 0.5893 - recall: 0.7110\n",
      "Epoch 670 - Train Recall: 0.6462 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.3581 - precision: 0.5894 - recall: 0.7106 - val_accuracy: 0.5967 - val_loss: 0.7026 - val_precision: 0.5988 - val_recall: 0.5862\n",
      "Epoch 671/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6093 - loss: 0.3251 - precision: 0.6169 - recall: 0.6313\n",
      "Epoch 671 - Train Recall: 0.6391 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6083 - loss: 0.3252 - precision: 0.6148 - recall: 0.6318 - val_accuracy: 0.5885 - val_loss: 0.6469 - val_precision: 0.5780 - val_recall: 0.6552\n",
      "Epoch 672/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5970 - loss: 0.3480 - precision: 0.5926 - recall: 0.6554\n",
      "Epoch 672 - Train Recall: 0.6241 - Val Recall: 0.6417\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5966 - loss: 0.3479 - precision: 0.5923 - recall: 0.6518 - val_accuracy: 0.6049 - val_loss: 0.6837 - val_precision: 0.5978 - val_recall: 0.6417\n",
      "Epoch 673/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6048 - loss: 0.3456 - precision: 0.5947 - recall: 0.6173\n",
      "Epoch 673 - Train Recall: 0.6034 - Val Recall: 0.6657\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6046 - loss: 0.3456 - precision: 0.5948 - recall: 0.6169 - val_accuracy: 0.5937 - val_loss: 0.6852 - val_precision: 0.5819 - val_recall: 0.6657\n",
      "Epoch 674/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6050 - loss: 0.3598 - precision: 0.6014 - recall: 0.5890\n",
      "Epoch 674 - Train Recall: 0.5615 - Val Recall: 0.4978\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6037 - loss: 0.3599 - precision: 0.6011 - recall: 0.5862 - val_accuracy: 0.5915 - val_loss: 0.7109 - val_precision: 0.6125 - val_recall: 0.4978\n",
      "Epoch 675/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5973 - loss: 0.3250 - precision: 0.5962 - recall: 0.6136\n",
      "Epoch 675 - Train Recall: 0.6492 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5973 - loss: 0.3250 - precision: 0.5960 - recall: 0.6144 - val_accuracy: 0.5855 - val_loss: 0.6411 - val_precision: 0.5733 - val_recall: 0.6687\n",
      "Epoch 676/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6029 - loss: 0.3444 - precision: 0.6025 - recall: 0.6436\n",
      "Epoch 676 - Train Recall: 0.6008 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6021 - loss: 0.3446 - precision: 0.6016 - recall: 0.6406 - val_accuracy: 0.6109 - val_loss: 0.6848 - val_precision: 0.6054 - val_recall: 0.6372\n",
      "Epoch 677/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5872 - loss: 0.3524 - precision: 0.5888 - recall: 0.5654\n",
      "Epoch 677 - Train Recall: 0.5697 - Val Recall: 0.5937\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5872 - loss: 0.3525 - precision: 0.5888 - recall: 0.5656 - val_accuracy: 0.5960 - val_loss: 0.6983 - val_precision: 0.5964 - val_recall: 0.5937\n",
      "Epoch 678/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5899 - loss: 0.3488 - precision: 0.5852 - recall: 0.5536\n",
      "Epoch 678 - Train Recall: 0.5645 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5900 - loss: 0.3489 - precision: 0.5857 - recall: 0.5541 - val_accuracy: 0.6049 - val_loss: 0.6887 - val_precision: 0.5972 - val_recall: 0.6447\n",
      "Epoch 679/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.3670 - precision: 0.6049 - recall: 0.5408\n",
      "Epoch 679 - Train Recall: 0.5210 - Val Recall: 0.4993\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5955 - loss: 0.3669 - precision: 0.6041 - recall: 0.5379 - val_accuracy: 0.5855 - val_loss: 0.7200 - val_precision: 0.6033 - val_recall: 0.4993\n",
      "Epoch 680/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6045 - loss: 0.3312 - precision: 0.6087 - recall: 0.5839\n",
      "Epoch 680 - Train Recall: 0.6023 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.3314 - precision: 0.6081 - recall: 0.5849 - val_accuracy: 0.5900 - val_loss: 0.6619 - val_precision: 0.5843 - val_recall: 0.6237\n",
      "Epoch 681/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6034 - loss: 0.3467 - precision: 0.5903 - recall: 0.5991\n",
      "Epoch 681 - Train Recall: 0.5993 - Val Recall: 0.5952\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6032 - loss: 0.3467 - precision: 0.5904 - recall: 0.5991 - val_accuracy: 0.5757 - val_loss: 0.6889 - val_precision: 0.5729 - val_recall: 0.5952\n",
      "Epoch 682/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5943 - loss: 0.3407 - precision: 0.5870 - recall: 0.6499\n",
      "Epoch 682 - Train Recall: 0.6406 - Val Recall: 0.5907\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 0.3407 - precision: 0.5870 - recall: 0.6493 - val_accuracy: 0.5960 - val_loss: 0.6728 - val_precision: 0.5970 - val_recall: 0.5907\n",
      "Epoch 683/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5967 - loss: 0.3297 - precision: 0.5915 - recall: 0.6298\n",
      "Epoch 683 - Train Recall: 0.6589 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5968 - loss: 0.3296 - precision: 0.5910 - recall: 0.6325 - val_accuracy: 0.5997 - val_loss: 0.6472 - val_precision: 0.5878 - val_recall: 0.6672\n",
      "Epoch 684/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5878 - loss: 0.3443 - precision: 0.5740 - recall: 0.6544\n",
      "Epoch 684 - Train Recall: 0.6518 - Val Recall: 0.5367\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5881 - loss: 0.3443 - precision: 0.5744 - recall: 0.6543 - val_accuracy: 0.5787 - val_loss: 0.6814 - val_precision: 0.5859 - val_recall: 0.5367\n",
      "Epoch 685/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5897 - loss: 0.3133 - precision: 0.5797 - recall: 0.6433\n",
      "Epoch 685 - Train Recall: 0.6795 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5898 - loss: 0.3132 - precision: 0.5795 - recall: 0.6452 - val_accuracy: 0.5915 - val_loss: 0.6111 - val_precision: 0.5768 - val_recall: 0.6867\n",
      "Epoch 686/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6012 - loss: 0.3434 - precision: 0.5931 - recall: 0.6895\n",
      "Epoch 686 - Train Recall: 0.6469 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6004 - loss: 0.3436 - precision: 0.5922 - recall: 0.6858 - val_accuracy: 0.6027 - val_loss: 0.6825 - val_precision: 0.6018 - val_recall: 0.6072\n",
      "Epoch 687/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6033 - loss: 0.3312 - precision: 0.5978 - recall: 0.6488\n",
      "Epoch 687 - Train Recall: 0.6458 - Val Recall: 0.6222\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6033 - loss: 0.3312 - precision: 0.5977 - recall: 0.6488 - val_accuracy: 0.5907 - val_loss: 0.6586 - val_precision: 0.5853 - val_recall: 0.6222\n",
      "Epoch 688/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5934 - loss: 0.3367 - precision: 0.5867 - recall: 0.6436\n",
      "Epoch 688 - Train Recall: 0.6383 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5934 - loss: 0.3367 - precision: 0.5866 - recall: 0.6436 - val_accuracy: 0.5982 - val_loss: 0.6587 - val_precision: 0.5861 - val_recall: 0.6687\n",
      "Epoch 689/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5912 - loss: 0.3496 - precision: 0.5835 - recall: 0.6145\n",
      "Epoch 689 - Train Recall: 0.6004 - Val Recall: 0.5307\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5916 - loss: 0.3496 - precision: 0.5844 - recall: 0.6136 - val_accuracy: 0.5832 - val_loss: 0.6978 - val_precision: 0.5930 - val_recall: 0.5307\n",
      "Epoch 690/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 0.3228 - precision: 0.5781 - recall: 0.6374\n",
      "Epoch 690 - Train Recall: 0.6773 - Val Recall: 0.6582\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5896 - loss: 0.3228 - precision: 0.5783 - recall: 0.6405 - val_accuracy: 0.6049 - val_loss: 0.6343 - val_precision: 0.5949 - val_recall: 0.6582\n",
      "Epoch 691/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5873 - loss: 0.3379 - precision: 0.5745 - recall: 0.7013\n",
      "Epoch 691 - Train Recall: 0.6867 - Val Recall: 0.5532\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5888 - loss: 0.3378 - precision: 0.5756 - recall: 0.6996 - val_accuracy: 0.5765 - val_loss: 0.6747 - val_precision: 0.5802 - val_recall: 0.5532\n",
      "Epoch 692/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5679 - loss: 0.3089 - precision: 0.5487 - recall: 0.6651\n",
      "Epoch 692 - Train Recall: 0.7024 - Val Recall: 0.7256\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5687 - loss: 0.3088 - precision: 0.5497 - recall: 0.6681 - val_accuracy: 0.5870 - val_loss: 0.6087 - val_precision: 0.5681 - val_recall: 0.7256\n",
      "Epoch 693/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5910 - loss: 0.3498 - precision: 0.5730 - recall: 0.7166\n",
      "Epoch 693 - Train Recall: 0.6574 - Val Recall: 0.7331\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5909 - loss: 0.3498 - precision: 0.5730 - recall: 0.7155 - val_accuracy: 0.6034 - val_loss: 0.6823 - val_precision: 0.5821 - val_recall: 0.7331\n",
      "Epoch 694/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5754 - loss: 0.3639 - precision: 0.5691 - recall: 0.5587\n",
      "Epoch 694 - Train Recall: 0.5382 - Val Recall: 0.4978\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5756 - loss: 0.3639 - precision: 0.5696 - recall: 0.5584 - val_accuracy: 0.5892 - val_loss: 0.7094 - val_precision: 0.6092 - val_recall: 0.4978\n",
      "Epoch 695/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5871 - loss: 0.3304 - precision: 0.5809 - recall: 0.6071\n",
      "Epoch 695 - Train Recall: 0.6432 - Val Recall: 0.8276\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5872 - loss: 0.3304 - precision: 0.5808 - recall: 0.6099 - val_accuracy: 0.5952 - val_loss: 0.6518 - val_precision: 0.5650 - val_recall: 0.8276\n",
      "Epoch 696/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6001 - loss: 0.3883 - precision: 0.6035 - recall: 0.5871\n",
      "Epoch 696 - Train Recall: 0.4963 - Val Recall: 0.5757\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5994 - loss: 0.3884 - precision: 0.6036 - recall: 0.5828 - val_accuracy: 0.5952 - val_loss: 0.7621 - val_precision: 0.5991 - val_recall: 0.5757\n",
      "Epoch 697/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5903 - loss: 0.3671 - precision: 0.6104 - recall: 0.4809\n",
      "Epoch 697 - Train Recall: 0.4861 - Val Recall: 0.5982\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5901 - loss: 0.3671 - precision: 0.6104 - recall: 0.4811 - val_accuracy: 0.5952 - val_loss: 0.7314 - val_precision: 0.5946 - val_recall: 0.5982\n",
      "Epoch 698/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5840 - loss: 0.3777 - precision: 0.6010 - recall: 0.4690\n",
      "Epoch 698 - Train Recall: 0.4674 - Val Recall: 0.5427\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5839 - loss: 0.3779 - precision: 0.6022 - recall: 0.4685 - val_accuracy: 0.5982 - val_loss: 0.7562 - val_precision: 0.6105 - val_recall: 0.5427\n",
      "Epoch 699/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5840 - loss: 0.3694 - precision: 0.6030 - recall: 0.5118\n",
      "Epoch 699 - Train Recall: 0.5026 - Val Recall: 0.5442\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5843 - loss: 0.3694 - precision: 0.6033 - recall: 0.5113 - val_accuracy: 0.6004 - val_loss: 0.7232 - val_precision: 0.6132 - val_recall: 0.5442\n",
      "Epoch 700/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5928 - loss: 0.3550 - precision: 0.5999 - recall: 0.5210\n",
      "Epoch 700 - Train Recall: 0.5491 - Val Recall: 0.4873\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5928 - loss: 0.3550 - precision: 0.5999 - recall: 0.5212 - val_accuracy: 0.5675 - val_loss: 0.7169 - val_precision: 0.5804 - val_recall: 0.4873\n",
      "Epoch 701/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5996 - loss: 0.3217 - precision: 0.5871 - recall: 0.6408\n",
      "Epoch 701 - Train Recall: 0.6709 - Val Recall: 0.7091\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5993 - loss: 0.3217 - precision: 0.5868 - recall: 0.6423 - val_accuracy: 0.5862 - val_loss: 0.6403 - val_precision: 0.5692 - val_recall: 0.7091\n",
      "Epoch 702/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5947 - loss: 0.3531 - precision: 0.5903 - recall: 0.6434\n",
      "Epoch 702 - Train Recall: 0.6196 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5947 - loss: 0.3531 - precision: 0.5903 - recall: 0.6427 - val_accuracy: 0.5802 - val_loss: 0.7104 - val_precision: 0.5710 - val_recall: 0.6447\n",
      "Epoch 703/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5964 - loss: 0.3483 - precision: 0.6024 - recall: 0.6065\n",
      "Epoch 703 - Train Recall: 0.5780 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5960 - loss: 0.3484 - precision: 0.6015 - recall: 0.6022 - val_accuracy: 0.5832 - val_loss: 0.6934 - val_precision: 0.5830 - val_recall: 0.5847\n",
      "Epoch 704/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5919 - loss: 0.3446 - precision: 0.5795 - recall: 0.6326\n",
      "Epoch 704 - Train Recall: 0.6308 - Val Recall: 0.6012\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5921 - loss: 0.3446 - precision: 0.5800 - recall: 0.6325 - val_accuracy: 0.5877 - val_loss: 0.6834 - val_precision: 0.5854 - val_recall: 0.6012\n",
      "Epoch 705/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6044 - loss: 0.3328 - precision: 0.6146 - recall: 0.6201\n",
      "Epoch 705 - Train Recall: 0.6394 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.3328 - precision: 0.6137 - recall: 0.6207 - val_accuracy: 0.5870 - val_loss: 0.6669 - val_precision: 0.5749 - val_recall: 0.6672\n",
      "Epoch 706/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5869 - loss: 0.3518 - precision: 0.5826 - recall: 0.6168\n",
      "Epoch 706 - Train Recall: 0.6038 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5875 - loss: 0.3517 - precision: 0.5833 - recall: 0.6161 - val_accuracy: 0.5892 - val_loss: 0.6867 - val_precision: 0.5756 - val_recall: 0.6792\n",
      "Epoch 707/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6006 - loss: 0.3603 - precision: 0.5905 - recall: 0.6043\n",
      "Epoch 707 - Train Recall: 0.5551 - Val Recall: 0.5397\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 0.3607 - precision: 0.5904 - recall: 0.5996 - val_accuracy: 0.5870 - val_loss: 0.7186 - val_precision: 0.5960 - val_recall: 0.5397\n",
      "Epoch 708/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 0.3344 - precision: 0.6044 - recall: 0.6047\n",
      "Epoch 708 - Train Recall: 0.6012 - Val Recall: 0.7016\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6027 - loss: 0.3345 - precision: 0.6041 - recall: 0.6046 - val_accuracy: 0.6079 - val_loss: 0.6637 - val_precision: 0.5909 - val_recall: 0.7016\n",
      "Epoch 709/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5878 - loss: 0.3705 - precision: 0.5848 - recall: 0.5451\n",
      "Epoch 709 - Train Recall: 0.5292 - Val Recall: 0.4783\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5881 - loss: 0.3703 - precision: 0.5872 - recall: 0.5431 - val_accuracy: 0.5915 - val_loss: 0.7314 - val_precision: 0.6182 - val_recall: 0.4783\n",
      "Epoch 710/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.3244 - precision: 0.6025 - recall: 0.5530\n",
      "Epoch 710 - Train Recall: 0.6196 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5973 - loss: 0.3244 - precision: 0.6017 - recall: 0.5615 - val_accuracy: 0.5832 - val_loss: 0.6438 - val_precision: 0.5783 - val_recall: 0.6147\n",
      "Epoch 711/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5974 - loss: 0.3399 - precision: 0.5783 - recall: 0.6577\n",
      "Epoch 711 - Train Recall: 0.6364 - Val Recall: 0.5712\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5974 - loss: 0.3399 - precision: 0.5783 - recall: 0.6576 - val_accuracy: 0.5840 - val_loss: 0.6772 - val_precision: 0.5862 - val_recall: 0.5712\n",
      "Epoch 712/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5857 - loss: 0.3263 - precision: 0.5767 - recall: 0.7133\n",
      "Epoch 712 - Train Recall: 0.7133 - Val Recall: 0.7076\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5858 - loss: 0.3262 - precision: 0.5766 - recall: 0.7133 - val_accuracy: 0.5877 - val_loss: 0.6439 - val_precision: 0.5707 - val_recall: 0.7076\n",
      "Epoch 713/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6003 - loss: 0.3394 - precision: 0.5904 - recall: 0.6718\n",
      "Epoch 713 - Train Recall: 0.6398 - Val Recall: 0.5547\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 0.3397 - precision: 0.5894 - recall: 0.6680 - val_accuracy: 0.5840 - val_loss: 0.6711 - val_precision: 0.5892 - val_recall: 0.5547\n",
      "Epoch 714/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6062 - loss: 0.3162 - precision: 0.5951 - recall: 0.7151\n",
      "Epoch 714 - Train Recall: 0.7028 - Val Recall: 0.7406\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6053 - loss: 0.3163 - precision: 0.5939 - recall: 0.7145 - val_accuracy: 0.5997 - val_loss: 0.6302 - val_precision: 0.5778 - val_recall: 0.7406\n",
      "Epoch 715/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5903 - loss: 0.3530 - precision: 0.5743 - recall: 0.6431\n",
      "Epoch 715 - Train Recall: 0.6001 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5903 - loss: 0.3530 - precision: 0.5745 - recall: 0.6426 - val_accuracy: 0.5690 - val_loss: 0.6999 - val_precision: 0.5642 - val_recall: 0.6057\n",
      "Epoch 716/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6054 - loss: 0.3425 - precision: 0.6000 - recall: 0.6341\n",
      "Epoch 716 - Train Recall: 0.6267 - Val Recall: 0.6597\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6050 - loss: 0.3426 - precision: 0.5996 - recall: 0.6335 - val_accuracy: 0.5982 - val_loss: 0.6818 - val_precision: 0.5874 - val_recall: 0.6597\n",
      "Epoch 717/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5931 - loss: 0.3507 - precision: 0.5938 - recall: 0.5774\n",
      "Epoch 717 - Train Recall: 0.5566 - Val Recall: 0.6402\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5930 - loss: 0.3507 - precision: 0.5938 - recall: 0.5770 - val_accuracy: 0.5855 - val_loss: 0.6940 - val_precision: 0.5770 - val_recall: 0.6402\n",
      "Epoch 718/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.3649 - precision: 0.5941 - recall: 0.5879\n",
      "Epoch 718 - Train Recall: 0.5765 - Val Recall: 0.5112\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5941 - loss: 0.3649 - precision: 0.5941 - recall: 0.5875 - val_accuracy: 0.5855 - val_loss: 0.7310 - val_precision: 0.6004 - val_recall: 0.5112\n",
      "Epoch 719/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6062 - loss: 0.3220 - precision: 0.6091 - recall: 0.6178\n",
      "Epoch 719 - Train Recall: 0.6668 - Val Recall: 0.7346\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6058 - loss: 0.3220 - precision: 0.6074 - recall: 0.6223 - val_accuracy: 0.5900 - val_loss: 0.6483 - val_precision: 0.5698 - val_recall: 0.7346\n",
      "Epoch 720/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5736 - loss: 0.3624 - precision: 0.5727 - recall: 0.6065\n",
      "Epoch 720 - Train Recall: 0.5877 - Val Recall: 0.5022\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5739 - loss: 0.3624 - precision: 0.5730 - recall: 0.6060 - val_accuracy: 0.5840 - val_loss: 0.7108 - val_precision: 0.6004 - val_recall: 0.5022\n",
      "Epoch 721/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 0.3160 - precision: 0.5934 - recall: 0.6288\n",
      "Epoch 721 - Train Recall: 0.6915 - Val Recall: 0.7451\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6025 - loss: 0.3160 - precision: 0.5926 - recall: 0.6332 - val_accuracy: 0.5832 - val_loss: 0.6266 - val_precision: 0.5629 - val_recall: 0.7451\n",
      "Epoch 722/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5927 - loss: 0.3568 - precision: 0.5756 - recall: 0.6594\n",
      "Epoch 722 - Train Recall: 0.6256 - Val Recall: 0.5637\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5928 - loss: 0.3568 - precision: 0.5767 - recall: 0.6564 - val_accuracy: 0.5892 - val_loss: 0.6996 - val_precision: 0.5940 - val_recall: 0.5637\n",
      "Epoch 723/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5904 - loss: 0.3262 - precision: 0.5840 - recall: 0.6921\n",
      "Epoch 723 - Train Recall: 0.6972 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5904 - loss: 0.3262 - precision: 0.5837 - recall: 0.6922 - val_accuracy: 0.5862 - val_loss: 0.6502 - val_precision: 0.5718 - val_recall: 0.6867\n",
      "Epoch 724/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5983 - loss: 0.3389 - precision: 0.5868 - recall: 0.6849\n",
      "Epoch 724 - Train Recall: 0.6582 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5981 - loss: 0.3389 - precision: 0.5866 - recall: 0.6836 - val_accuracy: 0.6012 - val_loss: 0.6705 - val_precision: 0.5952 - val_recall: 0.6327\n",
      "Epoch 725/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5925 - loss: 0.3350 - precision: 0.5819 - recall: 0.6584\n",
      "Epoch 725 - Train Recall: 0.6510 - Val Recall: 0.6597\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5923 - loss: 0.3351 - precision: 0.5817 - recall: 0.6579 - val_accuracy: 0.5960 - val_loss: 0.6627 - val_precision: 0.5851 - val_recall: 0.6597\n",
      "Epoch 726/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6035 - loss: 0.3433 - precision: 0.5964 - recall: 0.6508\n",
      "Epoch 726 - Train Recall: 0.6387 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6023 - loss: 0.3436 - precision: 0.5950 - recall: 0.6489 - val_accuracy: 0.5885 - val_loss: 0.6783 - val_precision: 0.5845 - val_recall: 0.6117\n",
      "Epoch 727/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5982 - loss: 0.3327 - precision: 0.5759 - recall: 0.6594\n",
      "Epoch 727 - Train Recall: 0.6683 - Val Recall: 0.7226\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5981 - loss: 0.3328 - precision: 0.5763 - recall: 0.6598 - val_accuracy: 0.5997 - val_loss: 0.6585 - val_precision: 0.5800 - val_recall: 0.7226\n",
      "Epoch 728/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5904 - loss: 0.3567 - precision: 0.5830 - recall: 0.6244\n",
      "Epoch 728 - Train Recall: 0.5990 - Val Recall: 0.6162\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5905 - loss: 0.3567 - precision: 0.5832 - recall: 0.6239 - val_accuracy: 0.6012 - val_loss: 0.7045 - val_precision: 0.5983 - val_recall: 0.6162\n",
      "Epoch 729/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5969 - loss: 0.3463 - precision: 0.6013 - recall: 0.5957\n",
      "Epoch 729 - Train Recall: 0.5903 - Val Recall: 0.6522\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5968 - loss: 0.3463 - precision: 0.6011 - recall: 0.5956 - val_accuracy: 0.5952 - val_loss: 0.6875 - val_precision: 0.5855 - val_recall: 0.6522\n",
      "Epoch 730/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6044 - loss: 0.3586 - precision: 0.6041 - recall: 0.5743\n",
      "Epoch 730 - Train Recall: 0.5667 - Val Recall: 0.5322\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6040 - loss: 0.3588 - precision: 0.6041 - recall: 0.5739 - val_accuracy: 0.5975 - val_loss: 0.7068 - val_precision: 0.6121 - val_recall: 0.5322\n",
      "Epoch 731/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6022 - loss: 0.3301 - precision: 0.5994 - recall: 0.5943\n",
      "Epoch 731 - Train Recall: 0.6278 - Val Recall: 0.6012\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6020 - loss: 0.3302 - precision: 0.5991 - recall: 0.5957 - val_accuracy: 0.5982 - val_loss: 0.6561 - val_precision: 0.5976 - val_recall: 0.6012\n",
      "Epoch 732/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6061 - loss: 0.3327 - precision: 0.5889 - recall: 0.6674\n",
      "Epoch 732 - Train Recall: 0.6518 - Val Recall: 0.6957\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6057 - loss: 0.3328 - precision: 0.5888 - recall: 0.6666 - val_accuracy: 0.5817 - val_loss: 0.6649 - val_precision: 0.5665 - val_recall: 0.6957\n",
      "Epoch 733/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5910 - loss: 0.3556 - precision: 0.5782 - recall: 0.6115\n",
      "Epoch 733 - Train Recall: 0.6068 - Val Recall: 0.6702\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5913 - loss: 0.3555 - precision: 0.5789 - recall: 0.6113 - val_accuracy: 0.5832 - val_loss: 0.7073 - val_precision: 0.5709 - val_recall: 0.6702\n",
      "Epoch 734/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5892 - loss: 0.3609 - precision: 0.5818 - recall: 0.5842\n",
      "Epoch 734 - Train Recall: 0.5693 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5896 - loss: 0.3608 - precision: 0.5832 - recall: 0.5829 - val_accuracy: 0.5877 - val_loss: 0.7104 - val_precision: 0.5880 - val_recall: 0.5862\n",
      "Epoch 735/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6011 - loss: 0.3459 - precision: 0.5946 - recall: 0.6025\n",
      "Epoch 735 - Train Recall: 0.6038 - Val Recall: 0.6132\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 0.3460 - precision: 0.5945 - recall: 0.6025 - val_accuracy: 0.5937 - val_loss: 0.6861 - val_precision: 0.5902 - val_recall: 0.6132\n",
      "Epoch 736/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5872 - loss: 0.3435 - precision: 0.5878 - recall: 0.5624\n",
      "Epoch 736 - Train Recall: 0.5675 - Val Recall: 0.4858\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5872 - loss: 0.3435 - precision: 0.5879 - recall: 0.5626 - val_accuracy: 0.5915 - val_loss: 0.6816 - val_precision: 0.6160 - val_recall: 0.4858\n",
      "Epoch 737/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5975 - loss: 0.3187 - precision: 0.5928 - recall: 0.6706\n",
      "Epoch 737 - Train Recall: 0.6979 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5979 - loss: 0.3184 - precision: 0.5923 - recall: 0.6729 - val_accuracy: 0.5930 - val_loss: 0.6297 - val_precision: 0.5814 - val_recall: 0.6642\n",
      "Epoch 738/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5870 - loss: 0.3344 - precision: 0.5678 - recall: 0.6606\n",
      "Epoch 738 - Train Recall: 0.6492 - Val Recall: 0.6747\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5870 - loss: 0.3344 - precision: 0.5680 - recall: 0.6606 - val_accuracy: 0.5915 - val_loss: 0.6582 - val_precision: 0.5784 - val_recall: 0.6747\n",
      "Epoch 739/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5921 - loss: 0.3490 - precision: 0.5754 - recall: 0.6517\n",
      "Epoch 739 - Train Recall: 0.6346 - Val Recall: 0.7136\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5922 - loss: 0.3490 - precision: 0.5758 - recall: 0.6511 - val_accuracy: 0.6162 - val_loss: 0.6828 - val_precision: 0.5972 - val_recall: 0.7136\n",
      "Epoch 740/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5936 - loss: 0.3598 - precision: 0.5874 - recall: 0.6221\n",
      "Epoch 740 - Train Recall: 0.5768 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5934 - loss: 0.3599 - precision: 0.5876 - recall: 0.6199 - val_accuracy: 0.6034 - val_loss: 0.7218 - val_precision: 0.6049 - val_recall: 0.5967\n",
      "Epoch 741/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5990 - loss: 0.3439 - precision: 0.6149 - recall: 0.5893\n",
      "Epoch 741 - Train Recall: 0.5892 - Val Recall: 0.4933\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5988 - loss: 0.3441 - precision: 0.6139 - recall: 0.5893 - val_accuracy: 0.5802 - val_loss: 0.6891 - val_precision: 0.5971 - val_recall: 0.4933\n",
      "Epoch 742/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5989 - loss: 0.3139 - precision: 0.6018 - recall: 0.6560\n",
      "Epoch 742 - Train Recall: 0.6923 - Val Recall: 0.6657\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5982 - loss: 0.3139 - precision: 0.5997 - recall: 0.6588 - val_accuracy: 0.6019 - val_loss: 0.6254 - val_precision: 0.5904 - val_recall: 0.6657\n",
      "Epoch 743/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5853 - loss: 0.3371 - precision: 0.5588 - recall: 0.6735\n",
      "Epoch 743 - Train Recall: 0.6724 - Val Recall: 0.7121\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5866 - loss: 0.3368 - precision: 0.5618 - recall: 0.6733 - val_accuracy: 0.6072 - val_loss: 0.6597 - val_precision: 0.5886 - val_recall: 0.7121\n",
      "Epoch 744/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6043 - loss: 0.3503 - precision: 0.5948 - recall: 0.6682\n",
      "Epoch 744 - Train Recall: 0.6233 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6039 - loss: 0.3504 - precision: 0.5945 - recall: 0.6664 - val_accuracy: 0.5667 - val_loss: 0.6973 - val_precision: 0.5675 - val_recall: 0.5607\n",
      "Epoch 745/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5857 - loss: 0.3267 - precision: 0.5722 - recall: 0.6278\n",
      "Epoch 745 - Train Recall: 0.6657 - Val Recall: 0.6567\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5863 - loss: 0.3266 - precision: 0.5732 - recall: 0.6320 - val_accuracy: 0.6102 - val_loss: 0.6359 - val_precision: 0.6008 - val_recall: 0.6567\n",
      "Epoch 746/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5997 - loss: 0.3377 - precision: 0.5924 - recall: 0.6547\n",
      "Epoch 746 - Train Recall: 0.6248 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5995 - loss: 0.3378 - precision: 0.5922 - recall: 0.6534 - val_accuracy: 0.5645 - val_loss: 0.6833 - val_precision: 0.5620 - val_recall: 0.5847\n",
      "Epoch 747/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5971 - loss: 0.3315 - precision: 0.6050 - recall: 0.6698\n",
      "Epoch 747 - Train Recall: 0.6664 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5971 - loss: 0.3315 - precision: 0.6036 - recall: 0.6697 - val_accuracy: 0.5630 - val_loss: 0.6624 - val_precision: 0.5506 - val_recall: 0.6852\n",
      "Epoch 748/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5869 - loss: 0.3474 - precision: 0.5702 - recall: 0.6062\n",
      "Epoch 748 - Train Recall: 0.6012 - Val Recall: 0.6882\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5867 - loss: 0.3474 - precision: 0.5708 - recall: 0.6059 - val_accuracy: 0.6094 - val_loss: 0.6889 - val_precision: 0.5946 - val_recall: 0.6882\n",
      "Epoch 749/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5865 - loss: 0.3674 - precision: 0.5866 - recall: 0.5518\n",
      "Epoch 749 - Train Recall: 0.5319 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5866 - loss: 0.3674 - precision: 0.5870 - recall: 0.5513 - val_accuracy: 0.6094 - val_loss: 0.7226 - val_precision: 0.6070 - val_recall: 0.6207\n",
      "Epoch 750/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5792 - loss: 0.3709 - precision: 0.5959 - recall: 0.4524\n",
      "Epoch 750 - Train Recall: 0.4588 - Val Recall: 0.4258\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5793 - loss: 0.3709 - precision: 0.5963 - recall: 0.4526 - val_accuracy: 0.5832 - val_loss: 0.7260 - val_precision: 0.6214 - val_recall: 0.4258\n",
      "Epoch 751/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5979 - loss: 0.3291 - precision: 0.5970 - recall: 0.5890\n",
      "Epoch 751 - Train Recall: 0.6391 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5976 - loss: 0.3291 - precision: 0.5963 - recall: 0.5934 - val_accuracy: 0.5862 - val_loss: 0.6574 - val_precision: 0.5795 - val_recall: 0.6282\n",
      "Epoch 752/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5943 - loss: 0.3384 - precision: 0.5804 - recall: 0.6541\n",
      "Epoch 752 - Train Recall: 0.6271 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5942 - loss: 0.3384 - precision: 0.5805 - recall: 0.6534 - val_accuracy: 0.5870 - val_loss: 0.6692 - val_precision: 0.5788 - val_recall: 0.6387\n",
      "Epoch 753/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6057 - loss: 0.3422 - precision: 0.5991 - recall: 0.6344\n",
      "Epoch 753 - Train Recall: 0.6214 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6056 - loss: 0.3422 - precision: 0.5991 - recall: 0.6342 - val_accuracy: 0.5885 - val_loss: 0.6832 - val_precision: 0.5819 - val_recall: 0.6282\n",
      "Epoch 754/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.3444 - precision: 0.5973 - recall: 0.6131\n",
      "Epoch 754 - Train Recall: 0.6169 - Val Recall: 0.6132\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5964 - loss: 0.3444 - precision: 0.5964 - recall: 0.6134 - val_accuracy: 0.6004 - val_loss: 0.6745 - val_precision: 0.5980 - val_recall: 0.6132\n",
      "Epoch 755/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6114 - loss: 0.3387 - precision: 0.6081 - recall: 0.6471\n",
      "Epoch 755 - Train Recall: 0.6376 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6105 - loss: 0.3388 - precision: 0.6068 - recall: 0.6465 - val_accuracy: 0.5937 - val_loss: 0.6708 - val_precision: 0.5867 - val_recall: 0.6342\n",
      "Epoch 756/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6004 - loss: 0.3405 - precision: 0.6044 - recall: 0.6777\n",
      "Epoch 756 - Train Recall: 0.6732 - Val Recall: 0.6597\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5994 - loss: 0.3406 - precision: 0.6011 - recall: 0.6774 - val_accuracy: 0.6027 - val_loss: 0.6755 - val_precision: 0.5922 - val_recall: 0.6597\n",
      "Epoch 757/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6057 - loss: 0.3359 - precision: 0.5997 - recall: 0.6322\n",
      "Epoch 757 - Train Recall: 0.6293 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6055 - loss: 0.3360 - precision: 0.5995 - recall: 0.6322 - val_accuracy: 0.5885 - val_loss: 0.6675 - val_precision: 0.5819 - val_recall: 0.6282\n",
      "Epoch 758/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5963 - loss: 0.3380 - precision: 0.5952 - recall: 0.6381\n",
      "Epoch 758 - Train Recall: 0.6173 - Val Recall: 0.6132\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5963 - loss: 0.3381 - precision: 0.5950 - recall: 0.6374 - val_accuracy: 0.6004 - val_loss: 0.6765 - val_precision: 0.5980 - val_recall: 0.6132\n",
      "Epoch 759/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6010 - loss: 0.3375 - precision: 0.5984 - recall: 0.6063\n",
      "Epoch 759 - Train Recall: 0.6143 - Val Recall: 0.6012\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 0.3376 - precision: 0.5982 - recall: 0.6066 - val_accuracy: 0.5772 - val_loss: 0.6768 - val_precision: 0.5737 - val_recall: 0.6012\n",
      "Epoch 760/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5882 - loss: 0.3389 - precision: 0.5919 - recall: 0.6621\n",
      "Epoch 760 - Train Recall: 0.6627 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5880 - loss: 0.3388 - precision: 0.5897 - recall: 0.6628 - val_accuracy: 0.5825 - val_loss: 0.6697 - val_precision: 0.5788 - val_recall: 0.6057\n",
      "Epoch 761/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5929 - loss: 0.3275 - precision: 0.5851 - recall: 0.6254\n",
      "Epoch 761 - Train Recall: 0.6548 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5928 - loss: 0.3275 - precision: 0.5850 - recall: 0.6259 - val_accuracy: 0.5960 - val_loss: 0.6478 - val_precision: 0.5877 - val_recall: 0.6432\n",
      "Epoch 762/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5886 - loss: 0.3403 - precision: 0.5796 - recall: 0.6381\n",
      "Epoch 762 - Train Recall: 0.6391 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5889 - loss: 0.3402 - precision: 0.5800 - recall: 0.6381 - val_accuracy: 0.6102 - val_loss: 0.6660 - val_precision: 0.6055 - val_recall: 0.6327\n",
      "Epoch 763/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5978 - loss: 0.3386 - precision: 0.5900 - recall: 0.6376\n",
      "Epoch 763 - Train Recall: 0.6286 - Val Recall: 0.6297\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5971 - loss: 0.3389 - precision: 0.5895 - recall: 0.6366 - val_accuracy: 0.5937 - val_loss: 0.6678 - val_precision: 0.5874 - val_recall: 0.6297\n",
      "Epoch 764/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6000 - loss: 0.3406 - precision: 0.5899 - recall: 0.6267\n",
      "Epoch 764 - Train Recall: 0.6192 - Val Recall: 0.5877\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5997 - loss: 0.3406 - precision: 0.5899 - recall: 0.6264 - val_accuracy: 0.5960 - val_loss: 0.6761 - val_precision: 0.5976 - val_recall: 0.5877\n",
      "Epoch 765/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6021 - loss: 0.3311 - precision: 0.5910 - recall: 0.6621\n",
      "Epoch 765 - Train Recall: 0.6619 - Val Recall: 0.7016\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6020 - loss: 0.3311 - precision: 0.5909 - recall: 0.6621 - val_accuracy: 0.6049 - val_loss: 0.6594 - val_precision: 0.5879 - val_recall: 0.7016\n",
      "Epoch 766/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6064 - loss: 0.3511 - precision: 0.6059 - recall: 0.6368\n",
      "Epoch 766 - Train Recall: 0.5945 - Val Recall: 0.5472\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6058 - loss: 0.3512 - precision: 0.6055 - recall: 0.6328 - val_accuracy: 0.5892 - val_loss: 0.6993 - val_precision: 0.5974 - val_recall: 0.5472\n",
      "Epoch 767/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5853 - loss: 0.3295 - precision: 0.5763 - recall: 0.6179\n",
      "Epoch 767 - Train Recall: 0.6492 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5854 - loss: 0.3295 - precision: 0.5764 - recall: 0.6184 - val_accuracy: 0.5915 - val_loss: 0.6495 - val_precision: 0.5794 - val_recall: 0.6672\n",
      "Epoch 768/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 0.3474 - precision: 0.5836 - recall: 0.6707\n",
      "Epoch 768 - Train Recall: 0.6402 - Val Recall: 0.6402\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5953 - loss: 0.3474 - precision: 0.5836 - recall: 0.6700 - val_accuracy: 0.5990 - val_loss: 0.6838 - val_precision: 0.5914 - val_recall: 0.6402\n",
      "Epoch 769/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5943 - loss: 0.3415 - precision: 0.6007 - recall: 0.6189\n",
      "Epoch 769 - Train Recall: 0.6293 - Val Recall: 0.5292\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5946 - loss: 0.3415 - precision: 0.6001 - recall: 0.6198 - val_accuracy: 0.5772 - val_loss: 0.6812 - val_precision: 0.5854 - val_recall: 0.5292\n",
      "Epoch 770/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6057 - loss: 0.3138 - precision: 0.5971 - recall: 0.6568\n",
      "Epoch 770 - Train Recall: 0.6915 - Val Recall: 0.6927\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 0.3139 - precision: 0.5950 - recall: 0.6613 - val_accuracy: 0.5915 - val_loss: 0.6172 - val_precision: 0.5761 - val_recall: 0.6927\n",
      "Epoch 771/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5965 - loss: 0.3396 - precision: 0.5727 - recall: 0.6728\n",
      "Epoch 771 - Train Recall: 0.6518 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5964 - loss: 0.3397 - precision: 0.5733 - recall: 0.6719 - val_accuracy: 0.6087 - val_loss: 0.6761 - val_precision: 0.5910 - val_recall: 0.7061\n",
      "Epoch 772/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5822 - loss: 0.3573 - precision: 0.5707 - recall: 0.5958\n",
      "Epoch 772 - Train Recall: 0.5843 - Val Recall: 0.5757\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5831 - loss: 0.3572 - precision: 0.5727 - recall: 0.5947 - val_accuracy: 0.5877 - val_loss: 0.7003 - val_precision: 0.5899 - val_recall: 0.5757\n",
      "Epoch 773/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 0.3395 - precision: 0.5844 - recall: 0.6239\n",
      "Epoch 773 - Train Recall: 0.6256 - Val Recall: 0.6192\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5895 - loss: 0.3394 - precision: 0.5846 - recall: 0.6239 - val_accuracy: 0.5997 - val_loss: 0.6722 - val_precision: 0.5960 - val_recall: 0.6192\n",
      "Epoch 774/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5943 - loss: 0.3393 - precision: 0.5933 - recall: 0.6162\n",
      "Epoch 774 - Train Recall: 0.6293 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 0.3393 - precision: 0.5932 - recall: 0.6167 - val_accuracy: 0.5960 - val_loss: 0.6716 - val_precision: 0.5925 - val_recall: 0.6147\n",
      "Epoch 775/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5944 - loss: 0.3358 - precision: 0.5731 - recall: 0.6286\n",
      "Epoch 775 - Train Recall: 0.6529 - Val Recall: 0.5187\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5947 - loss: 0.3360 - precision: 0.5748 - recall: 0.6313 - val_accuracy: 0.5750 - val_loss: 0.6757 - val_precision: 0.5845 - val_recall: 0.5187\n",
      "Epoch 776/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6003 - loss: 0.3045 - precision: 0.5855 - recall: 0.7176\n",
      "Epoch 776 - Train Recall: 0.7507 - Val Recall: 0.7781\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6003 - loss: 0.3045 - precision: 0.5854 - recall: 0.7178 - val_accuracy: 0.6184 - val_loss: 0.5938 - val_precision: 0.5898 - val_recall: 0.7781\n",
      "Epoch 777/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5923 - loss: 0.3470 - precision: 0.5759 - recall: 0.7019\n",
      "Epoch 777 - Train Recall: 0.6589 - Val Recall: 0.6657\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5924 - loss: 0.3470 - precision: 0.5763 - recall: 0.6999 - val_accuracy: 0.5967 - val_loss: 0.7032 - val_precision: 0.5850 - val_recall: 0.6657\n",
      "Epoch 778/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 0.3438 - precision: 0.5850 - recall: 0.5943\n",
      "Epoch 778 - Train Recall: 0.5986 - Val Recall: 0.7076\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5942 - loss: 0.3439 - precision: 0.5860 - recall: 0.5943 - val_accuracy: 0.6049 - val_loss: 0.6779 - val_precision: 0.5871 - val_recall: 0.7076\n",
      "Epoch 779/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5900 - loss: 0.3699 - precision: 0.5975 - recall: 0.5958\n",
      "Epoch 779 - Train Recall: 0.5412 - Val Recall: 0.3448\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5899 - loss: 0.3699 - precision: 0.5976 - recall: 0.5922 - val_accuracy: 0.5652 - val_loss: 0.7360 - val_precision: 0.6166 - val_recall: 0.3448\n",
      "Epoch 780/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5995 - loss: 0.2808 - precision: 0.6024 - recall: 0.6354\n",
      "Epoch 780 - Train Recall: 0.7399 - Val Recall: 0.7871\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 0.2806 - precision: 0.6013 - recall: 0.6391 - val_accuracy: 0.5945 - val_loss: 0.5360 - val_precision: 0.5682 - val_recall: 0.7871\n",
      "Epoch 781/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6037 - loss: 0.3532 - precision: 0.5809 - recall: 0.7353\n",
      "Epoch 781 - Train Recall: 0.6717 - Val Recall: 0.6267\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6031 - loss: 0.3532 - precision: 0.5813 - recall: 0.7298 - val_accuracy: 0.5847 - val_loss: 0.7005 - val_precision: 0.5781 - val_recall: 0.6267\n",
      "Epoch 782/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5868 - loss: 0.3328 - precision: 0.5872 - recall: 0.6376\n",
      "Epoch 782 - Train Recall: 0.6525 - Val Recall: 0.6312\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5881 - loss: 0.3325 - precision: 0.5874 - recall: 0.6397 - val_accuracy: 0.5772 - val_loss: 0.6579 - val_precision: 0.5697 - val_recall: 0.6312\n",
      "Epoch 783/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6023 - loss: 0.3348 - precision: 0.5980 - recall: 0.6653\n",
      "Epoch 783 - Train Recall: 0.6540 - Val Recall: 0.6897\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6022 - loss: 0.3348 - precision: 0.5979 - recall: 0.6653 - val_accuracy: 0.5825 - val_loss: 0.6662 - val_precision: 0.5679 - val_recall: 0.6897\n",
      "Epoch 784/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5876 - loss: 0.3500 - precision: 0.5930 - recall: 0.6095\n",
      "Epoch 784 - Train Recall: 0.5963 - Val Recall: 0.6822\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5881 - loss: 0.3500 - precision: 0.5929 - recall: 0.6081 - val_accuracy: 0.6019 - val_loss: 0.6908 - val_precision: 0.5879 - val_recall: 0.6822\n",
      "Epoch 785/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5976 - loss: 0.3652 - precision: 0.6069 - recall: 0.5664\n",
      "Epoch 785 - Train Recall: 0.5307 - Val Recall: 0.5487\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5974 - loss: 0.3652 - precision: 0.6070 - recall: 0.5648 - val_accuracy: 0.5900 - val_loss: 0.7221 - val_precision: 0.5980 - val_recall: 0.5487\n",
      "Epoch 786/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6009 - loss: 0.3466 - precision: 0.6047 - recall: 0.5760\n",
      "Epoch 786 - Train Recall: 0.5903 - Val Recall: 0.5937\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6004 - loss: 0.3467 - precision: 0.6039 - recall: 0.5774 - val_accuracy: 0.5840 - val_loss: 0.6899 - val_precision: 0.5824 - val_recall: 0.5937\n",
      "Epoch 787/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6158 - loss: 0.3377 - precision: 0.6105 - recall: 0.6156\n",
      "Epoch 787 - Train Recall: 0.6083 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6151 - loss: 0.3379 - precision: 0.6099 - recall: 0.6153 - val_accuracy: 0.6072 - val_loss: 0.6743 - val_precision: 0.6020 - val_recall: 0.6327\n",
      "Epoch 788/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6056 - loss: 0.3458 - precision: 0.6035 - recall: 0.6555\n",
      "Epoch 788 - Train Recall: 0.6256 - Val Recall: 0.5922\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6053 - loss: 0.3459 - precision: 0.6031 - recall: 0.6545 - val_accuracy: 0.6012 - val_loss: 0.6917 - val_precision: 0.6031 - val_recall: 0.5922\n",
      "Epoch 789/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6002 - loss: 0.3323 - precision: 0.5970 - recall: 0.5653\n",
      "Epoch 789 - Train Recall: 0.6008 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6000 - loss: 0.3322 - precision: 0.5971 - recall: 0.5685 - val_accuracy: 0.6004 - val_loss: 0.6551 - val_precision: 0.5884 - val_recall: 0.6687\n",
      "Epoch 790/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5913 - loss: 0.3598 - precision: 0.5893 - recall: 0.6376\n",
      "Epoch 790 - Train Recall: 0.5802 - Val Recall: 0.5727\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5913 - loss: 0.3598 - precision: 0.5894 - recall: 0.6355 - val_accuracy: 0.5825 - val_loss: 0.7190 - val_precision: 0.5841 - val_recall: 0.5727\n",
      "Epoch 791/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5998 - loss: 0.3410 - precision: 0.6031 - recall: 0.5803\n",
      "Epoch 791 - Train Recall: 0.5941 - Val Recall: 0.6522\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5984 - loss: 0.3411 - precision: 0.6012 - recall: 0.5815 - val_accuracy: 0.6109 - val_loss: 0.6679 - val_precision: 0.6025 - val_recall: 0.6522\n",
      "Epoch 792/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6088 - loss: 0.3537 - precision: 0.6110 - recall: 0.6178\n",
      "Epoch 792 - Train Recall: 0.5933 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6081 - loss: 0.3539 - precision: 0.6103 - recall: 0.6167 - val_accuracy: 0.6027 - val_loss: 0.7058 - val_precision: 0.5961 - val_recall: 0.6372\n",
      "Epoch 793/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6018 - loss: 0.3530 - precision: 0.6085 - recall: 0.5957\n",
      "Epoch 793 - Train Recall: 0.5948 - Val Recall: 0.4648\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6017 - loss: 0.3530 - precision: 0.6082 - recall: 0.5957 - val_accuracy: 0.5675 - val_loss: 0.7053 - val_precision: 0.5849 - val_recall: 0.4648\n",
      "Epoch 794/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6074 - loss: 0.3031 - precision: 0.6059 - recall: 0.6622\n",
      "Epoch 794 - Train Recall: 0.7103 - Val Recall: 0.7451\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6068 - loss: 0.3030 - precision: 0.6041 - recall: 0.6656 - val_accuracy: 0.6034 - val_loss: 0.5894 - val_precision: 0.5806 - val_recall: 0.7451\n",
      "Epoch 795/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.3482 - precision: 0.5875 - recall: 0.6789\n",
      "Epoch 795 - Train Recall: 0.6383 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5980 - loss: 0.3483 - precision: 0.5873 - recall: 0.6770 - val_accuracy: 0.6019 - val_loss: 0.6903 - val_precision: 0.5874 - val_recall: 0.6852\n",
      "Epoch 796/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5872 - loss: 0.3535 - precision: 0.5886 - recall: 0.5952\n",
      "Epoch 796 - Train Recall: 0.5832 - Val Recall: 0.6042\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5874 - loss: 0.3535 - precision: 0.5888 - recall: 0.5948 - val_accuracy: 0.5960 - val_loss: 0.6974 - val_precision: 0.5944 - val_recall: 0.6042\n",
      "Epoch 797/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5879 - loss: 0.3479 - precision: 0.5928 - recall: 0.5679\n",
      "Epoch 797 - Train Recall: 0.5708 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5881 - loss: 0.3479 - precision: 0.5929 - recall: 0.5681 - val_accuracy: 0.5802 - val_loss: 0.6920 - val_precision: 0.5776 - val_recall: 0.5967\n",
      "Epoch 798/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.3492 - precision: 0.5796 - recall: 0.6245\n",
      "Epoch 798 - Train Recall: 0.5993 - Val Recall: 0.6087\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5932 - loss: 0.3494 - precision: 0.5803 - recall: 0.6207 - val_accuracy: 0.6064 - val_loss: 0.6877 - val_precision: 0.6060 - val_recall: 0.6087\n",
      "Epoch 799/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6071 - loss: 0.3417 - precision: 0.6091 - recall: 0.6299\n",
      "Epoch 799 - Train Recall: 0.6072 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6070 - loss: 0.3417 - precision: 0.6090 - recall: 0.6298 - val_accuracy: 0.5952 - val_loss: 0.6827 - val_precision: 0.5883 - val_recall: 0.6342\n",
      "Epoch 800/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5891 - loss: 0.3489 - precision: 0.5947 - recall: 0.6092\n",
      "Epoch 800 - Train Recall: 0.5978 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5893 - loss: 0.3488 - precision: 0.5945 - recall: 0.6087 - val_accuracy: 0.5945 - val_loss: 0.6923 - val_precision: 0.5799 - val_recall: 0.6852\n",
      "Epoch 801/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5891 - loss: 0.3684 - precision: 0.5820 - recall: 0.5769\n",
      "Epoch 801 - Train Recall: 0.5296 - Val Recall: 0.5142\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5892 - loss: 0.3681 - precision: 0.5840 - recall: 0.5721 - val_accuracy: 0.5900 - val_loss: 0.7287 - val_precision: 0.6060 - val_recall: 0.5142\n",
      "Epoch 802/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6053 - loss: 0.3372 - precision: 0.6160 - recall: 0.6196\n",
      "Epoch 802 - Train Recall: 0.6256 - Val Recall: 0.7241\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6050 - loss: 0.3372 - precision: 0.6150 - recall: 0.6198 - val_accuracy: 0.6027 - val_loss: 0.6595 - val_precision: 0.5826 - val_recall: 0.7241\n",
      "Epoch 803/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5990 - loss: 0.3647 - precision: 0.6098 - recall: 0.6031\n",
      "Epoch 803 - Train Recall: 0.5757 - Val Recall: 0.5037\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5981 - loss: 0.3652 - precision: 0.6076 - recall: 0.6000 - val_accuracy: 0.5862 - val_loss: 0.7274 - val_precision: 0.6032 - val_recall: 0.5037\n",
      "Epoch 804/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5986 - loss: 0.3219 - precision: 0.5954 - recall: 0.6001\n",
      "Epoch 804 - Train Recall: 0.6466 - Val Recall: 0.7166\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5985 - loss: 0.3219 - precision: 0.5953 - recall: 0.6007 - val_accuracy: 0.5840 - val_loss: 0.6340 - val_precision: 0.5664 - val_recall: 0.7166\n",
      "Epoch 805/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 0.3591 - precision: 0.5926 - recall: 0.6944\n",
      "Epoch 805 - Train Recall: 0.6413 - Val Recall: 0.6192\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6025 - loss: 0.3591 - precision: 0.5925 - recall: 0.6919 - val_accuracy: 0.6177 - val_loss: 0.7060 - val_precision: 0.6173 - val_recall: 0.6192\n",
      "Epoch 806/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6066 - loss: 0.3335 - precision: 0.5972 - recall: 0.5962\n",
      "Epoch 806 - Train Recall: 0.6372 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6054 - loss: 0.3337 - precision: 0.5962 - recall: 0.5990 - val_accuracy: 0.5975 - val_loss: 0.6659 - val_precision: 0.5886 - val_recall: 0.6477\n",
      "Epoch 807/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5967 - loss: 0.3428 - precision: 0.6018 - recall: 0.6346\n",
      "Epoch 807 - Train Recall: 0.6323 - Val Recall: 0.6297\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5964 - loss: 0.3431 - precision: 0.5996 - recall: 0.6345 - val_accuracy: 0.6027 - val_loss: 0.6799 - val_precision: 0.5974 - val_recall: 0.6297\n",
      "Epoch 808/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5929 - loss: 0.3400 - precision: 0.5827 - recall: 0.6394\n",
      "Epoch 808 - Train Recall: 0.6466 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5931 - loss: 0.3400 - precision: 0.5829 - recall: 0.6397 - val_accuracy: 0.5757 - val_loss: 0.6794 - val_precision: 0.5781 - val_recall: 0.5607\n",
      "Epoch 809/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5950 - loss: 0.3199 - precision: 0.5754 - recall: 0.6749\n",
      "Epoch 809 - Train Recall: 0.6990 - Val Recall: 0.7571\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5952 - loss: 0.3198 - precision: 0.5759 - recall: 0.6768 - val_accuracy: 0.6012 - val_loss: 0.6299 - val_precision: 0.5771 - val_recall: 0.7571\n",
      "Epoch 810/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 0.3560 - precision: 0.5864 - recall: 0.7038\n",
      "Epoch 810 - Train Recall: 0.6630 - Val Recall: 0.6312\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6016 - loss: 0.3560 - precision: 0.5865 - recall: 0.7028 - val_accuracy: 0.6064 - val_loss: 0.7022 - val_precision: 0.6014 - val_recall: 0.6312\n",
      "Epoch 811/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5918 - loss: 0.3326 - precision: 0.5810 - recall: 0.6102\n",
      "Epoch 811 - Train Recall: 0.6334 - Val Recall: 0.6417\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5921 - loss: 0.3328 - precision: 0.5819 - recall: 0.6125 - val_accuracy: 0.5975 - val_loss: 0.6613 - val_precision: 0.5895 - val_recall: 0.6417\n",
      "Epoch 812/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6113 - loss: 0.3381 - precision: 0.5959 - recall: 0.6862\n",
      "Epoch 812 - Train Recall: 0.6548 - Val Recall: 0.6132\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6110 - loss: 0.3382 - precision: 0.5958 - recall: 0.6855 - val_accuracy: 0.5840 - val_loss: 0.6841 - val_precision: 0.5793 - val_recall: 0.6132\n",
      "Epoch 813/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5953 - loss: 0.3297 - precision: 0.5890 - recall: 0.6399\n",
      "Epoch 813 - Train Recall: 0.6713 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5954 - loss: 0.3297 - precision: 0.5884 - recall: 0.6426 - val_accuracy: 0.5922 - val_loss: 0.6523 - val_precision: 0.5846 - val_recall: 0.6372\n",
      "Epoch 814/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5972 - loss: 0.3314 - precision: 0.5826 - recall: 0.7033\n",
      "Epoch 814 - Train Recall: 0.6987 - Val Recall: 0.7391\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5971 - loss: 0.3315 - precision: 0.5825 - recall: 0.7032 - val_accuracy: 0.5855 - val_loss: 0.6561 - val_precision: 0.5654 - val_recall: 0.7391\n",
      "Epoch 815/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5855 - loss: 0.3529 - precision: 0.5693 - recall: 0.6370\n",
      "Epoch 815 - Train Recall: 0.6297 - Val Recall: 0.4798\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5861 - loss: 0.3528 - precision: 0.5709 - recall: 0.6364 - val_accuracy: 0.5652 - val_loss: 0.6994 - val_precision: 0.5787 - val_recall: 0.4798\n",
      "Epoch 816/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 0.2998 - precision: 0.5905 - recall: 0.6925\n",
      "Epoch 816 - Train Recall: 0.7350 - Val Recall: 0.8471\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6026 - loss: 0.2997 - precision: 0.5896 - recall: 0.6952 - val_accuracy: 0.5892 - val_loss: 0.5864 - val_precision: 0.5589 - val_recall: 0.8471\n",
      "Epoch 817/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6021 - loss: 0.3688 - precision: 0.5838 - recall: 0.6704\n",
      "Epoch 817 - Train Recall: 0.5960 - Val Recall: 0.4813\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6016 - loss: 0.3688 - precision: 0.5843 - recall: 0.6665 - val_accuracy: 0.5877 - val_loss: 0.7216 - val_precision: 0.6114 - val_recall: 0.4813\n",
      "Epoch 818/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5993 - loss: 0.3061 - precision: 0.5871 - recall: 0.6496\n",
      "Epoch 818 - Train Recall: 0.6908 - Val Recall: 0.7106\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 0.3061 - precision: 0.5870 - recall: 0.6501 - val_accuracy: 0.5982 - val_loss: 0.6029 - val_precision: 0.5802 - val_recall: 0.7106\n",
      "Epoch 819/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5964 - loss: 0.3480 - precision: 0.5857 - recall: 0.7079\n",
      "Epoch 819 - Train Recall: 0.6645 - Val Recall: 0.6252\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5965 - loss: 0.3479 - precision: 0.5858 - recall: 0.7038 - val_accuracy: 0.6019 - val_loss: 0.6819 - val_precision: 0.5974 - val_recall: 0.6252\n",
      "Epoch 820/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 0.3331 - precision: 0.5916 - recall: 0.6056\n",
      "Epoch 820 - Train Recall: 0.6376 - Val Recall: 0.6942\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5894 - loss: 0.3331 - precision: 0.5914 - recall: 0.6062 - val_accuracy: 0.6042 - val_loss: 0.6503 - val_precision: 0.5883 - val_recall: 0.6942\n",
      "Epoch 821/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5915 - loss: 0.3568 - precision: 0.5918 - recall: 0.6223\n",
      "Epoch 821 - Train Recall: 0.6012 - Val Recall: 0.5652\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5917 - loss: 0.3569 - precision: 0.5919 - recall: 0.6206 - val_accuracy: 0.5997 - val_loss: 0.7057 - val_precision: 0.6071 - val_recall: 0.5652\n",
      "Epoch 822/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6092 - loss: 0.3292 - precision: 0.6002 - recall: 0.6037\n",
      "Epoch 822 - Train Recall: 0.6237 - Val Recall: 0.6957\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6088 - loss: 0.3292 - precision: 0.6000 - recall: 0.6045 - val_accuracy: 0.6079 - val_loss: 0.6517 - val_precision: 0.5918 - val_recall: 0.6957\n",
      "Epoch 823/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6025 - loss: 0.3587 - precision: 0.5968 - recall: 0.6562\n",
      "Epoch 823 - Train Recall: 0.6079 - Val Recall: 0.5667\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6022 - loss: 0.3588 - precision: 0.5966 - recall: 0.6548 - val_accuracy: 0.5840 - val_loss: 0.7164 - val_precision: 0.5870 - val_recall: 0.5667\n",
      "Epoch 824/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6056 - loss: 0.3290 - precision: 0.5996 - recall: 0.6208\n",
      "Epoch 824 - Train Recall: 0.6496 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6056 - loss: 0.3290 - precision: 0.5995 - recall: 0.6211 - val_accuracy: 0.5855 - val_loss: 0.6548 - val_precision: 0.5764 - val_recall: 0.6447\n",
      "Epoch 825/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5963 - loss: 0.3398 - precision: 0.5829 - recall: 0.6485\n",
      "Epoch 825 - Train Recall: 0.6406 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5962 - loss: 0.3398 - precision: 0.5829 - recall: 0.6484 - val_accuracy: 0.5922 - val_loss: 0.6732 - val_precision: 0.5844 - val_recall: 0.6387\n",
      "Epoch 826/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5868 - loss: 0.3412 - precision: 0.5748 - recall: 0.6323\n",
      "Epoch 826 - Train Recall: 0.6514 - Val Recall: 0.6222\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5872 - loss: 0.3411 - precision: 0.5753 - recall: 0.6338 - val_accuracy: 0.5862 - val_loss: 0.6778 - val_precision: 0.5804 - val_recall: 0.6222\n",
      "Epoch 827/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5952 - loss: 0.3334 - precision: 0.5903 - recall: 0.6760\n",
      "Epoch 827 - Train Recall: 0.6773 - Val Recall: 0.6582\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5941 - loss: 0.3336 - precision: 0.5877 - recall: 0.6764 - val_accuracy: 0.5930 - val_loss: 0.6620 - val_precision: 0.5822 - val_recall: 0.6582\n",
      "Epoch 828/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5902 - loss: 0.3388 - precision: 0.5739 - recall: 0.6743\n",
      "Epoch 828 - Train Recall: 0.6837 - Val Recall: 0.6357\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5905 - loss: 0.3387 - precision: 0.5743 - recall: 0.6746 - val_accuracy: 0.5795 - val_loss: 0.6712 - val_precision: 0.5714 - val_recall: 0.6357\n",
      "Epoch 829/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5847 - loss: 0.3299 - precision: 0.5694 - recall: 0.6793\n",
      "Epoch 829 - Train Recall: 0.6837 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5853 - loss: 0.3299 - precision: 0.5701 - recall: 0.6796 - val_accuracy: 0.5817 - val_loss: 0.6578 - val_precision: 0.5684 - val_recall: 0.6792\n",
      "Epoch 830/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.3395 - precision: 0.5881 - recall: 0.6818\n",
      "Epoch 830 - Train Recall: 0.6732 - Val Recall: 0.6297\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5941 - loss: 0.3395 - precision: 0.5879 - recall: 0.6816 - val_accuracy: 0.6042 - val_loss: 0.6680 - val_precision: 0.5991 - val_recall: 0.6297\n",
      "Epoch 831/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5969 - loss: 0.3305 - precision: 0.5832 - recall: 0.6490\n",
      "Epoch 831 - Train Recall: 0.6758 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5974 - loss: 0.3304 - precision: 0.5838 - recall: 0.6517 - val_accuracy: 0.5810 - val_loss: 0.6589 - val_precision: 0.5771 - val_recall: 0.6057\n",
      "Epoch 832/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5956 - loss: 0.3236 - precision: 0.5835 - recall: 0.6914\n",
      "Epoch 832 - Train Recall: 0.6904 - Val Recall: 0.7016\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5954 - loss: 0.3236 - precision: 0.5829 - recall: 0.6915 - val_accuracy: 0.5937 - val_loss: 0.6416 - val_precision: 0.5771 - val_recall: 0.7016\n",
      "Epoch 833/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6053 - loss: 0.3395 - precision: 0.5977 - recall: 0.6694\n",
      "Epoch 833 - Train Recall: 0.6458 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6052 - loss: 0.3395 - precision: 0.5976 - recall: 0.6690 - val_accuracy: 0.5930 - val_loss: 0.6819 - val_precision: 0.5906 - val_recall: 0.6057\n",
      "Epoch 834/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5983 - loss: 0.3313 - precision: 0.5860 - recall: 0.6338\n",
      "Epoch 834 - Train Recall: 0.6503 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5983 - loss: 0.3313 - precision: 0.5860 - recall: 0.6339 - val_accuracy: 0.5900 - val_loss: 0.6532 - val_precision: 0.5822 - val_recall: 0.6372\n",
      "Epoch 835/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6045 - loss: 0.3367 - precision: 0.5989 - recall: 0.6556\n",
      "Epoch 835 - Train Recall: 0.6548 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.3368 - precision: 0.5983 - recall: 0.6556 - val_accuracy: 0.5975 - val_loss: 0.6698 - val_precision: 0.5827 - val_recall: 0.6867\n",
      "Epoch 836/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6251 - loss: 0.3452 - precision: 0.6124 - recall: 0.6601\n",
      "Epoch 836 - Train Recall: 0.6259 - Val Recall: 0.5922\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6232 - loss: 0.3456 - precision: 0.6110 - recall: 0.6576 - val_accuracy: 0.5907 - val_loss: 0.6951 - val_precision: 0.5904 - val_recall: 0.5922\n",
      "Epoch 837/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6000 - loss: 0.3314 - precision: 0.5881 - recall: 0.6556\n",
      "Epoch 837 - Train Recall: 0.6645 - Val Recall: 0.7196\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5997 - loss: 0.3316 - precision: 0.5875 - recall: 0.6567 - val_accuracy: 0.5862 - val_loss: 0.6584 - val_precision: 0.5680 - val_recall: 0.7196\n",
      "Epoch 838/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5919 - loss: 0.3564 - precision: 0.5849 - recall: 0.6551\n",
      "Epoch 838 - Train Recall: 0.6233 - Val Recall: 0.5892\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5920 - loss: 0.3564 - precision: 0.5850 - recall: 0.6547 - val_accuracy: 0.6109 - val_loss: 0.7073 - val_precision: 0.6160 - val_recall: 0.5892\n",
      "Epoch 839/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6005 - loss: 0.3313 - precision: 0.5852 - recall: 0.6304\n",
      "Epoch 839 - Train Recall: 0.6458 - Val Recall: 0.6132\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6002 - loss: 0.3313 - precision: 0.5856 - recall: 0.6318 - val_accuracy: 0.5930 - val_loss: 0.6615 - val_precision: 0.5893 - val_recall: 0.6132\n",
      "Epoch 840/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5833 - loss: 0.3353 - precision: 0.5802 - recall: 0.6458\n",
      "Epoch 840 - Train Recall: 0.6533 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5842 - loss: 0.3351 - precision: 0.5803 - recall: 0.6464 - val_accuracy: 0.6102 - val_loss: 0.6525 - val_precision: 0.5995 - val_recall: 0.6642\n",
      "Epoch 841/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5907 - loss: 0.3415 - precision: 0.5872 - recall: 0.6679\n",
      "Epoch 841 - Train Recall: 0.6451 - Val Recall: 0.6192\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5907 - loss: 0.3415 - precision: 0.5870 - recall: 0.6673 - val_accuracy: 0.5975 - val_loss: 0.6813 - val_precision: 0.5934 - val_recall: 0.6192\n",
      "Epoch 842/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5839 - loss: 0.3365 - precision: 0.5736 - recall: 0.6257\n",
      "Epoch 842 - Train Recall: 0.6383 - Val Recall: 0.6252\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5846 - loss: 0.3363 - precision: 0.5745 - recall: 0.6268 - val_accuracy: 0.5967 - val_loss: 0.6643 - val_precision: 0.5915 - val_recall: 0.6252\n",
      "Epoch 843/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5940 - loss: 0.3404 - precision: 0.5826 - recall: 0.6254\n",
      "Epoch 843 - Train Recall: 0.6271 - Val Recall: 0.7436\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5939 - loss: 0.3403 - precision: 0.5827 - recall: 0.6254 - val_accuracy: 0.6147 - val_loss: 0.6648 - val_precision: 0.5912 - val_recall: 0.7436\n",
      "Epoch 844/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6039 - loss: 0.3703 - precision: 0.6100 - recall: 0.5911\n",
      "Epoch 844 - Train Recall: 0.5513 - Val Recall: 0.5097\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 0.3703 - precision: 0.6091 - recall: 0.5869 - val_accuracy: 0.5757 - val_loss: 0.7598 - val_precision: 0.5872 - val_recall: 0.5097\n",
      "Epoch 845/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.3287 - precision: 0.5974 - recall: 0.6032\n",
      "Epoch 845 - Train Recall: 0.6259 - Val Recall: 0.6717\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5982 - loss: 0.3288 - precision: 0.5972 - recall: 0.6037 - val_accuracy: 0.6004 - val_loss: 0.6477 - val_precision: 0.5879 - val_recall: 0.6717\n",
      "Epoch 846/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6011 - loss: 0.3533 - precision: 0.5867 - recall: 0.6538\n",
      "Epoch 846 - Train Recall: 0.6267 - Val Recall: 0.5937\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6012 - loss: 0.3533 - precision: 0.5870 - recall: 0.6529 - val_accuracy: 0.6034 - val_loss: 0.6997 - val_precision: 0.6055 - val_recall: 0.5937\n",
      "Epoch 847/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.3318 - precision: 0.6012 - recall: 0.6256\n",
      "Epoch 847 - Train Recall: 0.6312 - Val Recall: 0.7136\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5967 - loss: 0.3318 - precision: 0.6003 - recall: 0.6260 - val_accuracy: 0.5892 - val_loss: 0.6599 - val_precision: 0.5714 - val_recall: 0.7136\n",
      "Epoch 848/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 0.3591 - precision: 0.6013 - recall: 0.6016\n",
      "Epoch 848 - Train Recall: 0.5611 - Val Recall: 0.4933\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 0.3591 - precision: 0.6014 - recall: 0.6006 - val_accuracy: 0.5840 - val_loss: 0.7267 - val_precision: 0.6026 - val_recall: 0.4933\n",
      "Epoch 849/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5928 - loss: 0.3200 - precision: 0.5828 - recall: 0.6093\n",
      "Epoch 849 - Train Recall: 0.6514 - Val Recall: 0.6597\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5934 - loss: 0.3200 - precision: 0.5836 - recall: 0.6130 - val_accuracy: 0.5855 - val_loss: 0.6361 - val_precision: 0.5744 - val_recall: 0.6597\n",
      "Epoch 850/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6001 - loss: 0.3425 - precision: 0.5921 - recall: 0.6989\n",
      "Epoch 850 - Train Recall: 0.6694 - Val Recall: 0.7016\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5995 - loss: 0.3428 - precision: 0.5907 - recall: 0.6956 - val_accuracy: 0.5960 - val_loss: 0.6772 - val_precision: 0.5792 - val_recall: 0.7016\n",
      "Epoch 851/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6202 - loss: 0.3469 - precision: 0.6100 - recall: 0.6715\n",
      "Epoch 851 - Train Recall: 0.6357 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6195 - loss: 0.3470 - precision: 0.6097 - recall: 0.6686 - val_accuracy: 0.5930 - val_loss: 0.6886 - val_precision: 0.5852 - val_recall: 0.6387\n",
      "Epoch 852/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6007 - loss: 0.3424 - precision: 0.5905 - recall: 0.5746\n",
      "Epoch 852 - Train Recall: 0.5990 - Val Recall: 0.6957\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6006 - loss: 0.3424 - precision: 0.5911 - recall: 0.5761 - val_accuracy: 0.5997 - val_loss: 0.6746 - val_precision: 0.5836 - val_recall: 0.6957\n",
      "Epoch 853/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5946 - loss: 0.3657 - precision: 0.5998 - recall: 0.6174\n",
      "Epoch 853 - Train Recall: 0.5675 - Val Recall: 0.4888\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5946 - loss: 0.3657 - precision: 0.5997 - recall: 0.6162 - val_accuracy: 0.5945 - val_loss: 0.7288 - val_precision: 0.6198 - val_recall: 0.4888\n",
      "Epoch 854/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6002 - loss: 0.3181 - precision: 0.6077 - recall: 0.6048\n",
      "Epoch 854 - Train Recall: 0.6627 - Val Recall: 0.7226\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6000 - loss: 0.3179 - precision: 0.6052 - recall: 0.6120 - val_accuracy: 0.5772 - val_loss: 0.6321 - val_precision: 0.5598 - val_recall: 0.7226\n",
      "Epoch 855/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5933 - loss: 0.3573 - precision: 0.5809 - recall: 0.6543\n",
      "Epoch 855 - Train Recall: 0.6068 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5935 - loss: 0.3572 - precision: 0.5814 - recall: 0.6529 - val_accuracy: 0.6057 - val_loss: 0.7071 - val_precision: 0.5992 - val_recall: 0.6387\n",
      "Epoch 856/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5961 - loss: 0.3485 - precision: 0.5853 - recall: 0.6003\n",
      "Epoch 856 - Train Recall: 0.5735 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5957 - loss: 0.3488 - precision: 0.5868 - recall: 0.5966 - val_accuracy: 0.5930 - val_loss: 0.6882 - val_precision: 0.5842 - val_recall: 0.6447\n",
      "Epoch 857/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6023 - loss: 0.3591 - precision: 0.5952 - recall: 0.6209\n",
      "Epoch 857 - Train Recall: 0.5911 - Val Recall: 0.5457\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6019 - loss: 0.3593 - precision: 0.5954 - recall: 0.6183 - val_accuracy: 0.5870 - val_loss: 0.7150 - val_precision: 0.5948 - val_recall: 0.5457\n",
      "Epoch 858/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6043 - loss: 0.3264 - precision: 0.6032 - recall: 0.6518\n",
      "Epoch 858 - Train Recall: 0.6694 - Val Recall: 0.6702\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6043 - loss: 0.3264 - precision: 0.6031 - recall: 0.6519 - val_accuracy: 0.6079 - val_loss: 0.6454 - val_precision: 0.5960 - val_recall: 0.6702\n",
      "Epoch 859/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6001 - loss: 0.3400 - precision: 0.5799 - recall: 0.6757\n",
      "Epoch 859 - Train Recall: 0.6454 - Val Recall: 0.6957\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5996 - loss: 0.3402 - precision: 0.5800 - recall: 0.6740 - val_accuracy: 0.6079 - val_loss: 0.6712 - val_precision: 0.5918 - val_recall: 0.6957\n",
      "Epoch 860/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5934 - loss: 0.3543 - precision: 0.5841 - recall: 0.6546\n",
      "Epoch 860 - Train Recall: 0.6199 - Val Recall: 0.5367\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5933 - loss: 0.3543 - precision: 0.5846 - recall: 0.6499 - val_accuracy: 0.5900 - val_loss: 0.7008 - val_precision: 0.6007 - val_recall: 0.5367\n",
      "Epoch 861/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6015 - loss: 0.3192 - precision: 0.5995 - recall: 0.6705\n",
      "Epoch 861 - Train Recall: 0.7058 - Val Recall: 0.7331\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6013 - loss: 0.3192 - precision: 0.5989 - recall: 0.6716 - val_accuracy: 0.5952 - val_loss: 0.6239 - val_precision: 0.5746 - val_recall: 0.7331\n",
      "Epoch 862/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6039 - loss: 0.3444 - precision: 0.5926 - recall: 0.6825\n",
      "Epoch 862 - Train Recall: 0.6529 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6037 - loss: 0.3446 - precision: 0.5926 - recall: 0.6802 - val_accuracy: 0.5945 - val_loss: 0.6870 - val_precision: 0.5861 - val_recall: 0.6432\n",
      "Epoch 863/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5920 - loss: 0.3386 - precision: 0.5813 - recall: 0.6335\n",
      "Epoch 863 - Train Recall: 0.6334 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5921 - loss: 0.3387 - precision: 0.5817 - recall: 0.6335 - val_accuracy: 0.5922 - val_loss: 0.6686 - val_precision: 0.5821 - val_recall: 0.6537\n",
      "Epoch 864/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6108 - loss: 0.3427 - precision: 0.5997 - recall: 0.6638\n",
      "Epoch 864 - Train Recall: 0.6297 - Val Recall: 0.6417\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6101 - loss: 0.3429 - precision: 0.5993 - recall: 0.6621 - val_accuracy: 0.5952 - val_loss: 0.6896 - val_precision: 0.5871 - val_recall: 0.6417\n",
      "Epoch 865/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 0.3425 - precision: 0.5985 - recall: 0.6179\n",
      "Epoch 865 - Train Recall: 0.6124 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5959 - loss: 0.3426 - precision: 0.5983 - recall: 0.6171 - val_accuracy: 0.5967 - val_loss: 0.6846 - val_precision: 0.5950 - val_recall: 0.6057\n",
      "Epoch 866/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6098 - loss: 0.3383 - precision: 0.6079 - recall: 0.6508\n",
      "Epoch 866 - Train Recall: 0.6289 - Val Recall: 0.7361\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6093 - loss: 0.3383 - precision: 0.6072 - recall: 0.6502 - val_accuracy: 0.5997 - val_loss: 0.6714 - val_precision: 0.5783 - val_recall: 0.7361\n",
      "Epoch 867/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5904 - loss: 0.3680 - precision: 0.5920 - recall: 0.5635\n",
      "Epoch 867 - Train Recall: 0.5469 - Val Recall: 0.5877\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5905 - loss: 0.3679 - precision: 0.5924 - recall: 0.5625 - val_accuracy: 0.5937 - val_loss: 0.7448 - val_precision: 0.5948 - val_recall: 0.5877\n",
      "Epoch 868/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5935 - loss: 0.3549 - precision: 0.5867 - recall: 0.5773\n",
      "Epoch 868 - Train Recall: 0.5810 - Val Recall: 0.5982\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5936 - loss: 0.3549 - precision: 0.5870 - recall: 0.5774 - val_accuracy: 0.5877 - val_loss: 0.6974 - val_precision: 0.5859 - val_recall: 0.5982\n",
      "Epoch 869/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6019 - loss: 0.3465 - precision: 0.5973 - recall: 0.6315\n",
      "Epoch 869 - Train Recall: 0.6259 - Val Recall: 0.5922\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6016 - loss: 0.3465 - precision: 0.5969 - recall: 0.6311 - val_accuracy: 0.5975 - val_loss: 0.6861 - val_precision: 0.5985 - val_recall: 0.5922\n",
      "Epoch 870/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6012 - loss: 0.3324 - precision: 0.5972 - recall: 0.6262\n",
      "Epoch 870 - Train Recall: 0.6462 - Val Recall: 0.6717\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6012 - loss: 0.3323 - precision: 0.5972 - recall: 0.6263 - val_accuracy: 0.6049 - val_loss: 0.6597 - val_precision: 0.5926 - val_recall: 0.6717\n",
      "Epoch 871/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6009 - loss: 0.3475 - precision: 0.5934 - recall: 0.6132\n",
      "Epoch 871 - Train Recall: 0.6218 - Val Recall: 0.6402\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6014 - loss: 0.3476 - precision: 0.5944 - recall: 0.6141 - val_accuracy: 0.5870 - val_loss: 0.6906 - val_precision: 0.5786 - val_recall: 0.6402\n",
      "Epoch 872/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6006 - loss: 0.3468 - precision: 0.5926 - recall: 0.6405\n",
      "Epoch 872 - Train Recall: 0.6357 - Val Recall: 0.7286\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6005 - loss: 0.3467 - precision: 0.5926 - recall: 0.6405 - val_accuracy: 0.6019 - val_loss: 0.6820 - val_precision: 0.5813 - val_recall: 0.7286\n",
      "Epoch 873/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5903 - loss: 0.3639 - precision: 0.5867 - recall: 0.5876\n",
      "Epoch 873 - Train Recall: 0.5600 - Val Recall: 0.5547\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5903 - loss: 0.3640 - precision: 0.5869 - recall: 0.5869 - val_accuracy: 0.5900 - val_loss: 0.7241 - val_precision: 0.5968 - val_recall: 0.5547\n",
      "Epoch 874/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6021 - loss: 0.3391 - precision: 0.6149 - recall: 0.6009\n",
      "Epoch 874 - Train Recall: 0.6166 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6017 - loss: 0.3391 - precision: 0.6131 - recall: 0.6022 - val_accuracy: 0.5945 - val_loss: 0.6968 - val_precision: 0.5940 - val_recall: 0.5967\n",
      "Epoch 875/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5985 - loss: 0.3370 - precision: 0.6004 - recall: 0.6314\n",
      "Epoch 875 - Train Recall: 0.6349 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5985 - loss: 0.3370 - precision: 0.6003 - recall: 0.6314 - val_accuracy: 0.5907 - val_loss: 0.6679 - val_precision: 0.5763 - val_recall: 0.6852\n",
      "Epoch 876/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5865 - loss: 0.3558 - precision: 0.5859 - recall: 0.5997\n",
      "Epoch 876 - Train Recall: 0.5930 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5866 - loss: 0.3557 - precision: 0.5860 - recall: 0.5992 - val_accuracy: 0.5885 - val_loss: 0.7018 - val_precision: 0.5937 - val_recall: 0.5607\n",
      "Epoch 877/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5804 - loss: 0.3359 - precision: 0.5837 - recall: 0.5914\n",
      "Epoch 877 - Train Recall: 0.6432 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5808 - loss: 0.3358 - precision: 0.5838 - recall: 0.5926 - val_accuracy: 0.6027 - val_loss: 0.6507 - val_precision: 0.5891 - val_recall: 0.6792\n",
      "Epoch 878/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5987 - loss: 0.3497 - precision: 0.5899 - recall: 0.6453\n",
      "Epoch 878 - Train Recall: 0.6166 - Val Recall: 0.5547\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5984 - loss: 0.3498 - precision: 0.5898 - recall: 0.6431 - val_accuracy: 0.5885 - val_loss: 0.6980 - val_precision: 0.5949 - val_recall: 0.5547\n",
      "Epoch 879/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6038 - loss: 0.3243 - precision: 0.5918 - recall: 0.6529\n",
      "Epoch 879 - Train Recall: 0.6777 - Val Recall: 0.7001\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6039 - loss: 0.3242 - precision: 0.5918 - recall: 0.6541 - val_accuracy: 0.6087 - val_loss: 0.6378 - val_precision: 0.5919 - val_recall: 0.7001\n",
      "Epoch 880/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5895 - loss: 0.3470 - precision: 0.5820 - recall: 0.6546\n",
      "Epoch 880 - Train Recall: 0.6289 - Val Recall: 0.5952\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5897 - loss: 0.3470 - precision: 0.5822 - recall: 0.6538 - val_accuracy: 0.5877 - val_loss: 0.6838 - val_precision: 0.5864 - val_recall: 0.5952\n",
      "Epoch 881/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6116 - loss: 0.3298 - precision: 0.6068 - recall: 0.6280\n",
      "Epoch 881 - Train Recall: 0.6484 - Val Recall: 0.6567\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6112 - loss: 0.3299 - precision: 0.6063 - recall: 0.6286 - val_accuracy: 0.5847 - val_loss: 0.6574 - val_precision: 0.5740 - val_recall: 0.6567\n",
      "Epoch 882/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6025 - loss: 0.3430 - precision: 0.6009 - recall: 0.6359\n",
      "Epoch 882 - Train Recall: 0.6289 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6024 - loss: 0.3431 - precision: 0.6007 - recall: 0.6357 - val_accuracy: 0.5975 - val_loss: 0.6797 - val_precision: 0.5876 - val_recall: 0.6537\n",
      "Epoch 883/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6171 - loss: 0.3452 - precision: 0.6055 - recall: 0.6635\n",
      "Epoch 883 - Train Recall: 0.6012 - Val Recall: 0.5112\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6155 - loss: 0.3454 - precision: 0.6047 - recall: 0.6587 - val_accuracy: 0.5742 - val_loss: 0.6895 - val_precision: 0.5849 - val_recall: 0.5112\n",
      "Epoch 884/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5959 - loss: 0.3145 - precision: 0.5819 - recall: 0.6732\n",
      "Epoch 884 - Train Recall: 0.7028 - Val Recall: 0.7151\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5959 - loss: 0.3145 - precision: 0.5819 - recall: 0.6735 - val_accuracy: 0.5967 - val_loss: 0.6174 - val_precision: 0.5782 - val_recall: 0.7151\n",
      "Epoch 885/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5899 - loss: 0.3459 - precision: 0.5747 - recall: 0.6886\n",
      "Epoch 885 - Train Recall: 0.6825 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5905 - loss: 0.3456 - precision: 0.5755 - recall: 0.6883 - val_accuracy: 0.5922 - val_loss: 0.6819 - val_precision: 0.5887 - val_recall: 0.6117\n",
      "Epoch 886/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5987 - loss: 0.3229 - precision: 0.5836 - recall: 0.6490\n",
      "Epoch 886 - Train Recall: 0.6619 - Val Recall: 0.7376\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5980 - loss: 0.3230 - precision: 0.5836 - recall: 0.6503 - val_accuracy: 0.6079 - val_loss: 0.6465 - val_precision: 0.5857 - val_recall: 0.7376\n",
      "Epoch 887/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5879 - loss: 0.3633 - precision: 0.5773 - recall: 0.6288\n",
      "Epoch 887 - Train Recall: 0.6027 - Val Recall: 0.5802\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5880 - loss: 0.3633 - precision: 0.5777 - recall: 0.6280 - val_accuracy: 0.5780 - val_loss: 0.7262 - val_precision: 0.5776 - val_recall: 0.5802\n",
      "Epoch 888/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6045 - loss: 0.3365 - precision: 0.6071 - recall: 0.5667\n",
      "Epoch 888 - Train Recall: 0.6128 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6040 - loss: 0.3365 - precision: 0.6058 - recall: 0.5719 - val_accuracy: 0.6019 - val_loss: 0.6653 - val_precision: 0.5844 - val_recall: 0.7061\n",
      "Epoch 889/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5888 - loss: 0.3654 - precision: 0.5865 - recall: 0.6022\n",
      "Epoch 889 - Train Recall: 0.5690 - Val Recall: 0.5322\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5889 - loss: 0.3655 - precision: 0.5867 - recall: 0.6016 - val_accuracy: 0.5885 - val_loss: 0.7286 - val_precision: 0.5997 - val_recall: 0.5322\n",
      "Epoch 890/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6038 - loss: 0.3302 - precision: 0.6026 - recall: 0.6198\n",
      "Epoch 890 - Train Recall: 0.6372 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6036 - loss: 0.3302 - precision: 0.6020 - recall: 0.6208 - val_accuracy: 0.6004 - val_loss: 0.6496 - val_precision: 0.5866 - val_recall: 0.6807\n",
      "Epoch 891/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.3550 - precision: 0.5821 - recall: 0.6323\n",
      "Epoch 891 - Train Recall: 0.6132 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5942 - loss: 0.3550 - precision: 0.5822 - recall: 0.6320 - val_accuracy: 0.5975 - val_loss: 0.6997 - val_precision: 0.5964 - val_recall: 0.6027\n",
      "Epoch 892/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6011 - loss: 0.3389 - precision: 0.5946 - recall: 0.6033\n",
      "Epoch 892 - Train Recall: 0.6308 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6007 - loss: 0.3389 - precision: 0.5942 - recall: 0.6070 - val_accuracy: 0.6049 - val_loss: 0.6691 - val_precision: 0.5902 - val_recall: 0.6867\n",
      "Epoch 893/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5931 - loss: 0.3580 - precision: 0.5856 - recall: 0.6351\n",
      "Epoch 893 - Train Recall: 0.6241 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5933 - loss: 0.3579 - precision: 0.5859 - recall: 0.6346 - val_accuracy: 0.5990 - val_loss: 0.7068 - val_precision: 0.5902 - val_recall: 0.6477\n",
      "Epoch 894/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5996 - loss: 0.3475 - precision: 0.6082 - recall: 0.6018\n",
      "Epoch 894 - Train Recall: 0.6094 - Val Recall: 0.5727\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5993 - loss: 0.3476 - precision: 0.6071 - recall: 0.6026 - val_accuracy: 0.6072 - val_loss: 0.6875 - val_precision: 0.6151 - val_recall: 0.5727\n",
      "Epoch 895/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6061 - loss: 0.3299 - precision: 0.6118 - recall: 0.6372\n",
      "Epoch 895 - Train Recall: 0.6537 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6057 - loss: 0.3300 - precision: 0.6108 - recall: 0.6378 - val_accuracy: 0.5997 - val_loss: 0.6524 - val_precision: 0.5858 - val_recall: 0.6807\n",
      "Epoch 896/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5949 - loss: 0.3463 - precision: 0.5912 - recall: 0.6324\n",
      "Epoch 896 - Train Recall: 0.6154 - Val Recall: 0.5937\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5948 - loss: 0.3463 - precision: 0.5911 - recall: 0.6317 - val_accuracy: 0.5697 - val_loss: 0.6917 - val_precision: 0.5665 - val_recall: 0.5937\n",
      "Epoch 897/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5928 - loss: 0.3336 - precision: 0.5878 - recall: 0.6404\n",
      "Epoch 897 - Train Recall: 0.6458 - Val Recall: 0.6822\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5929 - loss: 0.3337 - precision: 0.5877 - recall: 0.6407 - val_accuracy: 0.5990 - val_loss: 0.6606 - val_precision: 0.5848 - val_recall: 0.6822\n",
      "Epoch 898/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5986 - loss: 0.3481 - precision: 0.5873 - recall: 0.6213\n",
      "Epoch 898 - Train Recall: 0.6162 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5984 - loss: 0.3482 - precision: 0.5874 - recall: 0.6211 - val_accuracy: 0.5930 - val_loss: 0.6940 - val_precision: 0.5859 - val_recall: 0.6342\n",
      "Epoch 899/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6092 - loss: 0.3419 - precision: 0.5968 - recall: 0.6350\n",
      "Epoch 899 - Train Recall: 0.6308 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6089 - loss: 0.3421 - precision: 0.5970 - recall: 0.6347 - val_accuracy: 0.5907 - val_loss: 0.6882 - val_precision: 0.5806 - val_recall: 0.6537\n",
      "Epoch 900/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5912 - loss: 0.3481 - precision: 0.5989 - recall: 0.6237\n",
      "Epoch 900 - Train Recall: 0.6109 - Val Recall: 0.6567\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5917 - loss: 0.3480 - precision: 0.5978 - recall: 0.6217 - val_accuracy: 0.5952 - val_loss: 0.6855 - val_precision: 0.5848 - val_recall: 0.6567\n",
      "Epoch 901/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6010 - loss: 0.3509 - precision: 0.5929 - recall: 0.6140\n",
      "Epoch 901 - Train Recall: 0.5810 - Val Recall: 0.5832\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6009 - loss: 0.3509 - precision: 0.5929 - recall: 0.6134 - val_accuracy: 0.5952 - val_loss: 0.7013 - val_precision: 0.5975 - val_recall: 0.5832\n",
      "Epoch 902/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6008 - loss: 0.3410 - precision: 0.6084 - recall: 0.5711\n",
      "Epoch 902 - Train Recall: 0.6053 - Val Recall: 0.6267\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 0.3410 - precision: 0.6082 - recall: 0.5715 - val_accuracy: 0.6042 - val_loss: 0.6782 - val_precision: 0.5997 - val_recall: 0.6267\n",
      "Epoch 903/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6044 - loss: 0.3462 - precision: 0.6072 - recall: 0.6339\n",
      "Epoch 903 - Train Recall: 0.6297 - Val Recall: 0.5727\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6043 - loss: 0.3463 - precision: 0.6066 - recall: 0.6337 - val_accuracy: 0.6072 - val_loss: 0.6822 - val_precision: 0.6151 - val_recall: 0.5727\n",
      "Epoch 904/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6141 - loss: 0.3224 - precision: 0.5962 - recall: 0.6374\n",
      "Epoch 904 - Train Recall: 0.6492 - Val Recall: 0.6627\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6135 - loss: 0.3226 - precision: 0.5963 - recall: 0.6387 - val_accuracy: 0.5667 - val_loss: 0.6558 - val_precision: 0.5560 - val_recall: 0.6627\n",
      "Epoch 905/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5927 - loss: 0.3441 - precision: 0.5760 - recall: 0.6724\n",
      "Epoch 905 - Train Recall: 0.6582 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5929 - loss: 0.3443 - precision: 0.5771 - recall: 0.6705 - val_accuracy: 0.5877 - val_loss: 0.6832 - val_precision: 0.5798 - val_recall: 0.6372\n",
      "Epoch 906/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6075 - loss: 0.3348 - precision: 0.6126 - recall: 0.6456\n",
      "Epoch 906 - Train Recall: 0.6458 - Val Recall: 0.6627\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6067 - loss: 0.3350 - precision: 0.6105 - recall: 0.6457 - val_accuracy: 0.5907 - val_loss: 0.6681 - val_precision: 0.5793 - val_recall: 0.6627\n",
      "Epoch 907/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6119 - loss: 0.3418 - precision: 0.6201 - recall: 0.6319\n",
      "Epoch 907 - Train Recall: 0.6229 - Val Recall: 0.5922\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6113 - loss: 0.3420 - precision: 0.6189 - recall: 0.6314 - val_accuracy: 0.5795 - val_loss: 0.6875 - val_precision: 0.5775 - val_recall: 0.5922\n",
      "Epoch 908/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5828 - loss: 0.3364 - precision: 0.5820 - recall: 0.6111\n",
      "Epoch 908 - Train Recall: 0.6488 - Val Recall: 0.6747\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5837 - loss: 0.3363 - precision: 0.5821 - recall: 0.6139 - val_accuracy: 0.5840 - val_loss: 0.6585 - val_precision: 0.5711 - val_recall: 0.6747\n",
      "Epoch 909/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6137 - loss: 0.3455 - precision: 0.6041 - recall: 0.6868\n",
      "Epoch 909 - Train Recall: 0.6518 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6129 - loss: 0.3457 - precision: 0.6034 - recall: 0.6843 - val_accuracy: 0.6034 - val_loss: 0.6865 - val_precision: 0.6030 - val_recall: 0.6057\n",
      "Epoch 910/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5987 - loss: 0.3290 - precision: 0.5898 - recall: 0.6600\n",
      "Epoch 910 - Train Recall: 0.6814 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5993 - loss: 0.3289 - precision: 0.5899 - recall: 0.6629 - val_accuracy: 0.5832 - val_loss: 0.6474 - val_precision: 0.5691 - val_recall: 0.6852\n",
      "Epoch 911/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.3404 - precision: 0.5723 - recall: 0.6582\n",
      "Epoch 911 - Train Recall: 0.6570 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5965 - loss: 0.3405 - precision: 0.5729 - recall: 0.6581 - val_accuracy: 0.5817 - val_loss: 0.6785 - val_precision: 0.5741 - val_recall: 0.6327\n",
      "Epoch 912/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5987 - loss: 0.3325 - precision: 0.5780 - recall: 0.6576\n",
      "Epoch 912 - Train Recall: 0.6657 - Val Recall: 0.6987\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5988 - loss: 0.3328 - precision: 0.5794 - recall: 0.6588 - val_accuracy: 0.6027 - val_loss: 0.6607 - val_precision: 0.5862 - val_recall: 0.6987\n",
      "Epoch 913/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 0.3490 - precision: 0.5710 - recall: 0.6402\n",
      "Epoch 913 - Train Recall: 0.6406 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5956 - loss: 0.3489 - precision: 0.5728 - recall: 0.6401 - val_accuracy: 0.5615 - val_loss: 0.7040 - val_precision: 0.5534 - val_recall: 0.6372\n",
      "Epoch 914/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5902 - loss: 0.3412 - precision: 0.5734 - recall: 0.6231\n",
      "Epoch 914 - Train Recall: 0.6406 - Val Recall: 0.6927\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5903 - loss: 0.3412 - precision: 0.5738 - recall: 0.6238 - val_accuracy: 0.6057 - val_loss: 0.6743 - val_precision: 0.5900 - val_recall: 0.6927\n",
      "Epoch 915/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6000 - loss: 0.3538 - precision: 0.6009 - recall: 0.6272\n",
      "Epoch 915 - Train Recall: 0.6139 - Val Recall: 0.6162\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5997 - loss: 0.3537 - precision: 0.6002 - recall: 0.6260 - val_accuracy: 0.6019 - val_loss: 0.7032 - val_precision: 0.5991 - val_recall: 0.6162\n",
      "Epoch 916/2000\n",
      "\u001b[1m141/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5882 - loss: 0.3432 - precision: 0.5848 - recall: 0.5969\n",
      "Epoch 916 - Train Recall: 0.6143 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5889 - loss: 0.3431 - precision: 0.5850 - recall: 0.6002 - val_accuracy: 0.6019 - val_loss: 0.6755 - val_precision: 0.5924 - val_recall: 0.6537\n",
      "Epoch 917/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5925 - loss: 0.3500 - precision: 0.5880 - recall: 0.6126\n",
      "Epoch 917 - Train Recall: 0.6121 - Val Recall: 0.5217\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5927 - loss: 0.3501 - precision: 0.5882 - recall: 0.6126 - val_accuracy: 0.5892 - val_loss: 0.7031 - val_precision: 0.6031 - val_recall: 0.5217\n",
      "Epoch 918/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6087 - loss: 0.3160 - precision: 0.5995 - recall: 0.6570\n",
      "Epoch 918 - Train Recall: 0.6919 - Val Recall: 0.7541\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6083 - loss: 0.3159 - precision: 0.5985 - recall: 0.6606 - val_accuracy: 0.6079 - val_loss: 0.6174 - val_precision: 0.5835 - val_recall: 0.7541\n",
      "Epoch 919/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6036 - loss: 0.3557 - precision: 0.5924 - recall: 0.6554\n",
      "Epoch 919 - Train Recall: 0.6151 - Val Recall: 0.5007\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6034 - loss: 0.3557 - precision: 0.5925 - recall: 0.6542 - val_accuracy: 0.5697 - val_loss: 0.7114 - val_precision: 0.5809 - val_recall: 0.5007\n",
      "Epoch 920/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5874 - loss: 0.3098 - precision: 0.5763 - recall: 0.6268\n",
      "Epoch 920 - Train Recall: 0.6998 - Val Recall: 0.7031\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5880 - loss: 0.3096 - precision: 0.5764 - recall: 0.6338 - val_accuracy: 0.6072 - val_loss: 0.6066 - val_precision: 0.5899 - val_recall: 0.7031\n",
      "Epoch 921/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5917 - loss: 0.3424 - precision: 0.5836 - recall: 0.6806\n",
      "Epoch 921 - Train Recall: 0.6777 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5917 - loss: 0.3423 - precision: 0.5831 - recall: 0.6806 - val_accuracy: 0.5937 - val_loss: 0.6809 - val_precision: 0.5843 - val_recall: 0.6492\n",
      "Epoch 922/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5915 - loss: 0.3359 - precision: 0.5837 - recall: 0.6321\n",
      "Epoch 922 - Train Recall: 0.6578 - Val Recall: 0.6717\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5916 - loss: 0.3358 - precision: 0.5838 - recall: 0.6326 - val_accuracy: 0.5885 - val_loss: 0.6620 - val_precision: 0.5758 - val_recall: 0.6717\n",
      "Epoch 923/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5912 - loss: 0.3445 - precision: 0.5889 - recall: 0.6451\n",
      "Epoch 923 - Train Recall: 0.6357 - Val Recall: 0.5922\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5913 - loss: 0.3445 - precision: 0.5889 - recall: 0.6449 - val_accuracy: 0.5930 - val_loss: 0.6798 - val_precision: 0.5931 - val_recall: 0.5922\n",
      "Epoch 924/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6065 - loss: 0.3301 - precision: 0.6119 - recall: 0.6349\n",
      "Epoch 924 - Train Recall: 0.6432 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6064 - loss: 0.3301 - precision: 0.6117 - recall: 0.6350 - val_accuracy: 0.5922 - val_loss: 0.6559 - val_precision: 0.5898 - val_recall: 0.6057\n",
      "Epoch 925/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5838 - loss: 0.3332 - precision: 0.5808 - recall: 0.6554\n",
      "Epoch 925 - Train Recall: 0.6743 - Val Recall: 0.7466\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5844 - loss: 0.3331 - precision: 0.5810 - recall: 0.6561 - val_accuracy: 0.5960 - val_loss: 0.6556 - val_precision: 0.5737 - val_recall: 0.7466\n",
      "Epoch 926/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5776 - loss: 0.3623 - precision: 0.5659 - recall: 0.5920\n",
      "Epoch 926 - Train Recall: 0.5870 - Val Recall: 0.5787\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5778 - loss: 0.3622 - precision: 0.5662 - recall: 0.5919 - val_accuracy: 0.5952 - val_loss: 0.7057 - val_precision: 0.5984 - val_recall: 0.5787\n",
      "Epoch 927/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6051 - loss: 0.3376 - precision: 0.6051 - recall: 0.6231\n",
      "Epoch 927 - Train Recall: 0.6304 - Val Recall: 0.6087\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.3378 - precision: 0.6036 - recall: 0.6238 - val_accuracy: 0.5990 - val_loss: 0.6664 - val_precision: 0.5971 - val_recall: 0.6087\n",
      "Epoch 928/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6045 - loss: 0.3314 - precision: 0.6004 - recall: 0.6447\n",
      "Epoch 928 - Train Recall: 0.6454 - Val Recall: 0.7601\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 0.3315 - precision: 0.5998 - recall: 0.6448 - val_accuracy: 0.5960 - val_loss: 0.6658 - val_precision: 0.5722 - val_recall: 0.7601\n",
      "Epoch 929/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.3703 - precision: 0.5985 - recall: 0.5672\n",
      "Epoch 929 - Train Recall: 0.5457 - Val Recall: 0.4513\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5970 - loss: 0.3702 - precision: 0.5995 - recall: 0.5657 - val_accuracy: 0.5735 - val_loss: 0.7295 - val_precision: 0.5972 - val_recall: 0.4513\n",
      "Epoch 930/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5953 - loss: 0.3123 - precision: 0.5910 - recall: 0.5953\n",
      "Epoch 930 - Train Recall: 0.6623 - Val Recall: 0.7391\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5953 - loss: 0.3122 - precision: 0.5909 - recall: 0.5961 - val_accuracy: 0.5967 - val_loss: 0.6122 - val_precision: 0.5753 - val_recall: 0.7391\n",
      "Epoch 931/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5936 - loss: 0.3615 - precision: 0.5836 - recall: 0.6530\n",
      "Epoch 931 - Train Recall: 0.6083 - Val Recall: 0.5247\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5933 - loss: 0.3614 - precision: 0.5839 - recall: 0.6494 - val_accuracy: 0.5832 - val_loss: 0.7145 - val_precision: 0.5942 - val_recall: 0.5247\n",
      "Epoch 932/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5976 - loss: 0.3181 - precision: 0.5917 - recall: 0.6375\n",
      "Epoch 932 - Train Recall: 0.6777 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5975 - loss: 0.3181 - precision: 0.5913 - recall: 0.6391 - val_accuracy: 0.5750 - val_loss: 0.6350 - val_precision: 0.5687 - val_recall: 0.6207\n",
      "Epoch 933/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5926 - loss: 0.3267 - precision: 0.5806 - recall: 0.6711\n",
      "Epoch 933 - Train Recall: 0.6784 - Val Recall: 0.7781\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5927 - loss: 0.3267 - precision: 0.5806 - recall: 0.6716 - val_accuracy: 0.5967 - val_loss: 0.6446 - val_precision: 0.5710 - val_recall: 0.7781\n",
      "Epoch 934/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5921 - loss: 0.3653 - precision: 0.5856 - recall: 0.6372\n",
      "Epoch 934 - Train Recall: 0.6008 - Val Recall: 0.4483\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5921 - loss: 0.3653 - precision: 0.5857 - recall: 0.6368 - val_accuracy: 0.5690 - val_loss: 0.7300 - val_precision: 0.5909 - val_recall: 0.4483\n",
      "Epoch 935/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5932 - loss: 0.2982 - precision: 0.5894 - recall: 0.6328\n",
      "Epoch 935 - Train Recall: 0.7061 - Val Recall: 0.7136\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5932 - loss: 0.2982 - precision: 0.5893 - recall: 0.6337 - val_accuracy: 0.5855 - val_loss: 0.5815 - val_precision: 0.5680 - val_recall: 0.7136\n",
      "Epoch 936/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5972 - loss: 0.3417 - precision: 0.5803 - recall: 0.7413\n",
      "Epoch 936 - Train Recall: 0.6852 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5969 - loss: 0.3419 - precision: 0.5802 - recall: 0.7352 - val_accuracy: 0.6042 - val_loss: 0.6781 - val_precision: 0.5983 - val_recall: 0.6342\n",
      "Epoch 937/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6076 - loss: 0.3251 - precision: 0.5942 - recall: 0.6706\n",
      "Epoch 937 - Train Recall: 0.6960 - Val Recall: 0.6777\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6075 - loss: 0.3252 - precision: 0.5940 - recall: 0.6712 - val_accuracy: 0.5615 - val_loss: 0.6611 - val_precision: 0.5499 - val_recall: 0.6777\n",
      "Epoch 938/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5971 - loss: 0.3377 - precision: 0.5841 - recall: 0.6886\n",
      "Epoch 938 - Train Recall: 0.6747 - Val Recall: 0.6942\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5976 - loss: 0.3376 - precision: 0.5845 - recall: 0.6873 - val_accuracy: 0.5952 - val_loss: 0.6709 - val_precision: 0.5795 - val_recall: 0.6942\n",
      "Epoch 939/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5986 - loss: 0.3474 - precision: 0.5876 - recall: 0.6679\n",
      "Epoch 939 - Train Recall: 0.6582 - Val Recall: 0.7016\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5987 - loss: 0.3473 - precision: 0.5878 - recall: 0.6676 - val_accuracy: 0.6004 - val_loss: 0.6809 - val_precision: 0.5835 - val_recall: 0.7016\n",
      "Epoch 940/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5888 - loss: 0.3504 - precision: 0.5977 - recall: 0.5894\n",
      "Epoch 940 - Train Recall: 0.5975 - Val Recall: 0.5487\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5894 - loss: 0.3505 - precision: 0.5975 - recall: 0.5900 - val_accuracy: 0.5907 - val_loss: 0.7066 - val_precision: 0.5990 - val_recall: 0.5487\n",
      "Epoch 941/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6000 - loss: 0.3270 - precision: 0.5836 - recall: 0.6467\n",
      "Epoch 941 - Train Recall: 0.6600 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6001 - loss: 0.3270 - precision: 0.5840 - recall: 0.6473 - val_accuracy: 0.5877 - val_loss: 0.6535 - val_precision: 0.5789 - val_recall: 0.6432\n",
      "Epoch 942/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5834 - loss: 0.3381 - precision: 0.5712 - recall: 0.6386\n",
      "Epoch 942 - Train Recall: 0.6451 - Val Recall: 0.7361\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5835 - loss: 0.3381 - precision: 0.5715 - recall: 0.6388 - val_accuracy: 0.5922 - val_loss: 0.6655 - val_precision: 0.5716 - val_recall: 0.7361\n",
      "Epoch 943/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5924 - loss: 0.3648 - precision: 0.5985 - recall: 0.5887\n",
      "Epoch 943 - Train Recall: 0.5667 - Val Recall: 0.5922\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5931 - loss: 0.3647 - precision: 0.5992 - recall: 0.5868 - val_accuracy: 0.6019 - val_loss: 0.7177 - val_precision: 0.6040 - val_recall: 0.5922\n",
      "Epoch 944/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5964 - loss: 0.3462 - precision: 0.6094 - recall: 0.5350\n",
      "Epoch 944 - Train Recall: 0.5596 - Val Recall: 0.5547\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5963 - loss: 0.3463 - precision: 0.6090 - recall: 0.5358 - val_accuracy: 0.6012 - val_loss: 0.6887 - val_precision: 0.6116 - val_recall: 0.5547\n",
      "Epoch 945/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5894 - loss: 0.3403 - precision: 0.5818 - recall: 0.6065\n",
      "Epoch 945 - Train Recall: 0.5963 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5894 - loss: 0.3402 - precision: 0.5823 - recall: 0.6055 - val_accuracy: 0.5930 - val_loss: 0.6690 - val_precision: 0.5791 - val_recall: 0.6807\n",
      "Epoch 946/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5872 - loss: 0.3665 - precision: 0.5828 - recall: 0.6112\n",
      "Epoch 946 - Train Recall: 0.5821 - Val Recall: 0.5247\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5872 - loss: 0.3665 - precision: 0.5829 - recall: 0.6107 - val_accuracy: 0.5952 - val_loss: 0.7243 - val_precision: 0.6108 - val_recall: 0.5247\n",
      "Epoch 947/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6003 - loss: 0.3239 - precision: 0.5950 - recall: 0.5838\n",
      "Epoch 947 - Train Recall: 0.6173 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5997 - loss: 0.3240 - precision: 0.5945 - recall: 0.5874 - val_accuracy: 0.5975 - val_loss: 0.6392 - val_precision: 0.5827 - val_recall: 0.6867\n",
      "Epoch 948/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6138 - loss: 0.3550 - precision: 0.6038 - recall: 0.6595\n",
      "Epoch 948 - Train Recall: 0.6128 - Val Recall: 0.5067\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6126 - loss: 0.3554 - precision: 0.6030 - recall: 0.6559 - val_accuracy: 0.5855 - val_loss: 0.7123 - val_precision: 0.6014 - val_recall: 0.5067\n",
      "Epoch 949/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6069 - loss: 0.3101 - precision: 0.5899 - recall: 0.6449\n",
      "Epoch 949 - Train Recall: 0.6833 - Val Recall: 0.7406\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6068 - loss: 0.3101 - precision: 0.5899 - recall: 0.6454 - val_accuracy: 0.5870 - val_loss: 0.6112 - val_precision: 0.5665 - val_recall: 0.7406\n",
      "Epoch 950/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5904 - loss: 0.3568 - precision: 0.5789 - recall: 0.7019\n",
      "Epoch 950 - Train Recall: 0.6477 - Val Recall: 0.5592\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5909 - loss: 0.3567 - precision: 0.5796 - recall: 0.6957 - val_accuracy: 0.6027 - val_loss: 0.7018 - val_precision: 0.6125 - val_recall: 0.5592\n",
      "Epoch 951/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5946 - loss: 0.3196 - precision: 0.5898 - recall: 0.6080\n",
      "Epoch 951 - Train Recall: 0.6469 - Val Recall: 0.7136\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 0.3194 - precision: 0.5886 - recall: 0.6130 - val_accuracy: 0.5825 - val_loss: 0.6285 - val_precision: 0.5653 - val_recall: 0.7136\n",
      "Epoch 952/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 0.3598 - precision: 0.5879 - recall: 0.6633\n",
      "Epoch 952 - Train Recall: 0.6286 - Val Recall: 0.6657\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5954 - loss: 0.3597 - precision: 0.5878 - recall: 0.6608 - val_accuracy: 0.5982 - val_loss: 0.7087 - val_precision: 0.5865 - val_recall: 0.6657\n",
      "Epoch 953/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.3509 - precision: 0.6030 - recall: 0.5725\n",
      "Epoch 953 - Train Recall: 0.5795 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5980 - loss: 0.3508 - precision: 0.6027 - recall: 0.5731 - val_accuracy: 0.5937 - val_loss: 0.6928 - val_precision: 0.5912 - val_recall: 0.6072\n",
      "Epoch 954/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6075 - loss: 0.3462 - precision: 0.6042 - recall: 0.6071\n",
      "Epoch 954 - Train Recall: 0.6109 - Val Recall: 0.6087\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6071 - loss: 0.3465 - precision: 0.6039 - recall: 0.6074 - val_accuracy: 0.6027 - val_loss: 0.6885 - val_precision: 0.6015 - val_recall: 0.6087\n",
      "Epoch 955/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5955 - loss: 0.3402 - precision: 0.5858 - recall: 0.6410\n",
      "Epoch 955 - Train Recall: 0.6304 - Val Recall: 0.6657\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5952 - loss: 0.3402 - precision: 0.5856 - recall: 0.6404 - val_accuracy: 0.6124 - val_loss: 0.6754 - val_precision: 0.6016 - val_recall: 0.6657\n",
      "Epoch 956/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5965 - loss: 0.3498 - precision: 0.5954 - recall: 0.6382\n",
      "Epoch 956 - Train Recall: 0.6237 - Val Recall: 0.5427\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5965 - loss: 0.3499 - precision: 0.5953 - recall: 0.6379 - val_accuracy: 0.6057 - val_loss: 0.6893 - val_precision: 0.6209 - val_recall: 0.5427\n",
      "Epoch 957/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6004 - loss: 0.3170 - precision: 0.5945 - recall: 0.6723\n",
      "Epoch 957 - Train Recall: 0.6983 - Val Recall: 0.7196\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5999 - loss: 0.3171 - precision: 0.5931 - recall: 0.6746 - val_accuracy: 0.6124 - val_loss: 0.6246 - val_precision: 0.5926 - val_recall: 0.7196\n",
      "Epoch 958/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6035 - loss: 0.3464 - precision: 0.5967 - recall: 0.6486\n",
      "Epoch 958 - Train Recall: 0.6428 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6034 - loss: 0.3464 - precision: 0.5966 - recall: 0.6484 - val_accuracy: 0.5697 - val_loss: 0.6965 - val_precision: 0.5654 - val_recall: 0.6027\n",
      "Epoch 959/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5998 - loss: 0.3308 - precision: 0.5876 - recall: 0.6462\n",
      "Epoch 959 - Train Recall: 0.6529 - Val Recall: 0.6567\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5995 - loss: 0.3308 - precision: 0.5876 - recall: 0.6467 - val_accuracy: 0.5690 - val_loss: 0.6590 - val_precision: 0.5587 - val_recall: 0.6567\n",
      "Epoch 960/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5945 - loss: 0.3435 - precision: 0.5821 - recall: 0.6359\n",
      "Epoch 960 - Train Recall: 0.6391 - Val Recall: 0.6657\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5946 - loss: 0.3434 - precision: 0.5824 - recall: 0.6360 - val_accuracy: 0.6004 - val_loss: 0.6747 - val_precision: 0.5889 - val_recall: 0.6657\n",
      "Epoch 961/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5929 - loss: 0.3480 - precision: 0.5835 - recall: 0.6327\n",
      "Epoch 961 - Train Recall: 0.6181 - Val Recall: 0.5502\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5929 - loss: 0.3480 - precision: 0.5837 - recall: 0.6323 - val_accuracy: 0.5975 - val_loss: 0.6850 - val_precision: 0.6076 - val_recall: 0.5502\n",
      "Epoch 962/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5898 - loss: 0.3241 - precision: 0.5739 - recall: 0.6238\n",
      "Epoch 962 - Train Recall: 0.6705 - Val Recall: 0.7676\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5907 - loss: 0.3239 - precision: 0.5755 - recall: 0.6290 - val_accuracy: 0.6079 - val_loss: 0.6325 - val_precision: 0.5818 - val_recall: 0.7676\n",
      "Epoch 963/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5923 - loss: 0.3665 - precision: 0.5844 - recall: 0.6597\n",
      "Epoch 963 - Train Recall: 0.6094 - Val Recall: 0.5457\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5924 - loss: 0.3665 - precision: 0.5845 - recall: 0.6591 - val_accuracy: 0.5990 - val_loss: 0.7236 - val_precision: 0.6107 - val_recall: 0.5457\n",
      "Epoch 964/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6085 - loss: 0.3210 - precision: 0.6199 - recall: 0.5811\n",
      "Epoch 964 - Train Recall: 0.6346 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6075 - loss: 0.3213 - precision: 0.6173 - recall: 0.5857 - val_accuracy: 0.5960 - val_loss: 0.6450 - val_precision: 0.5858 - val_recall: 0.6552\n",
      "Epoch 965/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6035 - loss: 0.3455 - precision: 0.5893 - recall: 0.6788\n",
      "Epoch 965 - Train Recall: 0.6488 - Val Recall: 0.7391\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6033 - loss: 0.3455 - precision: 0.5892 - recall: 0.6781 - val_accuracy: 0.6042 - val_loss: 0.6832 - val_precision: 0.5821 - val_recall: 0.7391\n",
      "Epoch 966/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6032 - loss: 0.3643 - precision: 0.5975 - recall: 0.6027\n",
      "Epoch 966 - Train Recall: 0.5806 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6031 - loss: 0.3642 - precision: 0.5983 - recall: 0.6009 - val_accuracy: 0.5975 - val_loss: 0.7230 - val_precision: 0.5997 - val_recall: 0.5862\n",
      "Epoch 967/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6143 - loss: 0.3399 - precision: 0.6150 - recall: 0.6298\n",
      "Epoch 967 - Train Recall: 0.6214 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6141 - loss: 0.3399 - precision: 0.6147 - recall: 0.6296 - val_accuracy: 0.6004 - val_loss: 0.6761 - val_precision: 0.6034 - val_recall: 0.5862\n",
      "Epoch 968/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5930 - loss: 0.3319 - precision: 0.5932 - recall: 0.6383\n",
      "Epoch 968 - Train Recall: 0.6664 - Val Recall: 0.6522\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5932 - loss: 0.3318 - precision: 0.5931 - recall: 0.6392 - val_accuracy: 0.6004 - val_loss: 0.6546 - val_precision: 0.5910 - val_recall: 0.6522\n",
      "Epoch 969/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6070 - loss: 0.3364 - precision: 0.5998 - recall: 0.6762\n",
      "Epoch 969 - Train Recall: 0.6496 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6061 - loss: 0.3365 - precision: 0.5986 - recall: 0.6737 - val_accuracy: 0.5997 - val_loss: 0.6651 - val_precision: 0.5933 - val_recall: 0.6342\n",
      "Epoch 970/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6084 - loss: 0.3343 - precision: 0.5868 - recall: 0.6460\n",
      "Epoch 970 - Train Recall: 0.6421 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6082 - loss: 0.3343 - precision: 0.5871 - recall: 0.6459 - val_accuracy: 0.5952 - val_loss: 0.6645 - val_precision: 0.5866 - val_recall: 0.6447\n",
      "Epoch 971/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6118 - loss: 0.3401 - precision: 0.5949 - recall: 0.6537\n",
      "Epoch 971 - Train Recall: 0.6256 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6103 - loss: 0.3402 - precision: 0.5945 - recall: 0.6503 - val_accuracy: 0.5915 - val_loss: 0.6766 - val_precision: 0.5813 - val_recall: 0.6537\n",
      "Epoch 972/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5808 - loss: 0.3512 - precision: 0.5713 - recall: 0.6321\n",
      "Epoch 972 - Train Recall: 0.6327 - Val Recall: 0.5412\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5815 - loss: 0.3510 - precision: 0.5722 - recall: 0.6321 - val_accuracy: 0.6019 - val_loss: 0.6864 - val_precision: 0.6160 - val_recall: 0.5412\n",
      "Epoch 973/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.3154 - precision: 0.5886 - recall: 0.6487\n",
      "Epoch 973 - Train Recall: 0.6833 - Val Recall: 0.7436\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5939 - loss: 0.3155 - precision: 0.5876 - recall: 0.6518 - val_accuracy: 0.6034 - val_loss: 0.6183 - val_precision: 0.5808 - val_recall: 0.7436\n",
      "Epoch 974/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 0.3572 - precision: 0.5886 - recall: 0.6653\n",
      "Epoch 974 - Train Recall: 0.6282 - Val Recall: 0.6717\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6026 - loss: 0.3571 - precision: 0.5893 - recall: 0.6606 - val_accuracy: 0.5990 - val_loss: 0.7027 - val_precision: 0.5864 - val_recall: 0.6717\n",
      "Epoch 975/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6001 - loss: 0.3524 - precision: 0.6077 - recall: 0.5857\n",
      "Epoch 975 - Train Recall: 0.5941 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6003 - loss: 0.3525 - precision: 0.6076 - recall: 0.5861 - val_accuracy: 0.5967 - val_loss: 0.6977 - val_precision: 0.5947 - val_recall: 0.6072\n",
      "Epoch 976/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6055 - loss: 0.3448 - precision: 0.6066 - recall: 0.5925\n",
      "Epoch 976 - Train Recall: 0.6061 - Val Recall: 0.6597\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6054 - loss: 0.3448 - precision: 0.6064 - recall: 0.5932 - val_accuracy: 0.6072 - val_loss: 0.6812 - val_precision: 0.5970 - val_recall: 0.6597\n",
      "Epoch 977/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6017 - loss: 0.3543 - precision: 0.6046 - recall: 0.6179\n",
      "Epoch 977 - Train Recall: 0.5911 - Val Recall: 0.5562\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6015 - loss: 0.3544 - precision: 0.6042 - recall: 0.6164 - val_accuracy: 0.5825 - val_loss: 0.7075 - val_precision: 0.5870 - val_recall: 0.5562\n",
      "Epoch 978/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6053 - loss: 0.3305 - precision: 0.6000 - recall: 0.6141\n",
      "Epoch 978 - Train Recall: 0.6166 - Val Recall: 0.6897\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.3307 - precision: 0.5989 - recall: 0.6144 - val_accuracy: 0.6072 - val_loss: 0.6530 - val_precision: 0.5920 - val_recall: 0.6897\n",
      "Epoch 979/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5891 - loss: 0.3601 - precision: 0.5808 - recall: 0.6193\n",
      "Epoch 979 - Train Recall: 0.5975 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5891 - loss: 0.3602 - precision: 0.5812 - recall: 0.6180 - val_accuracy: 0.5937 - val_loss: 0.7126 - val_precision: 0.5907 - val_recall: 0.6102\n",
      "Epoch 980/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6035 - loss: 0.3426 - precision: 0.6130 - recall: 0.5893\n",
      "Epoch 980 - Train Recall: 0.6136 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 0.3427 - precision: 0.6115 - recall: 0.5914 - val_accuracy: 0.5982 - val_loss: 0.6810 - val_precision: 0.5884 - val_recall: 0.6537\n",
      "Epoch 981/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5792 - loss: 0.3518 - precision: 0.5886 - recall: 0.5691\n",
      "Epoch 981 - Train Recall: 0.5840 - Val Recall: 0.5232\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5800 - loss: 0.3518 - precision: 0.5889 - recall: 0.5700 - val_accuracy: 0.5870 - val_loss: 0.7028 - val_precision: 0.5997 - val_recall: 0.5232\n",
      "Epoch 982/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5949 - loss: 0.3246 - precision: 0.6027 - recall: 0.6183\n",
      "Epoch 982 - Train Recall: 0.6533 - Val Recall: 0.6987\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5949 - loss: 0.3246 - precision: 0.6026 - recall: 0.6186 - val_accuracy: 0.5840 - val_loss: 0.6365 - val_precision: 0.5683 - val_recall: 0.6987\n",
      "Epoch 983/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5940 - loss: 0.3513 - precision: 0.5734 - recall: 0.6641\n",
      "Epoch 983 - Train Recall: 0.6484 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5942 - loss: 0.3514 - precision: 0.5745 - recall: 0.6630 - val_accuracy: 0.5810 - val_loss: 0.6991 - val_precision: 0.5801 - val_recall: 0.5862\n",
      "Epoch 984/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6014 - loss: 0.3237 - precision: 0.5817 - recall: 0.6518\n",
      "Epoch 984 - Train Recall: 0.6825 - Val Recall: 0.7736\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6013 - loss: 0.3237 - precision: 0.5817 - recall: 0.6523 - val_accuracy: 0.5990 - val_loss: 0.6418 - val_precision: 0.5733 - val_recall: 0.7736\n",
      "Epoch 985/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5962 - loss: 0.3656 - precision: 0.5883 - recall: 0.6495\n",
      "Epoch 985 - Train Recall: 0.5922 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5959 - loss: 0.3654 - precision: 0.5886 - recall: 0.6440 - val_accuracy: 0.5945 - val_loss: 0.7182 - val_precision: 0.5908 - val_recall: 0.6147\n",
      "Epoch 986/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 0.3443 - precision: 0.6133 - recall: 0.6227\n",
      "Epoch 986 - Train Recall: 0.6166 - Val Recall: 0.5757\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6097 - loss: 0.3444 - precision: 0.6127 - recall: 0.6224 - val_accuracy: 0.5855 - val_loss: 0.6887 - val_precision: 0.5872 - val_recall: 0.5757\n",
      "Epoch 987/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6214 - loss: 0.3244 - precision: 0.6197 - recall: 0.6631\n",
      "Epoch 987 - Train Recall: 0.6687 - Val Recall: 0.6132\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6198 - loss: 0.3247 - precision: 0.6171 - recall: 0.6639 - val_accuracy: 0.5885 - val_loss: 0.6554 - val_precision: 0.5843 - val_recall: 0.6132\n",
      "Epoch 988/2000\n",
      "\u001b[1m141/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6206 - loss: 0.3201 - precision: 0.6053 - recall: 0.6886\n",
      "Epoch 988 - Train Recall: 0.6773 - Val Recall: 0.7361\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6176 - loss: 0.3209 - precision: 0.6024 - recall: 0.6866 - val_accuracy: 0.6049 - val_loss: 0.6485 - val_precision: 0.5831 - val_recall: 0.7361\n",
      "Epoch 989/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6041 - loss: 0.3538 - precision: 0.5905 - recall: 0.6529\n",
      "Epoch 989 - Train Recall: 0.6233 - Val Recall: 0.6897\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6040 - loss: 0.3538 - precision: 0.5907 - recall: 0.6520 - val_accuracy: 0.5750 - val_loss: 0.7178 - val_precision: 0.5610 - val_recall: 0.6897\n",
      "Epoch 990/2000\n",
      "\u001b[1m141/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5889 - loss: 0.3596 - precision: 0.5936 - recall: 0.5581\n",
      "Epoch 990 - Train Recall: 0.5813 - Val Recall: 0.6132\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5897 - loss: 0.3594 - precision: 0.5942 - recall: 0.5613 - val_accuracy: 0.5922 - val_loss: 0.7065 - val_precision: 0.5885 - val_recall: 0.6132\n",
      "Epoch 991/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5981 - loss: 0.3505 - precision: 0.5972 - recall: 0.6027\n",
      "Epoch 991 - Train Recall: 0.6057 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5980 - loss: 0.3505 - precision: 0.5972 - recall: 0.6028 - val_accuracy: 0.5990 - val_loss: 0.6927 - val_precision: 0.5907 - val_recall: 0.6447\n",
      "Epoch 992/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6006 - loss: 0.3522 - precision: 0.5980 - recall: 0.5991\n",
      "Epoch 992 - Train Recall: 0.5971 - Val Recall: 0.6627\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6004 - loss: 0.3522 - precision: 0.5980 - recall: 0.5988 - val_accuracy: 0.5967 - val_loss: 0.6979 - val_precision: 0.5854 - val_recall: 0.6627\n",
      "Epoch 993/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6010 - loss: 0.3575 - precision: 0.6046 - recall: 0.5882\n",
      "Epoch 993 - Train Recall: 0.5753 - Val Recall: 0.5307\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 0.3576 - precision: 0.6044 - recall: 0.5877 - val_accuracy: 0.5810 - val_loss: 0.7108 - val_precision: 0.5900 - val_recall: 0.5307\n",
      "Epoch 994/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6111 - loss: 0.3261 - precision: 0.6055 - recall: 0.6385\n",
      "Epoch 994 - Train Recall: 0.6533 - Val Recall: 0.6897\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6110 - loss: 0.3261 - precision: 0.6053 - recall: 0.6394 - val_accuracy: 0.6064 - val_loss: 0.6441 - val_precision: 0.5913 - val_recall: 0.6897\n",
      "Epoch 995/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6008 - loss: 0.3485 - precision: 0.5914 - recall: 0.6166\n",
      "Epoch 995 - Train Recall: 0.6064 - Val Recall: 0.6192\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6007 - loss: 0.3485 - precision: 0.5914 - recall: 0.6164 - val_accuracy: 0.5817 - val_loss: 0.6954 - val_precision: 0.5760 - val_recall: 0.6192\n",
      "Epoch 996/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5986 - loss: 0.3431 - precision: 0.5898 - recall: 0.6117\n",
      "Epoch 996 - Train Recall: 0.6203 - Val Recall: 0.6897\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5980 - loss: 0.3433 - precision: 0.5898 - recall: 0.6129 - val_accuracy: 0.6079 - val_loss: 0.6777 - val_precision: 0.5928 - val_recall: 0.6897\n",
      "Epoch 997/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5941 - loss: 0.3592 - precision: 0.5901 - recall: 0.5848\n",
      "Epoch 997 - Train Recall: 0.5817 - Val Recall: 0.5187\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5941 - loss: 0.3592 - precision: 0.5904 - recall: 0.5846 - val_accuracy: 0.5817 - val_loss: 0.7155 - val_precision: 0.5935 - val_recall: 0.5187\n",
      "Epoch 998/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5914 - loss: 0.3245 - precision: 0.6020 - recall: 0.6212\n",
      "Epoch 998 - Train Recall: 0.6563 - Val Recall: 0.6912\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5916 - loss: 0.3244 - precision: 0.6010 - recall: 0.6233 - val_accuracy: 0.5862 - val_loss: 0.6434 - val_precision: 0.5713 - val_recall: 0.6912\n",
      "Epoch 999/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5924 - loss: 0.3499 - precision: 0.5839 - recall: 0.6295\n",
      "Epoch 999 - Train Recall: 0.6098 - Val Recall: 0.6912\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5923 - loss: 0.3499 - precision: 0.5840 - recall: 0.6285 - val_accuracy: 0.6064 - val_loss: 0.6890 - val_precision: 0.5910 - val_recall: 0.6912\n",
      "Epoch 1000/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6061 - loss: 0.3596 - precision: 0.6055 - recall: 0.6131\n",
      "Epoch 1000 - Train Recall: 0.5832 - Val Recall: 0.6402\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6058 - loss: 0.3596 - precision: 0.6053 - recall: 0.6125 - val_accuracy: 0.5847 - val_loss: 0.7222 - val_precision: 0.5762 - val_recall: 0.6402\n",
      "Epoch 1001/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5968 - loss: 0.3557 - precision: 0.6101 - recall: 0.5756\n",
      "Epoch 1001 - Train Recall: 0.5618 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5967 - loss: 0.3558 - precision: 0.6091 - recall: 0.5736 - val_accuracy: 0.5937 - val_loss: 0.7075 - val_precision: 0.5954 - val_recall: 0.5847\n",
      "Epoch 1002/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6014 - loss: 0.3462 - precision: 0.6107 - recall: 0.5867\n",
      "Epoch 1002 - Train Recall: 0.5885 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6013 - loss: 0.3462 - precision: 0.6103 - recall: 0.5868 - val_accuracy: 0.5960 - val_loss: 0.6871 - val_precision: 0.5982 - val_recall: 0.5847\n",
      "Epoch 1003/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5940 - loss: 0.3416 - precision: 0.5842 - recall: 0.6353\n",
      "Epoch 1003 - Train Recall: 0.6394 - Val Recall: 0.6192\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5938 - loss: 0.3416 - precision: 0.5841 - recall: 0.6355 - val_accuracy: 0.5960 - val_loss: 0.6712 - val_precision: 0.5917 - val_recall: 0.6192\n",
      "Epoch 1004/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5933 - loss: 0.3368 - precision: 0.5794 - recall: 0.6448\n",
      "Epoch 1004 - Train Recall: 0.6548 - Val Recall: 0.7346\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5935 - loss: 0.3368 - precision: 0.5796 - recall: 0.6452 - val_accuracy: 0.6049 - val_loss: 0.6650 - val_precision: 0.5833 - val_recall: 0.7346\n",
      "Epoch 1005/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6069 - loss: 0.3560 - precision: 0.6035 - recall: 0.6141\n",
      "Epoch 1005 - Train Recall: 0.5832 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6062 - loss: 0.3564 - precision: 0.6035 - recall: 0.6109 - val_accuracy: 0.5937 - val_loss: 0.7161 - val_precision: 0.5889 - val_recall: 0.6207\n",
      "Epoch 1006/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5977 - loss: 0.3542 - precision: 0.6049 - recall: 0.6064\n",
      "Epoch 1006 - Train Recall: 0.6023 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5978 - loss: 0.3541 - precision: 0.6046 - recall: 0.6063 - val_accuracy: 0.5930 - val_loss: 0.6994 - val_precision: 0.5859 - val_recall: 0.6342\n",
      "Epoch 1007/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6020 - loss: 0.3481 - precision: 0.6180 - recall: 0.6255\n",
      "Epoch 1007 - Train Recall: 0.6106 - Val Recall: 0.5502\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6023 - loss: 0.3482 - precision: 0.6160 - recall: 0.6244 - val_accuracy: 0.5990 - val_loss: 0.6924 - val_precision: 0.6096 - val_recall: 0.5502\n",
      "Epoch 1008/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5920 - loss: 0.3251 - precision: 0.5885 - recall: 0.6072\n",
      "Epoch 1008 - Train Recall: 0.6653 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5928 - loss: 0.3250 - precision: 0.5882 - recall: 0.6154 - val_accuracy: 0.6004 - val_loss: 0.6400 - val_precision: 0.5857 - val_recall: 0.6867\n",
      "Epoch 1009/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6108 - loss: 0.3442 - precision: 0.5914 - recall: 0.6858\n",
      "Epoch 1009 - Train Recall: 0.6615 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6093 - loss: 0.3443 - precision: 0.5907 - recall: 0.6835 - val_accuracy: 0.5900 - val_loss: 0.6867 - val_precision: 0.5763 - val_recall: 0.6792\n",
      "Epoch 1010/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5987 - loss: 0.3454 - precision: 0.5897 - recall: 0.6071\n",
      "Epoch 1010 - Train Recall: 0.6181 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5988 - loss: 0.3454 - precision: 0.5900 - recall: 0.6076 - val_accuracy: 0.6057 - val_loss: 0.6815 - val_precision: 0.5922 - val_recall: 0.6792\n",
      "Epoch 1011/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5991 - loss: 0.3562 - precision: 0.5966 - recall: 0.6024\n",
      "Epoch 1011 - Train Recall: 0.5832 - Val Recall: 0.5577\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5990 - loss: 0.3562 - precision: 0.5966 - recall: 0.6023 - val_accuracy: 0.5772 - val_loss: 0.7144 - val_precision: 0.5803 - val_recall: 0.5577\n",
      "Epoch 1012/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5988 - loss: 0.3342 - precision: 0.5931 - recall: 0.6298\n",
      "Epoch 1012 - Train Recall: 0.6578 - Val Recall: 0.6612\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5988 - loss: 0.3341 - precision: 0.5928 - recall: 0.6316 - val_accuracy: 0.5877 - val_loss: 0.6639 - val_precision: 0.5765 - val_recall: 0.6612\n",
      "Epoch 1013/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6099 - loss: 0.3386 - precision: 0.6033 - recall: 0.6997\n",
      "Epoch 1013 - Train Recall: 0.6769 - Val Recall: 0.6732\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6086 - loss: 0.3389 - precision: 0.6014 - recall: 0.6969 - val_accuracy: 0.6049 - val_loss: 0.6717 - val_precision: 0.5923 - val_recall: 0.6732\n",
      "Epoch 1014/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6120 - loss: 0.3368 - precision: 0.6005 - recall: 0.6609\n",
      "Epoch 1014 - Train Recall: 0.6447 - Val Recall: 0.7076\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6111 - loss: 0.3369 - precision: 0.5999 - recall: 0.6597 - val_accuracy: 0.5937 - val_loss: 0.6768 - val_precision: 0.5763 - val_recall: 0.7076\n",
      "Epoch 1015/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5999 - loss: 0.3575 - precision: 0.5966 - recall: 0.6227\n",
      "Epoch 1015 - Train Recall: 0.6199 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6006 - loss: 0.3573 - precision: 0.5976 - recall: 0.6223 - val_accuracy: 0.6057 - val_loss: 0.7057 - val_precision: 0.6020 - val_recall: 0.6237\n",
      "Epoch 1016/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5806 - loss: 0.3438 - precision: 0.5689 - recall: 0.5734\n",
      "Epoch 1016 - Train Recall: 0.6214 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5822 - loss: 0.3436 - precision: 0.5713 - recall: 0.5780 - val_accuracy: 0.5960 - val_loss: 0.6799 - val_precision: 0.5891 - val_recall: 0.6342\n",
      "Epoch 1017/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5951 - loss: 0.3447 - precision: 0.5975 - recall: 0.6111\n",
      "Epoch 1017 - Train Recall: 0.6226 - Val Recall: 0.5232\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5953 - loss: 0.3446 - precision: 0.5975 - recall: 0.6114 - val_accuracy: 0.5780 - val_loss: 0.6874 - val_precision: 0.5875 - val_recall: 0.5232\n",
      "Epoch 1018/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5918 - loss: 0.3130 - precision: 0.5801 - recall: 0.6552\n",
      "Epoch 1018 - Train Recall: 0.6844 - Val Recall: 0.6777\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5922 - loss: 0.3130 - precision: 0.5801 - recall: 0.6581 - val_accuracy: 0.5817 - val_loss: 0.6239 - val_precision: 0.5686 - val_recall: 0.6777\n",
      "Epoch 1019/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6054 - loss: 0.3389 - precision: 0.5922 - recall: 0.7333\n",
      "Epoch 1019 - Train Recall: 0.6979 - Val Recall: 0.6897\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6052 - loss: 0.3389 - precision: 0.5920 - recall: 0.7327 - val_accuracy: 0.5975 - val_loss: 0.6695 - val_precision: 0.5823 - val_recall: 0.6897\n",
      "Epoch 1020/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6165 - loss: 0.3347 - precision: 0.6015 - recall: 0.6738\n",
      "Epoch 1020 - Train Recall: 0.6672 - Val Recall: 0.5982\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6156 - loss: 0.3348 - precision: 0.6009 - recall: 0.6735 - val_accuracy: 0.5705 - val_loss: 0.6789 - val_precision: 0.5668 - val_recall: 0.5982\n",
      "Epoch 1021/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5997 - loss: 0.3237 - precision: 0.5962 - recall: 0.6726\n",
      "Epoch 1021 - Train Recall: 0.7031 - Val Recall: 0.6987\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5996 - loss: 0.3236 - precision: 0.5958 - recall: 0.6733 - val_accuracy: 0.5960 - val_loss: 0.6385 - val_precision: 0.5796 - val_recall: 0.6987\n",
      "Epoch 1022/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6015 - loss: 0.3371 - precision: 0.5832 - recall: 0.6821\n",
      "Epoch 1022 - Train Recall: 0.6735 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 0.3374 - precision: 0.5830 - recall: 0.6814 - val_accuracy: 0.5862 - val_loss: 0.6761 - val_precision: 0.5695 - val_recall: 0.7061\n",
      "Epoch 1023/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6092 - loss: 0.3446 - precision: 0.6067 - recall: 0.6577\n",
      "Epoch 1023 - Train Recall: 0.6128 - Val Recall: 0.6417\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6087 - loss: 0.3448 - precision: 0.6061 - recall: 0.6556 - val_accuracy: 0.6027 - val_loss: 0.6873 - val_precision: 0.5953 - val_recall: 0.6417\n",
      "Epoch 1024/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5901 - loss: 0.3509 - precision: 0.5828 - recall: 0.5760\n",
      "Epoch 1024 - Train Recall: 0.5948 - Val Recall: 0.4933\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5901 - loss: 0.3509 - precision: 0.5829 - recall: 0.5761 - val_accuracy: 0.5862 - val_loss: 0.6922 - val_precision: 0.6059 - val_recall: 0.4933\n",
      "Epoch 1025/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6116 - loss: 0.3089 - precision: 0.5965 - recall: 0.6374\n",
      "Epoch 1025 - Train Recall: 0.6807 - Val Recall: 0.7781\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6114 - loss: 0.3089 - precision: 0.5963 - recall: 0.6394 - val_accuracy: 0.6004 - val_loss: 0.6081 - val_precision: 0.5741 - val_recall: 0.7781\n",
      "Epoch 1026/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6008 - loss: 0.3649 - precision: 0.5852 - recall: 0.6961\n",
      "Epoch 1026 - Train Recall: 0.6368 - Val Recall: 0.5787\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 0.3649 - precision: 0.5859 - recall: 0.6908 - val_accuracy: 0.5975 - val_loss: 0.7246 - val_precision: 0.6012 - val_recall: 0.5787\n",
      "Epoch 1027/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5940 - loss: 0.3262 - precision: 0.5946 - recall: 0.6024\n",
      "Epoch 1027 - Train Recall: 0.6510 - Val Recall: 0.6822\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 0.3261 - precision: 0.5942 - recall: 0.6053 - val_accuracy: 0.6004 - val_loss: 0.6419 - val_precision: 0.5863 - val_recall: 0.6822\n",
      "Epoch 1028/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5998 - loss: 0.3471 - precision: 0.5907 - recall: 0.6805\n",
      "Epoch 1028 - Train Recall: 0.6473 - Val Recall: 0.6267\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5995 - loss: 0.3472 - precision: 0.5903 - recall: 0.6783 - val_accuracy: 0.5990 - val_loss: 0.6863 - val_precision: 0.5938 - val_recall: 0.6267\n",
      "Epoch 1029/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6029 - loss: 0.3332 - precision: 0.6008 - recall: 0.6399\n",
      "Epoch 1029 - Train Recall: 0.6503 - Val Recall: 0.6222\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 0.3334 - precision: 0.6002 - recall: 0.6408 - val_accuracy: 0.5885 - val_loss: 0.6654 - val_precision: 0.5829 - val_recall: 0.6222\n",
      "Epoch 1030/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6022 - loss: 0.3308 - precision: 0.5988 - recall: 0.6530\n",
      "Epoch 1030 - Train Recall: 0.6522 - Val Recall: 0.6162\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6016 - loss: 0.3309 - precision: 0.5979 - recall: 0.6529 - val_accuracy: 0.6004 - val_loss: 0.6610 - val_precision: 0.5974 - val_recall: 0.6162\n",
      "Epoch 1031/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5972 - loss: 0.3323 - precision: 0.5892 - recall: 0.6569\n",
      "Epoch 1031 - Train Recall: 0.6765 - Val Recall: 0.7346\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5974 - loss: 0.3322 - precision: 0.5891 - recall: 0.6583 - val_accuracy: 0.5907 - val_loss: 0.6610 - val_precision: 0.5704 - val_recall: 0.7346\n",
      "Epoch 1032/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5973 - loss: 0.3542 - precision: 0.5943 - recall: 0.6377\n",
      "Epoch 1032 - Train Recall: 0.6072 - Val Recall: 0.5982\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5969 - loss: 0.3542 - precision: 0.5941 - recall: 0.6356 - val_accuracy: 0.5997 - val_loss: 0.7016 - val_precision: 0.6000 - val_recall: 0.5982\n",
      "Epoch 1033/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6039 - loss: 0.3385 - precision: 0.6082 - recall: 0.6138\n",
      "Epoch 1033 - Train Recall: 0.6263 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6036 - loss: 0.3385 - precision: 0.6073 - recall: 0.6146 - val_accuracy: 0.6004 - val_loss: 0.6648 - val_precision: 0.5936 - val_recall: 0.6372\n",
      "Epoch 1034/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6144 - loss: 0.3395 - precision: 0.6123 - recall: 0.6378\n",
      "Epoch 1034 - Train Recall: 0.6297 - Val Recall: 0.6912\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6144 - loss: 0.3395 - precision: 0.6122 - recall: 0.6378 - val_accuracy: 0.5997 - val_loss: 0.6773 - val_precision: 0.5843 - val_recall: 0.6912\n",
      "Epoch 1035/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5962 - loss: 0.3569 - precision: 0.5944 - recall: 0.6520\n",
      "Epoch 1035 - Train Recall: 0.6233 - Val Recall: 0.5832\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5969 - loss: 0.3568 - precision: 0.5948 - recall: 0.6494 - val_accuracy: 0.5802 - val_loss: 0.7175 - val_precision: 0.5797 - val_recall: 0.5832\n",
      "Epoch 1036/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6105 - loss: 0.3272 - precision: 0.6046 - recall: 0.6208\n",
      "Epoch 1036 - Train Recall: 0.6308 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6100 - loss: 0.3274 - precision: 0.6041 - recall: 0.6213 - val_accuracy: 0.5937 - val_loss: 0.6504 - val_precision: 0.5841 - val_recall: 0.6507\n",
      "Epoch 1037/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6072 - loss: 0.3455 - precision: 0.5908 - recall: 0.6705\n",
      "Epoch 1037 - Train Recall: 0.6312 - Val Recall: 0.6567\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6065 - loss: 0.3455 - precision: 0.5909 - recall: 0.6672 - val_accuracy: 0.5960 - val_loss: 0.6866 - val_precision: 0.5856 - val_recall: 0.6567\n",
      "Epoch 1038/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5931 - loss: 0.3472 - precision: 0.5831 - recall: 0.5746\n",
      "Epoch 1038 - Train Recall: 0.6042 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5935 - loss: 0.3473 - precision: 0.5844 - recall: 0.5784 - val_accuracy: 0.6094 - val_loss: 0.6852 - val_precision: 0.6046 - val_recall: 0.6327\n",
      "Epoch 1039/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5919 - loss: 0.3497 - precision: 0.5807 - recall: 0.6249\n",
      "Epoch 1039 - Train Recall: 0.6271 - Val Recall: 0.5727\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5937 - loss: 0.3495 - precision: 0.5833 - recall: 0.6256 - val_accuracy: 0.6027 - val_loss: 0.6866 - val_precision: 0.6093 - val_recall: 0.5727\n",
      "Epoch 1040/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6026 - loss: 0.3266 - precision: 0.5933 - recall: 0.6592\n",
      "Epoch 1040 - Train Recall: 0.6833 - Val Recall: 0.6747\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6026 - loss: 0.3266 - precision: 0.5930 - recall: 0.6611 - val_accuracy: 0.5765 - val_loss: 0.6500 - val_precision: 0.5639 - val_recall: 0.6747\n",
      "Epoch 1041/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5980 - loss: 0.3387 - precision: 0.5854 - recall: 0.6419\n",
      "Epoch 1041 - Train Recall: 0.6525 - Val Recall: 0.7211\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5980 - loss: 0.3387 - precision: 0.5855 - recall: 0.6419 - val_accuracy: 0.6034 - val_loss: 0.6715 - val_precision: 0.5837 - val_recall: 0.7211\n",
      "Epoch 1042/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5875 - loss: 0.3590 - precision: 0.5758 - recall: 0.6151\n",
      "Epoch 1042 - Train Recall: 0.5813 - Val Recall: 0.5892\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5883 - loss: 0.3589 - precision: 0.5781 - recall: 0.6111 - val_accuracy: 0.5960 - val_loss: 0.7108 - val_precision: 0.5973 - val_recall: 0.5892\n",
      "Epoch 1043/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5806 - loss: 0.3446 - precision: 0.5844 - recall: 0.5766\n",
      "Epoch 1043 - Train Recall: 0.5930 - Val Recall: 0.5712\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5811 - loss: 0.3445 - precision: 0.5847 - recall: 0.5774 - val_accuracy: 0.5855 - val_loss: 0.6783 - val_precision: 0.5880 - val_recall: 0.5712\n",
      "Epoch 1044/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6162 - loss: 0.3327 - precision: 0.6084 - recall: 0.6734\n",
      "Epoch 1044 - Train Recall: 0.6694 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6159 - loss: 0.3327 - precision: 0.6080 - recall: 0.6733 - val_accuracy: 0.5937 - val_loss: 0.6605 - val_precision: 0.5920 - val_recall: 0.6027\n",
      "Epoch 1045/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5917 - loss: 0.3232 - precision: 0.5743 - recall: 0.6618\n",
      "Epoch 1045 - Train Recall: 0.6765 - Val Recall: 0.6732\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5922 - loss: 0.3231 - precision: 0.5750 - recall: 0.6628 - val_accuracy: 0.5990 - val_loss: 0.6408 - val_precision: 0.5862 - val_recall: 0.6732\n",
      "Epoch 1046/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6086 - loss: 0.3387 - precision: 0.5976 - recall: 0.6950\n",
      "Epoch 1046 - Train Recall: 0.6773 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6083 - loss: 0.3388 - precision: 0.5971 - recall: 0.6932 - val_accuracy: 0.5997 - val_loss: 0.6717 - val_precision: 0.5957 - val_recall: 0.6207\n",
      "Epoch 1047/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6003 - loss: 0.3251 - precision: 0.5892 - recall: 0.6776\n",
      "Epoch 1047 - Train Recall: 0.6810 - Val Recall: 0.6252\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6002 - loss: 0.3252 - precision: 0.5890 - recall: 0.6777 - val_accuracy: 0.5982 - val_loss: 0.6425 - val_precision: 0.5932 - val_recall: 0.6252\n",
      "Epoch 1048/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5974 - loss: 0.3256 - precision: 0.5931 - recall: 0.6762\n",
      "Epoch 1048 - Train Recall: 0.6960 - Val Recall: 0.6897\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5975 - loss: 0.3256 - precision: 0.5926 - recall: 0.6772 - val_accuracy: 0.5990 - val_loss: 0.6501 - val_precision: 0.5838 - val_recall: 0.6897\n",
      "Epoch 1049/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5944 - loss: 0.3383 - precision: 0.5807 - recall: 0.6752\n",
      "Epoch 1049 - Train Recall: 0.6567 - Val Recall: 0.6597\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5945 - loss: 0.3384 - precision: 0.5808 - recall: 0.6749 - val_accuracy: 0.6184 - val_loss: 0.6675 - val_precision: 0.6094 - val_recall: 0.6597\n",
      "Epoch 1050/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 0.3409 - precision: 0.5918 - recall: 0.6382\n",
      "Epoch 1050 - Train Recall: 0.6469 - Val Recall: 0.7106\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6016 - loss: 0.3409 - precision: 0.5918 - recall: 0.6385 - val_accuracy: 0.5945 - val_loss: 0.6777 - val_precision: 0.5766 - val_recall: 0.7106\n",
      "Epoch 1051/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6071 - loss: 0.3560 - precision: 0.6119 - recall: 0.6357\n",
      "Epoch 1051 - Train Recall: 0.6072 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6069 - loss: 0.3561 - precision: 0.6114 - recall: 0.6347 - val_accuracy: 0.6034 - val_loss: 0.7003 - val_precision: 0.6131 - val_recall: 0.5607\n",
      "Epoch 1052/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5990 - loss: 0.3278 - precision: 0.6011 - recall: 0.5931\n",
      "Epoch 1052 - Train Recall: 0.6256 - Val Recall: 0.6222\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5991 - loss: 0.3278 - precision: 0.6010 - recall: 0.5936 - val_accuracy: 0.5937 - val_loss: 0.6486 - val_precision: 0.5887 - val_recall: 0.6222\n",
      "Epoch 1053/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 0.3388 - precision: 0.5935 - recall: 0.6663\n",
      "Epoch 1053 - Train Recall: 0.6593 - Val Recall: 0.6192\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6016 - loss: 0.3388 - precision: 0.5934 - recall: 0.6661 - val_accuracy: 0.5840 - val_loss: 0.6771 - val_precision: 0.5784 - val_recall: 0.6192\n",
      "Epoch 1054/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6092 - loss: 0.3270 - precision: 0.5964 - recall: 0.6707\n",
      "Epoch 1054 - Train Recall: 0.6645 - Val Recall: 0.7511\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6088 - loss: 0.3271 - precision: 0.5960 - recall: 0.6704 - val_accuracy: 0.5877 - val_loss: 0.6547 - val_precision: 0.5661 - val_recall: 0.7511\n",
      "Epoch 1055/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6045 - loss: 0.3616 - precision: 0.5967 - recall: 0.6349\n",
      "Epoch 1055 - Train Recall: 0.5952 - Val Recall: 0.5907\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6043 - loss: 0.3616 - precision: 0.5971 - recall: 0.6323 - val_accuracy: 0.5705 - val_loss: 0.7260 - val_precision: 0.5677 - val_recall: 0.5907\n",
      "Epoch 1056/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5998 - loss: 0.3397 - precision: 0.5958 - recall: 0.5857\n",
      "Epoch 1056 - Train Recall: 0.5986 - Val Recall: 0.6837\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5998 - loss: 0.3397 - precision: 0.5959 - recall: 0.5860 - val_accuracy: 0.5967 - val_loss: 0.6700 - val_precision: 0.5824 - val_recall: 0.6837\n",
      "Epoch 1057/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6074 - loss: 0.3599 - precision: 0.6056 - recall: 0.6203\n",
      "Epoch 1057 - Train Recall: 0.5888 - Val Recall: 0.5757\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6061 - loss: 0.3602 - precision: 0.6047 - recall: 0.6168 - val_accuracy: 0.5997 - val_loss: 0.7234 - val_precision: 0.6047 - val_recall: 0.5757\n",
      "Epoch 1058/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6057 - loss: 0.3352 - precision: 0.6041 - recall: 0.6077\n",
      "Epoch 1058 - Train Recall: 0.6278 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6055 - loss: 0.3352 - precision: 0.6037 - recall: 0.6086 - val_accuracy: 0.5885 - val_loss: 0.6698 - val_precision: 0.5891 - val_recall: 0.5847\n",
      "Epoch 1059/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5816 - loss: 0.3334 - precision: 0.5683 - recall: 0.6317\n",
      "Epoch 1059 - Train Recall: 0.6574 - Val Recall: 0.6942\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5834 - loss: 0.3330 - precision: 0.5702 - recall: 0.6340 - val_accuracy: 0.5982 - val_loss: 0.6512 - val_precision: 0.5824 - val_recall: 0.6942\n",
      "Epoch 1060/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5990 - loss: 0.3492 - precision: 0.5872 - recall: 0.6820\n",
      "Epoch 1060 - Train Recall: 0.6619 - Val Recall: 0.5622\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5988 - loss: 0.3493 - precision: 0.5870 - recall: 0.6809 - val_accuracy: 0.5952 - val_loss: 0.6918 - val_precision: 0.6019 - val_recall: 0.5622\n",
      "Epoch 1061/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5925 - loss: 0.3158 - precision: 0.5768 - recall: 0.6608\n",
      "Epoch 1061 - Train Recall: 0.7020 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5929 - loss: 0.3157 - precision: 0.5770 - recall: 0.6632 - val_accuracy: 0.5982 - val_loss: 0.6214 - val_precision: 0.5834 - val_recall: 0.6867\n",
      "Epoch 1062/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5831 - loss: 0.3403 - precision: 0.5687 - recall: 0.7090\n",
      "Epoch 1062 - Train Recall: 0.6942 - Val Recall: 0.7091\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5837 - loss: 0.3401 - precision: 0.5693 - recall: 0.7083 - val_accuracy: 0.6027 - val_loss: 0.6657 - val_precision: 0.5847 - val_recall: 0.7091\n",
      "Epoch 1063/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5977 - loss: 0.3458 - precision: 0.5843 - recall: 0.6715\n",
      "Epoch 1063 - Train Recall: 0.6619 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5979 - loss: 0.3457 - precision: 0.5847 - recall: 0.6710 - val_accuracy: 0.6034 - val_loss: 0.6774 - val_precision: 0.6049 - val_recall: 0.5967\n",
      "Epoch 1064/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5985 - loss: 0.3251 - precision: 0.5851 - recall: 0.6489\n",
      "Epoch 1064 - Train Recall: 0.6747 - Val Recall: 0.6822\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5985 - loss: 0.3250 - precision: 0.5850 - recall: 0.6502 - val_accuracy: 0.5997 - val_loss: 0.6371 - val_precision: 0.5856 - val_recall: 0.6822\n",
      "Epoch 1065/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5995 - loss: 0.3415 - precision: 0.5851 - recall: 0.6660\n",
      "Epoch 1065 - Train Recall: 0.6484 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5995 - loss: 0.3415 - precision: 0.5852 - recall: 0.6657 - val_accuracy: 0.6124 - val_loss: 0.6742 - val_precision: 0.6100 - val_recall: 0.6237\n",
      "Epoch 1066/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5971 - loss: 0.3331 - precision: 0.5733 - recall: 0.6338\n",
      "Epoch 1066 - Train Recall: 0.6507 - Val Recall: 0.6162\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5973 - loss: 0.3331 - precision: 0.5740 - recall: 0.6344 - val_accuracy: 0.5862 - val_loss: 0.6695 - val_precision: 0.5813 - val_recall: 0.6162\n",
      "Epoch 1067/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6117 - loss: 0.3271 - precision: 0.5947 - recall: 0.6965\n",
      "Epoch 1067 - Train Recall: 0.6649 - Val Recall: 0.7676\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6117 - loss: 0.3272 - precision: 0.5947 - recall: 0.6964 - val_accuracy: 0.6169 - val_loss: 0.6533 - val_precision: 0.5899 - val_recall: 0.7676\n",
      "Epoch 1068/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 0.3657 - precision: 0.5852 - recall: 0.6293\n",
      "Epoch 1068 - Train Recall: 0.5862 - Val Recall: 0.4963\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5952 - loss: 0.3657 - precision: 0.5853 - recall: 0.6281 - val_accuracy: 0.5795 - val_loss: 0.7238 - val_precision: 0.5953 - val_recall: 0.4963\n",
      "Epoch 1069/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5867 - loss: 0.3180 - precision: 0.5903 - recall: 0.6158\n",
      "Epoch 1069 - Train Recall: 0.6810 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5875 - loss: 0.3176 - precision: 0.5897 - recall: 0.6210 - val_accuracy: 0.6079 - val_loss: 0.6177 - val_precision: 0.5945 - val_recall: 0.6792\n",
      "Epoch 1070/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5982 - loss: 0.3394 - precision: 0.5861 - recall: 0.6975\n",
      "Epoch 1070 - Train Recall: 0.6750 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5983 - loss: 0.3394 - precision: 0.5862 - recall: 0.6953 - val_accuracy: 0.6087 - val_loss: 0.6666 - val_precision: 0.6017 - val_recall: 0.6432\n",
      "Epoch 1071/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5960 - loss: 0.3341 - precision: 0.5902 - recall: 0.6451\n",
      "Epoch 1071 - Train Recall: 0.6608 - Val Recall: 0.6192\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5966 - loss: 0.3339 - precision: 0.5904 - recall: 0.6468 - val_accuracy: 0.5787 - val_loss: 0.6647 - val_precision: 0.5728 - val_recall: 0.6192\n",
      "Epoch 1072/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.3316 - precision: 0.5775 - recall: 0.6785\n",
      "Epoch 1072 - Train Recall: 0.7031 - Val Recall: 0.7196\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 0.3316 - precision: 0.5776 - recall: 0.6791 - val_accuracy: 0.5892 - val_loss: 0.6527 - val_precision: 0.5707 - val_recall: 0.7196\n",
      "Epoch 1073/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6162 - loss: 0.3406 - precision: 0.6054 - recall: 0.6761\n",
      "Epoch 1073 - Train Recall: 0.6537 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6139 - loss: 0.3411 - precision: 0.6031 - recall: 0.6738 - val_accuracy: 0.5892 - val_loss: 0.6856 - val_precision: 0.5797 - val_recall: 0.6492\n",
      "Epoch 1074/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 0.3381 - precision: 0.5789 - recall: 0.6120\n",
      "Epoch 1074 - Train Recall: 0.6259 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5953 - loss: 0.3381 - precision: 0.5797 - recall: 0.6128 - val_accuracy: 0.5922 - val_loss: 0.6708 - val_precision: 0.5890 - val_recall: 0.6102\n",
      "Epoch 1075/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6120 - loss: 0.3330 - precision: 0.6072 - recall: 0.6735\n",
      "Epoch 1075 - Train Recall: 0.6713 - Val Recall: 0.6987\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6108 - loss: 0.3332 - precision: 0.6051 - recall: 0.6733 - val_accuracy: 0.5982 - val_loss: 0.6644 - val_precision: 0.5818 - val_recall: 0.6987\n",
      "Epoch 1076/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 0.3470 - precision: 0.5952 - recall: 0.6551\n",
      "Epoch 1076 - Train Recall: 0.6466 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6027 - loss: 0.3470 - precision: 0.5948 - recall: 0.6549 - val_accuracy: 0.5967 - val_loss: 0.6885 - val_precision: 0.5882 - val_recall: 0.6447\n",
      "Epoch 1077/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6081 - loss: 0.3386 - precision: 0.6044 - recall: 0.6586\n",
      "Epoch 1077 - Train Recall: 0.6499 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6078 - loss: 0.3387 - precision: 0.6038 - recall: 0.6581 - val_accuracy: 0.5855 - val_loss: 0.6738 - val_precision: 0.5764 - val_recall: 0.6447\n",
      "Epoch 1078/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5873 - loss: 0.3407 - precision: 0.5932 - recall: 0.6033\n",
      "Epoch 1078 - Train Recall: 0.6391 - Val Recall: 0.5937\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5879 - loss: 0.3407 - precision: 0.5932 - recall: 0.6050 - val_accuracy: 0.5892 - val_loss: 0.6727 - val_precision: 0.5884 - val_recall: 0.5937\n",
      "Epoch 1079/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6172 - loss: 0.3245 - precision: 0.6062 - recall: 0.6743\n",
      "Epoch 1079 - Train Recall: 0.6750 - Val Recall: 0.7691\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6162 - loss: 0.3247 - precision: 0.6050 - recall: 0.6745 - val_accuracy: 0.5870 - val_loss: 0.6511 - val_precision: 0.5637 - val_recall: 0.7691\n",
      "Epoch 1080/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6076 - loss: 0.3625 - precision: 0.6009 - recall: 0.6502\n",
      "Epoch 1080 - Train Recall: 0.6136 - Val Recall: 0.5067\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6076 - loss: 0.3625 - precision: 0.6009 - recall: 0.6500 - val_accuracy: 0.5847 - val_loss: 0.7206 - val_precision: 0.6004 - val_recall: 0.5067\n",
      "Epoch 1081/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.3122 - precision: 0.5968 - recall: 0.6015\n",
      "Epoch 1081 - Train Recall: 0.6672 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5951 - loss: 0.3119 - precision: 0.5959 - recall: 0.6104 - val_accuracy: 0.5877 - val_loss: 0.6172 - val_precision: 0.5740 - val_recall: 0.6807\n",
      "Epoch 1082/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6045 - loss: 0.3433 - precision: 0.5985 - recall: 0.6696\n",
      "Epoch 1082 - Train Recall: 0.6694 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6045 - loss: 0.3432 - precision: 0.5976 - recall: 0.6693 - val_accuracy: 0.5982 - val_loss: 0.6778 - val_precision: 0.5916 - val_recall: 0.6342\n",
      "Epoch 1083/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6121 - loss: 0.3287 - precision: 0.5991 - recall: 0.6711\n",
      "Epoch 1083 - Train Recall: 0.6664 - Val Recall: 0.6042\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6114 - loss: 0.3289 - precision: 0.5985 - recall: 0.6708 - val_accuracy: 0.5847 - val_loss: 0.6628 - val_precision: 0.5815 - val_recall: 0.6042\n",
      "Epoch 1084/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6108 - loss: 0.3214 - precision: 0.5929 - recall: 0.7235\n",
      "Epoch 1084 - Train Recall: 0.7065 - Val Recall: 0.7841\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6098 - loss: 0.3217 - precision: 0.5919 - recall: 0.7215 - val_accuracy: 0.5937 - val_loss: 0.6436 - val_precision: 0.5679 - val_recall: 0.7841\n",
      "Epoch 1085/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5766 - loss: 0.3604 - precision: 0.5706 - recall: 0.6367\n",
      "Epoch 1085 - Train Recall: 0.6308 - Val Recall: 0.5217\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5768 - loss: 0.3604 - precision: 0.5708 - recall: 0.6366 - val_accuracy: 0.5922 - val_loss: 0.7136 - val_precision: 0.6073 - val_recall: 0.5217\n",
      "Epoch 1086/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5976 - loss: 0.3113 - precision: 0.5906 - recall: 0.6593\n",
      "Epoch 1086 - Train Recall: 0.7050 - Val Recall: 0.7241\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5980 - loss: 0.3112 - precision: 0.5901 - recall: 0.6634 - val_accuracy: 0.6064 - val_loss: 0.6090 - val_precision: 0.5862 - val_recall: 0.7241\n",
      "Epoch 1087/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5902 - loss: 0.3467 - precision: 0.5731 - recall: 0.7053\n",
      "Epoch 1087 - Train Recall: 0.6788 - Val Recall: 0.7016\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5902 - loss: 0.3466 - precision: 0.5731 - recall: 0.7048 - val_accuracy: 0.5982 - val_loss: 0.6887 - val_precision: 0.5814 - val_recall: 0.7016\n",
      "Epoch 1088/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6140 - loss: 0.3447 - precision: 0.6153 - recall: 0.6595\n",
      "Epoch 1088 - Train Recall: 0.6331 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6135 - loss: 0.3448 - precision: 0.6143 - recall: 0.6582 - val_accuracy: 0.6042 - val_loss: 0.6839 - val_precision: 0.5994 - val_recall: 0.6282\n",
      "Epoch 1089/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6085 - loss: 0.3370 - precision: 0.5986 - recall: 0.5957\n",
      "Epoch 1089 - Train Recall: 0.6222 - Val Recall: 0.6267\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6083 - loss: 0.3370 - precision: 0.5985 - recall: 0.5961 - val_accuracy: 0.6027 - val_loss: 0.6703 - val_precision: 0.5980 - val_recall: 0.6267\n",
      "Epoch 1090/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6043 - loss: 0.3384 - precision: 0.5847 - recall: 0.6306\n",
      "Epoch 1090 - Train Recall: 0.6289 - Val Recall: 0.6762\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6043 - loss: 0.3384 - precision: 0.5847 - recall: 0.6306 - val_accuracy: 0.6004 - val_loss: 0.6713 - val_precision: 0.5872 - val_recall: 0.6762\n",
      "Epoch 1091/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6081 - loss: 0.3504 - precision: 0.5966 - recall: 0.6434\n",
      "Epoch 1091 - Train Recall: 0.6057 - Val Recall: 0.5337\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6079 - loss: 0.3504 - precision: 0.5966 - recall: 0.6425 - val_accuracy: 0.5862 - val_loss: 0.6962 - val_precision: 0.5963 - val_recall: 0.5337\n",
      "Epoch 1092/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6069 - loss: 0.3159 - precision: 0.6006 - recall: 0.6461\n",
      "Epoch 1092 - Train Recall: 0.6653 - Val Recall: 0.7931\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6062 - loss: 0.3162 - precision: 0.5990 - recall: 0.6483 - val_accuracy: 0.5832 - val_loss: 0.6418 - val_precision: 0.5586 - val_recall: 0.7931\n",
      "Epoch 1093/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5967 - loss: 0.3743 - precision: 0.5975 - recall: 0.6529\n",
      "Epoch 1093 - Train Recall: 0.6004 - Val Recall: 0.5172\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5967 - loss: 0.3743 - precision: 0.5975 - recall: 0.6526 - val_accuracy: 0.5855 - val_loss: 0.7394 - val_precision: 0.5990 - val_recall: 0.5172\n",
      "Epoch 1094/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 0.3180 - precision: 0.6027 - recall: 0.6076\n",
      "Epoch 1094 - Train Recall: 0.6544 - Val Recall: 0.7106\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6015 - loss: 0.3179 - precision: 0.6018 - recall: 0.6108 - val_accuracy: 0.5937 - val_loss: 0.6264 - val_precision: 0.5759 - val_recall: 0.7106\n",
      "Epoch 1095/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5924 - loss: 0.3521 - precision: 0.5862 - recall: 0.6578\n",
      "Epoch 1095 - Train Recall: 0.6203 - Val Recall: 0.5157\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5920 - loss: 0.3524 - precision: 0.5861 - recall: 0.6527 - val_accuracy: 0.6012 - val_loss: 0.7020 - val_precision: 0.6221 - val_recall: 0.5157\n",
      "Epoch 1096/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6166 - loss: 0.3109 - precision: 0.6110 - recall: 0.6583\n",
      "Epoch 1096 - Train Recall: 0.6983 - Val Recall: 0.7976\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6156 - loss: 0.3109 - precision: 0.6091 - recall: 0.6613 - val_accuracy: 0.5885 - val_loss: 0.6120 - val_precision: 0.5624 - val_recall: 0.7976\n",
      "Epoch 1097/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6109 - loss: 0.3599 - precision: 0.6056 - recall: 0.6800\n",
      "Epoch 1097 - Train Recall: 0.6196 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6097 - loss: 0.3602 - precision: 0.6046 - recall: 0.6753 - val_accuracy: 0.6072 - val_loss: 0.7207 - val_precision: 0.6095 - val_recall: 0.5967\n",
      "Epoch 1098/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6086 - loss: 0.3337 - precision: 0.6113 - recall: 0.5976\n",
      "Epoch 1098 - Train Recall: 0.6061 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6072 - loss: 0.3339 - precision: 0.6095 - recall: 0.5982 - val_accuracy: 0.5825 - val_loss: 0.6683 - val_precision: 0.5775 - val_recall: 0.6147\n",
      "Epoch 1099/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6058 - loss: 0.3417 - precision: 0.6041 - recall: 0.6534\n",
      "Epoch 1099 - Train Recall: 0.6267 - Val Recall: 0.6312\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6057 - loss: 0.3417 - precision: 0.6040 - recall: 0.6529 - val_accuracy: 0.5960 - val_loss: 0.6776 - val_precision: 0.5896 - val_recall: 0.6312\n",
      "Epoch 1100/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5975 - loss: 0.3401 - precision: 0.5891 - recall: 0.5931\n",
      "Epoch 1100 - Train Recall: 0.6098 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5974 - loss: 0.3402 - precision: 0.5894 - recall: 0.5940 - val_accuracy: 0.5930 - val_loss: 0.6742 - val_precision: 0.5906 - val_recall: 0.6057\n",
      "Epoch 1101/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6089 - loss: 0.3384 - precision: 0.6001 - recall: 0.6557\n",
      "Epoch 1101 - Train Recall: 0.6492 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6086 - loss: 0.3385 - precision: 0.5998 - recall: 0.6555 - val_accuracy: 0.5930 - val_loss: 0.6718 - val_precision: 0.5868 - val_recall: 0.6282\n",
      "Epoch 1102/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5970 - loss: 0.3347 - precision: 0.5900 - recall: 0.6416\n",
      "Epoch 1102 - Train Recall: 0.6488 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5977 - loss: 0.3345 - precision: 0.5905 - recall: 0.6426 - val_accuracy: 0.5975 - val_loss: 0.6646 - val_precision: 0.5860 - val_recall: 0.6642\n",
      "Epoch 1103/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5974 - loss: 0.3457 - precision: 0.5862 - recall: 0.6494\n",
      "Epoch 1103 - Train Recall: 0.6346 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5975 - loss: 0.3456 - precision: 0.5866 - recall: 0.6483 - val_accuracy: 0.5960 - val_loss: 0.6876 - val_precision: 0.5894 - val_recall: 0.6327\n",
      "Epoch 1104/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6059 - loss: 0.3385 - precision: 0.5919 - recall: 0.6358\n",
      "Epoch 1104 - Train Recall: 0.6477 - Val Recall: 0.7556\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6054 - loss: 0.3386 - precision: 0.5921 - recall: 0.6368 - val_accuracy: 0.6094 - val_loss: 0.6722 - val_precision: 0.5847 - val_recall: 0.7556\n",
      "Epoch 1105/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5958 - loss: 0.3693 - precision: 0.5904 - recall: 0.5884\n",
      "Epoch 1105 - Train Recall: 0.5637 - Val Recall: 0.5997\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5958 - loss: 0.3692 - precision: 0.5906 - recall: 0.5881 - val_accuracy: 0.5862 - val_loss: 0.7309 - val_precision: 0.5839 - val_recall: 0.5997\n",
      "Epoch 1106/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5904 - loss: 0.3504 - precision: 0.6007 - recall: 0.5756\n",
      "Epoch 1106 - Train Recall: 0.5986 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5913 - loss: 0.3504 - precision: 0.6007 - recall: 0.5784 - val_accuracy: 0.6042 - val_loss: 0.6948 - val_precision: 0.6021 - val_recall: 0.6147\n",
      "Epoch 1107/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6112 - loss: 0.3420 - precision: 0.6073 - recall: 0.6193\n",
      "Epoch 1107 - Train Recall: 0.6286 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6109 - loss: 0.3421 - precision: 0.6069 - recall: 0.6196 - val_accuracy: 0.5900 - val_loss: 0.6860 - val_precision: 0.5796 - val_recall: 0.6552\n",
      "Epoch 1108/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5990 - loss: 0.3450 - precision: 0.5897 - recall: 0.6147\n",
      "Epoch 1108 - Train Recall: 0.6192 - Val Recall: 0.6132\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5990 - loss: 0.3452 - precision: 0.5900 - recall: 0.6152 - val_accuracy: 0.5832 - val_loss: 0.6893 - val_precision: 0.5785 - val_recall: 0.6132\n",
      "Epoch 1109/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5978 - loss: 0.3369 - precision: 0.5923 - recall: 0.6485\n",
      "Epoch 1109 - Train Recall: 0.6522 - Val Recall: 0.5697\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5978 - loss: 0.3370 - precision: 0.5921 - recall: 0.6487 - val_accuracy: 0.6004 - val_loss: 0.6708 - val_precision: 0.6070 - val_recall: 0.5697\n",
      "Epoch 1110/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.3204 - precision: 0.5976 - recall: 0.6427\n",
      "Epoch 1110 - Train Recall: 0.6728 - Val Recall: 0.6957\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5964 - loss: 0.3203 - precision: 0.5957 - recall: 0.6458 - val_accuracy: 0.5967 - val_loss: 0.6302 - val_precision: 0.5807 - val_recall: 0.6957\n",
      "Epoch 1111/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6055 - loss: 0.3446 - precision: 0.5909 - recall: 0.6733\n",
      "Epoch 1111 - Train Recall: 0.6533 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6055 - loss: 0.3446 - precision: 0.5909 - recall: 0.6732 - val_accuracy: 0.5997 - val_loss: 0.6826 - val_precision: 0.5883 - val_recall: 0.6642\n",
      "Epoch 1112/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5973 - loss: 0.3448 - precision: 0.5812 - recall: 0.6208\n",
      "Epoch 1112 - Train Recall: 0.6274 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5978 - loss: 0.3446 - precision: 0.5830 - recall: 0.6212 - val_accuracy: 0.6004 - val_loss: 0.6809 - val_precision: 0.6000 - val_recall: 0.6027\n",
      "Epoch 1113/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6065 - loss: 0.3327 - precision: 0.6092 - recall: 0.6516\n",
      "Epoch 1113 - Train Recall: 0.6507 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6064 - loss: 0.3327 - precision: 0.6089 - recall: 0.6516 - val_accuracy: 0.5937 - val_loss: 0.6778 - val_precision: 0.5850 - val_recall: 0.6447\n",
      "Epoch 1114/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6044 - loss: 0.3375 - precision: 0.5953 - recall: 0.6485\n",
      "Epoch 1114 - Train Recall: 0.6724 - Val Recall: 0.7586\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6036 - loss: 0.3376 - precision: 0.5944 - recall: 0.6518 - val_accuracy: 0.5907 - val_loss: 0.6720 - val_precision: 0.5679 - val_recall: 0.7586\n",
      "Epoch 1115/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5907 - loss: 0.3628 - precision: 0.5849 - recall: 0.5978\n",
      "Epoch 1115 - Train Recall: 0.5858 - Val Recall: 0.5397\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5909 - loss: 0.3628 - precision: 0.5855 - recall: 0.5970 - val_accuracy: 0.5952 - val_loss: 0.7151 - val_precision: 0.6071 - val_recall: 0.5397\n",
      "Epoch 1116/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5941 - loss: 0.3294 - precision: 0.5938 - recall: 0.6236\n",
      "Epoch 1116 - Train Recall: 0.6507 - Val Recall: 0.6252\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 0.3293 - precision: 0.5930 - recall: 0.6265 - val_accuracy: 0.5870 - val_loss: 0.6469 - val_precision: 0.5808 - val_recall: 0.6252\n",
      "Epoch 1117/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6172 - loss: 0.3304 - precision: 0.6038 - recall: 0.6718\n",
      "Epoch 1117 - Train Recall: 0.6593 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6170 - loss: 0.3304 - precision: 0.6036 - recall: 0.6717 - val_accuracy: 0.6064 - val_loss: 0.6587 - val_precision: 0.5986 - val_recall: 0.6462\n",
      "Epoch 1118/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6022 - loss: 0.3354 - precision: 0.5874 - recall: 0.6451\n",
      "Epoch 1118 - Train Recall: 0.6522 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6022 - loss: 0.3355 - precision: 0.5876 - recall: 0.6454 - val_accuracy: 0.5870 - val_loss: 0.6699 - val_precision: 0.5797 - val_recall: 0.6327\n",
      "Epoch 1119/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6053 - loss: 0.3345 - precision: 0.5985 - recall: 0.6706\n",
      "Epoch 1119 - Train Recall: 0.6687 - Val Recall: 0.6657\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6046 - loss: 0.3345 - precision: 0.5973 - recall: 0.6705 - val_accuracy: 0.6004 - val_loss: 0.6614 - val_precision: 0.5889 - val_recall: 0.6657\n",
      "Epoch 1120/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 0.3392 - precision: 0.6022 - recall: 0.6267\n",
      "Epoch 1120 - Train Recall: 0.6278 - Val Recall: 0.7391\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6027 - loss: 0.3393 - precision: 0.6017 - recall: 0.6267 - val_accuracy: 0.5930 - val_loss: 0.6709 - val_precision: 0.5719 - val_recall: 0.7391\n",
      "Epoch 1121/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6041 - loss: 0.3693 - precision: 0.5975 - recall: 0.6127\n",
      "Epoch 1121 - Train Recall: 0.5720 - Val Recall: 0.5367\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6037 - loss: 0.3692 - precision: 0.5983 - recall: 0.6087 - val_accuracy: 0.5960 - val_loss: 0.7326 - val_precision: 0.6088 - val_recall: 0.5367\n",
      "Epoch 1122/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 0.3303 - precision: 0.6068 - recall: 0.5961\n",
      "Epoch 1122 - Train Recall: 0.6158 - Val Recall: 0.5697\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6020 - loss: 0.3303 - precision: 0.6061 - recall: 0.5987 - val_accuracy: 0.5817 - val_loss: 0.6572 - val_precision: 0.5837 - val_recall: 0.5697\n",
      "Epoch 1123/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6100 - loss: 0.3241 - precision: 0.6016 - recall: 0.6565\n",
      "Epoch 1123 - Train Recall: 0.6657 - Val Recall: 0.5562\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6098 - loss: 0.3243 - precision: 0.6012 - recall: 0.6574 - val_accuracy: 0.5847 - val_loss: 0.6574 - val_precision: 0.5898 - val_recall: 0.5562\n",
      "Epoch 1124/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6008 - loss: 0.3106 - precision: 0.5882 - recall: 0.6971\n",
      "Epoch 1124 - Train Recall: 0.7121 - Val Recall: 0.7511\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 0.3106 - precision: 0.5882 - recall: 0.6972 - val_accuracy: 0.5930 - val_loss: 0.6156 - val_precision: 0.5706 - val_recall: 0.7511\n",
      "Epoch 1125/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6100 - loss: 0.3475 - precision: 0.5900 - recall: 0.7254\n",
      "Epoch 1125 - Train Recall: 0.6762 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6089 - loss: 0.3477 - precision: 0.5900 - recall: 0.7196 - val_accuracy: 0.5945 - val_loss: 0.6985 - val_precision: 0.5845 - val_recall: 0.6537\n",
      "Epoch 1126/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6040 - loss: 0.3328 - precision: 0.6037 - recall: 0.6225\n",
      "Epoch 1126 - Train Recall: 0.6488 - Val Recall: 0.6717\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6038 - loss: 0.3329 - precision: 0.6032 - recall: 0.6236 - val_accuracy: 0.5817 - val_loss: 0.6672 - val_precision: 0.5693 - val_recall: 0.6717\n",
      "Epoch 1127/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5960 - loss: 0.3481 - precision: 0.5823 - recall: 0.6321\n",
      "Epoch 1127 - Train Recall: 0.6319 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5965 - loss: 0.3479 - precision: 0.5834 - recall: 0.6322 - val_accuracy: 0.6012 - val_loss: 0.6834 - val_precision: 0.5941 - val_recall: 0.6387\n",
      "Epoch 1128/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5833 - loss: 0.3435 - precision: 0.5727 - recall: 0.6206\n",
      "Epoch 1128 - Train Recall: 0.6241 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5834 - loss: 0.3435 - precision: 0.5730 - recall: 0.6207 - val_accuracy: 0.5997 - val_loss: 0.6794 - val_precision: 0.5912 - val_recall: 0.6462\n",
      "Epoch 1129/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6069 - loss: 0.3455 - precision: 0.5969 - recall: 0.6437\n",
      "Epoch 1129 - Train Recall: 0.6293 - Val Recall: 0.6762\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6057 - loss: 0.3456 - precision: 0.5963 - recall: 0.6419 - val_accuracy: 0.6049 - val_loss: 0.6873 - val_precision: 0.5919 - val_recall: 0.6762\n",
      "Epoch 1130/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5985 - loss: 0.3515 - precision: 0.5946 - recall: 0.5882\n",
      "Epoch 1130 - Train Recall: 0.5873 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5984 - loss: 0.3516 - precision: 0.5947 - recall: 0.5882 - val_accuracy: 0.5990 - val_loss: 0.6976 - val_precision: 0.5917 - val_recall: 0.6387\n",
      "Epoch 1131/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6038 - loss: 0.3538 - precision: 0.6049 - recall: 0.5675\n",
      "Epoch 1131 - Train Recall: 0.5832 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6032 - loss: 0.3539 - precision: 0.6049 - recall: 0.5695 - val_accuracy: 0.6019 - val_loss: 0.7019 - val_precision: 0.5907 - val_recall: 0.6642\n",
      "Epoch 1132/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5919 - loss: 0.3621 - precision: 0.6125 - recall: 0.5130\n",
      "Epoch 1132 - Train Recall: 0.5232 - Val Recall: 0.6012\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5920 - loss: 0.3622 - precision: 0.6123 - recall: 0.5135 - val_accuracy: 0.6042 - val_loss: 0.7168 - val_precision: 0.6048 - val_recall: 0.6012\n",
      "Epoch 1133/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5957 - loss: 0.3640 - precision: 0.6019 - recall: 0.5244\n",
      "Epoch 1133 - Train Recall: 0.5165 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5957 - loss: 0.3641 - precision: 0.6032 - recall: 0.5234 - val_accuracy: 0.5945 - val_loss: 0.7230 - val_precision: 0.5960 - val_recall: 0.5862\n",
      "Epoch 1134/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6004 - loss: 0.3600 - precision: 0.6094 - recall: 0.5510\n",
      "Epoch 1134 - Train Recall: 0.5382 - Val Recall: 0.5712\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6002 - loss: 0.3600 - precision: 0.6094 - recall: 0.5504 - val_accuracy: 0.5705 - val_loss: 0.7229 - val_precision: 0.5704 - val_recall: 0.5712\n",
      "Epoch 1135/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6059 - loss: 0.3483 - precision: 0.6066 - recall: 0.5756\n",
      "Epoch 1135 - Train Recall: 0.5798 - Val Recall: 0.6762\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6063 - loss: 0.3484 - precision: 0.6074 - recall: 0.5759 - val_accuracy: 0.5855 - val_loss: 0.7044 - val_precision: 0.5723 - val_recall: 0.6762\n",
      "Epoch 1136/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5986 - loss: 0.3667 - precision: 0.6047 - recall: 0.5813\n",
      "Epoch 1136 - Train Recall: 0.5296 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5975 - loss: 0.3669 - precision: 0.6042 - recall: 0.5747 - val_accuracy: 0.6094 - val_loss: 0.7290 - val_precision: 0.6123 - val_recall: 0.5967\n",
      "Epoch 1137/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5944 - loss: 0.3610 - precision: 0.6306 - recall: 0.5187\n",
      "Epoch 1137 - Train Recall: 0.5244 - Val Recall: 0.5037\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 0.3609 - precision: 0.6281 - recall: 0.5194 - val_accuracy: 0.5750 - val_loss: 0.7222 - val_precision: 0.5874 - val_recall: 0.5037\n",
      "Epoch 1138/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5912 - loss: 0.3325 - precision: 0.5825 - recall: 0.5662\n",
      "Epoch 1138 - Train Recall: 0.6034 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5913 - loss: 0.3327 - precision: 0.5832 - recall: 0.5693 - val_accuracy: 0.5870 - val_loss: 0.6634 - val_precision: 0.5734 - val_recall: 0.6792\n",
      "Epoch 1139/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6147 - loss: 0.3582 - precision: 0.6182 - recall: 0.6266\n",
      "Epoch 1139 - Train Recall: 0.5881 - Val Recall: 0.5082\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6141 - loss: 0.3582 - precision: 0.6177 - recall: 0.6237 - val_accuracy: 0.6004 - val_loss: 0.7206 - val_precision: 0.6232 - val_recall: 0.5082\n",
      "Epoch 1140/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5994 - loss: 0.3174 - precision: 0.5951 - recall: 0.5886\n",
      "Epoch 1140 - Train Recall: 0.6338 - Val Recall: 0.7826\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 0.3174 - precision: 0.5947 - recall: 0.5907 - val_accuracy: 0.5967 - val_loss: 0.6318 - val_precision: 0.5705 - val_recall: 0.7826\n",
      "Epoch 1141/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5918 - loss: 0.3815 - precision: 0.5905 - recall: 0.6370\n",
      "Epoch 1141 - Train Recall: 0.5986 - Val Recall: 0.5127\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5918 - loss: 0.3814 - precision: 0.5905 - recall: 0.6363 - val_accuracy: 0.5862 - val_loss: 0.7540 - val_precision: 0.6011 - val_recall: 0.5127\n",
      "Epoch 1142/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5927 - loss: 0.3174 - precision: 0.5864 - recall: 0.5947\n",
      "Epoch 1142 - Train Recall: 0.6481 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5932 - loss: 0.3175 - precision: 0.5865 - recall: 0.5998 - val_accuracy: 0.5997 - val_loss: 0.6246 - val_precision: 0.5849 - val_recall: 0.6867\n",
      "Epoch 1143/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5962 - loss: 0.3501 - precision: 0.5805 - recall: 0.6748\n",
      "Epoch 1143 - Train Recall: 0.6522 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5961 - loss: 0.3501 - precision: 0.5805 - recall: 0.6744 - val_accuracy: 0.5982 - val_loss: 0.6944 - val_precision: 0.5861 - val_recall: 0.6687\n",
      "Epoch 1144/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5975 - loss: 0.3463 - precision: 0.5895 - recall: 0.6335\n",
      "Epoch 1144 - Train Recall: 0.6421 - Val Recall: 0.7256\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5976 - loss: 0.3462 - precision: 0.5896 - recall: 0.6342 - val_accuracy: 0.6169 - val_loss: 0.6805 - val_precision: 0.5961 - val_recall: 0.7256\n",
      "Epoch 1145/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6029 - loss: 0.3591 - precision: 0.5949 - recall: 0.6208\n",
      "Epoch 1145 - Train Recall: 0.5697 - Val Recall: 0.5202\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 0.3591 - precision: 0.5949 - recall: 0.6205 - val_accuracy: 0.5982 - val_loss: 0.7163 - val_precision: 0.6163 - val_recall: 0.5202\n",
      "Epoch 1146/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6159 - loss: 0.3229 - precision: 0.6182 - recall: 0.6218\n",
      "Epoch 1146 - Train Recall: 0.6544 - Val Recall: 0.6222\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6145 - loss: 0.3232 - precision: 0.6157 - recall: 0.6245 - val_accuracy: 0.6034 - val_loss: 0.6414 - val_precision: 0.5997 - val_recall: 0.6222\n",
      "Epoch 1147/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6042 - loss: 0.3291 - precision: 0.5865 - recall: 0.6756\n",
      "Epoch 1147 - Train Recall: 0.6754 - Val Recall: 0.7676\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6039 - loss: 0.3292 - precision: 0.5864 - recall: 0.6755 - val_accuracy: 0.5825 - val_loss: 0.6583 - val_precision: 0.5602 - val_recall: 0.7676\n",
      "Epoch 1148/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.3618 - precision: 0.5921 - recall: 0.6542\n",
      "Epoch 1148 - Train Recall: 0.6012 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6028 - loss: 0.3620 - precision: 0.5922 - recall: 0.6469 - val_accuracy: 0.6019 - val_loss: 0.7208 - val_precision: 0.5934 - val_recall: 0.6477\n",
      "Epoch 1149/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5985 - loss: 0.3523 - precision: 0.5906 - recall: 0.5800\n",
      "Epoch 1149 - Train Recall: 0.5772 - Val Recall: 0.5517\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5984 - loss: 0.3523 - precision: 0.5909 - recall: 0.5799 - val_accuracy: 0.5735 - val_loss: 0.7078 - val_precision: 0.5768 - val_recall: 0.5517\n",
      "Epoch 1150/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5929 - loss: 0.3350 - precision: 0.5991 - recall: 0.6096\n",
      "Epoch 1150 - Train Recall: 0.6481 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5938 - loss: 0.3347 - precision: 0.5979 - recall: 0.6151 - val_accuracy: 0.6034 - val_loss: 0.6657 - val_precision: 0.5948 - val_recall: 0.6492\n",
      "Epoch 1151/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6062 - loss: 0.3388 - precision: 0.5924 - recall: 0.6729\n",
      "Epoch 1151 - Train Recall: 0.6451 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6060 - loss: 0.3389 - precision: 0.5923 - recall: 0.6721 - val_accuracy: 0.5922 - val_loss: 0.6758 - val_precision: 0.5860 - val_recall: 0.6282\n",
      "Epoch 1152/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5958 - loss: 0.3363 - precision: 0.5881 - recall: 0.6796\n",
      "Epoch 1152 - Train Recall: 0.6818 - Val Recall: 0.5697\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5959 - loss: 0.3362 - precision: 0.5881 - recall: 0.6796 - val_accuracy: 0.6004 - val_loss: 0.6663 - val_precision: 0.6070 - val_recall: 0.5697\n",
      "Epoch 1153/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5902 - loss: 0.3120 - precision: 0.5784 - recall: 0.6500\n",
      "Epoch 1153 - Train Recall: 0.6900 - Val Recall: 0.7421\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5909 - loss: 0.3119 - precision: 0.5789 - recall: 0.6544 - val_accuracy: 0.5990 - val_loss: 0.6159 - val_precision: 0.5769 - val_recall: 0.7421\n",
      "Epoch 1154/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6110 - loss: 0.3509 - precision: 0.6037 - recall: 0.6980\n",
      "Epoch 1154 - Train Recall: 0.6694 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6108 - loss: 0.3509 - precision: 0.6033 - recall: 0.6972 - val_accuracy: 0.5997 - val_loss: 0.6996 - val_precision: 0.5957 - val_recall: 0.6207\n",
      "Epoch 1155/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5904 - loss: 0.3296 - precision: 0.5881 - recall: 0.6230\n",
      "Epoch 1155 - Train Recall: 0.6548 - Val Recall: 0.5907\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5915 - loss: 0.3294 - precision: 0.5884 - recall: 0.6262 - val_accuracy: 0.5975 - val_loss: 0.6505 - val_precision: 0.5988 - val_recall: 0.5907\n",
      "Epoch 1156/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6004 - loss: 0.3219 - precision: 0.5832 - recall: 0.6982\n",
      "Epoch 1156 - Train Recall: 0.6964 - Val Recall: 0.6777\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6001 - loss: 0.3219 - precision: 0.5830 - recall: 0.6980 - val_accuracy: 0.6079 - val_loss: 0.6399 - val_precision: 0.5947 - val_recall: 0.6777\n",
      "Epoch 1157/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 0.3345 - precision: 0.5774 - recall: 0.6901\n",
      "Epoch 1157 - Train Recall: 0.6825 - Val Recall: 0.6297\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 0.3345 - precision: 0.5777 - recall: 0.6899 - val_accuracy: 0.5825 - val_loss: 0.6750 - val_precision: 0.5753 - val_recall: 0.6297\n",
      "Epoch 1158/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5995 - loss: 0.3233 - precision: 0.5855 - recall: 0.7076\n",
      "Epoch 1158 - Train Recall: 0.6942 - Val Recall: 0.7181\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 0.3235 - precision: 0.5851 - recall: 0.7068 - val_accuracy: 0.6079 - val_loss: 0.6454 - val_precision: 0.5885 - val_recall: 0.7181\n",
      "Epoch 1159/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 0.3451 - precision: 0.5834 - recall: 0.6970\n",
      "Epoch 1159 - Train Recall: 0.6720 - Val Recall: 0.6417\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5993 - loss: 0.3451 - precision: 0.5837 - recall: 0.6959 - val_accuracy: 0.5930 - val_loss: 0.6903 - val_precision: 0.5847 - val_recall: 0.6417\n",
      "Epoch 1160/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5964 - loss: 0.3337 - precision: 0.5941 - recall: 0.6049\n",
      "Epoch 1160 - Train Recall: 0.6394 - Val Recall: 0.6717\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5966 - loss: 0.3336 - precision: 0.5940 - recall: 0.6062 - val_accuracy: 0.6042 - val_loss: 0.6583 - val_precision: 0.5918 - val_recall: 0.6717\n",
      "Epoch 1161/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6160 - loss: 0.3466 - precision: 0.6154 - recall: 0.6463\n",
      "Epoch 1161 - Train Recall: 0.6151 - Val Recall: 0.5727\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6139 - loss: 0.3468 - precision: 0.6130 - recall: 0.6423 - val_accuracy: 0.5892 - val_loss: 0.6932 - val_precision: 0.5922 - val_recall: 0.5727\n",
      "Epoch 1162/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5950 - loss: 0.3285 - precision: 0.5960 - recall: 0.6001\n",
      "Epoch 1162 - Train Recall: 0.6301 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5951 - loss: 0.3285 - precision: 0.5959 - recall: 0.6010 - val_accuracy: 0.5997 - val_loss: 0.6495 - val_precision: 0.5851 - val_recall: 0.6852\n",
      "Epoch 1163/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6086 - loss: 0.3533 - precision: 0.6045 - recall: 0.6528\n",
      "Epoch 1163 - Train Recall: 0.6218 - Val Recall: 0.5487\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6084 - loss: 0.3533 - precision: 0.6043 - recall: 0.6519 - val_accuracy: 0.5960 - val_loss: 0.7008 - val_precision: 0.6060 - val_recall: 0.5487\n",
      "Epoch 1164/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6127 - loss: 0.3195 - precision: 0.6040 - recall: 0.6566\n",
      "Epoch 1164 - Train Recall: 0.6777 - Val Recall: 0.7736\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6119 - loss: 0.3195 - precision: 0.6027 - recall: 0.6588 - val_accuracy: 0.6079 - val_loss: 0.6303 - val_precision: 0.5811 - val_recall: 0.7736\n",
      "Epoch 1165/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6064 - loss: 0.3608 - precision: 0.5908 - recall: 0.6653\n",
      "Epoch 1165 - Train Recall: 0.6331 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6060 - loss: 0.3609 - precision: 0.5907 - recall: 0.6641 - val_accuracy: 0.5877 - val_loss: 0.7242 - val_precision: 0.5880 - val_recall: 0.5862\n",
      "Epoch 1166/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5985 - loss: 0.3279 - precision: 0.5951 - recall: 0.6002\n",
      "Epoch 1166 - Train Recall: 0.6271 - Val Recall: 0.7481\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5983 - loss: 0.3279 - precision: 0.5947 - recall: 0.6032 - val_accuracy: 0.5862 - val_loss: 0.6605 - val_precision: 0.5651 - val_recall: 0.7481\n",
      "Epoch 1167/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6009 - loss: 0.3721 - precision: 0.5929 - recall: 0.6029\n",
      "Epoch 1167 - Train Recall: 0.5630 - Val Recall: 0.5397\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 0.3719 - precision: 0.5937 - recall: 0.6006 - val_accuracy: 0.5825 - val_loss: 0.7447 - val_precision: 0.5902 - val_recall: 0.5397\n",
      "Epoch 1168/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6055 - loss: 0.3329 - precision: 0.6074 - recall: 0.6054\n",
      "Epoch 1168 - Train Recall: 0.6312 - Val Recall: 0.5427\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6051 - loss: 0.3330 - precision: 0.6065 - recall: 0.6072 - val_accuracy: 0.5810 - val_loss: 0.6623 - val_precision: 0.5877 - val_recall: 0.5427\n",
      "Epoch 1169/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6099 - loss: 0.3148 - precision: 0.5920 - recall: 0.6695\n",
      "Epoch 1169 - Train Recall: 0.6968 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6097 - loss: 0.3147 - precision: 0.5919 - recall: 0.6713 - val_accuracy: 0.6049 - val_loss: 0.6278 - val_precision: 0.5933 - val_recall: 0.6672\n",
      "Epoch 1170/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6160 - loss: 0.3294 - precision: 0.5950 - recall: 0.7200\n",
      "Epoch 1170 - Train Recall: 0.6777 - Val Recall: 0.6627\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6148 - loss: 0.3297 - precision: 0.5945 - recall: 0.7160 - val_accuracy: 0.5982 - val_loss: 0.6684 - val_precision: 0.5870 - val_recall: 0.6627\n",
      "Epoch 1171/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6009 - loss: 0.3351 - precision: 0.5964 - recall: 0.6567\n",
      "Epoch 1171 - Train Recall: 0.6578 - Val Recall: 0.5832\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6009 - loss: 0.3351 - precision: 0.5961 - recall: 0.6568 - val_accuracy: 0.5847 - val_loss: 0.6794 - val_precision: 0.5850 - val_recall: 0.5832\n",
      "Epoch 1172/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5958 - loss: 0.3220 - precision: 0.5838 - recall: 0.6691\n",
      "Epoch 1172 - Train Recall: 0.6852 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5958 - loss: 0.3220 - precision: 0.5838 - recall: 0.6692 - val_accuracy: 0.5825 - val_loss: 0.6400 - val_precision: 0.5684 - val_recall: 0.6852\n",
      "Epoch 1173/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5972 - loss: 0.3412 - precision: 0.5878 - recall: 0.6884\n",
      "Epoch 1173 - Train Recall: 0.6735 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5972 - loss: 0.3412 - precision: 0.5876 - recall: 0.6875 - val_accuracy: 0.5997 - val_loss: 0.6780 - val_precision: 0.5935 - val_recall: 0.6327\n",
      "Epoch 1174/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 0.3299 - precision: 0.5727 - recall: 0.6467\n",
      "Epoch 1174 - Train Recall: 0.6570 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5957 - loss: 0.3299 - precision: 0.5736 - recall: 0.6472 - val_accuracy: 0.5840 - val_loss: 0.6525 - val_precision: 0.5791 - val_recall: 0.6147\n",
      "Epoch 1175/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6167 - loss: 0.3253 - precision: 0.5958 - recall: 0.7106\n",
      "Epoch 1175 - Train Recall: 0.6953 - Val Recall: 0.7316\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6158 - loss: 0.3255 - precision: 0.5953 - recall: 0.7093 - val_accuracy: 0.5990 - val_loss: 0.6562 - val_precision: 0.5782 - val_recall: 0.7316\n",
      "Epoch 1176/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5935 - loss: 0.3488 - precision: 0.5724 - recall: 0.6705\n",
      "Epoch 1176 - Train Recall: 0.6379 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5937 - loss: 0.3489 - precision: 0.5732 - recall: 0.6689 - val_accuracy: 0.5907 - val_loss: 0.6873 - val_precision: 0.5851 - val_recall: 0.6237\n",
      "Epoch 1177/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5987 - loss: 0.3367 - precision: 0.5836 - recall: 0.6607\n",
      "Epoch 1177 - Train Recall: 0.6484 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5986 - loss: 0.3367 - precision: 0.5841 - recall: 0.6592 - val_accuracy: 0.5862 - val_loss: 0.6704 - val_precision: 0.5770 - val_recall: 0.6462\n",
      "Epoch 1178/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6026 - loss: 0.3391 - precision: 0.5934 - recall: 0.6879\n",
      "Epoch 1178 - Train Recall: 0.6630 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6024 - loss: 0.3391 - precision: 0.5931 - recall: 0.6871 - val_accuracy: 0.5937 - val_loss: 0.6708 - val_precision: 0.5920 - val_recall: 0.6027\n",
      "Epoch 1179/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6100 - loss: 0.3236 - precision: 0.5926 - recall: 0.6796\n",
      "Epoch 1179 - Train Recall: 0.6870 - Val Recall: 0.7301\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6090 - loss: 0.3238 - precision: 0.5920 - recall: 0.6806 - val_accuracy: 0.6034 - val_loss: 0.6406 - val_precision: 0.5825 - val_recall: 0.7301\n",
      "Epoch 1180/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6073 - loss: 0.3460 - precision: 0.6079 - recall: 0.6721\n",
      "Epoch 1180 - Train Recall: 0.6424 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6071 - loss: 0.3461 - precision: 0.6076 - recall: 0.6714 - val_accuracy: 0.5720 - val_loss: 0.7120 - val_precision: 0.5637 - val_recall: 0.6372\n",
      "Epoch 1181/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5971 - loss: 0.3389 - precision: 0.5939 - recall: 0.5824\n",
      "Epoch 1181 - Train Recall: 0.6109 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5971 - loss: 0.3389 - precision: 0.5940 - recall: 0.5827 - val_accuracy: 0.6072 - val_loss: 0.6679 - val_precision: 0.5955 - val_recall: 0.6687\n",
      "Epoch 1182/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6020 - loss: 0.3551 - precision: 0.5979 - recall: 0.6207\n",
      "Epoch 1182 - Train Recall: 0.6027 - Val Recall: 0.4903\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6021 - loss: 0.3551 - precision: 0.5981 - recall: 0.6200 - val_accuracy: 0.5877 - val_loss: 0.7105 - val_precision: 0.6089 - val_recall: 0.4903\n",
      "Epoch 1183/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6010 - loss: 0.3082 - precision: 0.5861 - recall: 0.6449\n",
      "Epoch 1183 - Train Recall: 0.6934 - Val Recall: 0.7811\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 0.3081 - precision: 0.5860 - recall: 0.6493 - val_accuracy: 0.5907 - val_loss: 0.6101 - val_precision: 0.5657 - val_recall: 0.7811\n",
      "Epoch 1184/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6012 - loss: 0.3613 - precision: 0.5876 - recall: 0.6844\n",
      "Epoch 1184 - Train Recall: 0.6376 - Val Recall: 0.5667\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6010 - loss: 0.3613 - precision: 0.5880 - recall: 0.6814 - val_accuracy: 0.5990 - val_loss: 0.7180 - val_precision: 0.6058 - val_recall: 0.5667\n",
      "Epoch 1185/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5935 - loss: 0.3236 - precision: 0.6006 - recall: 0.5980\n",
      "Epoch 1185 - Train Recall: 0.6510 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5937 - loss: 0.3235 - precision: 0.6003 - recall: 0.5995 - val_accuracy: 0.6079 - val_loss: 0.6344 - val_precision: 0.5970 - val_recall: 0.6642\n",
      "Epoch 1186/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6196 - loss: 0.3409 - precision: 0.6125 - recall: 0.6694\n",
      "Epoch 1186 - Train Recall: 0.6458 - Val Recall: 0.6087\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6185 - loss: 0.3411 - precision: 0.6113 - recall: 0.6682 - val_accuracy: 0.5862 - val_loss: 0.6772 - val_precision: 0.5825 - val_recall: 0.6087\n",
      "Epoch 1187/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5985 - loss: 0.3296 - precision: 0.5876 - recall: 0.6467\n",
      "Epoch 1187 - Train Recall: 0.6604 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5985 - loss: 0.3296 - precision: 0.5876 - recall: 0.6475 - val_accuracy: 0.5892 - val_loss: 0.6577 - val_precision: 0.5799 - val_recall: 0.6477\n",
      "Epoch 1188/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 0.3376 - precision: 0.5879 - recall: 0.6684\n",
      "Epoch 1188 - Train Recall: 0.6720 - Val Recall: 0.7196\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6027 - loss: 0.3375 - precision: 0.5881 - recall: 0.6691 - val_accuracy: 0.5975 - val_loss: 0.6683 - val_precision: 0.5783 - val_recall: 0.7196\n",
      "Epoch 1189/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5972 - loss: 0.3503 - precision: 0.5966 - recall: 0.6300\n",
      "Epoch 1189 - Train Recall: 0.6286 - Val Recall: 0.6177\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5973 - loss: 0.3503 - precision: 0.5965 - recall: 0.6300 - val_accuracy: 0.6079 - val_loss: 0.6973 - val_precision: 0.6059 - val_recall: 0.6177\n",
      "Epoch 1190/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5963 - loss: 0.3373 - precision: 0.5899 - recall: 0.6030\n",
      "Epoch 1190 - Train Recall: 0.6226 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5968 - loss: 0.3372 - precision: 0.5906 - recall: 0.6045 - val_accuracy: 0.5787 - val_loss: 0.6728 - val_precision: 0.5683 - val_recall: 0.6552\n",
      "Epoch 1191/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6063 - loss: 0.3484 - precision: 0.5958 - recall: 0.6246\n",
      "Epoch 1191 - Train Recall: 0.6154 - Val Recall: 0.6087\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6063 - loss: 0.3484 - precision: 0.5961 - recall: 0.6242 - val_accuracy: 0.6094 - val_loss: 0.6906 - val_precision: 0.6096 - val_recall: 0.6087\n",
      "Epoch 1192/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6049 - loss: 0.3354 - precision: 0.5958 - recall: 0.6369\n",
      "Epoch 1192 - Train Recall: 0.6406 - Val Recall: 0.6582\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6046 - loss: 0.3355 - precision: 0.5956 - recall: 0.6371 - val_accuracy: 0.5945 - val_loss: 0.6705 - val_precision: 0.5838 - val_recall: 0.6582\n",
      "Epoch 1193/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5912 - loss: 0.3448 - precision: 0.5862 - recall: 0.6254\n",
      "Epoch 1193 - Train Recall: 0.6244 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5916 - loss: 0.3448 - precision: 0.5866 - recall: 0.6254 - val_accuracy: 0.5802 - val_loss: 0.6883 - val_precision: 0.5698 - val_recall: 0.6552\n",
      "Epoch 1194/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6032 - loss: 0.3470 - precision: 0.5994 - recall: 0.6218\n",
      "Epoch 1194 - Train Recall: 0.6064 - Val Recall: 0.6762\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 0.3471 - precision: 0.5996 - recall: 0.6202 - val_accuracy: 0.6034 - val_loss: 0.6936 - val_precision: 0.5903 - val_recall: 0.6762\n",
      "Epoch 1195/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6022 - loss: 0.3566 - precision: 0.6139 - recall: 0.5906\n",
      "Epoch 1195 - Train Recall: 0.5723 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6018 - loss: 0.3567 - precision: 0.6131 - recall: 0.5900 - val_accuracy: 0.5982 - val_loss: 0.7095 - val_precision: 0.5956 - val_recall: 0.6117\n",
      "Epoch 1196/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5946 - loss: 0.3524 - precision: 0.6046 - recall: 0.5869\n",
      "Epoch 1196 - Train Recall: 0.6023 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5952 - loss: 0.3523 - precision: 0.6044 - recall: 0.5883 - val_accuracy: 0.6087 - val_loss: 0.6926 - val_precision: 0.6084 - val_recall: 0.6102\n",
      "Epoch 1197/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6103 - loss: 0.3393 - precision: 0.6115 - recall: 0.6336\n",
      "Epoch 1197 - Train Recall: 0.6248 - Val Recall: 0.5697\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6102 - loss: 0.3394 - precision: 0.6112 - recall: 0.6335 - val_accuracy: 0.5915 - val_loss: 0.6902 - val_precision: 0.5956 - val_recall: 0.5697\n",
      "Epoch 1198/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6065 - loss: 0.3267 - precision: 0.5997 - recall: 0.6846\n",
      "Epoch 1198 - Train Recall: 0.6942 - Val Recall: 0.7091\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6063 - loss: 0.3266 - precision: 0.5987 - recall: 0.6856 - val_accuracy: 0.5975 - val_loss: 0.6448 - val_precision: 0.5797 - val_recall: 0.7091\n",
      "Epoch 1199/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6067 - loss: 0.3414 - precision: 0.5866 - recall: 0.6531\n",
      "Epoch 1199 - Train Recall: 0.6346 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6064 - loss: 0.3416 - precision: 0.5877 - recall: 0.6510 - val_accuracy: 0.6004 - val_loss: 0.6802 - val_precision: 0.5991 - val_recall: 0.6072\n",
      "Epoch 1200/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6118 - loss: 0.3286 - precision: 0.6041 - recall: 0.6973\n",
      "Epoch 1200 - Train Recall: 0.6833 - Val Recall: 0.6627\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6107 - loss: 0.3288 - precision: 0.6025 - recall: 0.6961 - val_accuracy: 0.5780 - val_loss: 0.6668 - val_precision: 0.5667 - val_recall: 0.6627\n",
      "Epoch 1201/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5996 - loss: 0.3343 - precision: 0.5815 - recall: 0.6458\n",
      "Epoch 1201 - Train Recall: 0.6499 - Val Recall: 0.7151\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5997 - loss: 0.3343 - precision: 0.5818 - recall: 0.6459 - val_accuracy: 0.5945 - val_loss: 0.6655 - val_precision: 0.5761 - val_recall: 0.7151\n",
      "Epoch 1202/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6005 - loss: 0.3568 - precision: 0.5871 - recall: 0.6554\n",
      "Epoch 1202 - Train Recall: 0.6327 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6006 - loss: 0.3567 - precision: 0.5878 - recall: 0.6534 - val_accuracy: 0.6042 - val_loss: 0.7054 - val_precision: 0.6003 - val_recall: 0.6237\n",
      "Epoch 1203/2000\n",
      "\u001b[1m140/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6050 - loss: 0.3367 - precision: 0.5982 - recall: 0.5956\n",
      "Epoch 1203 - Train Recall: 0.6304 - Val Recall: 0.7991\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6036 - loss: 0.3369 - precision: 0.5966 - recall: 0.6010 - val_accuracy: 0.5960 - val_loss: 0.6775 - val_precision: 0.5682 - val_recall: 0.7991\n",
      "Epoch 1204/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5961 - loss: 0.3848 - precision: 0.6031 - recall: 0.5885\n",
      "Epoch 1204 - Train Recall: 0.5517 - Val Recall: 0.6012\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5960 - loss: 0.3846 - precision: 0.6032 - recall: 0.5850 - val_accuracy: 0.6124 - val_loss: 0.7526 - val_precision: 0.6150 - val_recall: 0.6012\n",
      "Epoch 1205/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6112 - loss: 0.3546 - precision: 0.6222 - recall: 0.5434\n",
      "Epoch 1205 - Train Recall: 0.5528 - Val Recall: 0.5292\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6107 - loss: 0.3546 - precision: 0.6218 - recall: 0.5440 - val_accuracy: 0.5915 - val_loss: 0.7020 - val_precision: 0.6045 - val_recall: 0.5292\n",
      "Epoch 1206/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6038 - loss: 0.3327 - precision: 0.6075 - recall: 0.6213\n",
      "Epoch 1206 - Train Recall: 0.6364 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6037 - loss: 0.3327 - precision: 0.6074 - recall: 0.6214 - val_accuracy: 0.5847 - val_loss: 0.6658 - val_precision: 0.5847 - val_recall: 0.5847\n",
      "Epoch 1207/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6062 - loss: 0.3226 - precision: 0.5957 - recall: 0.6906\n",
      "Epoch 1207 - Train Recall: 0.6983 - Val Recall: 0.7841\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6054 - loss: 0.3230 - precision: 0.5946 - recall: 0.6911 - val_accuracy: 0.5997 - val_loss: 0.6485 - val_precision: 0.5728 - val_recall: 0.7841\n",
      "Epoch 1208/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5991 - loss: 0.3604 - precision: 0.5878 - recall: 0.6567\n",
      "Epoch 1208 - Train Recall: 0.6248 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5988 - loss: 0.3606 - precision: 0.5879 - recall: 0.6543 - val_accuracy: 0.5967 - val_loss: 0.7119 - val_precision: 0.5950 - val_recall: 0.6057\n",
      "Epoch 1209/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5911 - loss: 0.3385 - precision: 0.5987 - recall: 0.6193\n",
      "Epoch 1209 - Train Recall: 0.6413 - Val Recall: 0.7286\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5916 - loss: 0.3382 - precision: 0.5981 - recall: 0.6210 - val_accuracy: 0.6064 - val_loss: 0.6680 - val_precision: 0.5855 - val_recall: 0.7286\n",
      "Epoch 1210/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6173 - loss: 0.3580 - precision: 0.6149 - recall: 0.6576\n",
      "Epoch 1210 - Train Recall: 0.6132 - Val Recall: 0.5067\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6171 - loss: 0.3581 - precision: 0.6147 - recall: 0.6568 - val_accuracy: 0.6064 - val_loss: 0.7124 - val_precision: 0.6330 - val_recall: 0.5067\n",
      "Epoch 1211/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6105 - loss: 0.3114 - precision: 0.6069 - recall: 0.6308\n",
      "Epoch 1211 - Train Recall: 0.6627 - Val Recall: 0.6417\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6104 - loss: 0.3114 - precision: 0.6065 - recall: 0.6314 - val_accuracy: 0.5930 - val_loss: 0.6154 - val_precision: 0.5847 - val_recall: 0.6417\n",
      "Epoch 1212/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6104 - loss: 0.3323 - precision: 0.5946 - recall: 0.6916\n",
      "Epoch 1212 - Train Recall: 0.6615 - Val Recall: 0.5697\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6098 - loss: 0.3324 - precision: 0.5944 - recall: 0.6899 - val_accuracy: 0.5697 - val_loss: 0.6726 - val_precision: 0.5697 - val_recall: 0.5697\n",
      "Epoch 1213/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6033 - loss: 0.3163 - precision: 0.5875 - recall: 0.6858\n",
      "Epoch 1213 - Train Recall: 0.6975 - Val Recall: 0.7166\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6033 - loss: 0.3163 - precision: 0.5875 - recall: 0.6860 - val_accuracy: 0.6072 - val_loss: 0.6198 - val_precision: 0.5879 - val_recall: 0.7166\n",
      "Epoch 1214/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6085 - loss: 0.3414 - precision: 0.5938 - recall: 0.7072\n",
      "Epoch 1214 - Train Recall: 0.6664 - Val Recall: 0.5367\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6079 - loss: 0.3417 - precision: 0.5933 - recall: 0.7038 - val_accuracy: 0.5937 - val_loss: 0.6844 - val_precision: 0.6058 - val_recall: 0.5367\n",
      "Epoch 1215/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5962 - loss: 0.3058 - precision: 0.5975 - recall: 0.6573\n",
      "Epoch 1215 - Train Recall: 0.6975 - Val Recall: 0.7076\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5966 - loss: 0.3056 - precision: 0.5953 - recall: 0.6631 - val_accuracy: 0.5982 - val_loss: 0.6064 - val_precision: 0.5806 - val_recall: 0.7076\n",
      "Epoch 1216/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6019 - loss: 0.3449 - precision: 0.5791 - recall: 0.7145\n",
      "Epoch 1216 - Train Recall: 0.6792 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6014 - loss: 0.3448 - precision: 0.5797 - recall: 0.7101 - val_accuracy: 0.6042 - val_loss: 0.6791 - val_precision: 0.5904 - val_recall: 0.6807\n",
      "Epoch 1217/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6077 - loss: 0.3363 - precision: 0.6045 - recall: 0.6466\n",
      "Epoch 1217 - Train Recall: 0.6376 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6075 - loss: 0.3364 - precision: 0.6041 - recall: 0.6463 - val_accuracy: 0.6034 - val_loss: 0.6735 - val_precision: 0.5948 - val_recall: 0.6492\n",
      "Epoch 1218/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6073 - loss: 0.3403 - precision: 0.6112 - recall: 0.6517\n",
      "Epoch 1218 - Train Recall: 0.6481 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6074 - loss: 0.3404 - precision: 0.6101 - recall: 0.6515 - val_accuracy: 0.5937 - val_loss: 0.6851 - val_precision: 0.5904 - val_recall: 0.6117\n",
      "Epoch 1219/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6115 - loss: 0.3287 - precision: 0.6119 - recall: 0.6518\n",
      "Epoch 1219 - Train Recall: 0.6522 - Val Recall: 0.6567\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6112 - loss: 0.3288 - precision: 0.6111 - recall: 0.6519 - val_accuracy: 0.5900 - val_loss: 0.6603 - val_precision: 0.5794 - val_recall: 0.6567\n",
      "Epoch 1220/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6032 - loss: 0.3395 - precision: 0.5971 - recall: 0.6745\n",
      "Epoch 1220 - Train Recall: 0.6705 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6036 - loss: 0.3396 - precision: 0.5967 - recall: 0.6744 - val_accuracy: 0.6004 - val_loss: 0.6772 - val_precision: 0.5952 - val_recall: 0.6282\n",
      "Epoch 1221/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6068 - loss: 0.3278 - precision: 0.5972 - recall: 0.6791\n",
      "Epoch 1221 - Train Recall: 0.6799 - Val Recall: 0.7046\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6065 - loss: 0.3279 - precision: 0.5968 - recall: 0.6791 - val_accuracy: 0.5945 - val_loss: 0.6566 - val_precision: 0.5774 - val_recall: 0.7046\n",
      "Epoch 1222/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6015 - loss: 0.3464 - precision: 0.6001 - recall: 0.6732\n",
      "Epoch 1222 - Train Recall: 0.6533 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6017 - loss: 0.3463 - precision: 0.5995 - recall: 0.6714 - val_accuracy: 0.6057 - val_loss: 0.6836 - val_precision: 0.6000 - val_recall: 0.6342\n",
      "Epoch 1223/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6104 - loss: 0.3329 - precision: 0.6119 - recall: 0.6521\n",
      "Epoch 1223 - Train Recall: 0.6499 - Val Recall: 0.6777\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6101 - loss: 0.3329 - precision: 0.6112 - recall: 0.6520 - val_accuracy: 0.6027 - val_loss: 0.6635 - val_precision: 0.5893 - val_recall: 0.6777\n",
      "Epoch 1224/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6092 - loss: 0.3446 - precision: 0.6075 - recall: 0.6264\n",
      "Epoch 1224 - Train Recall: 0.6143 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6089 - loss: 0.3448 - precision: 0.6071 - recall: 0.6252 - val_accuracy: 0.6027 - val_loss: 0.6902 - val_precision: 0.6018 - val_recall: 0.6072\n",
      "Epoch 1225/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6038 - loss: 0.3384 - precision: 0.6081 - recall: 0.5955\n",
      "Epoch 1225 - Train Recall: 0.6106 - Val Recall: 0.5922\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6038 - loss: 0.3384 - precision: 0.6079 - recall: 0.5960 - val_accuracy: 0.6027 - val_loss: 0.6722 - val_precision: 0.6049 - val_recall: 0.5922\n",
      "Epoch 1226/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5951 - loss: 0.3350 - precision: 0.5884 - recall: 0.6375\n",
      "Epoch 1226 - Train Recall: 0.6451 - Val Recall: 0.5997\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5957 - loss: 0.3349 - precision: 0.5888 - recall: 0.6382 - val_accuracy: 0.6147 - val_loss: 0.6594 - val_precision: 0.6182 - val_recall: 0.5997\n",
      "Epoch 1227/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6087 - loss: 0.3273 - precision: 0.5934 - recall: 0.6387\n",
      "Epoch 1227 - Train Recall: 0.6645 - Val Recall: 0.6612\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6087 - loss: 0.3273 - precision: 0.5936 - recall: 0.6397 - val_accuracy: 0.5960 - val_loss: 0.6475 - val_precision: 0.5849 - val_recall: 0.6612\n",
      "Epoch 1228/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6009 - loss: 0.3397 - precision: 0.5790 - recall: 0.6727\n",
      "Epoch 1228 - Train Recall: 0.6694 - Val Recall: 0.6732\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6009 - loss: 0.3397 - precision: 0.5792 - recall: 0.6727 - val_accuracy: 0.5682 - val_loss: 0.6821 - val_precision: 0.5564 - val_recall: 0.6732\n",
      "Epoch 1229/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5977 - loss: 0.3407 - precision: 0.5827 - recall: 0.6399\n",
      "Epoch 1229 - Train Recall: 0.6402 - Val Recall: 0.7406\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5990 - loss: 0.3405 - precision: 0.5850 - recall: 0.6399 - val_accuracy: 0.5892 - val_loss: 0.6863 - val_precision: 0.5685 - val_recall: 0.7406\n",
      "Epoch 1230/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5959 - loss: 0.3644 - precision: 0.6016 - recall: 0.6166\n",
      "Epoch 1230 - Train Recall: 0.5956 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5962 - loss: 0.3645 - precision: 0.6016 - recall: 0.6152 - val_accuracy: 0.6109 - val_loss: 0.7227 - val_precision: 0.6171 - val_recall: 0.5847\n",
      "Epoch 1231/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6086 - loss: 0.3362 - precision: 0.6242 - recall: 0.5816\n",
      "Epoch 1231 - Train Recall: 0.6076 - Val Recall: 0.4978\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6083 - loss: 0.3362 - precision: 0.6222 - recall: 0.5847 - val_accuracy: 0.5735 - val_loss: 0.6731 - val_precision: 0.5866 - val_recall: 0.4978\n",
      "Epoch 1232/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6039 - loss: 0.3100 - precision: 0.6043 - recall: 0.6561\n",
      "Epoch 1232 - Train Recall: 0.6923 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6039 - loss: 0.3099 - precision: 0.6036 - recall: 0.6577 - val_accuracy: 0.5772 - val_loss: 0.6170 - val_precision: 0.5682 - val_recall: 0.6432\n",
      "Epoch 1233/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.3264 - precision: 0.5906 - recall: 0.6887\n",
      "Epoch 1233 - Train Recall: 0.6837 - Val Recall: 0.7301\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6039 - loss: 0.3266 - precision: 0.5902 - recall: 0.6880 - val_accuracy: 0.6102 - val_loss: 0.6462 - val_precision: 0.5889 - val_recall: 0.7301\n",
      "Epoch 1234/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6100 - loss: 0.3497 - precision: 0.5976 - recall: 0.6749\n",
      "Epoch 1234 - Train Recall: 0.6267 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6093 - loss: 0.3498 - precision: 0.5972 - recall: 0.6727 - val_accuracy: 0.5907 - val_loss: 0.6988 - val_precision: 0.5844 - val_recall: 0.6282\n",
      "Epoch 1235/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5990 - loss: 0.3391 - precision: 0.6034 - recall: 0.6044\n",
      "Epoch 1235 - Train Recall: 0.6098 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 0.3392 - precision: 0.6030 - recall: 0.6050 - val_accuracy: 0.5720 - val_loss: 0.6837 - val_precision: 0.5619 - val_recall: 0.6537\n",
      "Epoch 1236/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5934 - loss: 0.3516 - precision: 0.5815 - recall: 0.6060\n",
      "Epoch 1236 - Train Recall: 0.5978 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5940 - loss: 0.3517 - precision: 0.5840 - recall: 0.6048 - val_accuracy: 0.5945 - val_loss: 0.6946 - val_precision: 0.5885 - val_recall: 0.6282\n",
      "Epoch 1237/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5968 - loss: 0.3501 - precision: 0.5921 - recall: 0.6293\n",
      "Epoch 1237 - Train Recall: 0.6263 - Val Recall: 0.5772\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5969 - loss: 0.3501 - precision: 0.5921 - recall: 0.6293 - val_accuracy: 0.5937 - val_loss: 0.6973 - val_precision: 0.5969 - val_recall: 0.5772\n",
      "Epoch 1238/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 0.3269 - precision: 0.5885 - recall: 0.6197\n",
      "Epoch 1238 - Train Recall: 0.6548 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5957 - loss: 0.3269 - precision: 0.5887 - recall: 0.6216 - val_accuracy: 0.6154 - val_loss: 0.6457 - val_precision: 0.6043 - val_recall: 0.6687\n",
      "Epoch 1239/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6154 - loss: 0.3397 - precision: 0.6029 - recall: 0.6880\n",
      "Epoch 1239 - Train Recall: 0.6630 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6152 - loss: 0.3397 - precision: 0.6028 - recall: 0.6877 - val_accuracy: 0.6034 - val_loss: 0.6827 - val_precision: 0.5915 - val_recall: 0.6687\n",
      "Epoch 1240/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6087 - loss: 0.3392 - precision: 0.5987 - recall: 0.6567\n",
      "Epoch 1240 - Train Recall: 0.6634 - Val Recall: 0.6402\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6085 - loss: 0.3393 - precision: 0.5984 - recall: 0.6572 - val_accuracy: 0.5870 - val_loss: 0.6817 - val_precision: 0.5786 - val_recall: 0.6402\n",
      "Epoch 1241/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6095 - loss: 0.3343 - precision: 0.5962 - recall: 0.6671\n",
      "Epoch 1241 - Train Recall: 0.6630 - Val Recall: 0.6987\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6094 - loss: 0.3343 - precision: 0.5962 - recall: 0.6670 - val_accuracy: 0.5825 - val_loss: 0.6671 - val_precision: 0.5669 - val_recall: 0.6987\n",
      "Epoch 1242/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6073 - loss: 0.3476 - precision: 0.5859 - recall: 0.6485\n",
      "Epoch 1242 - Train Recall: 0.6233 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6070 - loss: 0.3478 - precision: 0.5872 - recall: 0.6464 - val_accuracy: 0.6072 - val_loss: 0.6923 - val_precision: 0.6011 - val_recall: 0.6372\n",
      "Epoch 1243/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6073 - loss: 0.3433 - precision: 0.5975 - recall: 0.6242\n",
      "Epoch 1243 - Train Recall: 0.6121 - Val Recall: 0.6567\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6071 - loss: 0.3433 - precision: 0.5975 - recall: 0.6239 - val_accuracy: 0.5990 - val_loss: 0.6841 - val_precision: 0.5887 - val_recall: 0.6567\n",
      "Epoch 1244/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6087 - loss: 0.3505 - precision: 0.6096 - recall: 0.6368\n",
      "Epoch 1244 - Train Recall: 0.6196 - Val Recall: 0.4903\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6084 - loss: 0.3506 - precision: 0.6087 - recall: 0.6349 - val_accuracy: 0.5727 - val_loss: 0.7057 - val_precision: 0.5871 - val_recall: 0.4903\n",
      "Epoch 1245/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6006 - loss: 0.3048 - precision: 0.6041 - recall: 0.6607\n",
      "Epoch 1245 - Train Recall: 0.6994 - Val Recall: 0.7166\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 0.3047 - precision: 0.6037 - recall: 0.6618 - val_accuracy: 0.5832 - val_loss: 0.6002 - val_precision: 0.5657 - val_recall: 0.7166\n",
      "Epoch 1246/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6078 - loss: 0.3433 - precision: 0.5870 - recall: 0.7040\n",
      "Epoch 1246 - Train Recall: 0.6750 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6076 - loss: 0.3434 - precision: 0.5870 - recall: 0.7035 - val_accuracy: 0.5772 - val_loss: 0.6902 - val_precision: 0.5730 - val_recall: 0.6057\n",
      "Epoch 1247/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6090 - loss: 0.3211 - precision: 0.5949 - recall: 0.6909\n",
      "Epoch 1247 - Train Recall: 0.7009 - Val Recall: 0.6612\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6088 - loss: 0.3211 - precision: 0.5946 - recall: 0.6914 - val_accuracy: 0.5967 - val_loss: 0.6444 - val_precision: 0.5857 - val_recall: 0.6612\n",
      "Epoch 1248/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6097 - loss: 0.3259 - precision: 0.5926 - recall: 0.7094\n",
      "Epoch 1248 - Train Recall: 0.6994 - Val Recall: 0.6732\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6097 - loss: 0.3259 - precision: 0.5926 - recall: 0.7092 - val_accuracy: 0.6012 - val_loss: 0.6578 - val_precision: 0.5885 - val_recall: 0.6732\n",
      "Epoch 1249/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6051 - loss: 0.3336 - precision: 0.5982 - recall: 0.6972\n",
      "Epoch 1249 - Train Recall: 0.6968 - Val Recall: 0.7046\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6052 - loss: 0.3336 - precision: 0.5977 - recall: 0.6972 - val_accuracy: 0.5945 - val_loss: 0.6617 - val_precision: 0.5774 - val_recall: 0.7046\n",
      "Epoch 1250/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6097 - loss: 0.3394 - precision: 0.5901 - recall: 0.6753\n",
      "Epoch 1250 - Train Recall: 0.6642 - Val Recall: 0.6132\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6091 - loss: 0.3395 - precision: 0.5904 - recall: 0.6739 - val_accuracy: 0.5907 - val_loss: 0.6790 - val_precision: 0.5868 - val_recall: 0.6132\n",
      "Epoch 1251/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6174 - loss: 0.3225 - precision: 0.6079 - recall: 0.6808\n",
      "Epoch 1251 - Train Recall: 0.6818 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6167 - loss: 0.3227 - precision: 0.6071 - recall: 0.6808 - val_accuracy: 0.6034 - val_loss: 0.6452 - val_precision: 0.5858 - val_recall: 0.7061\n",
      "Epoch 1252/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6117 - loss: 0.3450 - precision: 0.5906 - recall: 0.6948\n",
      "Epoch 1252 - Train Recall: 0.6642 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6107 - loss: 0.3451 - precision: 0.5906 - recall: 0.6919 - val_accuracy: 0.6064 - val_loss: 0.6844 - val_precision: 0.5917 - val_recall: 0.6867\n",
      "Epoch 1253/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6097 - loss: 0.3434 - precision: 0.5933 - recall: 0.6408\n",
      "Epoch 1253 - Train Recall: 0.6383 - Val Recall: 0.6162\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6096 - loss: 0.3434 - precision: 0.5935 - recall: 0.6407 - val_accuracy: 0.5757 - val_loss: 0.6931 - val_precision: 0.5700 - val_recall: 0.6162\n",
      "Epoch 1254/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6095 - loss: 0.3313 - precision: 0.6066 - recall: 0.6477\n",
      "Epoch 1254 - Train Recall: 0.6507 - Val Recall: 0.6912\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6080 - loss: 0.3318 - precision: 0.6042 - recall: 0.6484 - val_accuracy: 0.5960 - val_loss: 0.6640 - val_precision: 0.5806 - val_recall: 0.6912\n",
      "Epoch 1255/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5961 - loss: 0.3511 - precision: 0.5874 - recall: 0.6276\n",
      "Epoch 1255 - Train Recall: 0.6331 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5965 - loss: 0.3511 - precision: 0.5880 - recall: 0.6278 - val_accuracy: 0.6072 - val_loss: 0.6977 - val_precision: 0.6072 - val_recall: 0.6072\n",
      "Epoch 1256/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5974 - loss: 0.3324 - precision: 0.5809 - recall: 0.6103\n",
      "Epoch 1256 - Train Recall: 0.6319 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5975 - loss: 0.3325 - precision: 0.5826 - recall: 0.6124 - val_accuracy: 0.5802 - val_loss: 0.6616 - val_precision: 0.5709 - val_recall: 0.6462\n",
      "Epoch 1257/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5985 - loss: 0.3433 - precision: 0.5938 - recall: 0.6585\n",
      "Epoch 1257 - Train Recall: 0.6417 - Val Recall: 0.6612\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5982 - loss: 0.3434 - precision: 0.5931 - recall: 0.6567 - val_accuracy: 0.6019 - val_loss: 0.6779 - val_precision: 0.5912 - val_recall: 0.6612\n",
      "Epoch 1258/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6158 - loss: 0.3408 - precision: 0.6157 - recall: 0.6644\n",
      "Epoch 1258 - Train Recall: 0.6488 - Val Recall: 0.5682\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6155 - loss: 0.3410 - precision: 0.6149 - recall: 0.6634 - val_accuracy: 0.5757 - val_loss: 0.6885 - val_precision: 0.5769 - val_recall: 0.5682\n",
      "Epoch 1259/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6055 - loss: 0.3181 - precision: 0.5896 - recall: 0.6326\n",
      "Epoch 1259 - Train Recall: 0.6724 - Val Recall: 0.7331\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6055 - loss: 0.3181 - precision: 0.5898 - recall: 0.6342 - val_accuracy: 0.5870 - val_loss: 0.6325 - val_precision: 0.5673 - val_recall: 0.7331\n",
      "Epoch 1260/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6172 - loss: 0.3521 - precision: 0.5870 - recall: 0.7038\n",
      "Epoch 1260 - Train Recall: 0.6492 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6167 - loss: 0.3522 - precision: 0.5874 - recall: 0.7016 - val_accuracy: 0.5907 - val_loss: 0.7091 - val_precision: 0.5844 - val_recall: 0.6282\n",
      "Epoch 1261/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6055 - loss: 0.3361 - precision: 0.6043 - recall: 0.6267\n",
      "Epoch 1261 - Train Recall: 0.6469 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6058 - loss: 0.3359 - precision: 0.6037 - recall: 0.6289 - val_accuracy: 0.6072 - val_loss: 0.6632 - val_precision: 0.5935 - val_recall: 0.6807\n",
      "Epoch 1262/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6150 - loss: 0.3461 - precision: 0.6000 - recall: 0.6588\n",
      "Epoch 1262 - Train Recall: 0.6282 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6144 - loss: 0.3462 - precision: 0.5998 - recall: 0.6574 - val_accuracy: 0.6072 - val_loss: 0.6902 - val_precision: 0.6075 - val_recall: 0.6057\n",
      "Epoch 1263/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5991 - loss: 0.3334 - precision: 0.5805 - recall: 0.6323\n",
      "Epoch 1263 - Train Recall: 0.6507 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5996 - loss: 0.3334 - precision: 0.5816 - recall: 0.6337 - val_accuracy: 0.5877 - val_loss: 0.6652 - val_precision: 0.5811 - val_recall: 0.6282\n",
      "Epoch 1264/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6135 - loss: 0.3315 - precision: 0.5919 - recall: 0.6944\n",
      "Epoch 1264 - Train Recall: 0.6709 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6131 - loss: 0.3316 - precision: 0.5920 - recall: 0.6933 - val_accuracy: 0.5907 - val_loss: 0.6636 - val_precision: 0.5844 - val_recall: 0.6282\n",
      "Epoch 1265/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6121 - loss: 0.3260 - precision: 0.5973 - recall: 0.6662\n",
      "Epoch 1265 - Train Recall: 0.6889 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6117 - loss: 0.3262 - precision: 0.5970 - recall: 0.6686 - val_accuracy: 0.6042 - val_loss: 0.6496 - val_precision: 0.5906 - val_recall: 0.6792\n",
      "Epoch 1266/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6002 - loss: 0.3378 - precision: 0.5821 - recall: 0.6714\n",
      "Epoch 1266 - Train Recall: 0.6758 - Val Recall: 0.7226\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6003 - loss: 0.3378 - precision: 0.5824 - recall: 0.6715 - val_accuracy: 0.6057 - val_loss: 0.6673 - val_precision: 0.5857 - val_recall: 0.7226\n",
      "Epoch 1267/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5966 - loss: 0.3502 - precision: 0.5912 - recall: 0.6427\n",
      "Epoch 1267 - Train Recall: 0.6338 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5965 - loss: 0.3503 - precision: 0.5911 - recall: 0.6426 - val_accuracy: 0.5967 - val_loss: 0.6944 - val_precision: 0.5947 - val_recall: 0.6072\n",
      "Epoch 1268/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6071 - loss: 0.3342 - precision: 0.6005 - recall: 0.6391\n",
      "Epoch 1268 - Train Recall: 0.6361 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6067 - loss: 0.3341 - precision: 0.6000 - recall: 0.6388 - val_accuracy: 0.6094 - val_loss: 0.6607 - val_precision: 0.6011 - val_recall: 0.6507\n",
      "Epoch 1269/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6165 - loss: 0.3405 - precision: 0.6114 - recall: 0.6554\n",
      "Epoch 1269 - Train Recall: 0.6278 - Val Recall: 0.6252\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6153 - loss: 0.3408 - precision: 0.6100 - recall: 0.6521 - val_accuracy: 0.6027 - val_loss: 0.6851 - val_precision: 0.5983 - val_recall: 0.6252\n",
      "Epoch 1270/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6034 - loss: 0.3380 - precision: 0.5922 - recall: 0.6462\n",
      "Epoch 1270 - Train Recall: 0.6413 - Val Recall: 0.6582\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 0.3381 - precision: 0.5919 - recall: 0.6459 - val_accuracy: 0.5922 - val_loss: 0.6742 - val_precision: 0.5815 - val_recall: 0.6582\n",
      "Epoch 1271/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6118 - loss: 0.3408 - precision: 0.6059 - recall: 0.6682\n",
      "Epoch 1271 - Train Recall: 0.6267 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6108 - loss: 0.3411 - precision: 0.6050 - recall: 0.6640 - val_accuracy: 0.5990 - val_loss: 0.6855 - val_precision: 0.5959 - val_recall: 0.6147\n",
      "Epoch 1272/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6122 - loss: 0.3374 - precision: 0.6087 - recall: 0.5853\n",
      "Epoch 1272 - Train Recall: 0.6192 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6120 - loss: 0.3374 - precision: 0.6085 - recall: 0.5871 - val_accuracy: 0.5922 - val_loss: 0.6707 - val_precision: 0.5837 - val_recall: 0.6432\n",
      "Epoch 1273/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6120 - loss: 0.3456 - precision: 0.6064 - recall: 0.6547\n",
      "Epoch 1273 - Train Recall: 0.6421 - Val Recall: 0.6417\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6119 - loss: 0.3455 - precision: 0.6062 - recall: 0.6536 - val_accuracy: 0.5997 - val_loss: 0.6863 - val_precision: 0.5920 - val_recall: 0.6417\n",
      "Epoch 1274/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6056 - loss: 0.3366 - precision: 0.5965 - recall: 0.6075\n",
      "Epoch 1274 - Train Recall: 0.6113 - Val Recall: 0.5982\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6055 - loss: 0.3366 - precision: 0.5966 - recall: 0.6075 - val_accuracy: 0.5982 - val_loss: 0.6771 - val_precision: 0.5982 - val_recall: 0.5982\n",
      "Epoch 1275/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5975 - loss: 0.3360 - precision: 0.5875 - recall: 0.6362\n",
      "Epoch 1275 - Train Recall: 0.6383 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5984 - loss: 0.3359 - precision: 0.5885 - recall: 0.6368 - val_accuracy: 0.5952 - val_loss: 0.6615 - val_precision: 0.5859 - val_recall: 0.6492\n",
      "Epoch 1276/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6063 - loss: 0.3437 - precision: 0.6010 - recall: 0.6350\n",
      "Epoch 1276 - Train Recall: 0.6293 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6062 - loss: 0.3436 - precision: 0.6010 - recall: 0.6348 - val_accuracy: 0.5960 - val_loss: 0.6874 - val_precision: 0.5933 - val_recall: 0.6102\n",
      "Epoch 1277/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5985 - loss: 0.3367 - precision: 0.5901 - recall: 0.6098\n",
      "Epoch 1277 - Train Recall: 0.6211 - Val Recall: 0.5562\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5989 - loss: 0.3365 - precision: 0.5910 - recall: 0.6109 - val_accuracy: 0.5907 - val_loss: 0.6681 - val_precision: 0.5974 - val_recall: 0.5562\n",
      "Epoch 1278/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6117 - loss: 0.3196 - precision: 0.5972 - recall: 0.6704\n",
      "Epoch 1278 - Train Recall: 0.6814 - Val Recall: 0.7496\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6116 - loss: 0.3197 - precision: 0.5971 - recall: 0.6707 - val_accuracy: 0.5922 - val_loss: 0.6456 - val_precision: 0.5701 - val_recall: 0.7496\n",
      "Epoch 1279/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 0.3555 - precision: 0.5905 - recall: 0.6626\n",
      "Epoch 1279 - Train Recall: 0.6424 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6013 - loss: 0.3555 - precision: 0.5906 - recall: 0.6622 - val_accuracy: 0.6117 - val_loss: 0.7026 - val_precision: 0.6127 - val_recall: 0.6072\n",
      "Epoch 1280/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6136 - loss: 0.3321 - precision: 0.6148 - recall: 0.6002\n",
      "Epoch 1280 - Train Recall: 0.6304 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6134 - loss: 0.3321 - precision: 0.6143 - recall: 0.6022 - val_accuracy: 0.6057 - val_loss: 0.6563 - val_precision: 0.6161 - val_recall: 0.5607\n",
      "Epoch 1281/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6090 - loss: 0.3204 - precision: 0.6098 - recall: 0.6545\n",
      "Epoch 1281 - Train Recall: 0.6717 - Val Recall: 0.5712\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6089 - loss: 0.3204 - precision: 0.6086 - recall: 0.6560 - val_accuracy: 0.5862 - val_loss: 0.6439 - val_precision: 0.5889 - val_recall: 0.5712\n",
      "Epoch 1282/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 0.3131 - precision: 0.5959 - recall: 0.6875\n",
      "Epoch 1282 - Train Recall: 0.6867 - Val Recall: 0.7316\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6099 - loss: 0.3131 - precision: 0.5956 - recall: 0.6876 - val_accuracy: 0.6057 - val_loss: 0.6244 - val_precision: 0.5844 - val_recall: 0.7316\n",
      "Epoch 1283/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6033 - loss: 0.3509 - precision: 0.5804 - recall: 0.6605\n",
      "Epoch 1283 - Train Recall: 0.6263 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6030 - loss: 0.3510 - precision: 0.5809 - recall: 0.6589 - val_accuracy: 0.5982 - val_loss: 0.6985 - val_precision: 0.5968 - val_recall: 0.6057\n",
      "Epoch 1284/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6202 - loss: 0.3323 - precision: 0.6075 - recall: 0.6262\n",
      "Epoch 1284 - Train Recall: 0.6338 - Val Recall: 0.5667\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6191 - loss: 0.3324 - precision: 0.6074 - recall: 0.6271 - val_accuracy: 0.5952 - val_loss: 0.6650 - val_precision: 0.6010 - val_recall: 0.5667\n",
      "Epoch 1285/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6010 - loss: 0.3222 - precision: 0.5819 - recall: 0.6446\n",
      "Epoch 1285 - Train Recall: 0.6619 - Val Recall: 0.6747\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6011 - loss: 0.3222 - precision: 0.5824 - recall: 0.6454 - val_accuracy: 0.6162 - val_loss: 0.6378 - val_precision: 0.6040 - val_recall: 0.6747\n",
      "Epoch 1286/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5900 - loss: 0.3452 - precision: 0.5737 - recall: 0.6238\n",
      "Epoch 1286 - Train Recall: 0.6297 - Val Recall: 0.7001\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5911 - loss: 0.3451 - precision: 0.5757 - recall: 0.6243 - val_accuracy: 0.5967 - val_loss: 0.6871 - val_precision: 0.5801 - val_recall: 0.7001\n",
      "Epoch 1287/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6179 - loss: 0.3561 - precision: 0.6123 - recall: 0.6493\n",
      "Epoch 1287 - Train Recall: 0.6184 - Val Recall: 0.6777\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6175 - loss: 0.3561 - precision: 0.6121 - recall: 0.6484 - val_accuracy: 0.5997 - val_loss: 0.7155 - val_precision: 0.5863 - val_recall: 0.6777\n",
      "Epoch 1288/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5884 - loss: 0.3573 - precision: 0.5955 - recall: 0.5491\n",
      "Epoch 1288 - Train Recall: 0.5543 - Val Recall: 0.5622\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5892 - loss: 0.3571 - precision: 0.5964 - recall: 0.5496 - val_accuracy: 0.6034 - val_loss: 0.7047 - val_precision: 0.6127 - val_recall: 0.5622\n",
      "Epoch 1289/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6034 - loss: 0.3411 - precision: 0.6205 - recall: 0.5689\n",
      "Epoch 1289 - Train Recall: 0.6023 - Val Recall: 0.6597\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6032 - loss: 0.3414 - precision: 0.6180 - recall: 0.5734 - val_accuracy: 0.5915 - val_loss: 0.6848 - val_precision: 0.5805 - val_recall: 0.6597\n",
      "Epoch 1290/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6118 - loss: 0.3531 - precision: 0.6105 - recall: 0.6196\n",
      "Epoch 1290 - Train Recall: 0.5918 - Val Recall: 0.5007\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6116 - loss: 0.3532 - precision: 0.6106 - recall: 0.6185 - val_accuracy: 0.6012 - val_loss: 0.7064 - val_precision: 0.6266 - val_recall: 0.5007\n",
      "Epoch 1291/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6078 - loss: 0.3126 - precision: 0.5998 - recall: 0.6037\n",
      "Epoch 1291 - Train Recall: 0.6683 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6075 - loss: 0.3127 - precision: 0.5993 - recall: 0.6093 - val_accuracy: 0.5862 - val_loss: 0.6277 - val_precision: 0.5766 - val_recall: 0.6492\n",
      "Epoch 1292/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6002 - loss: 0.3366 - precision: 0.5812 - recall: 0.6799\n",
      "Epoch 1292 - Train Recall: 0.6544 - Val Recall: 0.6267\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6003 - loss: 0.3366 - precision: 0.5818 - recall: 0.6784 - val_accuracy: 0.6094 - val_loss: 0.6612 - val_precision: 0.6058 - val_recall: 0.6267\n",
      "Epoch 1293/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5949 - loss: 0.3342 - precision: 0.5829 - recall: 0.6615\n",
      "Epoch 1293 - Train Recall: 0.6638 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5958 - loss: 0.3340 - precision: 0.5838 - recall: 0.6618 - val_accuracy: 0.5907 - val_loss: 0.6607 - val_precision: 0.5791 - val_recall: 0.6642\n",
      "Epoch 1294/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6133 - loss: 0.3401 - precision: 0.5984 - recall: 0.6692\n",
      "Epoch 1294 - Train Recall: 0.6664 - Val Recall: 0.7211\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6131 - loss: 0.3401 - precision: 0.5983 - recall: 0.6691 - val_accuracy: 0.6064 - val_loss: 0.6762 - val_precision: 0.5866 - val_recall: 0.7211\n",
      "Epoch 1295/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6232 - loss: 0.3496 - precision: 0.6248 - recall: 0.6366\n",
      "Epoch 1295 - Train Recall: 0.6169 - Val Recall: 0.5787\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6229 - loss: 0.3497 - precision: 0.6244 - recall: 0.6362 - val_accuracy: 0.5982 - val_loss: 0.7010 - val_precision: 0.6022 - val_recall: 0.5787\n",
      "Epoch 1296/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6061 - loss: 0.3300 - precision: 0.6123 - recall: 0.6277\n",
      "Epoch 1296 - Train Recall: 0.6364 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6064 - loss: 0.3300 - precision: 0.6108 - recall: 0.6288 - val_accuracy: 0.5735 - val_loss: 0.6656 - val_precision: 0.5640 - val_recall: 0.6477\n",
      "Epoch 1297/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6065 - loss: 0.3431 - precision: 0.5946 - recall: 0.6774\n",
      "Epoch 1297 - Train Recall: 0.6604 - Val Recall: 0.7316\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6061 - loss: 0.3432 - precision: 0.5942 - recall: 0.6767 - val_accuracy: 0.6094 - val_loss: 0.6810 - val_precision: 0.5880 - val_recall: 0.7316\n",
      "Epoch 1298/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6012 - loss: 0.3584 - precision: 0.5997 - recall: 0.6205\n",
      "Epoch 1298 - Train Recall: 0.6019 - Val Recall: 0.5517\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6009 - loss: 0.3583 - precision: 0.5994 - recall: 0.6192 - val_accuracy: 0.5967 - val_loss: 0.7096 - val_precision: 0.6063 - val_recall: 0.5517\n",
      "Epoch 1299/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6058 - loss: 0.3244 - precision: 0.5932 - recall: 0.5927\n",
      "Epoch 1299 - Train Recall: 0.6346 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6056 - loss: 0.3246 - precision: 0.5943 - recall: 0.5981 - val_accuracy: 0.6147 - val_loss: 0.6405 - val_precision: 0.6005 - val_recall: 0.6852\n",
      "Epoch 1300/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6290 - loss: 0.3485 - precision: 0.6183 - recall: 0.6749\n",
      "Epoch 1300 - Train Recall: 0.6368 - Val Recall: 0.5712\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6281 - loss: 0.3487 - precision: 0.6177 - recall: 0.6731 - val_accuracy: 0.5945 - val_loss: 0.6990 - val_precision: 0.5991 - val_recall: 0.5712\n",
      "Epoch 1301/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6163 - loss: 0.3178 - precision: 0.6051 - recall: 0.6349\n",
      "Epoch 1301 - Train Recall: 0.6488 - Val Recall: 0.7046\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6161 - loss: 0.3178 - precision: 0.6049 - recall: 0.6351 - val_accuracy: 0.5922 - val_loss: 0.6412 - val_precision: 0.5753 - val_recall: 0.7046\n",
      "Epoch 1302/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5998 - loss: 0.3546 - precision: 0.5838 - recall: 0.6570\n",
      "Epoch 1302 - Train Recall: 0.6166 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5999 - loss: 0.3546 - precision: 0.5849 - recall: 0.6538 - val_accuracy: 0.5922 - val_loss: 0.6978 - val_precision: 0.5895 - val_recall: 0.6072\n",
      "Epoch 1303/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5976 - loss: 0.3371 - precision: 0.5953 - recall: 0.6175\n",
      "Epoch 1303 - Train Recall: 0.6308 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5976 - loss: 0.3371 - precision: 0.5952 - recall: 0.6180 - val_accuracy: 0.6027 - val_loss: 0.6719 - val_precision: 0.5851 - val_recall: 0.7061\n",
      "Epoch 1304/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6073 - loss: 0.3588 - precision: 0.5979 - recall: 0.5883\n",
      "Epoch 1304 - Train Recall: 0.5795 - Val Recall: 0.6882\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6072 - loss: 0.3588 - precision: 0.5980 - recall: 0.5882 - val_accuracy: 0.6154 - val_loss: 0.7138 - val_precision: 0.6008 - val_recall: 0.6882\n",
      "Epoch 1305/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6087 - loss: 0.3677 - precision: 0.6137 - recall: 0.5631\n",
      "Epoch 1305 - Train Recall: 0.5427 - Val Recall: 0.5682\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6084 - loss: 0.3678 - precision: 0.6139 - recall: 0.5619 - val_accuracy: 0.5795 - val_loss: 0.7401 - val_precision: 0.5813 - val_recall: 0.5682\n",
      "Epoch 1306/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5971 - loss: 0.3461 - precision: 0.5952 - recall: 0.5408\n",
      "Epoch 1306 - Train Recall: 0.5581 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5976 - loss: 0.3463 - precision: 0.5969 - recall: 0.5424 - val_accuracy: 0.5937 - val_loss: 0.6877 - val_precision: 0.5954 - val_recall: 0.5847\n",
      "Epoch 1307/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6086 - loss: 0.3462 - precision: 0.6133 - recall: 0.5961\n",
      "Epoch 1307 - Train Recall: 0.5978 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6084 - loss: 0.3463 - precision: 0.6130 - recall: 0.5961 - val_accuracy: 0.6057 - val_loss: 0.6882 - val_precision: 0.5941 - val_recall: 0.6672\n",
      "Epoch 1308/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6166 - loss: 0.3563 - precision: 0.6222 - recall: 0.5903\n",
      "Epoch 1308 - Train Recall: 0.5716 - Val Recall: 0.5892\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6164 - loss: 0.3564 - precision: 0.6220 - recall: 0.5900 - val_accuracy: 0.5982 - val_loss: 0.7156 - val_precision: 0.6000 - val_recall: 0.5892\n",
      "Epoch 1309/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6012 - loss: 0.3458 - precision: 0.6085 - recall: 0.5581\n",
      "Epoch 1309 - Train Recall: 0.5971 - Val Recall: 0.6717\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6027 - loss: 0.3455 - precision: 0.6096 - recall: 0.5628 - val_accuracy: 0.5900 - val_loss: 0.6914 - val_precision: 0.5773 - val_recall: 0.6717\n",
      "Epoch 1310/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6014 - loss: 0.3624 - precision: 0.5926 - recall: 0.5779\n",
      "Epoch 1310 - Train Recall: 0.5723 - Val Recall: 0.6012\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6010 - loss: 0.3624 - precision: 0.5933 - recall: 0.5774 - val_accuracy: 0.6004 - val_loss: 0.7170 - val_precision: 0.6003 - val_recall: 0.6012\n",
      "Epoch 1311/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6100 - loss: 0.3458 - precision: 0.6118 - recall: 0.5837\n",
      "Epoch 1311 - Train Recall: 0.5821 - Val Recall: 0.5472\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6092 - loss: 0.3459 - precision: 0.6110 - recall: 0.5836 - val_accuracy: 0.5900 - val_loss: 0.6968 - val_precision: 0.5984 - val_recall: 0.5472\n",
      "Epoch 1312/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6112 - loss: 0.3288 - precision: 0.6031 - recall: 0.6192\n",
      "Epoch 1312 - Train Recall: 0.6391 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6109 - loss: 0.3288 - precision: 0.6028 - recall: 0.6198 - val_accuracy: 0.6034 - val_loss: 0.6521 - val_precision: 0.5940 - val_recall: 0.6537\n",
      "Epoch 1313/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6066 - loss: 0.3416 - precision: 0.5955 - recall: 0.6354\n",
      "Epoch 1313 - Train Recall: 0.6331 - Val Recall: 0.6912\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6066 - loss: 0.3417 - precision: 0.5956 - recall: 0.6353 - val_accuracy: 0.6147 - val_loss: 0.6754 - val_precision: 0.5995 - val_recall: 0.6912\n",
      "Epoch 1314/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6147 - loss: 0.3499 - precision: 0.6065 - recall: 0.6267\n",
      "Epoch 1314 - Train Recall: 0.6121 - Val Recall: 0.5712\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6144 - loss: 0.3500 - precision: 0.6064 - recall: 0.6263 - val_accuracy: 0.6072 - val_loss: 0.7053 - val_precision: 0.6155 - val_recall: 0.5712\n",
      "Epoch 1315/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6090 - loss: 0.3271 - precision: 0.5991 - recall: 0.6470\n",
      "Epoch 1315 - Train Recall: 0.6608 - Val Recall: 0.7241\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6087 - loss: 0.3272 - precision: 0.5986 - recall: 0.6484 - val_accuracy: 0.6019 - val_loss: 0.6494 - val_precision: 0.5819 - val_recall: 0.7241\n",
      "Epoch 1316/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5996 - loss: 0.3549 - precision: 0.5956 - recall: 0.6521\n",
      "Epoch 1316 - Train Recall: 0.6327 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5999 - loss: 0.3549 - precision: 0.5957 - recall: 0.6510 - val_accuracy: 0.6094 - val_loss: 0.7105 - val_precision: 0.6055 - val_recall: 0.6282\n",
      "Epoch 1317/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5966 - loss: 0.3387 - precision: 0.5884 - recall: 0.6040\n",
      "Epoch 1317 - Train Recall: 0.6057 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5971 - loss: 0.3387 - precision: 0.5894 - recall: 0.6039 - val_accuracy: 0.6064 - val_loss: 0.6700 - val_precision: 0.5983 - val_recall: 0.6477\n",
      "Epoch 1318/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6072 - loss: 0.3520 - precision: 0.5983 - recall: 0.6188\n",
      "Epoch 1318 - Train Recall: 0.6057 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6070 - loss: 0.3520 - precision: 0.5986 - recall: 0.6180 - val_accuracy: 0.5870 - val_loss: 0.7078 - val_precision: 0.5795 - val_recall: 0.6342\n",
      "Epoch 1319/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6158 - loss: 0.3459 - precision: 0.6084 - recall: 0.6218\n",
      "Epoch 1319 - Train Recall: 0.6117 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6151 - loss: 0.3461 - precision: 0.6085 - recall: 0.6206 - val_accuracy: 0.6094 - val_loss: 0.6880 - val_precision: 0.6025 - val_recall: 0.6432\n",
      "Epoch 1320/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6216 - loss: 0.3463 - precision: 0.6107 - recall: 0.6261\n",
      "Epoch 1320 - Train Recall: 0.5978 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6211 - loss: 0.3464 - precision: 0.6108 - recall: 0.6249 - val_accuracy: 0.6012 - val_loss: 0.6899 - val_precision: 0.6021 - val_recall: 0.5967\n",
      "Epoch 1321/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6148 - loss: 0.3357 - precision: 0.6044 - recall: 0.6308\n",
      "Epoch 1321 - Train Recall: 0.6136 - Val Recall: 0.7016\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6139 - loss: 0.3360 - precision: 0.6040 - recall: 0.6294 - val_accuracy: 0.5967 - val_loss: 0.6828 - val_precision: 0.5799 - val_recall: 0.7016\n",
      "Epoch 1322/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6253 - loss: 0.3598 - precision: 0.6196 - recall: 0.6387\n",
      "Epoch 1322 - Train Recall: 0.5967 - Val Recall: 0.5112\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6240 - loss: 0.3601 - precision: 0.6188 - recall: 0.6363 - val_accuracy: 0.5832 - val_loss: 0.7308 - val_precision: 0.5972 - val_recall: 0.5112\n",
      "Epoch 1323/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6036 - loss: 0.3171 - precision: 0.5971 - recall: 0.6247\n",
      "Epoch 1323 - Train Recall: 0.6687 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6037 - loss: 0.3171 - precision: 0.5971 - recall: 0.6252 - val_accuracy: 0.5652 - val_loss: 0.6391 - val_precision: 0.5542 - val_recall: 0.6672\n",
      "Epoch 1324/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6114 - loss: 0.3384 - precision: 0.5951 - recall: 0.6938\n",
      "Epoch 1324 - Train Recall: 0.6818 - Val Recall: 0.5787\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6113 - loss: 0.3385 - precision: 0.5951 - recall: 0.6935 - val_accuracy: 0.6049 - val_loss: 0.6780 - val_precision: 0.6108 - val_recall: 0.5787\n",
      "Epoch 1325/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6219 - loss: 0.3112 - precision: 0.6073 - recall: 0.6708\n",
      "Epoch 1325 - Train Recall: 0.6885 - Val Recall: 0.7241\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6217 - loss: 0.3112 - precision: 0.6071 - recall: 0.6712 - val_accuracy: 0.5832 - val_loss: 0.6239 - val_precision: 0.5649 - val_recall: 0.7241\n",
      "Epoch 1326/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6155 - loss: 0.3456 - precision: 0.5974 - recall: 0.6818\n",
      "Epoch 1326 - Train Recall: 0.6540 - Val Recall: 0.5802\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6143 - loss: 0.3459 - precision: 0.5973 - recall: 0.6788 - val_accuracy: 0.5990 - val_loss: 0.6914 - val_precision: 0.6028 - val_recall: 0.5802\n",
      "Epoch 1327/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6070 - loss: 0.3214 - precision: 0.5968 - recall: 0.6437\n",
      "Epoch 1327 - Train Recall: 0.6784 - Val Recall: 0.7211\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6066 - loss: 0.3212 - precision: 0.5962 - recall: 0.6476 - val_accuracy: 0.6102 - val_loss: 0.6323 - val_precision: 0.5902 - val_recall: 0.7211\n",
      "Epoch 1328/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6135 - loss: 0.3495 - precision: 0.5918 - recall: 0.6923\n",
      "Epoch 1328 - Train Recall: 0.6653 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6133 - loss: 0.3495 - precision: 0.5921 - recall: 0.6912 - val_accuracy: 0.6004 - val_loss: 0.6989 - val_precision: 0.5936 - val_recall: 0.6372\n",
      "Epoch 1329/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6164 - loss: 0.3308 - precision: 0.6094 - recall: 0.6676\n",
      "Epoch 1329 - Train Recall: 0.6567 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6153 - loss: 0.3310 - precision: 0.6080 - recall: 0.6663 - val_accuracy: 0.5742 - val_loss: 0.6675 - val_precision: 0.5659 - val_recall: 0.6372\n",
      "Epoch 1330/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6033 - loss: 0.3323 - precision: 0.6023 - recall: 0.6622\n",
      "Epoch 1330 - Train Recall: 0.6709 - Val Recall: 0.7136\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6033 - loss: 0.3323 - precision: 0.6021 - recall: 0.6624 - val_accuracy: 0.6049 - val_loss: 0.6641 - val_precision: 0.5862 - val_recall: 0.7136\n",
      "Epoch 1331/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6237 - loss: 0.3452 - precision: 0.6090 - recall: 0.6703\n",
      "Epoch 1331 - Train Recall: 0.6424 - Val Recall: 0.5742\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6217 - loss: 0.3460 - precision: 0.6083 - recall: 0.6665 - val_accuracy: 0.5907 - val_loss: 0.7027 - val_precision: 0.5938 - val_recall: 0.5742\n",
      "Epoch 1332/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6153 - loss: 0.3192 - precision: 0.6066 - recall: 0.6271\n",
      "Epoch 1332 - Train Recall: 0.6409 - Val Recall: 0.7181\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6148 - loss: 0.3193 - precision: 0.6062 - recall: 0.6279 - val_accuracy: 0.5952 - val_loss: 0.6485 - val_precision: 0.5764 - val_recall: 0.7181\n",
      "Epoch 1333/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6149 - loss: 0.3596 - precision: 0.6001 - recall: 0.6770\n",
      "Epoch 1333 - Train Recall: 0.6177 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6136 - loss: 0.3597 - precision: 0.6001 - recall: 0.6699 - val_accuracy: 0.6012 - val_loss: 0.7141 - val_precision: 0.5949 - val_recall: 0.6342\n",
      "Epoch 1334/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6092 - loss: 0.3437 - precision: 0.6158 - recall: 0.5852\n",
      "Epoch 1334 - Train Recall: 0.6079 - Val Recall: 0.5952\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6091 - loss: 0.3438 - precision: 0.6153 - recall: 0.5864 - val_accuracy: 0.5870 - val_loss: 0.6866 - val_precision: 0.5855 - val_recall: 0.5952\n",
      "Epoch 1335/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5970 - loss: 0.3347 - precision: 0.5897 - recall: 0.6153\n",
      "Epoch 1335 - Train Recall: 0.6331 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5972 - loss: 0.3347 - precision: 0.5900 - recall: 0.6163 - val_accuracy: 0.5757 - val_loss: 0.6772 - val_precision: 0.5660 - val_recall: 0.6492\n",
      "Epoch 1336/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6046 - loss: 0.3444 - precision: 0.6000 - recall: 0.6441\n",
      "Epoch 1336 - Train Recall: 0.6346 - Val Recall: 0.5982\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6048 - loss: 0.3444 - precision: 0.6002 - recall: 0.6436 - val_accuracy: 0.5787 - val_loss: 0.6892 - val_precision: 0.5758 - val_recall: 0.5982\n",
      "Epoch 1337/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6080 - loss: 0.3293 - precision: 0.5990 - recall: 0.6575\n",
      "Epoch 1337 - Train Recall: 0.6567 - Val Recall: 0.6762\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6079 - loss: 0.3293 - precision: 0.5990 - recall: 0.6575 - val_accuracy: 0.6042 - val_loss: 0.6521 - val_precision: 0.5911 - val_recall: 0.6762\n",
      "Epoch 1338/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6104 - loss: 0.3450 - precision: 0.5895 - recall: 0.6461\n",
      "Epoch 1338 - Train Recall: 0.6278 - Val Recall: 0.5817\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6104 - loss: 0.3449 - precision: 0.5916 - recall: 0.6438 - val_accuracy: 0.5922 - val_loss: 0.6871 - val_precision: 0.5942 - val_recall: 0.5817\n",
      "Epoch 1339/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6042 - loss: 0.3292 - precision: 0.5985 - recall: 0.6483\n",
      "Epoch 1339 - Train Recall: 0.6623 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6043 - loss: 0.3292 - precision: 0.5985 - recall: 0.6485 - val_accuracy: 0.6117 - val_loss: 0.6525 - val_precision: 0.6151 - val_recall: 0.5967\n",
      "Epoch 1340/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6084 - loss: 0.3206 - precision: 0.6021 - recall: 0.6725\n",
      "Epoch 1340 - Train Recall: 0.6889 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6082 - loss: 0.3209 - precision: 0.6011 - recall: 0.6741 - val_accuracy: 0.6042 - val_loss: 0.6419 - val_precision: 0.5894 - val_recall: 0.6867\n",
      "Epoch 1341/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6132 - loss: 0.3380 - precision: 0.6036 - recall: 0.6675\n",
      "Epoch 1341 - Train Recall: 0.6544 - Val Recall: 0.6522\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6125 - loss: 0.3380 - precision: 0.6029 - recall: 0.6662 - val_accuracy: 0.6004 - val_loss: 0.6754 - val_precision: 0.5910 - val_recall: 0.6522\n",
      "Epoch 1342/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6333 - loss: 0.3365 - precision: 0.6332 - recall: 0.6762\n",
      "Epoch 1342 - Train Recall: 0.6600 - Val Recall: 0.6177\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6319 - loss: 0.3368 - precision: 0.6312 - recall: 0.6751 - val_accuracy: 0.5892 - val_loss: 0.6779 - val_precision: 0.5844 - val_recall: 0.6177\n",
      "Epoch 1343/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6110 - loss: 0.3286 - precision: 0.6146 - recall: 0.6420\n",
      "Epoch 1343 - Train Recall: 0.6499 - Val Recall: 0.7241\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6105 - loss: 0.3285 - precision: 0.6124 - recall: 0.6429 - val_accuracy: 0.5855 - val_loss: 0.6595 - val_precision: 0.5669 - val_recall: 0.7241\n",
      "Epoch 1344/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6088 - loss: 0.3586 - precision: 0.5902 - recall: 0.6441\n",
      "Epoch 1344 - Train Recall: 0.6124 - Val Recall: 0.5727\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6088 - loss: 0.3586 - precision: 0.5917 - recall: 0.6415 - val_accuracy: 0.5907 - val_loss: 0.7147 - val_precision: 0.5941 - val_recall: 0.5727\n",
      "Epoch 1345/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5926 - loss: 0.3297 - precision: 0.5890 - recall: 0.6119\n",
      "Epoch 1345 - Train Recall: 0.6301 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5931 - loss: 0.3298 - precision: 0.5892 - recall: 0.6138 - val_accuracy: 0.5997 - val_loss: 0.6487 - val_precision: 0.5849 - val_recall: 0.6867\n",
      "Epoch 1346/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6093 - loss: 0.3527 - precision: 0.5999 - recall: 0.6395\n",
      "Epoch 1346 - Train Recall: 0.6079 - Val Recall: 0.5097\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6085 - loss: 0.3528 - precision: 0.5999 - recall: 0.6372 - val_accuracy: 0.5892 - val_loss: 0.7017 - val_precision: 0.6061 - val_recall: 0.5097\n",
      "Epoch 1347/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6093 - loss: 0.3132 - precision: 0.6124 - recall: 0.6252\n",
      "Epoch 1347 - Train Recall: 0.6668 - Val Recall: 0.7376\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6093 - loss: 0.3132 - precision: 0.6119 - recall: 0.6266 - val_accuracy: 0.5990 - val_loss: 0.6168 - val_precision: 0.5775 - val_recall: 0.7376\n",
      "Epoch 1348/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6125 - loss: 0.3554 - precision: 0.5973 - recall: 0.6799\n",
      "Epoch 1348 - Train Recall: 0.6327 - Val Recall: 0.6732\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6118 - loss: 0.3556 - precision: 0.5973 - recall: 0.6761 - val_accuracy: 0.6079 - val_loss: 0.7094 - val_precision: 0.5955 - val_recall: 0.6732\n",
      "Epoch 1349/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 0.3493 - precision: 0.6035 - recall: 0.6217\n",
      "Epoch 1349 - Train Recall: 0.6124 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6027 - loss: 0.3495 - precision: 0.6027 - recall: 0.6205 - val_accuracy: 0.5960 - val_loss: 0.6978 - val_precision: 0.5860 - val_recall: 0.6537\n",
      "Epoch 1350/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6182 - loss: 0.3461 - precision: 0.6103 - recall: 0.6071\n",
      "Epoch 1350 - Train Recall: 0.5978 - Val Recall: 0.5247\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6174 - loss: 0.3464 - precision: 0.6105 - recall: 0.6061 - val_accuracy: 0.5757 - val_loss: 0.7040 - val_precision: 0.5843 - val_recall: 0.5247\n",
      "Epoch 1351/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6079 - loss: 0.3158 - precision: 0.6045 - recall: 0.6516\n",
      "Epoch 1351 - Train Recall: 0.6679 - Val Recall: 0.6747\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6077 - loss: 0.3159 - precision: 0.6040 - recall: 0.6522 - val_accuracy: 0.5997 - val_loss: 0.6328 - val_precision: 0.5867 - val_recall: 0.6747\n",
      "Epoch 1352/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6023 - loss: 0.3403 - precision: 0.5861 - recall: 0.6605\n",
      "Epoch 1352 - Train Recall: 0.6496 - Val Recall: 0.4843\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6025 - loss: 0.3403 - precision: 0.5867 - recall: 0.6599 - val_accuracy: 0.5885 - val_loss: 0.6889 - val_precision: 0.6117 - val_recall: 0.4843\n",
      "Epoch 1353/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6047 - loss: 0.2952 - precision: 0.5841 - recall: 0.6624\n",
      "Epoch 1353 - Train Recall: 0.6998 - Val Recall: 0.7856\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6046 - loss: 0.2951 - precision: 0.5844 - recall: 0.6654 - val_accuracy: 0.5907 - val_loss: 0.5844 - val_precision: 0.5653 - val_recall: 0.7856\n",
      "Epoch 1354/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6057 - loss: 0.3607 - precision: 0.5874 - recall: 0.6859\n",
      "Epoch 1354 - Train Recall: 0.6409 - Val Recall: 0.4978\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6057 - loss: 0.3607 - precision: 0.5875 - recall: 0.6856 - val_accuracy: 0.5945 - val_loss: 0.7119 - val_precision: 0.6171 - val_recall: 0.4978\n",
      "Epoch 1355/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6258 - loss: 0.3004 - precision: 0.6252 - recall: 0.6741\n",
      "Epoch 1355 - Train Recall: 0.7076 - Val Recall: 0.6612\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6241 - loss: 0.3004 - precision: 0.6215 - recall: 0.6779 - val_accuracy: 0.6079 - val_loss: 0.5979 - val_precision: 0.5976 - val_recall: 0.6612\n",
      "Epoch 1356/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6192 - loss: 0.3256 - precision: 0.6074 - recall: 0.7447\n",
      "Epoch 1356 - Train Recall: 0.7125 - Val Recall: 0.7346\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6175 - loss: 0.3260 - precision: 0.6051 - recall: 0.7419 - val_accuracy: 0.6124 - val_loss: 0.6522 - val_precision: 0.5904 - val_recall: 0.7346\n",
      "Epoch 1357/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5970 - loss: 0.3467 - precision: 0.5919 - recall: 0.6502\n",
      "Epoch 1357 - Train Recall: 0.6454 - Val Recall: 0.6012\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5976 - loss: 0.3467 - precision: 0.5923 - recall: 0.6497 - val_accuracy: 0.6042 - val_loss: 0.6815 - val_precision: 0.6048 - val_recall: 0.6012\n",
      "Epoch 1358/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6097 - loss: 0.3268 - precision: 0.5988 - recall: 0.6375\n",
      "Epoch 1358 - Train Recall: 0.6372 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6091 - loss: 0.3270 - precision: 0.5986 - recall: 0.6375 - val_accuracy: 0.6012 - val_loss: 0.6543 - val_precision: 0.5873 - val_recall: 0.6807\n",
      "Epoch 1359/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6026 - loss: 0.3516 - precision: 0.5935 - recall: 0.6339\n",
      "Epoch 1359 - Train Recall: 0.6353 - Val Recall: 0.5877\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6026 - loss: 0.3516 - precision: 0.5936 - recall: 0.6340 - val_accuracy: 0.5975 - val_loss: 0.6981 - val_precision: 0.5994 - val_recall: 0.5877\n",
      "Epoch 1360/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6057 - loss: 0.3280 - precision: 0.6066 - recall: 0.6258\n",
      "Epoch 1360 - Train Recall: 0.6443 - Val Recall: 0.5082\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6057 - loss: 0.3280 - precision: 0.6065 - recall: 0.6264 - val_accuracy: 0.5720 - val_loss: 0.6718 - val_precision: 0.5825 - val_recall: 0.5082\n",
      "Epoch 1361/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6073 - loss: 0.3016 - precision: 0.5848 - recall: 0.7105\n",
      "Epoch 1361 - Train Recall: 0.7219 - Val Recall: 0.7421\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6073 - loss: 0.3016 - precision: 0.5848 - recall: 0.7106 - val_accuracy: 0.6019 - val_loss: 0.6030 - val_precision: 0.5796 - val_recall: 0.7421\n",
      "Epoch 1362/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.3490 - precision: 0.5700 - recall: 0.6976\n",
      "Epoch 1362 - Train Recall: 0.6758 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5948 - loss: 0.3488 - precision: 0.5713 - recall: 0.6962 - val_accuracy: 0.5960 - val_loss: 0.6906 - val_precision: 0.5823 - val_recall: 0.6792\n",
      "Epoch 1363/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6062 - loss: 0.3413 - precision: 0.6035 - recall: 0.6355\n",
      "Epoch 1363 - Train Recall: 0.6398 - Val Recall: 0.7076\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6059 - loss: 0.3414 - precision: 0.6028 - recall: 0.6359 - val_accuracy: 0.6124 - val_loss: 0.6751 - val_precision: 0.5945 - val_recall: 0.7076\n",
      "Epoch 1364/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6108 - loss: 0.3552 - precision: 0.6087 - recall: 0.6378\n",
      "Epoch 1364 - Train Recall: 0.6188 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6105 - loss: 0.3553 - precision: 0.6083 - recall: 0.6358 - val_accuracy: 0.6012 - val_loss: 0.7191 - val_precision: 0.5875 - val_recall: 0.6792\n",
      "Epoch 1365/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.3571 - precision: 0.6008 - recall: 0.5609\n",
      "Epoch 1365 - Train Recall: 0.5828 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5987 - loss: 0.3571 - precision: 0.6012 - recall: 0.5620 - val_accuracy: 0.6012 - val_loss: 0.7040 - val_precision: 0.5991 - val_recall: 0.6117\n",
      "Epoch 1366/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6249 - loss: 0.3436 - precision: 0.6194 - recall: 0.6142\n",
      "Epoch 1366 - Train Recall: 0.6057 - Val Recall: 0.5652\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6242 - loss: 0.3439 - precision: 0.6193 - recall: 0.6132 - val_accuracy: 0.5975 - val_loss: 0.6910 - val_precision: 0.6042 - val_recall: 0.5652\n",
      "Epoch 1367/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6054 - loss: 0.3264 - precision: 0.5965 - recall: 0.6377\n",
      "Epoch 1367 - Train Recall: 0.6462 - Val Recall: 0.7241\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6056 - loss: 0.3265 - precision: 0.5969 - recall: 0.6381 - val_accuracy: 0.6049 - val_loss: 0.6527 - val_precision: 0.5847 - val_recall: 0.7241\n",
      "Epoch 1368/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6238 - loss: 0.3559 - precision: 0.6095 - recall: 0.6665\n",
      "Epoch 1368 - Train Recall: 0.6132 - Val Recall: 0.6042\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6219 - loss: 0.3563 - precision: 0.6090 - recall: 0.6600 - val_accuracy: 0.6102 - val_loss: 0.7164 - val_precision: 0.6115 - val_recall: 0.6042\n",
      "Epoch 1369/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6053 - loss: 0.3361 - precision: 0.6007 - recall: 0.5874\n",
      "Epoch 1369 - Train Recall: 0.6233 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6059 - loss: 0.3361 - precision: 0.6016 - recall: 0.5921 - val_accuracy: 0.5802 - val_loss: 0.6763 - val_precision: 0.5793 - val_recall: 0.5862\n",
      "Epoch 1370/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6142 - loss: 0.3310 - precision: 0.6028 - recall: 0.6682\n",
      "Epoch 1370 - Train Recall: 0.6660 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6140 - loss: 0.3310 - precision: 0.6027 - recall: 0.6681 - val_accuracy: 0.6042 - val_loss: 0.6557 - val_precision: 0.5948 - val_recall: 0.6537\n",
      "Epoch 1371/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6204 - loss: 0.3319 - precision: 0.6115 - recall: 0.6733\n",
      "Epoch 1371 - Train Recall: 0.6585 - Val Recall: 0.5382\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6189 - loss: 0.3323 - precision: 0.6097 - recall: 0.6720 - val_accuracy: 0.5817 - val_loss: 0.6772 - val_precision: 0.5895 - val_recall: 0.5382\n",
      "Epoch 1372/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6265 - loss: 0.3062 - precision: 0.6131 - recall: 0.6817\n",
      "Epoch 1372 - Train Recall: 0.7039 - Val Recall: 0.7241\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6251 - loss: 0.3064 - precision: 0.6113 - recall: 0.6840 - val_accuracy: 0.5952 - val_loss: 0.6156 - val_precision: 0.5757 - val_recall: 0.7241\n",
      "Epoch 1373/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6103 - loss: 0.3428 - precision: 0.5866 - recall: 0.7094\n",
      "Epoch 1373 - Train Recall: 0.6627 - Val Recall: 0.7331\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6098 - loss: 0.3430 - precision: 0.5865 - recall: 0.7078 - val_accuracy: 0.6222 - val_loss: 0.6867 - val_precision: 0.6000 - val_recall: 0.7331\n",
      "Epoch 1374/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6135 - loss: 0.3566 - precision: 0.6085 - recall: 0.6287\n",
      "Epoch 1374 - Train Recall: 0.6136 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6132 - loss: 0.3566 - precision: 0.6085 - recall: 0.6273 - val_accuracy: 0.6057 - val_loss: 0.7038 - val_precision: 0.5939 - val_recall: 0.6687\n",
      "Epoch 1375/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6067 - loss: 0.3552 - precision: 0.6069 - recall: 0.5877\n",
      "Epoch 1375 - Train Recall: 0.5813 - Val Recall: 0.5682\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6076 - loss: 0.3550 - precision: 0.6090 - recall: 0.5869 - val_accuracy: 0.6034 - val_loss: 0.7072 - val_precision: 0.6113 - val_recall: 0.5682\n",
      "Epoch 1376/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5995 - loss: 0.3372 - precision: 0.5980 - recall: 0.5969\n",
      "Epoch 1376 - Train Recall: 0.6132 - Val Recall: 0.6912\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5998 - loss: 0.3371 - precision: 0.5983 - recall: 0.5980 - val_accuracy: 0.6027 - val_loss: 0.6691 - val_precision: 0.5873 - val_recall: 0.6912\n",
      "Epoch 1377/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6053 - loss: 0.3599 - precision: 0.6076 - recall: 0.6261\n",
      "Epoch 1377 - Train Recall: 0.6027 - Val Recall: 0.5007\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6053 - loss: 0.3599 - precision: 0.6075 - recall: 0.6236 - val_accuracy: 0.5810 - val_loss: 0.7210 - val_precision: 0.5964 - val_recall: 0.5007\n",
      "Epoch 1378/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6243 - loss: 0.3097 - precision: 0.6207 - recall: 0.6550\n",
      "Epoch 1378 - Train Recall: 0.6713 - Val Recall: 0.6357\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6241 - loss: 0.3098 - precision: 0.6204 - recall: 0.6553 - val_accuracy: 0.5907 - val_loss: 0.6153 - val_precision: 0.5832 - val_recall: 0.6357\n",
      "Epoch 1379/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6165 - loss: 0.3308 - precision: 0.6059 - recall: 0.7030\n",
      "Epoch 1379 - Train Recall: 0.6889 - Val Recall: 0.6837\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6156 - loss: 0.3308 - precision: 0.6047 - recall: 0.7016 - val_accuracy: 0.6042 - val_loss: 0.6575 - val_precision: 0.5899 - val_recall: 0.6837\n",
      "Epoch 1380/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6058 - loss: 0.3385 - precision: 0.5996 - recall: 0.6888\n",
      "Epoch 1380 - Train Recall: 0.6657 - Val Recall: 0.6132\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6056 - loss: 0.3385 - precision: 0.5987 - recall: 0.6867 - val_accuracy: 0.6049 - val_loss: 0.6742 - val_precision: 0.6032 - val_recall: 0.6132\n",
      "Epoch 1381/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5948 - loss: 0.3272 - precision: 0.5818 - recall: 0.6520\n",
      "Epoch 1381 - Train Recall: 0.6649 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5953 - loss: 0.3272 - precision: 0.5824 - recall: 0.6529 - val_accuracy: 0.5982 - val_loss: 0.6481 - val_precision: 0.5911 - val_recall: 0.6372\n",
      "Epoch 1382/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6079 - loss: 0.3331 - precision: 0.5929 - recall: 0.6780\n",
      "Epoch 1382 - Train Recall: 0.6645 - Val Recall: 0.6927\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6078 - loss: 0.3331 - precision: 0.5930 - recall: 0.6774 - val_accuracy: 0.6192 - val_loss: 0.6541 - val_precision: 0.6039 - val_recall: 0.6927\n",
      "Epoch 1383/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6105 - loss: 0.3459 - precision: 0.6067 - recall: 0.6543\n",
      "Epoch 1383 - Train Recall: 0.6323 - Val Recall: 0.6252\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6101 - loss: 0.3460 - precision: 0.6063 - recall: 0.6523 - val_accuracy: 0.6004 - val_loss: 0.6886 - val_precision: 0.5957 - val_recall: 0.6252\n",
      "Epoch 1384/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6072 - loss: 0.3373 - precision: 0.6093 - recall: 0.6032\n",
      "Epoch 1384 - Train Recall: 0.6229 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6073 - loss: 0.3373 - precision: 0.6093 - recall: 0.6038 - val_accuracy: 0.6027 - val_loss: 0.6703 - val_precision: 0.5915 - val_recall: 0.6642\n",
      "Epoch 1385/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6290 - loss: 0.3470 - precision: 0.6173 - recall: 0.6761\n",
      "Epoch 1385 - Train Recall: 0.6316 - Val Recall: 0.5517\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6281 - loss: 0.3472 - precision: 0.6169 - recall: 0.6733 - val_accuracy: 0.5825 - val_loss: 0.7026 - val_precision: 0.5879 - val_recall: 0.5517\n",
      "Epoch 1386/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6131 - loss: 0.3203 - precision: 0.6007 - recall: 0.6430\n",
      "Epoch 1386 - Train Recall: 0.6750 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6133 - loss: 0.3203 - precision: 0.6009 - recall: 0.6441 - val_accuracy: 0.5952 - val_loss: 0.6349 - val_precision: 0.5883 - val_recall: 0.6342\n",
      "Epoch 1387/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6164 - loss: 0.3268 - precision: 0.6034 - recall: 0.7062\n",
      "Epoch 1387 - Train Recall: 0.6848 - Val Recall: 0.7466\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6162 - loss: 0.3269 - precision: 0.6031 - recall: 0.7049 - val_accuracy: 0.6004 - val_loss: 0.6546 - val_precision: 0.5777 - val_recall: 0.7466\n",
      "Epoch 1388/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6069 - loss: 0.3558 - precision: 0.6003 - recall: 0.6474\n",
      "Epoch 1388 - Train Recall: 0.6439 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6065 - loss: 0.3557 - precision: 0.5998 - recall: 0.6471 - val_accuracy: 0.6012 - val_loss: 0.7068 - val_precision: 0.6009 - val_recall: 0.6027\n",
      "Epoch 1389/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6135 - loss: 0.3303 - precision: 0.6090 - recall: 0.6391\n",
      "Epoch 1389 - Train Recall: 0.6510 - Val Recall: 0.6822\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6134 - loss: 0.3303 - precision: 0.6089 - recall: 0.6394 - val_accuracy: 0.6072 - val_loss: 0.6549 - val_precision: 0.5932 - val_recall: 0.6822\n",
      "Epoch 1390/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6218 - loss: 0.3475 - precision: 0.6148 - recall: 0.6697\n",
      "Epoch 1390 - Train Recall: 0.6499 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6211 - loss: 0.3477 - precision: 0.6141 - recall: 0.6676 - val_accuracy: 0.5990 - val_loss: 0.6896 - val_precision: 0.5875 - val_recall: 0.6642\n",
      "Epoch 1391/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6040 - loss: 0.3453 - precision: 0.6036 - recall: 0.6251\n",
      "Epoch 1391 - Train Recall: 0.6196 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6046 - loss: 0.3451 - precision: 0.6039 - recall: 0.6246 - val_accuracy: 0.6027 - val_loss: 0.6800 - val_precision: 0.6039 - val_recall: 0.5967\n",
      "Epoch 1392/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6146 - loss: 0.3328 - precision: 0.6074 - recall: 0.6253\n",
      "Epoch 1392 - Train Recall: 0.6278 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6140 - loss: 0.3329 - precision: 0.6072 - recall: 0.6256 - val_accuracy: 0.6087 - val_loss: 0.6641 - val_precision: 0.6014 - val_recall: 0.6447\n",
      "Epoch 1393/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6071 - loss: 0.3397 - precision: 0.5994 - recall: 0.6414\n",
      "Epoch 1393 - Train Recall: 0.6181 - Val Recall: 0.5832\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6070 - loss: 0.3397 - precision: 0.5994 - recall: 0.6413 - val_accuracy: 0.5952 - val_loss: 0.6853 - val_precision: 0.5975 - val_recall: 0.5832\n",
      "Epoch 1394/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6097 - loss: 0.3290 - precision: 0.6042 - recall: 0.6312\n",
      "Epoch 1394 - Train Recall: 0.6364 - Val Recall: 0.6402\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6097 - loss: 0.3290 - precision: 0.6041 - recall: 0.6313 - val_accuracy: 0.6064 - val_loss: 0.6577 - val_precision: 0.5997 - val_recall: 0.6402\n",
      "Epoch 1395/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6094 - loss: 0.3393 - precision: 0.6015 - recall: 0.6687\n",
      "Epoch 1395 - Train Recall: 0.6492 - Val Recall: 0.7091\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6093 - loss: 0.3393 - precision: 0.6015 - recall: 0.6682 - val_accuracy: 0.6012 - val_loss: 0.6821 - val_precision: 0.5832 - val_recall: 0.7091\n",
      "Epoch 1396/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6076 - loss: 0.3537 - precision: 0.6014 - recall: 0.6159\n",
      "Epoch 1396 - Train Recall: 0.6121 - Val Recall: 0.6087\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6076 - loss: 0.3537 - precision: 0.6017 - recall: 0.6157 - val_accuracy: 0.6087 - val_loss: 0.7057 - val_precision: 0.6087 - val_recall: 0.6087\n",
      "Epoch 1397/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6176 - loss: 0.3377 - precision: 0.6192 - recall: 0.6205\n",
      "Epoch 1397 - Train Recall: 0.6087 - Val Recall: 0.5997\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6169 - loss: 0.3379 - precision: 0.6183 - recall: 0.6198 - val_accuracy: 0.5967 - val_loss: 0.6750 - val_precision: 0.5961 - val_recall: 0.5997\n",
      "Epoch 1398/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6064 - loss: 0.3361 - precision: 0.5908 - recall: 0.6153\n",
      "Epoch 1398 - Train Recall: 0.6398 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6069 - loss: 0.3361 - precision: 0.5924 - recall: 0.6177 - val_accuracy: 0.6057 - val_loss: 0.6688 - val_precision: 0.5880 - val_recall: 0.7061\n",
      "Epoch 1399/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6117 - loss: 0.3553 - precision: 0.6063 - recall: 0.6183\n",
      "Epoch 1399 - Train Recall: 0.6218 - Val Recall: 0.4963\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6115 - loss: 0.3553 - precision: 0.6063 - recall: 0.6184 - val_accuracy: 0.5840 - val_loss: 0.7133 - val_precision: 0.6018 - val_recall: 0.4963\n",
      "Epoch 1400/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6236 - loss: 0.3043 - precision: 0.6128 - recall: 0.6420\n",
      "Epoch 1400 - Train Recall: 0.6765 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6222 - loss: 0.3045 - precision: 0.6110 - recall: 0.6460 - val_accuracy: 0.6049 - val_loss: 0.6077 - val_precision: 0.5931 - val_recall: 0.6687\n",
      "Epoch 1401/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6093 - loss: 0.3371 - precision: 0.5936 - recall: 0.7105\n",
      "Epoch 1401 - Train Recall: 0.6904 - Val Recall: 0.6822\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6086 - loss: 0.3371 - precision: 0.5927 - recall: 0.7080 - val_accuracy: 0.5825 - val_loss: 0.6730 - val_precision: 0.5688 - val_recall: 0.6822\n",
      "Epoch 1402/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6151 - loss: 0.3370 - precision: 0.6071 - recall: 0.6794\n",
      "Epoch 1402 - Train Recall: 0.6687 - Val Recall: 0.6957\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6148 - loss: 0.3371 - precision: 0.6065 - recall: 0.6788 - val_accuracy: 0.6102 - val_loss: 0.6699 - val_precision: 0.5941 - val_recall: 0.6957\n",
      "Epoch 1403/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6066 - loss: 0.3463 - precision: 0.5997 - recall: 0.6186\n",
      "Epoch 1403 - Train Recall: 0.6177 - Val Recall: 0.6357\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6066 - loss: 0.3463 - precision: 0.5998 - recall: 0.6186 - val_accuracy: 0.5922 - val_loss: 0.6936 - val_precision: 0.5848 - val_recall: 0.6357\n",
      "Epoch 1404/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6181 - loss: 0.3426 - precision: 0.6037 - recall: 0.6452\n",
      "Epoch 1404 - Train Recall: 0.6331 - Val Recall: 0.5802\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6173 - loss: 0.3428 - precision: 0.6035 - recall: 0.6446 - val_accuracy: 0.6027 - val_loss: 0.6911 - val_precision: 0.6075 - val_recall: 0.5802\n",
      "Epoch 1405/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6242 - loss: 0.3236 - precision: 0.6272 - recall: 0.6428\n",
      "Epoch 1405 - Train Recall: 0.6570 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6235 - loss: 0.3238 - precision: 0.6257 - recall: 0.6435 - val_accuracy: 0.6057 - val_loss: 0.6488 - val_precision: 0.5972 - val_recall: 0.6492\n",
      "Epoch 1406/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6246 - loss: 0.3330 - precision: 0.6192 - recall: 0.6872\n",
      "Epoch 1406 - Train Recall: 0.6694 - Val Recall: 0.7421\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6234 - loss: 0.3333 - precision: 0.6174 - recall: 0.6859 - val_accuracy: 0.6034 - val_loss: 0.6728 - val_precision: 0.5810 - val_recall: 0.7421\n",
      "Epoch 1407/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6156 - loss: 0.3588 - precision: 0.6167 - recall: 0.6084\n",
      "Epoch 1407 - Train Recall: 0.5900 - Val Recall: 0.4963\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6149 - loss: 0.3588 - precision: 0.6161 - recall: 0.6069 - val_accuracy: 0.5952 - val_loss: 0.7127 - val_precision: 0.6187 - val_recall: 0.4963\n",
      "Epoch 1408/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6112 - loss: 0.3142 - precision: 0.6044 - recall: 0.6099\n",
      "Epoch 1408 - Train Recall: 0.6525 - Val Recall: 0.7181\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6111 - loss: 0.3141 - precision: 0.6041 - recall: 0.6137 - val_accuracy: 0.6102 - val_loss: 0.6198 - val_precision: 0.5906 - val_recall: 0.7181\n",
      "Epoch 1409/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6295 - loss: 0.3504 - precision: 0.6119 - recall: 0.7070\n",
      "Epoch 1409 - Train Recall: 0.6409 - Val Recall: 0.6192\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6264 - loss: 0.3511 - precision: 0.6104 - recall: 0.6986 - val_accuracy: 0.5982 - val_loss: 0.7052 - val_precision: 0.5942 - val_recall: 0.6192\n",
      "Epoch 1410/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6094 - loss: 0.3346 - precision: 0.5989 - recall: 0.6224\n",
      "Epoch 1410 - Train Recall: 0.6297 - Val Recall: 0.6267\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6095 - loss: 0.3346 - precision: 0.5994 - recall: 0.6229 - val_accuracy: 0.6124 - val_loss: 0.6611 - val_precision: 0.6093 - val_recall: 0.6267\n",
      "Epoch 1411/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6063 - loss: 0.3378 - precision: 0.5929 - recall: 0.6411\n",
      "Epoch 1411 - Train Recall: 0.6439 - Val Recall: 0.6042\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6062 - loss: 0.3379 - precision: 0.5934 - recall: 0.6413 - val_accuracy: 0.6027 - val_loss: 0.6742 - val_precision: 0.6024 - val_recall: 0.6042\n",
      "Epoch 1412/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5995 - loss: 0.3300 - precision: 0.5963 - recall: 0.6493\n",
      "Epoch 1412 - Train Recall: 0.6702 - Val Recall: 0.7391\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5997 - loss: 0.3300 - precision: 0.5963 - recall: 0.6500 - val_accuracy: 0.6094 - val_loss: 0.6522 - val_precision: 0.5869 - val_recall: 0.7391\n",
      "Epoch 1413/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6075 - loss: 0.3526 - precision: 0.5963 - recall: 0.6300\n",
      "Epoch 1413 - Train Recall: 0.6083 - Val Recall: 0.5787\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6074 - loss: 0.3529 - precision: 0.5970 - recall: 0.6285 - val_accuracy: 0.6147 - val_loss: 0.7087 - val_precision: 0.6236 - val_recall: 0.5787\n",
      "Epoch 1414/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6129 - loss: 0.3307 - precision: 0.6163 - recall: 0.6189\n",
      "Epoch 1414 - Train Recall: 0.6368 - Val Recall: 0.6627\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6125 - loss: 0.3308 - precision: 0.6149 - recall: 0.6210 - val_accuracy: 0.6132 - val_loss: 0.6565 - val_precision: 0.6030 - val_recall: 0.6627\n",
      "Epoch 1415/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6018 - loss: 0.3485 - precision: 0.6004 - recall: 0.6211\n",
      "Epoch 1415 - Train Recall: 0.6177 - Val Recall: 0.6252\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6018 - loss: 0.3485 - precision: 0.6004 - recall: 0.6211 - val_accuracy: 0.5915 - val_loss: 0.6907 - val_precision: 0.5857 - val_recall: 0.6252\n",
      "Epoch 1416/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6000 - loss: 0.3418 - precision: 0.5946 - recall: 0.6397\n",
      "Epoch 1416 - Train Recall: 0.6346 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6000 - loss: 0.3419 - precision: 0.5946 - recall: 0.6390 - val_accuracy: 0.5967 - val_loss: 0.6772 - val_precision: 0.5882 - val_recall: 0.6447\n",
      "Epoch 1417/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6268 - loss: 0.3388 - precision: 0.6250 - recall: 0.6411\n",
      "Epoch 1417 - Train Recall: 0.6188 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6264 - loss: 0.3389 - precision: 0.6246 - recall: 0.6403 - val_accuracy: 0.6019 - val_loss: 0.6869 - val_precision: 0.5907 - val_recall: 0.6642\n",
      "Epoch 1418/2000\n",
      "\u001b[1m141/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6061 - loss: 0.3499 - precision: 0.6127 - recall: 0.6185\n",
      "Epoch 1418 - Train Recall: 0.6046 - Val Recall: 0.4828\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6061 - loss: 0.3501 - precision: 0.6114 - recall: 0.6169 - val_accuracy: 0.5847 - val_loss: 0.7106 - val_precision: 0.6064 - val_recall: 0.4828\n",
      "Epoch 1419/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6037 - loss: 0.3078 - precision: 0.5969 - recall: 0.6177\n",
      "Epoch 1419 - Train Recall: 0.6788 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6045 - loss: 0.3073 - precision: 0.5968 - recall: 0.6263 - val_accuracy: 0.6012 - val_loss: 0.6064 - val_precision: 0.5923 - val_recall: 0.6492\n",
      "Epoch 1420/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6003 - loss: 0.3333 - precision: 0.5854 - recall: 0.6951\n",
      "Epoch 1420 - Train Recall: 0.6915 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 0.3333 - precision: 0.5859 - recall: 0.6948 - val_accuracy: 0.5975 - val_loss: 0.6654 - val_precision: 0.5835 - val_recall: 0.6807\n",
      "Epoch 1421/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6092 - loss: 0.3360 - precision: 0.5960 - recall: 0.6692\n",
      "Epoch 1421 - Train Recall: 0.6608 - Val Recall: 0.7271\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6090 - loss: 0.3361 - precision: 0.5960 - recall: 0.6689 - val_accuracy: 0.6079 - val_loss: 0.6691 - val_precision: 0.5872 - val_recall: 0.7271\n",
      "Epoch 1422/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6171 - loss: 0.3533 - precision: 0.6138 - recall: 0.6389\n",
      "Epoch 1422 - Train Recall: 0.6057 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6170 - loss: 0.3533 - precision: 0.6138 - recall: 0.6387 - val_accuracy: 0.6027 - val_loss: 0.7046 - val_precision: 0.6121 - val_recall: 0.5607\n",
      "Epoch 1423/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6146 - loss: 0.3252 - precision: 0.6312 - recall: 0.5984\n",
      "Epoch 1423 - Train Recall: 0.6188 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6140 - loss: 0.3254 - precision: 0.6292 - recall: 0.6001 - val_accuracy: 0.6124 - val_loss: 0.6537 - val_precision: 0.6126 - val_recall: 0.6117\n",
      "Epoch 1424/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6045 - loss: 0.3399 - precision: 0.5992 - recall: 0.6422\n",
      "Epoch 1424 - Train Recall: 0.6548 - Val Recall: 0.5712\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6048 - loss: 0.3399 - precision: 0.5994 - recall: 0.6424 - val_accuracy: 0.5847 - val_loss: 0.6720 - val_precision: 0.5871 - val_recall: 0.5712\n",
      "Epoch 1425/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6126 - loss: 0.3164 - precision: 0.6117 - recall: 0.6640\n",
      "Epoch 1425 - Train Recall: 0.6683 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6116 - loss: 0.3166 - precision: 0.6097 - recall: 0.6642 - val_accuracy: 0.5795 - val_loss: 0.6413 - val_precision: 0.5753 - val_recall: 0.6072\n",
      "Epoch 1426/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6111 - loss: 0.3238 - precision: 0.5962 - recall: 0.6903\n",
      "Epoch 1426 - Train Recall: 0.6975 - Val Recall: 0.7136\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6110 - loss: 0.3238 - precision: 0.5961 - recall: 0.6905 - val_accuracy: 0.5862 - val_loss: 0.6497 - val_precision: 0.5687 - val_recall: 0.7136\n",
      "Epoch 1427/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6144 - loss: 0.3426 - precision: 0.6041 - recall: 0.6856\n",
      "Epoch 1427 - Train Recall: 0.6672 - Val Recall: 0.5532\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6139 - loss: 0.3427 - precision: 0.6035 - recall: 0.6846 - val_accuracy: 0.5915 - val_loss: 0.6886 - val_precision: 0.5990 - val_recall: 0.5532\n",
      "Epoch 1428/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6164 - loss: 0.3089 - precision: 0.5998 - recall: 0.6738\n",
      "Epoch 1428 - Train Recall: 0.6885 - Val Recall: 0.6762\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6164 - loss: 0.3089 - precision: 0.5997 - recall: 0.6740 - val_accuracy: 0.6064 - val_loss: 0.6167 - val_precision: 0.5934 - val_recall: 0.6762\n",
      "Epoch 1429/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6189 - loss: 0.3337 - precision: 0.5965 - recall: 0.7106\n",
      "Epoch 1429 - Train Recall: 0.6893 - Val Recall: 0.6522\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6172 - loss: 0.3342 - precision: 0.5956 - recall: 0.7081 - val_accuracy: 0.5922 - val_loss: 0.6767 - val_precision: 0.5823 - val_recall: 0.6522\n",
      "Epoch 1430/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6144 - loss: 0.3299 - precision: 0.6050 - recall: 0.6817\n",
      "Epoch 1430 - Train Recall: 0.6743 - Val Recall: 0.6402\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6139 - loss: 0.3300 - precision: 0.6042 - recall: 0.6810 - val_accuracy: 0.6087 - val_loss: 0.6582 - val_precision: 0.6023 - val_recall: 0.6402\n",
      "Epoch 1431/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6129 - loss: 0.3301 - precision: 0.5983 - recall: 0.6506\n",
      "Epoch 1431 - Train Recall: 0.6619 - Val Recall: 0.6942\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6126 - loss: 0.3302 - precision: 0.5983 - recall: 0.6513 - val_accuracy: 0.6034 - val_loss: 0.6574 - val_precision: 0.5876 - val_recall: 0.6942\n",
      "Epoch 1432/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6110 - loss: 0.3482 - precision: 0.6023 - recall: 0.6561\n",
      "Epoch 1432 - Train Recall: 0.6368 - Val Recall: 0.5652\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6113 - loss: 0.3481 - precision: 0.6029 - recall: 0.6548 - val_accuracy: 0.5892 - val_loss: 0.6952 - val_precision: 0.5937 - val_recall: 0.5652\n",
      "Epoch 1433/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5994 - loss: 0.3216 - precision: 0.6032 - recall: 0.6199\n",
      "Epoch 1433 - Train Recall: 0.6612 - Val Recall: 0.6192\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6002 - loss: 0.3214 - precision: 0.6024 - recall: 0.6247 - val_accuracy: 0.5900 - val_loss: 0.6367 - val_precision: 0.5850 - val_recall: 0.6192\n",
      "Epoch 1434/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6130 - loss: 0.3298 - precision: 0.5959 - recall: 0.6745\n",
      "Epoch 1434 - Train Recall: 0.6773 - Val Recall: 0.6567\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6125 - loss: 0.3298 - precision: 0.5958 - recall: 0.6748 - val_accuracy: 0.6154 - val_loss: 0.6531 - val_precision: 0.6066 - val_recall: 0.6567\n",
      "Epoch 1435/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6040 - loss: 0.3353 - precision: 0.5868 - recall: 0.6723\n",
      "Epoch 1435 - Train Recall: 0.6762 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6040 - loss: 0.3353 - precision: 0.5869 - recall: 0.6723 - val_accuracy: 0.5885 - val_loss: 0.6751 - val_precision: 0.5848 - val_recall: 0.6102\n",
      "Epoch 1436/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6043 - loss: 0.3243 - precision: 0.5899 - recall: 0.6687\n",
      "Epoch 1436 - Train Recall: 0.6792 - Val Recall: 0.6627\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6043 - loss: 0.3243 - precision: 0.5899 - recall: 0.6687 - val_accuracy: 0.5855 - val_loss: 0.6461 - val_precision: 0.5740 - val_recall: 0.6627\n",
      "Epoch 1437/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 0.3339 - precision: 0.6022 - recall: 0.6830\n",
      "Epoch 1437 - Train Recall: 0.6893 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6102 - loss: 0.3339 - precision: 0.6019 - recall: 0.6835 - val_accuracy: 0.5960 - val_loss: 0.6690 - val_precision: 0.5925 - val_recall: 0.6147\n",
      "Epoch 1438/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6251 - loss: 0.3191 - precision: 0.6089 - recall: 0.6979\n",
      "Epoch 1438 - Train Recall: 0.6912 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6246 - loss: 0.3192 - precision: 0.6085 - recall: 0.6975 - val_accuracy: 0.5982 - val_loss: 0.6451 - val_precision: 0.5889 - val_recall: 0.6507\n",
      "Epoch 1439/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6131 - loss: 0.3276 - precision: 0.5995 - recall: 0.6785\n",
      "Epoch 1439 - Train Recall: 0.6803 - Val Recall: 0.6747\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6130 - loss: 0.3277 - precision: 0.5994 - recall: 0.6790 - val_accuracy: 0.5877 - val_loss: 0.6582 - val_precision: 0.5747 - val_recall: 0.6747\n",
      "Epoch 1440/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6279 - loss: 0.3340 - precision: 0.6098 - recall: 0.6816\n",
      "Epoch 1440 - Train Recall: 0.6608 - Val Recall: 0.6972\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6269 - loss: 0.3342 - precision: 0.6094 - recall: 0.6804 - val_accuracy: 0.5922 - val_loss: 0.6769 - val_precision: 0.5762 - val_recall: 0.6972\n",
      "Epoch 1441/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6050 - loss: 0.3497 - precision: 0.5984 - recall: 0.6177\n",
      "Epoch 1441 - Train Recall: 0.6177 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6050 - loss: 0.3497 - precision: 0.5985 - recall: 0.6177 - val_accuracy: 0.6079 - val_loss: 0.6896 - val_precision: 0.6065 - val_recall: 0.6147\n",
      "Epoch 1442/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6052 - loss: 0.3402 - precision: 0.6047 - recall: 0.6181\n",
      "Epoch 1442 - Train Recall: 0.6256 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6054 - loss: 0.3402 - precision: 0.6047 - recall: 0.6185 - val_accuracy: 0.6177 - val_loss: 0.6778 - val_precision: 0.6104 - val_recall: 0.6507\n",
      "Epoch 1443/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6150 - loss: 0.3427 - precision: 0.6064 - recall: 0.6455\n",
      "Epoch 1443 - Train Recall: 0.6462 - Val Recall: 0.6597\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6141 - loss: 0.3430 - precision: 0.6056 - recall: 0.6455 - val_accuracy: 0.6132 - val_loss: 0.6893 - val_precision: 0.6036 - val_recall: 0.6597\n",
      "Epoch 1444/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6072 - loss: 0.3430 - precision: 0.6013 - recall: 0.6171\n",
      "Epoch 1444 - Train Recall: 0.6113 - Val Recall: 0.6402\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6067 - loss: 0.3432 - precision: 0.6013 - recall: 0.6167 - val_accuracy: 0.6162 - val_loss: 0.6780 - val_precision: 0.6109 - val_recall: 0.6402\n",
      "Epoch 1445/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6189 - loss: 0.3448 - precision: 0.6257 - recall: 0.6063\n",
      "Epoch 1445 - Train Recall: 0.6076 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.3448 - precision: 0.6253 - recall: 0.6064 - val_accuracy: 0.6177 - val_loss: 0.6915 - val_precision: 0.6095 - val_recall: 0.6552\n",
      "Epoch 1446/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6093 - loss: 0.3534 - precision: 0.6230 - recall: 0.5799\n",
      "Epoch 1446 - Train Recall: 0.5941 - Val Recall: 0.5307\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6094 - loss: 0.3534 - precision: 0.6229 - recall: 0.5802 - val_accuracy: 0.5982 - val_loss: 0.6988 - val_precision: 0.6135 - val_recall: 0.5307\n",
      "Epoch 1447/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6068 - loss: 0.3223 - precision: 0.6074 - recall: 0.6174\n",
      "Epoch 1447 - Train Recall: 0.6462 - Val Recall: 0.7286\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6068 - loss: 0.3223 - precision: 0.6069 - recall: 0.6195 - val_accuracy: 0.6072 - val_loss: 0.6383 - val_precision: 0.5862 - val_recall: 0.7286\n",
      "Epoch 1448/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6103 - loss: 0.3608 - precision: 0.5997 - recall: 0.6457\n",
      "Epoch 1448 - Train Recall: 0.6113 - Val Recall: 0.4828\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6103 - loss: 0.3608 - precision: 0.6001 - recall: 0.6443 - val_accuracy: 0.5810 - val_loss: 0.7281 - val_precision: 0.6007 - val_recall: 0.4828\n",
      "Epoch 1449/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6090 - loss: 0.3061 - precision: 0.6105 - recall: 0.6260\n",
      "Epoch 1449 - Train Recall: 0.6589 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6092 - loss: 0.3058 - precision: 0.6092 - recall: 0.6299 - val_accuracy: 0.5907 - val_loss: 0.6057 - val_precision: 0.5828 - val_recall: 0.6387\n",
      "Epoch 1450/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6012 - loss: 0.3369 - precision: 0.5791 - recall: 0.7123\n",
      "Epoch 1450 - Train Recall: 0.7076 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6012 - loss: 0.3369 - precision: 0.5792 - recall: 0.7123 - val_accuracy: 0.6207 - val_loss: 0.6627 - val_precision: 0.6031 - val_recall: 0.7061\n",
      "Epoch 1451/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6328 - loss: 0.3342 - precision: 0.6204 - recall: 0.6765\n",
      "Epoch 1451 - Train Recall: 0.6582 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6321 - loss: 0.3344 - precision: 0.6198 - recall: 0.6759 - val_accuracy: 0.6117 - val_loss: 0.6695 - val_precision: 0.6005 - val_recall: 0.6672\n",
      "Epoch 1452/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6160 - loss: 0.3396 - precision: 0.6056 - recall: 0.6661\n",
      "Epoch 1452 - Train Recall: 0.6559 - Val Recall: 0.6012\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6154 - loss: 0.3398 - precision: 0.6049 - recall: 0.6655 - val_accuracy: 0.6124 - val_loss: 0.6763 - val_precision: 0.6150 - val_recall: 0.6012\n",
      "Epoch 1453/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6210 - loss: 0.3231 - precision: 0.6066 - recall: 0.6732\n",
      "Epoch 1453 - Train Recall: 0.6780 - Val Recall: 0.7166\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6207 - loss: 0.3232 - precision: 0.6064 - recall: 0.6734 - val_accuracy: 0.5922 - val_loss: 0.6500 - val_precision: 0.5738 - val_recall: 0.7166\n",
      "Epoch 1454/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6183 - loss: 0.3472 - precision: 0.6093 - recall: 0.6910\n",
      "Epoch 1454 - Train Recall: 0.6492 - Val Recall: 0.5457\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6179 - loss: 0.3473 - precision: 0.6089 - recall: 0.6891 - val_accuracy: 0.6057 - val_loss: 0.6984 - val_precision: 0.6201 - val_recall: 0.5457\n",
      "Epoch 1455/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6059 - loss: 0.3137 - precision: 0.6072 - recall: 0.6053\n",
      "Epoch 1455 - Train Recall: 0.6466 - Val Recall: 0.7751\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6063 - loss: 0.3136 - precision: 0.6069 - recall: 0.6082 - val_accuracy: 0.6154 - val_loss: 0.6158 - val_precision: 0.5875 - val_recall: 0.7751\n",
      "Epoch 1456/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6158 - loss: 0.3705 - precision: 0.6072 - recall: 0.6602\n",
      "Epoch 1456 - Train Recall: 0.6068 - Val Recall: 0.5007\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6155 - loss: 0.3705 - precision: 0.6072 - recall: 0.6589 - val_accuracy: 0.5825 - val_loss: 0.7392 - val_precision: 0.5986 - val_recall: 0.5007\n",
      "Epoch 1457/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6157 - loss: 0.3117 - precision: 0.6229 - recall: 0.5840\n",
      "Epoch 1457 - Train Recall: 0.6439 - Val Recall: 0.7121\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6151 - loss: 0.3114 - precision: 0.6206 - recall: 0.5903 - val_accuracy: 0.6012 - val_loss: 0.6141 - val_precision: 0.5828 - val_recall: 0.7121\n",
      "Epoch 1458/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6141 - loss: 0.3546 - precision: 0.5916 - recall: 0.6856\n",
      "Epoch 1458 - Train Recall: 0.6316 - Val Recall: 0.5592\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6139 - loss: 0.3547 - precision: 0.5917 - recall: 0.6847 - val_accuracy: 0.6019 - val_loss: 0.7201 - val_precision: 0.6115 - val_recall: 0.5592\n",
      "Epoch 1459/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 0.3208 - precision: 0.5998 - recall: 0.6326\n",
      "Epoch 1459 - Train Recall: 0.6687 - Val Recall: 0.7031\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 0.3208 - precision: 0.5998 - recall: 0.6328 - val_accuracy: 0.5907 - val_loss: 0.6349 - val_precision: 0.5741 - val_recall: 0.7031\n",
      "Epoch 1460/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6176 - loss: 0.3468 - precision: 0.6022 - recall: 0.6992\n",
      "Epoch 1460 - Train Recall: 0.6582 - Val Recall: 0.6087\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6161 - loss: 0.3471 - precision: 0.6015 - recall: 0.6945 - val_accuracy: 0.6094 - val_loss: 0.6888 - val_precision: 0.6096 - val_recall: 0.6087\n",
      "Epoch 1461/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6113 - loss: 0.3263 - precision: 0.6051 - recall: 0.6391\n",
      "Epoch 1461 - Train Recall: 0.6432 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6110 - loss: 0.3263 - precision: 0.6048 - recall: 0.6393 - val_accuracy: 0.6049 - val_loss: 0.6515 - val_precision: 0.6048 - val_recall: 0.6057\n",
      "Epoch 1462/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6131 - loss: 0.3295 - precision: 0.6027 - recall: 0.6750\n",
      "Epoch 1462 - Train Recall: 0.6713 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6129 - loss: 0.3295 - precision: 0.6024 - recall: 0.6748 - val_accuracy: 0.6019 - val_loss: 0.6549 - val_precision: 0.5994 - val_recall: 0.6147\n",
      "Epoch 1463/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6077 - loss: 0.3246 - precision: 0.5823 - recall: 0.6552\n",
      "Epoch 1463 - Train Recall: 0.6694 - Val Recall: 0.7391\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6079 - loss: 0.3246 - precision: 0.5840 - recall: 0.6565 - val_accuracy: 0.5952 - val_loss: 0.6462 - val_precision: 0.5739 - val_recall: 0.7391\n",
      "Epoch 1464/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6222 - loss: 0.3542 - precision: 0.6170 - recall: 0.6690\n",
      "Epoch 1464 - Train Recall: 0.6263 - Val Recall: 0.6312\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6217 - loss: 0.3543 - precision: 0.6166 - recall: 0.6670 - val_accuracy: 0.6064 - val_loss: 0.7123 - val_precision: 0.6014 - val_recall: 0.6312\n",
      "Epoch 1465/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6182 - loss: 0.3412 - precision: 0.6162 - recall: 0.6201\n",
      "Epoch 1465 - Train Recall: 0.6124 - Val Recall: 0.5577\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6177 - loss: 0.3413 - precision: 0.6157 - recall: 0.6193 - val_accuracy: 0.6102 - val_loss: 0.6757 - val_precision: 0.6231 - val_recall: 0.5577\n",
      "Epoch 1466/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6075 - loss: 0.3259 - precision: 0.6074 - recall: 0.6300\n",
      "Epoch 1466 - Train Recall: 0.6537 - Val Recall: 0.6942\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6081 - loss: 0.3258 - precision: 0.6071 - recall: 0.6324 - val_accuracy: 0.6094 - val_loss: 0.6415 - val_precision: 0.5936 - val_recall: 0.6942\n",
      "Epoch 1467/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6197 - loss: 0.3457 - precision: 0.6041 - recall: 0.6821\n",
      "Epoch 1467 - Train Recall: 0.6469 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6184 - loss: 0.3463 - precision: 0.6041 - recall: 0.6771 - val_accuracy: 0.6064 - val_loss: 0.6952 - val_precision: 0.5989 - val_recall: 0.6447\n",
      "Epoch 1468/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6083 - loss: 0.3399 - precision: 0.6121 - recall: 0.6141\n",
      "Epoch 1468 - Train Recall: 0.6342 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6088 - loss: 0.3398 - precision: 0.6117 - recall: 0.6164 - val_accuracy: 0.5930 - val_loss: 0.6830 - val_precision: 0.5906 - val_recall: 0.6057\n",
      "Epoch 1469/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6076 - loss: 0.3324 - precision: 0.5848 - recall: 0.6630\n",
      "Epoch 1469 - Train Recall: 0.6533 - Val Recall: 0.7541\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6076 - loss: 0.3324 - precision: 0.5860 - recall: 0.6621 - val_accuracy: 0.6124 - val_loss: 0.6566 - val_precision: 0.5876 - val_recall: 0.7541\n",
      "Epoch 1470/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6114 - loss: 0.3637 - precision: 0.6071 - recall: 0.6353\n",
      "Epoch 1470 - Train Recall: 0.6098 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6116 - loss: 0.3638 - precision: 0.6076 - recall: 0.6337 - val_accuracy: 0.6064 - val_loss: 0.7276 - val_precision: 0.6066 - val_recall: 0.6057\n",
      "Epoch 1471/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6080 - loss: 0.3399 - precision: 0.6117 - recall: 0.5867\n",
      "Epoch 1471 - Train Recall: 0.6177 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6091 - loss: 0.3397 - precision: 0.6126 - recall: 0.5891 - val_accuracy: 0.5945 - val_loss: 0.6778 - val_precision: 0.5913 - val_recall: 0.6117\n",
      "Epoch 1472/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6239 - loss: 0.3350 - precision: 0.6242 - recall: 0.6418\n",
      "Epoch 1472 - Train Recall: 0.6439 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6238 - loss: 0.3351 - precision: 0.6240 - recall: 0.6418 - val_accuracy: 0.6019 - val_loss: 0.6742 - val_precision: 0.5881 - val_recall: 0.6807\n",
      "Epoch 1473/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6204 - loss: 0.3493 - precision: 0.6191 - recall: 0.6151\n",
      "Epoch 1473 - Train Recall: 0.6113 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6201 - loss: 0.3493 - precision: 0.6188 - recall: 0.6150 - val_accuracy: 0.6049 - val_loss: 0.7006 - val_precision: 0.6012 - val_recall: 0.6237\n",
      "Epoch 1474/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6133 - loss: 0.3403 - precision: 0.6048 - recall: 0.6224\n",
      "Epoch 1474 - Train Recall: 0.6199 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6129 - loss: 0.3406 - precision: 0.6053 - recall: 0.6221 - val_accuracy: 0.5982 - val_loss: 0.6874 - val_precision: 0.5884 - val_recall: 0.6537\n",
      "Epoch 1475/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6158 - loss: 0.3476 - precision: 0.6199 - recall: 0.6270\n",
      "Epoch 1475 - Train Recall: 0.6308 - Val Recall: 0.5352\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6157 - loss: 0.3477 - precision: 0.6193 - recall: 0.6273 - val_accuracy: 0.5937 - val_loss: 0.6983 - val_precision: 0.6061 - val_recall: 0.5352\n",
      "Epoch 1476/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6172 - loss: 0.3123 - precision: 0.6176 - recall: 0.6554\n",
      "Epoch 1476 - Train Recall: 0.6713 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6169 - loss: 0.3124 - precision: 0.6163 - recall: 0.6565 - val_accuracy: 0.6192 - val_loss: 0.6230 - val_precision: 0.6053 - val_recall: 0.6852\n",
      "Epoch 1477/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6134 - loss: 0.3405 - precision: 0.6044 - recall: 0.6714\n",
      "Epoch 1477 - Train Recall: 0.6529 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6128 - loss: 0.3407 - precision: 0.6037 - recall: 0.6701 - val_accuracy: 0.6162 - val_loss: 0.6801 - val_precision: 0.6093 - val_recall: 0.6477\n",
      "Epoch 1478/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6196 - loss: 0.3374 - precision: 0.6122 - recall: 0.6351\n",
      "Epoch 1478 - Train Recall: 0.6484 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6192 - loss: 0.3374 - precision: 0.6122 - recall: 0.6363 - val_accuracy: 0.6019 - val_loss: 0.6797 - val_precision: 0.5977 - val_recall: 0.6237\n",
      "Epoch 1479/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6172 - loss: 0.3310 - precision: 0.6184 - recall: 0.6419\n",
      "Epoch 1479 - Train Recall: 0.6522 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6166 - loss: 0.3311 - precision: 0.6165 - recall: 0.6434 - val_accuracy: 0.5975 - val_loss: 0.6673 - val_precision: 0.5948 - val_recall: 0.6117\n",
      "Epoch 1480/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6079 - loss: 0.3295 - precision: 0.6017 - recall: 0.6506\n",
      "Epoch 1480 - Train Recall: 0.6574 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6080 - loss: 0.3294 - precision: 0.6015 - recall: 0.6510 - val_accuracy: 0.6019 - val_loss: 0.6567 - val_precision: 0.5872 - val_recall: 0.6867\n",
      "Epoch 1481/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6062 - loss: 0.3453 - precision: 0.5865 - recall: 0.6561\n",
      "Epoch 1481 - Train Recall: 0.6293 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6062 - loss: 0.3455 - precision: 0.5885 - recall: 0.6524 - val_accuracy: 0.6042 - val_loss: 0.6953 - val_precision: 0.6058 - val_recall: 0.5967\n",
      "Epoch 1482/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6194 - loss: 0.3288 - precision: 0.6168 - recall: 0.6755\n",
      "Epoch 1482 - Train Recall: 0.6844 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6194 - loss: 0.3288 - precision: 0.6165 - recall: 0.6756 - val_accuracy: 0.5990 - val_loss: 0.6696 - val_precision: 0.6015 - val_recall: 0.5862\n",
      "Epoch 1483/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6244 - loss: 0.3126 - precision: 0.6151 - recall: 0.6981\n",
      "Epoch 1483 - Train Recall: 0.6990 - Val Recall: 0.7121\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6230 - loss: 0.3128 - precision: 0.6130 - recall: 0.6982 - val_accuracy: 0.5960 - val_loss: 0.6299 - val_precision: 0.5779 - val_recall: 0.7121\n",
      "Epoch 1484/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6013 - loss: 0.3456 - precision: 0.5870 - recall: 0.7138\n",
      "Epoch 1484 - Train Recall: 0.6960 - Val Recall: 0.5952\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6015 - loss: 0.3455 - precision: 0.5871 - recall: 0.7126 - val_accuracy: 0.5982 - val_loss: 0.6838 - val_precision: 0.5988 - val_recall: 0.5952\n",
      "Epoch 1485/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6076 - loss: 0.3159 - precision: 0.5978 - recall: 0.6740\n",
      "Epoch 1485 - Train Recall: 0.7084 - Val Recall: 0.7991\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6078 - loss: 0.3158 - precision: 0.5976 - recall: 0.6760 - val_accuracy: 0.6034 - val_loss: 0.6262 - val_precision: 0.5744 - val_recall: 0.7991\n",
      "Epoch 1486/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 0.3587 - precision: 0.6094 - recall: 0.6951\n",
      "Epoch 1486 - Train Recall: 0.6540 - Val Recall: 0.5247\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6098 - loss: 0.3588 - precision: 0.6086 - recall: 0.6928 - val_accuracy: 0.5900 - val_loss: 0.7166 - val_precision: 0.6034 - val_recall: 0.5247\n",
      "Epoch 1487/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6165 - loss: 0.3058 - precision: 0.6141 - recall: 0.6384\n",
      "Epoch 1487 - Train Recall: 0.6570 - Val Recall: 0.6972\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6162 - loss: 0.3058 - precision: 0.6137 - recall: 0.6389 - val_accuracy: 0.5990 - val_loss: 0.6061 - val_precision: 0.5827 - val_recall: 0.6972\n",
      "Epoch 1488/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5941 - loss: 0.3553 - precision: 0.5803 - recall: 0.6626\n",
      "Epoch 1488 - Train Recall: 0.6533 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5942 - loss: 0.3553 - precision: 0.5805 - recall: 0.6624 - val_accuracy: 0.6094 - val_loss: 0.6942 - val_precision: 0.6093 - val_recall: 0.6102\n",
      "Epoch 1489/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6196 - loss: 0.3266 - precision: 0.6037 - recall: 0.6344\n",
      "Epoch 1489 - Train Recall: 0.6364 - Val Recall: 0.7391\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6180 - loss: 0.3268 - precision: 0.6030 - recall: 0.6344 - val_accuracy: 0.5982 - val_loss: 0.6537 - val_precision: 0.5766 - val_recall: 0.7391\n",
      "Epoch 1490/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5945 - loss: 0.3679 - precision: 0.5882 - recall: 0.6383\n",
      "Epoch 1490 - Train Recall: 0.6068 - Val Recall: 0.6312\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5949 - loss: 0.3678 - precision: 0.5889 - recall: 0.6368 - val_accuracy: 0.6079 - val_loss: 0.7274 - val_precision: 0.6032 - val_recall: 0.6312\n",
      "Epoch 1491/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6069 - loss: 0.3427 - precision: 0.6262 - recall: 0.5528\n",
      "Epoch 1491 - Train Recall: 0.5738 - Val Recall: 0.6957\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6073 - loss: 0.3429 - precision: 0.6254 - recall: 0.5554 - val_accuracy: 0.5975 - val_loss: 0.6952 - val_precision: 0.5815 - val_recall: 0.6957\n",
      "Epoch 1492/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.3747 - precision: 0.6140 - recall: 0.5383\n",
      "Epoch 1492 - Train Recall: 0.5330 - Val Recall: 0.5742\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6035 - loss: 0.3746 - precision: 0.6139 - recall: 0.5377 - val_accuracy: 0.5945 - val_loss: 0.7384 - val_precision: 0.5984 - val_recall: 0.5742\n",
      "Epoch 1493/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6136 - loss: 0.3493 - precision: 0.6215 - recall: 0.5562\n",
      "Epoch 1493 - Train Recall: 0.5484 - Val Recall: 0.5787\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6124 - loss: 0.3497 - precision: 0.6205 - recall: 0.5554 - val_accuracy: 0.6042 - val_loss: 0.6970 - val_precision: 0.6098 - val_recall: 0.5787\n",
      "Epoch 1494/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6194 - loss: 0.3467 - precision: 0.6268 - recall: 0.5896\n",
      "Epoch 1494 - Train Recall: 0.5862 - Val Recall: 0.6822\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6184 - loss: 0.3469 - precision: 0.6258 - recall: 0.5889 - val_accuracy: 0.6057 - val_loss: 0.6969 - val_precision: 0.5917 - val_recall: 0.6822\n",
      "Epoch 1495/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6132 - loss: 0.3634 - precision: 0.6183 - recall: 0.5686\n",
      "Epoch 1495 - Train Recall: 0.5600 - Val Recall: 0.5397\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6119 - loss: 0.3638 - precision: 0.6181 - recall: 0.5670 - val_accuracy: 0.6049 - val_loss: 0.7193 - val_precision: 0.6207 - val_recall: 0.5397\n",
      "Epoch 1496/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6230 - loss: 0.3318 - precision: 0.6353 - recall: 0.5953\n",
      "Epoch 1496 - Train Recall: 0.6042 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6224 - loss: 0.3319 - precision: 0.6342 - recall: 0.5958 - val_accuracy: 0.6094 - val_loss: 0.6660 - val_precision: 0.6064 - val_recall: 0.6237\n",
      "Epoch 1497/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6095 - loss: 0.3447 - precision: 0.6141 - recall: 0.6075\n",
      "Epoch 1497 - Train Recall: 0.6143 - Val Recall: 0.5892\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6095 - loss: 0.3447 - precision: 0.6140 - recall: 0.6077 - val_accuracy: 0.6124 - val_loss: 0.6961 - val_precision: 0.6179 - val_recall: 0.5892\n",
      "Epoch 1498/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6312 - loss: 0.3282 - precision: 0.6263 - recall: 0.6556\n",
      "Epoch 1498 - Train Recall: 0.6428 - Val Recall: 0.6402\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6296 - loss: 0.3286 - precision: 0.6247 - recall: 0.6542 - val_accuracy: 0.5915 - val_loss: 0.6649 - val_precision: 0.5833 - val_recall: 0.6402\n",
      "Epoch 1499/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6162 - loss: 0.3376 - precision: 0.6179 - recall: 0.6641\n",
      "Epoch 1499 - Train Recall: 0.6428 - Val Recall: 0.5487\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6159 - loss: 0.3377 - precision: 0.6171 - recall: 0.6628 - val_accuracy: 0.5907 - val_loss: 0.6808 - val_precision: 0.5990 - val_recall: 0.5487\n",
      "Epoch 1500/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6170 - loss: 0.3142 - precision: 0.6098 - recall: 0.6489\n",
      "Epoch 1500 - Train Recall: 0.6672 - Val Recall: 0.7181\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6167 - loss: 0.3142 - precision: 0.6091 - recall: 0.6505 - val_accuracy: 0.6027 - val_loss: 0.6246 - val_precision: 0.5834 - val_recall: 0.7181\n",
      "Epoch 1501/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6097 - loss: 0.3549 - precision: 0.5918 - recall: 0.6640\n",
      "Epoch 1501 - Train Recall: 0.6510 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6102 - loss: 0.3547 - precision: 0.5932 - recall: 0.6628 - val_accuracy: 0.5900 - val_loss: 0.7135 - val_precision: 0.5730 - val_recall: 0.7061\n",
      "Epoch 1502/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6175 - loss: 0.3517 - precision: 0.6112 - recall: 0.6331\n",
      "Epoch 1502 - Train Recall: 0.6139 - Val Recall: 0.5637\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6170 - loss: 0.3518 - precision: 0.6113 - recall: 0.6314 - val_accuracy: 0.5982 - val_loss: 0.7106 - val_precision: 0.6055 - val_recall: 0.5637\n",
      "Epoch 1503/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6140 - loss: 0.3250 - precision: 0.6052 - recall: 0.6203\n",
      "Epoch 1503 - Train Recall: 0.6451 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6141 - loss: 0.3250 - precision: 0.6054 - recall: 0.6211 - val_accuracy: 0.5997 - val_loss: 0.6512 - val_precision: 0.5897 - val_recall: 0.6552\n",
      "Epoch 1504/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6059 - loss: 0.3435 - precision: 0.5961 - recall: 0.6553\n",
      "Epoch 1504 - Train Recall: 0.6466 - Val Recall: 0.6312\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6068 - loss: 0.3434 - precision: 0.5972 - recall: 0.6544 - val_accuracy: 0.6132 - val_loss: 0.6822 - val_precision: 0.6093 - val_recall: 0.6312\n",
      "Epoch 1505/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6111 - loss: 0.3339 - precision: 0.6042 - recall: 0.6604\n",
      "Epoch 1505 - Train Recall: 0.6417 - Val Recall: 0.6987\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6105 - loss: 0.3341 - precision: 0.6036 - recall: 0.6594 - val_accuracy: 0.6087 - val_loss: 0.6673 - val_precision: 0.5921 - val_recall: 0.6987\n",
      "Epoch 1506/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6147 - loss: 0.3537 - precision: 0.6122 - recall: 0.6124\n",
      "Epoch 1506 - Train Recall: 0.6057 - Val Recall: 0.6252\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6144 - loss: 0.3537 - precision: 0.6124 - recall: 0.6111 - val_accuracy: 0.6019 - val_loss: 0.7018 - val_precision: 0.5974 - val_recall: 0.6252\n",
      "Epoch 1507/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6238 - loss: 0.3426 - precision: 0.6244 - recall: 0.6246\n",
      "Epoch 1507 - Train Recall: 0.6173 - Val Recall: 0.6957\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6229 - loss: 0.3428 - precision: 0.6234 - recall: 0.6241 - val_accuracy: 0.6064 - val_loss: 0.6859 - val_precision: 0.5903 - val_recall: 0.6957\n",
      "Epoch 1508/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6158 - loss: 0.3581 - precision: 0.6306 - recall: 0.5897\n",
      "Epoch 1508 - Train Recall: 0.5862 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6155 - loss: 0.3582 - precision: 0.6292 - recall: 0.5894 - val_accuracy: 0.5907 - val_loss: 0.7214 - val_precision: 0.5918 - val_recall: 0.5847\n",
      "Epoch 1509/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6213 - loss: 0.3370 - precision: 0.6204 - recall: 0.6174\n",
      "Epoch 1509 - Train Recall: 0.6192 - Val Recall: 0.5622\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6213 - loss: 0.3370 - precision: 0.6203 - recall: 0.6174 - val_accuracy: 0.5855 - val_loss: 0.6797 - val_precision: 0.5896 - val_recall: 0.5622\n",
      "Epoch 1510/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6163 - loss: 0.3231 - precision: 0.6138 - recall: 0.6332\n",
      "Epoch 1510 - Train Recall: 0.6514 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6163 - loss: 0.3231 - precision: 0.6134 - recall: 0.6344 - val_accuracy: 0.6064 - val_loss: 0.6488 - val_precision: 0.5927 - val_recall: 0.6807\n",
      "Epoch 1511/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6143 - loss: 0.3475 - precision: 0.6122 - recall: 0.6492\n",
      "Epoch 1511 - Train Recall: 0.6394 - Val Recall: 0.6312\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6142 - loss: 0.3475 - precision: 0.6118 - recall: 0.6485 - val_accuracy: 0.6192 - val_loss: 0.6864 - val_precision: 0.6164 - val_recall: 0.6312\n",
      "Epoch 1512/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6200 - loss: 0.3353 - precision: 0.6131 - recall: 0.6520\n",
      "Epoch 1512 - Train Recall: 0.6349 - Val Recall: 0.5817\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6197 - loss: 0.3354 - precision: 0.6130 - recall: 0.6511 - val_accuracy: 0.5907 - val_loss: 0.6824 - val_precision: 0.5924 - val_recall: 0.5817\n",
      "Epoch 1513/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6158 - loss: 0.3238 - precision: 0.5906 - recall: 0.6720\n",
      "Epoch 1513 - Train Recall: 0.6747 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6159 - loss: 0.3238 - precision: 0.5915 - recall: 0.6721 - val_accuracy: 0.6049 - val_loss: 0.6529 - val_precision: 0.6036 - val_recall: 0.6117\n",
      "Epoch 1514/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6218 - loss: 0.3211 - precision: 0.6055 - recall: 0.6925\n",
      "Epoch 1514 - Train Recall: 0.6810 - Val Recall: 0.6087\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6211 - loss: 0.3212 - precision: 0.6049 - recall: 0.6919 - val_accuracy: 0.6012 - val_loss: 0.6429 - val_precision: 0.5997 - val_recall: 0.6087\n",
      "Epoch 1515/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6089 - loss: 0.3195 - precision: 0.5897 - recall: 0.6881\n",
      "Epoch 1515 - Train Recall: 0.7028 - Val Recall: 0.6702\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6096 - loss: 0.3196 - precision: 0.5907 - recall: 0.6899 - val_accuracy: 0.6072 - val_loss: 0.6355 - val_precision: 0.5952 - val_recall: 0.6702\n",
      "Epoch 1516/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6122 - loss: 0.3286 - precision: 0.5788 - recall: 0.6883\n",
      "Epoch 1516 - Train Recall: 0.6792 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6123 - loss: 0.3287 - precision: 0.5801 - recall: 0.6877 - val_accuracy: 0.5907 - val_loss: 0.6627 - val_precision: 0.5830 - val_recall: 0.6372\n",
      "Epoch 1517/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6183 - loss: 0.3247 - precision: 0.6027 - recall: 0.6701\n",
      "Epoch 1517 - Train Recall: 0.6593 - Val Recall: 0.7451\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6171 - loss: 0.3252 - precision: 0.6020 - recall: 0.6690 - val_accuracy: 0.5937 - val_loss: 0.6560 - val_precision: 0.5719 - val_recall: 0.7451\n",
      "Epoch 1518/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6169 - loss: 0.3618 - precision: 0.6073 - recall: 0.6486\n",
      "Epoch 1518 - Train Recall: 0.6293 - Val Recall: 0.5757\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6169 - loss: 0.3618 - precision: 0.6073 - recall: 0.6483 - val_accuracy: 0.5990 - val_loss: 0.7228 - val_precision: 0.6038 - val_recall: 0.5757\n",
      "Epoch 1519/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6113 - loss: 0.3240 - precision: 0.6125 - recall: 0.6142\n",
      "Epoch 1519 - Train Recall: 0.6357 - Val Recall: 0.7016\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6115 - loss: 0.3240 - precision: 0.6124 - recall: 0.6152 - val_accuracy: 0.5690 - val_loss: 0.6516 - val_precision: 0.5545 - val_recall: 0.7016\n",
      "Epoch 1520/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6135 - loss: 0.3553 - precision: 0.6155 - recall: 0.6182\n",
      "Epoch 1520 - Train Recall: 0.6053 - Val Recall: 0.5697\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6133 - loss: 0.3553 - precision: 0.6152 - recall: 0.6176 - val_accuracy: 0.5975 - val_loss: 0.7035 - val_precision: 0.6032 - val_recall: 0.5697\n",
      "Epoch 1521/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6156 - loss: 0.3280 - precision: 0.6194 - recall: 0.6179\n",
      "Epoch 1521 - Train Recall: 0.6233 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6153 - loss: 0.3282 - precision: 0.6183 - recall: 0.6185 - val_accuracy: 0.6169 - val_loss: 0.6619 - val_precision: 0.6185 - val_recall: 0.6102\n",
      "Epoch 1522/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6109 - loss: 0.3364 - precision: 0.6010 - recall: 0.6496\n",
      "Epoch 1522 - Train Recall: 0.6555 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6108 - loss: 0.3363 - precision: 0.6009 - recall: 0.6501 - val_accuracy: 0.6072 - val_loss: 0.6674 - val_precision: 0.5989 - val_recall: 0.6492\n",
      "Epoch 1523/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6133 - loss: 0.3352 - precision: 0.6068 - recall: 0.6627\n",
      "Epoch 1523 - Train Recall: 0.6548 - Val Recall: 0.5802\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6131 - loss: 0.3354 - precision: 0.6064 - recall: 0.6619 - val_accuracy: 0.5937 - val_loss: 0.6754 - val_precision: 0.5963 - val_recall: 0.5802\n",
      "Epoch 1524/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6194 - loss: 0.3202 - precision: 0.6182 - recall: 0.6577\n",
      "Epoch 1524 - Train Recall: 0.6837 - Val Recall: 0.7571\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6183 - loss: 0.3203 - precision: 0.6157 - recall: 0.6604 - val_accuracy: 0.5877 - val_loss: 0.6381 - val_precision: 0.5655 - val_recall: 0.7571\n",
      "Epoch 1525/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6199 - loss: 0.3544 - precision: 0.6098 - recall: 0.6790\n",
      "Epoch 1525 - Train Recall: 0.6406 - Val Recall: 0.5922\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6196 - loss: 0.3545 - precision: 0.6097 - recall: 0.6776 - val_accuracy: 0.5952 - val_loss: 0.7126 - val_precision: 0.5958 - val_recall: 0.5922\n",
      "Epoch 1526/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6058 - loss: 0.3290 - precision: 0.5964 - recall: 0.6279\n",
      "Epoch 1526 - Train Recall: 0.6462 - Val Recall: 0.7091\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6059 - loss: 0.3289 - precision: 0.5965 - recall: 0.6281 - val_accuracy: 0.5937 - val_loss: 0.6549 - val_precision: 0.5761 - val_recall: 0.7091\n",
      "Epoch 1527/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6016 - loss: 0.3568 - precision: 0.5903 - recall: 0.6386\n",
      "Epoch 1527 - Train Recall: 0.6286 - Val Recall: 0.6402\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6017 - loss: 0.3568 - precision: 0.5905 - recall: 0.6385 - val_accuracy: 0.6132 - val_loss: 0.7108 - val_precision: 0.6074 - val_recall: 0.6402\n",
      "Epoch 1528/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5951 - loss: 0.3448 - precision: 0.5915 - recall: 0.5855\n",
      "Epoch 1528 - Train Recall: 0.6229 - Val Recall: 0.5802\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5955 - loss: 0.3448 - precision: 0.5919 - recall: 0.5866 - val_accuracy: 0.5982 - val_loss: 0.6827 - val_precision: 0.6019 - val_recall: 0.5802\n",
      "Epoch 1529/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6263 - loss: 0.3243 - precision: 0.6253 - recall: 0.6458\n",
      "Epoch 1529 - Train Recall: 0.6387 - Val Recall: 0.5952\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6260 - loss: 0.3244 - precision: 0.6249 - recall: 0.6456 - val_accuracy: 0.5817 - val_loss: 0.6559 - val_precision: 0.5796 - val_recall: 0.5952\n",
      "Epoch 1530/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6076 - loss: 0.3276 - precision: 0.5956 - recall: 0.6818\n",
      "Epoch 1530 - Train Recall: 0.6724 - Val Recall: 0.6657\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6078 - loss: 0.3276 - precision: 0.5958 - recall: 0.6808 - val_accuracy: 0.6117 - val_loss: 0.6507 - val_precision: 0.6008 - val_recall: 0.6657\n",
      "Epoch 1531/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6026 - loss: 0.3375 - precision: 0.5863 - recall: 0.6483\n",
      "Epoch 1531 - Train Recall: 0.6503 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6026 - loss: 0.3375 - precision: 0.5863 - recall: 0.6483 - val_accuracy: 0.5930 - val_loss: 0.6779 - val_precision: 0.5881 - val_recall: 0.6207\n",
      "Epoch 1532/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6076 - loss: 0.3309 - precision: 0.5951 - recall: 0.6638\n",
      "Epoch 1532 - Train Recall: 0.6559 - Val Recall: 0.7166\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6074 - loss: 0.3310 - precision: 0.5951 - recall: 0.6634 - val_accuracy: 0.5945 - val_loss: 0.6600 - val_precision: 0.5759 - val_recall: 0.7166\n",
      "Epoch 1533/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.3538 - precision: 0.5946 - recall: 0.6287\n",
      "Epoch 1533 - Train Recall: 0.6271 - Val Recall: 0.5742\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 0.3538 - precision: 0.5948 - recall: 0.6287 - val_accuracy: 0.6027 - val_loss: 0.7059 - val_precision: 0.6089 - val_recall: 0.5742\n",
      "Epoch 1534/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6129 - loss: 0.3241 - precision: 0.5977 - recall: 0.6207\n",
      "Epoch 1534 - Train Recall: 0.6289 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6129 - loss: 0.3241 - precision: 0.5978 - recall: 0.6207 - val_accuracy: 0.6042 - val_loss: 0.6472 - val_precision: 0.5923 - val_recall: 0.6687\n",
      "Epoch 1535/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6205 - loss: 0.3460 - precision: 0.6095 - recall: 0.6787\n",
      "Epoch 1535 - Train Recall: 0.6428 - Val Recall: 0.6612\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6199 - loss: 0.3464 - precision: 0.6091 - recall: 0.6757 - val_accuracy: 0.6034 - val_loss: 0.6983 - val_precision: 0.5927 - val_recall: 0.6612\n",
      "Epoch 1536/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6160 - loss: 0.3418 - precision: 0.6163 - recall: 0.6412\n",
      "Epoch 1536 - Train Recall: 0.6278 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6160 - loss: 0.3418 - precision: 0.6162 - recall: 0.6411 - val_accuracy: 0.5997 - val_loss: 0.6892 - val_precision: 0.5982 - val_recall: 0.6072\n",
      "Epoch 1537/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6172 - loss: 0.3317 - precision: 0.6167 - recall: 0.6162\n",
      "Epoch 1537 - Train Recall: 0.6259 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6171 - loss: 0.3317 - precision: 0.6165 - recall: 0.6164 - val_accuracy: 0.6004 - val_loss: 0.6654 - val_precision: 0.6000 - val_recall: 0.6027\n",
      "Epoch 1538/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6050 - loss: 0.3307 - precision: 0.5906 - recall: 0.6467\n",
      "Epoch 1538 - Train Recall: 0.6432 - Val Recall: 0.6957\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6051 - loss: 0.3308 - precision: 0.5910 - recall: 0.6465 - val_accuracy: 0.5997 - val_loss: 0.6689 - val_precision: 0.5836 - val_recall: 0.6957\n",
      "Epoch 1539/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6273 - loss: 0.3499 - precision: 0.6332 - recall: 0.6275\n",
      "Epoch 1539 - Train Recall: 0.6173 - Val Recall: 0.4828\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6267 - loss: 0.3501 - precision: 0.6322 - recall: 0.6267 - val_accuracy: 0.5750 - val_loss: 0.7098 - val_precision: 0.5919 - val_recall: 0.4828\n",
      "Epoch 1540/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6089 - loss: 0.3041 - precision: 0.6065 - recall: 0.6139\n",
      "Epoch 1540 - Train Recall: 0.6574 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6093 - loss: 0.3037 - precision: 0.6060 - recall: 0.6197 - val_accuracy: 0.5997 - val_loss: 0.5988 - val_precision: 0.5851 - val_recall: 0.6852\n",
      "Epoch 1541/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6018 - loss: 0.3510 - precision: 0.5948 - recall: 0.6439\n",
      "Epoch 1541 - Train Recall: 0.6394 - Val Recall: 0.5232\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6024 - loss: 0.3508 - precision: 0.5955 - recall: 0.6436 - val_accuracy: 0.6004 - val_loss: 0.6897 - val_precision: 0.6188 - val_recall: 0.5232\n",
      "Epoch 1542/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5973 - loss: 0.3106 - precision: 0.5835 - recall: 0.6355\n",
      "Epoch 1542 - Train Recall: 0.6765 - Val Recall: 0.5997\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5979 - loss: 0.3104 - precision: 0.5842 - recall: 0.6376 - val_accuracy: 0.6012 - val_loss: 0.6161 - val_precision: 0.6015 - val_recall: 0.5997\n",
      "Epoch 1543/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6091 - loss: 0.3161 - precision: 0.5863 - recall: 0.7013\n",
      "Epoch 1543 - Train Recall: 0.7084 - Val Recall: 0.7241\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6091 - loss: 0.3162 - precision: 0.5864 - recall: 0.7014 - val_accuracy: 0.6019 - val_loss: 0.6355 - val_precision: 0.5819 - val_recall: 0.7241\n",
      "Epoch 1544/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6170 - loss: 0.3403 - precision: 0.6017 - recall: 0.6967\n",
      "Epoch 1544 - Train Recall: 0.6777 - Val Recall: 0.5952\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6169 - loss: 0.3404 - precision: 0.6016 - recall: 0.6962 - val_accuracy: 0.5892 - val_loss: 0.6870 - val_precision: 0.5881 - val_recall: 0.5952\n",
      "Epoch 1545/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6206 - loss: 0.3179 - precision: 0.6225 - recall: 0.6763\n",
      "Epoch 1545 - Train Recall: 0.6904 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6205 - loss: 0.3179 - precision: 0.6207 - recall: 0.6777 - val_accuracy: 0.5922 - val_loss: 0.6445 - val_precision: 0.5898 - val_recall: 0.6057\n",
      "Epoch 1546/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6077 - loss: 0.3186 - precision: 0.5898 - recall: 0.6978\n",
      "Epoch 1546 - Train Recall: 0.7061 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6076 - loss: 0.3186 - precision: 0.5896 - recall: 0.6980 - val_accuracy: 0.5870 - val_loss: 0.6416 - val_precision: 0.5775 - val_recall: 0.6477\n",
      "Epoch 1547/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6182 - loss: 0.3238 - precision: 0.6023 - recall: 0.7259\n",
      "Epoch 1547 - Train Recall: 0.7193 - Val Recall: 0.7661\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6181 - loss: 0.3238 - precision: 0.6021 - recall: 0.7257 - val_accuracy: 0.6139 - val_loss: 0.6477 - val_precision: 0.5874 - val_recall: 0.7661\n",
      "Epoch 1548/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6195 - loss: 0.3487 - precision: 0.6000 - recall: 0.6622\n",
      "Epoch 1548 - Train Recall: 0.6383 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6193 - loss: 0.3488 - precision: 0.6001 - recall: 0.6615 - val_accuracy: 0.6034 - val_loss: 0.6970 - val_precision: 0.5938 - val_recall: 0.6552\n",
      "Epoch 1549/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6259 - loss: 0.3415 - precision: 0.6237 - recall: 0.6307\n",
      "Epoch 1549 - Train Recall: 0.6248 - Val Recall: 0.6222\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6251 - loss: 0.3417 - precision: 0.6230 - recall: 0.6301 - val_accuracy: 0.6049 - val_loss: 0.6873 - val_precision: 0.6014 - val_recall: 0.6222\n",
      "Epoch 1550/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6275 - loss: 0.3353 - precision: 0.6213 - recall: 0.6455\n",
      "Epoch 1550 - Train Recall: 0.6301 - Val Recall: 0.6417\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6267 - loss: 0.3354 - precision: 0.6207 - recall: 0.6448 - val_accuracy: 0.6154 - val_loss: 0.6783 - val_precision: 0.6097 - val_recall: 0.6417\n",
      "Epoch 1551/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6185 - loss: 0.3409 - precision: 0.6210 - recall: 0.6268\n",
      "Epoch 1551 - Train Recall: 0.6166 - Val Recall: 0.6702\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6178 - loss: 0.3410 - precision: 0.6198 - recall: 0.6255 - val_accuracy: 0.5982 - val_loss: 0.6871 - val_precision: 0.5858 - val_recall: 0.6702\n",
      "Epoch 1552/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6161 - loss: 0.3547 - precision: 0.6206 - recall: 0.6066\n",
      "Epoch 1552 - Train Recall: 0.5963 - Val Recall: 0.5997\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6162 - loss: 0.3545 - precision: 0.6206 - recall: 0.6060 - val_accuracy: 0.6064 - val_loss: 0.7067 - val_precision: 0.6079 - val_recall: 0.5997\n",
      "Epoch 1553/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6200 - loss: 0.3397 - precision: 0.6132 - recall: 0.6034\n",
      "Epoch 1553 - Train Recall: 0.6027 - Val Recall: 0.6822\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6197 - loss: 0.3398 - precision: 0.6132 - recall: 0.6034 - val_accuracy: 0.6064 - val_loss: 0.6757 - val_precision: 0.5924 - val_recall: 0.6822\n",
      "Epoch 1554/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6048 - loss: 0.3593 - precision: 0.6029 - recall: 0.6059\n",
      "Epoch 1554 - Train Recall: 0.5843 - Val Recall: 0.5952\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6054 - loss: 0.3595 - precision: 0.6042 - recall: 0.6034 - val_accuracy: 0.5907 - val_loss: 0.7201 - val_precision: 0.5899 - val_recall: 0.5952\n",
      "Epoch 1555/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6134 - loss: 0.3415 - precision: 0.6268 - recall: 0.5698\n",
      "Epoch 1555 - Train Recall: 0.5832 - Val Recall: 0.5652\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6126 - loss: 0.3416 - precision: 0.6253 - recall: 0.5708 - val_accuracy: 0.5990 - val_loss: 0.6839 - val_precision: 0.6061 - val_recall: 0.5652\n",
      "Epoch 1556/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6189 - loss: 0.3349 - precision: 0.6218 - recall: 0.6092\n",
      "Epoch 1556 - Train Recall: 0.6278 - Val Recall: 0.6522\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6190 - loss: 0.3348 - precision: 0.6215 - recall: 0.6108 - val_accuracy: 0.6004 - val_loss: 0.6677 - val_precision: 0.5910 - val_recall: 0.6522\n",
      "Epoch 1557/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6249 - loss: 0.3416 - precision: 0.6108 - recall: 0.6483\n",
      "Epoch 1557 - Train Recall: 0.6154 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6241 - loss: 0.3419 - precision: 0.6108 - recall: 0.6461 - val_accuracy: 0.5982 - val_loss: 0.6933 - val_precision: 0.5973 - val_recall: 0.6027\n",
      "Epoch 1558/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6211 - loss: 0.3342 - precision: 0.6287 - recall: 0.6070\n",
      "Epoch 1558 - Train Recall: 0.6207 - Val Recall: 0.5832\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6207 - loss: 0.3343 - precision: 0.6275 - recall: 0.6082 - val_accuracy: 0.5900 - val_loss: 0.6732 - val_precision: 0.5912 - val_recall: 0.5832\n",
      "Epoch 1559/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6107 - loss: 0.3292 - precision: 0.6068 - recall: 0.6267\n",
      "Epoch 1559 - Train Recall: 0.6458 - Val Recall: 0.7316\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6106 - loss: 0.3292 - precision: 0.6064 - recall: 0.6290 - val_accuracy: 0.5885 - val_loss: 0.6604 - val_precision: 0.5688 - val_recall: 0.7316\n",
      "Epoch 1560/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6188 - loss: 0.3579 - precision: 0.6135 - recall: 0.6386\n",
      "Epoch 1560 - Train Recall: 0.6076 - Val Recall: 0.5997\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.3581 - precision: 0.6138 - recall: 0.6371 - val_accuracy: 0.6027 - val_loss: 0.7179 - val_precision: 0.6033 - val_recall: 0.5997\n",
      "Epoch 1561/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6133 - loss: 0.3378 - precision: 0.6114 - recall: 0.5904\n",
      "Epoch 1561 - Train Recall: 0.6023 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6126 - loss: 0.3378 - precision: 0.6112 - recall: 0.5917 - val_accuracy: 0.5742 - val_loss: 0.6820 - val_precision: 0.5702 - val_recall: 0.6027\n",
      "Epoch 1562/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6078 - loss: 0.3394 - precision: 0.6048 - recall: 0.6216\n",
      "Epoch 1562 - Train Recall: 0.6327 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6083 - loss: 0.3394 - precision: 0.6052 - recall: 0.6224 - val_accuracy: 0.6132 - val_loss: 0.6729 - val_precision: 0.6047 - val_recall: 0.6537\n",
      "Epoch 1563/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6235 - loss: 0.3393 - precision: 0.6226 - recall: 0.6343\n",
      "Epoch 1563 - Train Recall: 0.6057 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6213 - loss: 0.3401 - precision: 0.6205 - recall: 0.6303 - val_accuracy: 0.6139 - val_loss: 0.6819 - val_precision: 0.6064 - val_recall: 0.6492\n",
      "Epoch 1564/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6221 - loss: 0.3502 - precision: 0.6244 - recall: 0.6131\n",
      "Epoch 1564 - Train Recall: 0.6023 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6211 - loss: 0.3504 - precision: 0.6235 - recall: 0.6117 - val_accuracy: 0.6162 - val_loss: 0.6961 - val_precision: 0.6060 - val_recall: 0.6642\n",
      "Epoch 1565/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6209 - loss: 0.3522 - precision: 0.6174 - recall: 0.6032\n",
      "Epoch 1565 - Train Recall: 0.5798 - Val Recall: 0.5832\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6207 - loss: 0.3523 - precision: 0.6176 - recall: 0.6025 - val_accuracy: 0.6042 - val_loss: 0.7037 - val_precision: 0.6088 - val_recall: 0.5832\n",
      "Epoch 1566/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6033 - loss: 0.3404 - precision: 0.5993 - recall: 0.5914\n",
      "Epoch 1566 - Train Recall: 0.5941 - Val Recall: 0.6732\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6035 - loss: 0.3404 - precision: 0.5996 - recall: 0.5914 - val_accuracy: 0.6147 - val_loss: 0.6743 - val_precision: 0.6027 - val_recall: 0.6732\n",
      "Epoch 1567/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6113 - loss: 0.3596 - precision: 0.6117 - recall: 0.6137\n",
      "Epoch 1567 - Train Recall: 0.5937 - Val Recall: 0.5892\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6113 - loss: 0.3597 - precision: 0.6120 - recall: 0.6119 - val_accuracy: 0.6049 - val_loss: 0.7189 - val_precision: 0.6084 - val_recall: 0.5892\n",
      "Epoch 1568/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6048 - loss: 0.3375 - precision: 0.6051 - recall: 0.5836\n",
      "Epoch 1568 - Train Recall: 0.5993 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6049 - loss: 0.3375 - precision: 0.6052 - recall: 0.5839 - val_accuracy: 0.6139 - val_loss: 0.6727 - val_precision: 0.6067 - val_recall: 0.6477\n",
      "Epoch 1569/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6147 - loss: 0.3505 - precision: 0.6143 - recall: 0.6118\n",
      "Epoch 1569 - Train Recall: 0.6079 - Val Recall: 0.4933\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6151 - loss: 0.3507 - precision: 0.6155 - recall: 0.6114 - val_accuracy: 0.5862 - val_loss: 0.7092 - val_precision: 0.6059 - val_recall: 0.4933\n",
      "Epoch 1570/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6154 - loss: 0.3086 - precision: 0.6197 - recall: 0.6313\n",
      "Epoch 1570 - Train Recall: 0.6582 - Val Recall: 0.7106\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6150 - loss: 0.3086 - precision: 0.6180 - recall: 0.6337 - val_accuracy: 0.6094 - val_loss: 0.6079 - val_precision: 0.5910 - val_recall: 0.7106\n",
      "Epoch 1571/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6308 - loss: 0.3486 - precision: 0.6163 - recall: 0.7016\n",
      "Epoch 1571 - Train Recall: 0.6525 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6300 - loss: 0.3488 - precision: 0.6158 - recall: 0.6987 - val_accuracy: 0.6019 - val_loss: 0.7050 - val_precision: 0.6000 - val_recall: 0.6117\n",
      "Epoch 1572/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6133 - loss: 0.3271 - precision: 0.6127 - recall: 0.6393\n",
      "Epoch 1572 - Train Recall: 0.6443 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6133 - loss: 0.3271 - precision: 0.6125 - recall: 0.6394 - val_accuracy: 0.6042 - val_loss: 0.6612 - val_precision: 0.5964 - val_recall: 0.6447\n",
      "Epoch 1573/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5972 - loss: 0.3433 - precision: 0.5897 - recall: 0.6394\n",
      "Epoch 1573 - Train Recall: 0.6334 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5984 - loss: 0.3431 - precision: 0.5912 - recall: 0.6388 - val_accuracy: 0.6124 - val_loss: 0.6777 - val_precision: 0.6126 - val_recall: 0.6117\n",
      "Epoch 1574/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6140 - loss: 0.3330 - precision: 0.6016 - recall: 0.6433\n",
      "Epoch 1574 - Train Recall: 0.6413 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6134 - loss: 0.3332 - precision: 0.6017 - recall: 0.6429 - val_accuracy: 0.6102 - val_loss: 0.6679 - val_precision: 0.6046 - val_recall: 0.6372\n",
      "Epoch 1575/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6227 - loss: 0.3355 - precision: 0.6118 - recall: 0.6639\n",
      "Epoch 1575 - Train Recall: 0.6544 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6222 - loss: 0.3356 - precision: 0.6114 - recall: 0.6632 - val_accuracy: 0.6004 - val_loss: 0.6744 - val_precision: 0.5933 - val_recall: 0.6387\n",
      "Epoch 1576/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6142 - loss: 0.3332 - precision: 0.6016 - recall: 0.6470\n",
      "Epoch 1576 - Train Recall: 0.6409 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6144 - loss: 0.3333 - precision: 0.6021 - recall: 0.6467 - val_accuracy: 0.6094 - val_loss: 0.6684 - val_precision: 0.6055 - val_recall: 0.6282\n",
      "Epoch 1577/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6242 - loss: 0.3366 - precision: 0.6103 - recall: 0.6543\n",
      "Epoch 1577 - Train Recall: 0.6510 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6238 - loss: 0.3364 - precision: 0.6104 - recall: 0.6538 - val_accuracy: 0.6072 - val_loss: 0.6688 - val_precision: 0.5981 - val_recall: 0.6537\n",
      "Epoch 1578/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6138 - loss: 0.3386 - precision: 0.6008 - recall: 0.6613\n",
      "Epoch 1578 - Train Recall: 0.6496 - Val Recall: 0.7211\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6139 - loss: 0.3387 - precision: 0.6013 - recall: 0.6606 - val_accuracy: 0.6049 - val_loss: 0.6859 - val_precision: 0.5852 - val_recall: 0.7211\n",
      "Epoch 1579/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6141 - loss: 0.3571 - precision: 0.6182 - recall: 0.6232\n",
      "Epoch 1579 - Train Recall: 0.6124 - Val Recall: 0.4723\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6148 - loss: 0.3571 - precision: 0.6188 - recall: 0.6219 - val_accuracy: 0.5877 - val_loss: 0.7147 - val_precision: 0.6140 - val_recall: 0.4723\n",
      "Epoch 1580/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6189 - loss: 0.3004 - precision: 0.6270 - recall: 0.6208\n",
      "Epoch 1580 - Train Recall: 0.6698 - Val Recall: 0.7466\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6186 - loss: 0.3004 - precision: 0.6249 - recall: 0.6253 - val_accuracy: 0.5892 - val_loss: 0.5980 - val_precision: 0.5678 - val_recall: 0.7466\n",
      "Epoch 1581/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6223 - loss: 0.3566 - precision: 0.6102 - recall: 0.6973\n",
      "Epoch 1581 - Train Recall: 0.6555 - Val Recall: 0.5457\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6223 - loss: 0.3567 - precision: 0.6101 - recall: 0.6971 - val_accuracy: 0.6034 - val_loss: 0.7185 - val_precision: 0.6169 - val_recall: 0.5457\n",
      "Epoch 1582/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6157 - loss: 0.3120 - precision: 0.6194 - recall: 0.6139\n",
      "Epoch 1582 - Train Recall: 0.6499 - Val Recall: 0.6927\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6153 - loss: 0.3120 - precision: 0.6182 - recall: 0.6163 - val_accuracy: 0.6102 - val_loss: 0.6140 - val_precision: 0.5946 - val_recall: 0.6927\n",
      "Epoch 1583/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6123 - loss: 0.3505 - precision: 0.6076 - recall: 0.6732\n",
      "Epoch 1583 - Train Recall: 0.6510 - Val Recall: 0.5727\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6124 - loss: 0.3505 - precision: 0.6075 - recall: 0.6721 - val_accuracy: 0.6004 - val_loss: 0.6943 - val_precision: 0.6063 - val_recall: 0.5727\n",
      "Epoch 1584/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6131 - loss: 0.3181 - precision: 0.6181 - recall: 0.6269\n",
      "Epoch 1584 - Train Recall: 0.6469 - Val Recall: 0.6942\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6133 - loss: 0.3181 - precision: 0.6180 - recall: 0.6274 - val_accuracy: 0.6087 - val_loss: 0.6335 - val_precision: 0.5928 - val_recall: 0.6942\n",
      "Epoch 1585/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6237 - loss: 0.3486 - precision: 0.6280 - recall: 0.6617\n",
      "Epoch 1585 - Train Recall: 0.6368 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6225 - loss: 0.3489 - precision: 0.6259 - recall: 0.6598 - val_accuracy: 0.5960 - val_loss: 0.6977 - val_precision: 0.6032 - val_recall: 0.5607\n",
      "Epoch 1586/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6270 - loss: 0.3147 - precision: 0.6159 - recall: 0.6429\n",
      "Epoch 1586 - Train Recall: 0.6394 - Val Recall: 0.7316\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6266 - loss: 0.3148 - precision: 0.6157 - recall: 0.6428 - val_accuracy: 0.6124 - val_loss: 0.6316 - val_precision: 0.5908 - val_recall: 0.7316\n",
      "Epoch 1587/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6224 - loss: 0.3569 - precision: 0.6255 - recall: 0.6541\n",
      "Epoch 1587 - Train Recall: 0.6139 - Val Recall: 0.5517\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6218 - loss: 0.3573 - precision: 0.6246 - recall: 0.6520 - val_accuracy: 0.6027 - val_loss: 0.7223 - val_precision: 0.6144 - val_recall: 0.5517\n",
      "Epoch 1588/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6235 - loss: 0.3188 - precision: 0.6168 - recall: 0.6196\n",
      "Epoch 1588 - Train Recall: 0.6353 - Val Recall: 0.6927\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6233 - loss: 0.3189 - precision: 0.6167 - recall: 0.6200 - val_accuracy: 0.5952 - val_loss: 0.6468 - val_precision: 0.5797 - val_recall: 0.6927\n",
      "Epoch 1589/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6210 - loss: 0.3560 - precision: 0.6150 - recall: 0.6559\n",
      "Epoch 1589 - Train Recall: 0.6394 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6213 - loss: 0.3557 - precision: 0.6155 - recall: 0.6542 - val_accuracy: 0.6027 - val_loss: 0.7093 - val_precision: 0.5969 - val_recall: 0.6327\n",
      "Epoch 1590/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6212 - loss: 0.3353 - precision: 0.6269 - recall: 0.6236\n",
      "Epoch 1590 - Train Recall: 0.6267 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6208 - loss: 0.3354 - precision: 0.6259 - recall: 0.6239 - val_accuracy: 0.6274 - val_loss: 0.6697 - val_precision: 0.6232 - val_recall: 0.6447\n",
      "Epoch 1591/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6086 - loss: 0.3439 - precision: 0.5943 - recall: 0.6277\n",
      "Epoch 1591 - Train Recall: 0.6177 - Val Recall: 0.5202\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6084 - loss: 0.3441 - precision: 0.5949 - recall: 0.6270 - val_accuracy: 0.5997 - val_loss: 0.6896 - val_precision: 0.6185 - val_recall: 0.5202\n",
      "Epoch 1592/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6225 - loss: 0.3102 - precision: 0.6131 - recall: 0.6556\n",
      "Epoch 1592 - Train Recall: 0.6724 - Val Recall: 0.7241\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6218 - loss: 0.3104 - precision: 0.6122 - recall: 0.6569 - val_accuracy: 0.6049 - val_loss: 0.6179 - val_precision: 0.5847 - val_recall: 0.7241\n",
      "Epoch 1593/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6171 - loss: 0.3496 - precision: 0.6075 - recall: 0.6685\n",
      "Epoch 1593 - Train Recall: 0.6372 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6168 - loss: 0.3497 - precision: 0.6072 - recall: 0.6676 - val_accuracy: 0.6034 - val_loss: 0.7034 - val_precision: 0.5975 - val_recall: 0.6342\n",
      "Epoch 1594/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6152 - loss: 0.3365 - precision: 0.6029 - recall: 0.6306\n",
      "Epoch 1594 - Train Recall: 0.6121 - Val Recall: 0.5952\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6143 - loss: 0.3368 - precision: 0.6030 - recall: 0.6290 - val_accuracy: 0.6072 - val_loss: 0.6715 - val_precision: 0.6098 - val_recall: 0.5952\n",
      "Epoch 1595/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6191 - loss: 0.3329 - precision: 0.6197 - recall: 0.6127\n",
      "Epoch 1595 - Train Recall: 0.6289 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6191 - loss: 0.3329 - precision: 0.6196 - recall: 0.6128 - val_accuracy: 0.6027 - val_loss: 0.6667 - val_precision: 0.5932 - val_recall: 0.6537\n",
      "Epoch 1596/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6254 - loss: 0.3425 - precision: 0.5991 - recall: 0.6401\n",
      "Epoch 1596 - Train Recall: 0.6214 - Val Recall: 0.6762\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6247 - loss: 0.3429 - precision: 0.6016 - recall: 0.6377 - val_accuracy: 0.6004 - val_loss: 0.6954 - val_precision: 0.5872 - val_recall: 0.6762\n",
      "Epoch 1597/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6102 - loss: 0.3567 - precision: 0.6036 - recall: 0.6191\n",
      "Epoch 1597 - Train Recall: 0.6109 - Val Recall: 0.6192\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6106 - loss: 0.3564 - precision: 0.6049 - recall: 0.6181 - val_accuracy: 0.5952 - val_loss: 0.7149 - val_precision: 0.5908 - val_recall: 0.6192\n",
      "Epoch 1598/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6132 - loss: 0.3418 - precision: 0.6198 - recall: 0.6097\n",
      "Epoch 1598 - Train Recall: 0.6139 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6132 - loss: 0.3418 - precision: 0.6194 - recall: 0.6101 - val_accuracy: 0.6192 - val_loss: 0.6767 - val_precision: 0.6276 - val_recall: 0.5862\n",
      "Epoch 1599/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6312 - loss: 0.3295 - precision: 0.6267 - recall: 0.6369\n",
      "Epoch 1599 - Train Recall: 0.6293 - Val Recall: 0.6087\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6306 - loss: 0.3296 - precision: 0.6262 - recall: 0.6366 - val_accuracy: 0.6034 - val_loss: 0.6642 - val_precision: 0.6024 - val_recall: 0.6087\n",
      "Epoch 1600/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6271 - loss: 0.3310 - precision: 0.6172 - recall: 0.6583\n",
      "Epoch 1600 - Train Recall: 0.6585 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6264 - loss: 0.3312 - precision: 0.6166 - recall: 0.6585 - val_accuracy: 0.5907 - val_loss: 0.6703 - val_precision: 0.5787 - val_recall: 0.6672\n",
      "Epoch 1601/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5977 - loss: 0.3442 - precision: 0.5855 - recall: 0.6259\n",
      "Epoch 1601 - Train Recall: 0.6312 - Val Recall: 0.6297\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 0.3440 - precision: 0.5877 - recall: 0.6265 - val_accuracy: 0.6102 - val_loss: 0.6827 - val_precision: 0.6061 - val_recall: 0.6297\n",
      "Epoch 1602/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6151 - loss: 0.3369 - precision: 0.6154 - recall: 0.6385\n",
      "Epoch 1602 - Train Recall: 0.6132 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6149 - loss: 0.3369 - precision: 0.6151 - recall: 0.6379 - val_accuracy: 0.6237 - val_loss: 0.6734 - val_precision: 0.6167 - val_recall: 0.6537\n",
      "Epoch 1603/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6243 - loss: 0.3481 - precision: 0.6190 - recall: 0.6131\n",
      "Epoch 1603 - Train Recall: 0.6012 - Val Recall: 0.5592\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6240 - loss: 0.3482 - precision: 0.6194 - recall: 0.6122 - val_accuracy: 0.6012 - val_loss: 0.6954 - val_precision: 0.6105 - val_recall: 0.5592\n",
      "Epoch 1604/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6115 - loss: 0.3270 - precision: 0.6119 - recall: 0.5937\n",
      "Epoch 1604 - Train Recall: 0.6098 - Val Recall: 0.5787\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6107 - loss: 0.3272 - precision: 0.6112 - recall: 0.5956 - val_accuracy: 0.6019 - val_loss: 0.6535 - val_precision: 0.6069 - val_recall: 0.5787\n",
      "Epoch 1605/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6136 - loss: 0.3295 - precision: 0.6069 - recall: 0.6427\n",
      "Epoch 1605 - Train Recall: 0.6477 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6137 - loss: 0.3296 - precision: 0.6069 - recall: 0.6431 - val_accuracy: 0.6012 - val_loss: 0.6600 - val_precision: 0.5934 - val_recall: 0.6432\n",
      "Epoch 1606/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6164 - loss: 0.3368 - precision: 0.6121 - recall: 0.6590\n",
      "Epoch 1606 - Train Recall: 0.6424 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6160 - loss: 0.3368 - precision: 0.6115 - recall: 0.6582 - val_accuracy: 0.6117 - val_loss: 0.6743 - val_precision: 0.6063 - val_recall: 0.6372\n",
      "Epoch 1607/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6248 - loss: 0.3337 - precision: 0.6141 - recall: 0.6443\n",
      "Epoch 1607 - Train Recall: 0.6349 - Val Recall: 0.5937\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6244 - loss: 0.3338 - precision: 0.6139 - recall: 0.6440 - val_accuracy: 0.5952 - val_loss: 0.6753 - val_precision: 0.5955 - val_recall: 0.5937\n",
      "Epoch 1608/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6191 - loss: 0.3266 - precision: 0.6068 - recall: 0.6513\n",
      "Epoch 1608 - Train Recall: 0.6443 - Val Recall: 0.5907\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6185 - loss: 0.3268 - precision: 0.6068 - recall: 0.6503 - val_accuracy: 0.6049 - val_loss: 0.6614 - val_precision: 0.6080 - val_recall: 0.5907\n",
      "Epoch 1609/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6105 - loss: 0.3234 - precision: 0.6095 - recall: 0.6440\n",
      "Epoch 1609 - Train Recall: 0.6570 - Val Recall: 0.6777\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6107 - loss: 0.3234 - precision: 0.6090 - recall: 0.6451 - val_accuracy: 0.5922 - val_loss: 0.6497 - val_precision: 0.5787 - val_recall: 0.6777\n",
      "Epoch 1610/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6104 - loss: 0.3444 - precision: 0.6003 - recall: 0.6704\n",
      "Epoch 1610 - Train Recall: 0.6518 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6100 - loss: 0.3445 - precision: 0.6001 - recall: 0.6682 - val_accuracy: 0.6042 - val_loss: 0.6847 - val_precision: 0.6003 - val_recall: 0.6237\n",
      "Epoch 1611/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6085 - loss: 0.3327 - precision: 0.5956 - recall: 0.6225\n",
      "Epoch 1611 - Train Recall: 0.6361 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6088 - loss: 0.3326 - precision: 0.5963 - recall: 0.6232 - val_accuracy: 0.5967 - val_loss: 0.6663 - val_precision: 0.5878 - val_recall: 0.6477\n",
      "Epoch 1612/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6031 - loss: 0.3430 - precision: 0.5905 - recall: 0.6466\n",
      "Epoch 1612 - Train Recall: 0.6402 - Val Recall: 0.5382\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6033 - loss: 0.3430 - precision: 0.5914 - recall: 0.6460 - val_accuracy: 0.5847 - val_loss: 0.6861 - val_precision: 0.5934 - val_recall: 0.5382\n",
      "Epoch 1613/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6169 - loss: 0.3093 - precision: 0.5989 - recall: 0.6534\n",
      "Epoch 1613 - Train Recall: 0.6694 - Val Recall: 0.6582\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6168 - loss: 0.3094 - precision: 0.5992 - recall: 0.6541 - val_accuracy: 0.6094 - val_loss: 0.6181 - val_precision: 0.5997 - val_recall: 0.6582\n",
      "Epoch 1614/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6159 - loss: 0.3370 - precision: 0.6129 - recall: 0.6859\n",
      "Epoch 1614 - Train Recall: 0.6713 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6161 - loss: 0.3369 - precision: 0.6122 - recall: 0.6843 - val_accuracy: 0.6019 - val_loss: 0.6695 - val_precision: 0.5939 - val_recall: 0.6447\n",
      "Epoch 1615/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6153 - loss: 0.3315 - precision: 0.6099 - recall: 0.6685\n",
      "Epoch 1615 - Train Recall: 0.6720 - Val Recall: 0.7001\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6153 - loss: 0.3315 - precision: 0.6097 - recall: 0.6686 - val_accuracy: 0.6079 - val_loss: 0.6601 - val_precision: 0.5911 - val_recall: 0.7001\n",
      "Epoch 1616/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6251 - loss: 0.3432 - precision: 0.6246 - recall: 0.6475\n",
      "Epoch 1616 - Train Recall: 0.6443 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6245 - loss: 0.3435 - precision: 0.6234 - recall: 0.6473 - val_accuracy: 0.6117 - val_loss: 0.6921 - val_precision: 0.6151 - val_recall: 0.5967\n",
      "Epoch 1617/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6248 - loss: 0.3246 - precision: 0.6225 - recall: 0.6351\n",
      "Epoch 1617 - Train Recall: 0.6473 - Val Recall: 0.6987\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6232 - loss: 0.3248 - precision: 0.6204 - recall: 0.6366 - val_accuracy: 0.6237 - val_loss: 0.6477 - val_precision: 0.6076 - val_recall: 0.6987\n",
      "Epoch 1618/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6321 - loss: 0.3474 - precision: 0.6046 - recall: 0.6777\n",
      "Epoch 1618 - Train Recall: 0.6173 - Val Recall: 0.6522\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6294 - loss: 0.3480 - precision: 0.6054 - recall: 0.6699 - val_accuracy: 0.5990 - val_loss: 0.7049 - val_precision: 0.5894 - val_recall: 0.6522\n",
      "Epoch 1619/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6230 - loss: 0.3450 - precision: 0.6233 - recall: 0.6483\n",
      "Epoch 1619 - Train Recall: 0.6237 - Val Recall: 0.5982\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6229 - loss: 0.3451 - precision: 0.6232 - recall: 0.6480 - val_accuracy: 0.6012 - val_loss: 0.6958 - val_precision: 0.6018 - val_recall: 0.5982\n",
      "Epoch 1620/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6278 - loss: 0.3288 - precision: 0.6273 - recall: 0.6303\n",
      "Epoch 1620 - Train Recall: 0.6312 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6257 - loss: 0.3293 - precision: 0.6247 - recall: 0.6305 - val_accuracy: 0.6139 - val_loss: 0.6572 - val_precision: 0.6070 - val_recall: 0.6462\n",
      "Epoch 1621/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6259 - loss: 0.3370 - precision: 0.6166 - recall: 0.6631\n",
      "Epoch 1621 - Train Recall: 0.6372 - Val Recall: 0.5997\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6245 - loss: 0.3376 - precision: 0.6157 - recall: 0.6604 - val_accuracy: 0.5997 - val_loss: 0.6869 - val_precision: 0.5997 - val_recall: 0.5997\n",
      "Epoch 1622/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6141 - loss: 0.3281 - precision: 0.6048 - recall: 0.6563\n",
      "Epoch 1622 - Train Recall: 0.6525 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6139 - loss: 0.3282 - precision: 0.6046 - recall: 0.6562 - val_accuracy: 0.6079 - val_loss: 0.6565 - val_precision: 0.6104 - val_recall: 0.5967\n",
      "Epoch 1623/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6358 - loss: 0.3194 - precision: 0.6252 - recall: 0.6813\n",
      "Epoch 1623 - Train Recall: 0.6780 - Val Recall: 0.6582\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6339 - loss: 0.3199 - precision: 0.6231 - recall: 0.6809 - val_accuracy: 0.6207 - val_loss: 0.6466 - val_precision: 0.6123 - val_recall: 0.6582\n",
      "Epoch 1624/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6083 - loss: 0.3340 - precision: 0.5929 - recall: 0.6673\n",
      "Epoch 1624 - Train Recall: 0.6717 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6083 - loss: 0.3340 - precision: 0.5929 - recall: 0.6673 - val_accuracy: 0.5952 - val_loss: 0.6788 - val_precision: 0.5930 - val_recall: 0.6072\n",
      "Epoch 1625/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6112 - loss: 0.3196 - precision: 0.5936 - recall: 0.6619\n",
      "Epoch 1625 - Train Recall: 0.6713 - Val Recall: 0.7091\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6113 - loss: 0.3198 - precision: 0.5941 - recall: 0.6627 - val_accuracy: 0.6124 - val_loss: 0.6394 - val_precision: 0.5942 - val_recall: 0.7091\n",
      "Epoch 1626/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6081 - loss: 0.3479 - precision: 0.5978 - recall: 0.6709\n",
      "Epoch 1626 - Train Recall: 0.6447 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6078 - loss: 0.3480 - precision: 0.5978 - recall: 0.6688 - val_accuracy: 0.5982 - val_loss: 0.6967 - val_precision: 0.5889 - val_recall: 0.6507\n",
      "Epoch 1627/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6192 - loss: 0.3402 - precision: 0.6063 - recall: 0.6284\n",
      "Epoch 1627 - Train Recall: 0.6199 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6195 - loss: 0.3401 - precision: 0.6074 - recall: 0.6280 - val_accuracy: 0.6057 - val_loss: 0.6868 - val_precision: 0.6011 - val_recall: 0.6282\n",
      "Epoch 1628/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6231 - loss: 0.3389 - precision: 0.6198 - recall: 0.6539\n",
      "Epoch 1628 - Train Recall: 0.6357 - Val Recall: 0.5772\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6228 - loss: 0.3390 - precision: 0.6195 - recall: 0.6528 - val_accuracy: 0.5975 - val_loss: 0.6849 - val_precision: 0.6016 - val_recall: 0.5772\n",
      "Epoch 1629/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6283 - loss: 0.3202 - precision: 0.6190 - recall: 0.6552\n",
      "Epoch 1629 - Train Recall: 0.6492 - Val Recall: 0.7526\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6272 - loss: 0.3205 - precision: 0.6181 - recall: 0.6547 - val_accuracy: 0.6237 - val_loss: 0.6464 - val_precision: 0.5983 - val_recall: 0.7526\n",
      "Epoch 1630/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6071 - loss: 0.3646 - precision: 0.6016 - recall: 0.6243\n",
      "Epoch 1630 - Train Recall: 0.5982 - Val Recall: 0.4993\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6074 - loss: 0.3645 - precision: 0.6023 - recall: 0.6232 - val_accuracy: 0.5982 - val_loss: 0.7381 - val_precision: 0.6224 - val_recall: 0.4993\n",
      "Epoch 1631/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6203 - loss: 0.3110 - precision: 0.6281 - recall: 0.6235\n",
      "Epoch 1631 - Train Recall: 0.6436 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6197 - loss: 0.3110 - precision: 0.6262 - recall: 0.6254 - val_accuracy: 0.6027 - val_loss: 0.6173 - val_precision: 0.5947 - val_recall: 0.6447\n",
      "Epoch 1632/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6188 - loss: 0.3377 - precision: 0.5998 - recall: 0.6800\n",
      "Epoch 1632 - Train Recall: 0.6627 - Val Recall: 0.6897\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.3377 - precision: 0.6000 - recall: 0.6794 - val_accuracy: 0.6132 - val_loss: 0.6782 - val_precision: 0.5982 - val_recall: 0.6897\n",
      "Epoch 1633/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6175 - loss: 0.3423 - precision: 0.6107 - recall: 0.6595\n",
      "Epoch 1633 - Train Recall: 0.6428 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6174 - loss: 0.3427 - precision: 0.6106 - recall: 0.6578 - val_accuracy: 0.6012 - val_loss: 0.6900 - val_precision: 0.5916 - val_recall: 0.6537\n",
      "Epoch 1634/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6135 - loss: 0.3412 - precision: 0.6181 - recall: 0.6269\n",
      "Epoch 1634 - Train Recall: 0.6244 - Val Recall: 0.6042\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6140 - loss: 0.3411 - precision: 0.6180 - recall: 0.6266 - val_accuracy: 0.6087 - val_loss: 0.6870 - val_precision: 0.6097 - val_recall: 0.6042\n",
      "Epoch 1635/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6234 - loss: 0.3312 - precision: 0.6132 - recall: 0.6287\n",
      "Epoch 1635 - Train Recall: 0.6421 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6232 - loss: 0.3315 - precision: 0.6137 - recall: 0.6302 - val_accuracy: 0.5847 - val_loss: 0.6664 - val_precision: 0.5804 - val_recall: 0.6117\n",
      "Epoch 1636/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6308 - loss: 0.3273 - precision: 0.6297 - recall: 0.6509\n",
      "Epoch 1636 - Train Recall: 0.6600 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6300 - loss: 0.3276 - precision: 0.6281 - recall: 0.6517 - val_accuracy: 0.5855 - val_loss: 0.6676 - val_precision: 0.5766 - val_recall: 0.6432\n",
      "Epoch 1637/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6301 - loss: 0.3298 - precision: 0.6210 - recall: 0.6620\n",
      "Epoch 1637 - Train Recall: 0.6548 - Val Recall: 0.7076\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6282 - loss: 0.3305 - precision: 0.6194 - recall: 0.6611 - val_accuracy: 0.6027 - val_loss: 0.6690 - val_precision: 0.5849 - val_recall: 0.7076\n",
      "Epoch 1638/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6377 - loss: 0.3467 - precision: 0.6377 - recall: 0.6465\n",
      "Epoch 1638 - Train Recall: 0.6173 - Val Recall: 0.5307\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6361 - loss: 0.3472 - precision: 0.6361 - recall: 0.6439 - val_accuracy: 0.5900 - val_loss: 0.7067 - val_precision: 0.6020 - val_recall: 0.5307\n",
      "Epoch 1639/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5993 - loss: 0.3195 - precision: 0.5894 - recall: 0.5899\n",
      "Epoch 1639 - Train Recall: 0.6432 - Val Recall: 0.6612\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6010 - loss: 0.3192 - precision: 0.5915 - recall: 0.5961 - val_accuracy: 0.5990 - val_loss: 0.6278 - val_precision: 0.5880 - val_recall: 0.6612\n",
      "Epoch 1640/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6271 - loss: 0.3414 - precision: 0.6191 - recall: 0.6719\n",
      "Epoch 1640 - Train Recall: 0.6559 - Val Recall: 0.5637\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6254 - loss: 0.3418 - precision: 0.6174 - recall: 0.6696 - val_accuracy: 0.6042 - val_loss: 0.6835 - val_precision: 0.6134 - val_recall: 0.5637\n",
      "Epoch 1641/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6173 - loss: 0.3124 - precision: 0.6049 - recall: 0.6796\n",
      "Epoch 1641 - Train Recall: 0.6709 - Val Recall: 0.5997\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6166 - loss: 0.3126 - precision: 0.6043 - recall: 0.6789 - val_accuracy: 0.5937 - val_loss: 0.6385 - val_precision: 0.5926 - val_recall: 0.5997\n",
      "Epoch 1642/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6333 - loss: 0.3180 - precision: 0.6127 - recall: 0.7162\n",
      "Epoch 1642 - Train Recall: 0.7054 - Val Recall: 0.7511\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6308 - loss: 0.3182 - precision: 0.6106 - recall: 0.7146 - val_accuracy: 0.6094 - val_loss: 0.6381 - val_precision: 0.5853 - val_recall: 0.7511\n",
      "Epoch 1643/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6150 - loss: 0.3493 - precision: 0.6013 - recall: 0.6893\n",
      "Epoch 1643 - Train Recall: 0.6608 - Val Recall: 0.5832\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6149 - loss: 0.3494 - precision: 0.6015 - recall: 0.6867 - val_accuracy: 0.5840 - val_loss: 0.7062 - val_precision: 0.5841 - val_recall: 0.5832\n",
      "Epoch 1644/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6231 - loss: 0.3158 - precision: 0.6208 - recall: 0.6598\n",
      "Epoch 1644 - Train Recall: 0.6657 - Val Recall: 0.6582\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6229 - loss: 0.3158 - precision: 0.6204 - recall: 0.6599 - val_accuracy: 0.6019 - val_loss: 0.6409 - val_precision: 0.5916 - val_recall: 0.6582\n",
      "Epoch 1645/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6302 - loss: 0.3339 - precision: 0.6258 - recall: 0.6649\n",
      "Epoch 1645 - Train Recall: 0.6454 - Val Recall: 0.5802\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6287 - loss: 0.3342 - precision: 0.6241 - recall: 0.6637 - val_accuracy: 0.5817 - val_loss: 0.6730 - val_precision: 0.5820 - val_recall: 0.5802\n",
      "Epoch 1646/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6041 - loss: 0.3244 - precision: 0.6003 - recall: 0.6536\n",
      "Epoch 1646 - Train Recall: 0.6717 - Val Recall: 0.6612\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6049 - loss: 0.3242 - precision: 0.6004 - recall: 0.6550 - val_accuracy: 0.6064 - val_loss: 0.6430 - val_precision: 0.5959 - val_recall: 0.6612\n",
      "Epoch 1647/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6138 - loss: 0.3350 - precision: 0.6070 - recall: 0.6656\n",
      "Epoch 1647 - Train Recall: 0.6540 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6135 - loss: 0.3351 - precision: 0.6066 - recall: 0.6645 - val_accuracy: 0.5892 - val_loss: 0.6812 - val_precision: 0.5794 - val_recall: 0.6507\n",
      "Epoch 1648/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6114 - loss: 0.3366 - precision: 0.6049 - recall: 0.6446\n",
      "Epoch 1648 - Train Recall: 0.6304 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6113 - loss: 0.3367 - precision: 0.6049 - recall: 0.6440 - val_accuracy: 0.6057 - val_loss: 0.6783 - val_precision: 0.6048 - val_recall: 0.6102\n",
      "Epoch 1649/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6201 - loss: 0.3312 - precision: 0.6077 - recall: 0.6591\n",
      "Epoch 1649 - Train Recall: 0.6387 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6199 - loss: 0.3313 - precision: 0.6080 - recall: 0.6578 - val_accuracy: 0.6027 - val_loss: 0.6683 - val_precision: 0.6062 - val_recall: 0.5862\n",
      "Epoch 1650/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6227 - loss: 0.3235 - precision: 0.6147 - recall: 0.6660\n",
      "Epoch 1650 - Train Recall: 0.6732 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6227 - loss: 0.3235 - precision: 0.6146 - recall: 0.6660 - val_accuracy: 0.6087 - val_loss: 0.6488 - val_precision: 0.6037 - val_recall: 0.6327\n",
      "Epoch 1651/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6059 - loss: 0.3300 - precision: 0.5853 - recall: 0.6678\n",
      "Epoch 1651 - Train Recall: 0.6623 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6064 - loss: 0.3298 - precision: 0.5870 - recall: 0.6668 - val_accuracy: 0.6169 - val_loss: 0.6527 - val_precision: 0.6063 - val_recall: 0.6672\n",
      "Epoch 1652/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6184 - loss: 0.3397 - precision: 0.6097 - recall: 0.6514\n",
      "Epoch 1652 - Train Recall: 0.6439 - Val Recall: 0.5487\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6177 - loss: 0.3398 - precision: 0.6093 - recall: 0.6504 - val_accuracy: 0.5982 - val_loss: 0.6880 - val_precision: 0.6090 - val_recall: 0.5487\n",
      "Epoch 1653/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6290 - loss: 0.3125 - precision: 0.6137 - recall: 0.6992\n",
      "Epoch 1653 - Train Recall: 0.7001 - Val Recall: 0.7511\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6288 - loss: 0.3125 - precision: 0.6134 - recall: 0.6992 - val_accuracy: 0.6019 - val_loss: 0.6255 - val_precision: 0.5785 - val_recall: 0.7511\n",
      "Epoch 1654/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6146 - loss: 0.3505 - precision: 0.6044 - recall: 0.6635\n",
      "Epoch 1654 - Train Recall: 0.6387 - Val Recall: 0.5082\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6143 - loss: 0.3506 - precision: 0.6046 - recall: 0.6609 - val_accuracy: 0.5930 - val_loss: 0.7017 - val_precision: 0.6119 - val_recall: 0.5082\n",
      "Epoch 1655/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6278 - loss: 0.3015 - precision: 0.6200 - recall: 0.6780\n",
      "Epoch 1655 - Train Recall: 0.6934 - Val Recall: 0.7106\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6271 - loss: 0.3016 - precision: 0.6188 - recall: 0.6787 - val_accuracy: 0.6192 - val_loss: 0.6097 - val_precision: 0.6008 - val_recall: 0.7106\n",
      "Epoch 1656/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6175 - loss: 0.3432 - precision: 0.6040 - recall: 0.7238\n",
      "Epoch 1656 - Train Recall: 0.6972 - Val Recall: 0.7106\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6173 - loss: 0.3432 - precision: 0.6037 - recall: 0.7213 - val_accuracy: 0.5960 - val_loss: 0.6854 - val_precision: 0.5780 - val_recall: 0.7106\n",
      "Epoch 1657/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6258 - loss: 0.3395 - precision: 0.6262 - recall: 0.6507\n",
      "Epoch 1657 - Train Recall: 0.6428 - Val Recall: 0.6657\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6257 - loss: 0.3395 - precision: 0.6259 - recall: 0.6506 - val_accuracy: 0.6034 - val_loss: 0.6808 - val_precision: 0.5920 - val_recall: 0.6657\n",
      "Epoch 1658/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6297 - loss: 0.3430 - precision: 0.6321 - recall: 0.6443\n",
      "Epoch 1658 - Train Recall: 0.6383 - Val Recall: 0.5772\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6295 - loss: 0.3431 - precision: 0.6314 - recall: 0.6437 - val_accuracy: 0.5967 - val_loss: 0.6921 - val_precision: 0.6006 - val_recall: 0.5772\n",
      "Epoch 1659/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6119 - loss: 0.3232 - precision: 0.6111 - recall: 0.6435\n",
      "Epoch 1659 - Train Recall: 0.6612 - Val Recall: 0.7391\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6119 - loss: 0.3232 - precision: 0.6109 - recall: 0.6438 - val_accuracy: 0.5930 - val_loss: 0.6473 - val_precision: 0.5719 - val_recall: 0.7391\n",
      "Epoch 1660/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6204 - loss: 0.3545 - precision: 0.6154 - recall: 0.6615\n",
      "Epoch 1660 - Train Recall: 0.6173 - Val Recall: 0.5952\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6191 - loss: 0.3549 - precision: 0.6142 - recall: 0.6585 - val_accuracy: 0.6162 - val_loss: 0.7144 - val_precision: 0.6213 - val_recall: 0.5952\n",
      "Epoch 1661/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6090 - loss: 0.3327 - precision: 0.6204 - recall: 0.5869\n",
      "Epoch 1661 - Train Recall: 0.6072 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6092 - loss: 0.3327 - precision: 0.6203 - recall: 0.5878 - val_accuracy: 0.6049 - val_loss: 0.6652 - val_precision: 0.6045 - val_recall: 0.6072\n",
      "Epoch 1662/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6225 - loss: 0.3381 - precision: 0.6161 - recall: 0.6414\n",
      "Epoch 1662 - Train Recall: 0.6349 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6221 - loss: 0.3382 - precision: 0.6159 - recall: 0.6412 - val_accuracy: 0.6079 - val_loss: 0.6788 - val_precision: 0.6084 - val_recall: 0.6057\n",
      "Epoch 1663/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6114 - loss: 0.3319 - precision: 0.6081 - recall: 0.6190\n",
      "Epoch 1663 - Train Recall: 0.6428 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6115 - loss: 0.3318 - precision: 0.6079 - recall: 0.6210 - val_accuracy: 0.5870 - val_loss: 0.6649 - val_precision: 0.5749 - val_recall: 0.6672\n",
      "Epoch 1664/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6026 - loss: 0.3469 - precision: 0.5890 - recall: 0.6429\n",
      "Epoch 1664 - Train Recall: 0.6496 - Val Recall: 0.5322\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6036 - loss: 0.3468 - precision: 0.5906 - recall: 0.6435 - val_accuracy: 0.5945 - val_loss: 0.6886 - val_precision: 0.6079 - val_recall: 0.5322\n",
      "Epoch 1665/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6205 - loss: 0.3065 - precision: 0.6204 - recall: 0.6390\n",
      "Epoch 1665 - Train Recall: 0.6638 - Val Recall: 0.6717\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6206 - loss: 0.3065 - precision: 0.6197 - recall: 0.6410 - val_accuracy: 0.6139 - val_loss: 0.6153 - val_precision: 0.6022 - val_recall: 0.6717\n",
      "Epoch 1666/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6082 - loss: 0.3418 - precision: 0.6042 - recall: 0.6722\n",
      "Epoch 1666 - Train Recall: 0.6679 - Val Recall: 0.7031\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6084 - loss: 0.3418 - precision: 0.6042 - recall: 0.6721 - val_accuracy: 0.6259 - val_loss: 0.6773 - val_precision: 0.6091 - val_recall: 0.7031\n",
      "Epoch 1667/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6254 - loss: 0.3451 - precision: 0.6311 - recall: 0.6455\n",
      "Epoch 1667 - Train Recall: 0.6293 - Val Recall: 0.5577\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6244 - loss: 0.3454 - precision: 0.6290 - recall: 0.6438 - val_accuracy: 0.6042 - val_loss: 0.6978 - val_precision: 0.6149 - val_recall: 0.5577\n",
      "Epoch 1668/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6014 - loss: 0.3236 - precision: 0.5922 - recall: 0.6297\n",
      "Epoch 1668 - Train Recall: 0.6645 - Val Recall: 0.6972\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6030 - loss: 0.3233 - precision: 0.5939 - recall: 0.6340 - val_accuracy: 0.5982 - val_loss: 0.6418 - val_precision: 0.5820 - val_recall: 0.6972\n",
      "Epoch 1669/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6210 - loss: 0.3441 - precision: 0.6009 - recall: 0.6630\n",
      "Epoch 1669 - Train Recall: 0.6361 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6207 - loss: 0.3442 - precision: 0.6014 - recall: 0.6615 - val_accuracy: 0.5795 - val_loss: 0.7012 - val_precision: 0.5716 - val_recall: 0.6342\n",
      "Epoch 1670/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6265 - loss: 0.3359 - precision: 0.6210 - recall: 0.6465\n",
      "Epoch 1670 - Train Recall: 0.6353 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6261 - loss: 0.3361 - precision: 0.6207 - recall: 0.6461 - val_accuracy: 0.5915 - val_loss: 0.6849 - val_precision: 0.5827 - val_recall: 0.6447\n",
      "Epoch 1671/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6223 - loss: 0.3412 - precision: 0.6173 - recall: 0.6221\n",
      "Epoch 1671 - Train Recall: 0.6256 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6222 - loss: 0.3412 - precision: 0.6172 - recall: 0.6221 - val_accuracy: 0.6072 - val_loss: 0.6822 - val_precision: 0.5955 - val_recall: 0.6687\n",
      "Epoch 1672/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6355 - loss: 0.3452 - precision: 0.6420 - recall: 0.6578\n",
      "Epoch 1672 - Train Recall: 0.6259 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6351 - loss: 0.3453 - precision: 0.6414 - recall: 0.6570 - val_accuracy: 0.5990 - val_loss: 0.7026 - val_precision: 0.5902 - val_recall: 0.6477\n",
      "Epoch 1673/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6254 - loss: 0.3445 - precision: 0.6299 - recall: 0.6183\n",
      "Epoch 1673 - Train Recall: 0.6083 - Val Recall: 0.5757\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6244 - loss: 0.3446 - precision: 0.6285 - recall: 0.6175 - val_accuracy: 0.5937 - val_loss: 0.6919 - val_precision: 0.5972 - val_recall: 0.5757\n",
      "Epoch 1674/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6114 - loss: 0.3312 - precision: 0.6030 - recall: 0.6063\n",
      "Epoch 1674 - Train Recall: 0.6308 - Val Recall: 0.6987\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6112 - loss: 0.3311 - precision: 0.6032 - recall: 0.6081 - val_accuracy: 0.6042 - val_loss: 0.6528 - val_precision: 0.5876 - val_recall: 0.6987\n",
      "Epoch 1675/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6152 - loss: 0.3585 - precision: 0.6213 - recall: 0.6312\n",
      "Epoch 1675 - Train Recall: 0.6199 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6154 - loss: 0.3584 - precision: 0.6212 - recall: 0.6305 - val_accuracy: 0.5960 - val_loss: 0.7114 - val_precision: 0.5982 - val_recall: 0.5847\n",
      "Epoch 1676/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6186 - loss: 0.3267 - precision: 0.6221 - recall: 0.5882\n",
      "Epoch 1676 - Train Recall: 0.6053 - Val Recall: 0.6522\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6180 - loss: 0.3270 - precision: 0.6216 - recall: 0.5898 - val_accuracy: 0.6102 - val_loss: 0.6556 - val_precision: 0.6017 - val_recall: 0.6522\n",
      "Epoch 1677/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6144 - loss: 0.3494 - precision: 0.6052 - recall: 0.6126\n",
      "Epoch 1677 - Train Recall: 0.5990 - Val Recall: 0.5877\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6143 - loss: 0.3495 - precision: 0.6054 - recall: 0.6122 - val_accuracy: 0.5840 - val_loss: 0.7152 - val_precision: 0.5833 - val_recall: 0.5877\n",
      "Epoch 1678/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6249 - loss: 0.3322 - precision: 0.6161 - recall: 0.6474\n",
      "Epoch 1678 - Train Recall: 0.6308 - Val Recall: 0.6297\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6242 - loss: 0.3324 - precision: 0.6158 - recall: 0.6463 - val_accuracy: 0.6079 - val_loss: 0.6742 - val_precision: 0.6034 - val_recall: 0.6297\n",
      "Epoch 1679/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6193 - loss: 0.3360 - precision: 0.6203 - recall: 0.6309\n",
      "Epoch 1679 - Train Recall: 0.6199 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6176 - loss: 0.3364 - precision: 0.6181 - recall: 0.6295 - val_accuracy: 0.5960 - val_loss: 0.6838 - val_precision: 0.5947 - val_recall: 0.6027\n",
      "Epoch 1680/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6138 - loss: 0.3338 - precision: 0.6088 - recall: 0.6463\n",
      "Epoch 1680 - Train Recall: 0.6391 - Val Recall: 0.6702\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6140 - loss: 0.3339 - precision: 0.6086 - recall: 0.6455 - val_accuracy: 0.6057 - val_loss: 0.6704 - val_precision: 0.5936 - val_recall: 0.6702\n",
      "Epoch 1681/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6245 - loss: 0.3453 - precision: 0.6317 - recall: 0.6256\n",
      "Epoch 1681 - Train Recall: 0.6286 - Val Recall: 0.4993\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6242 - loss: 0.3454 - precision: 0.6310 - recall: 0.6257 - val_accuracy: 0.5840 - val_loss: 0.7025 - val_precision: 0.6011 - val_recall: 0.4993\n",
      "Epoch 1682/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 0.3086 - precision: 0.6024 - recall: 0.6259\n",
      "Epoch 1682 - Train Recall: 0.6732 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6038 - loss: 0.3084 - precision: 0.6023 - recall: 0.6293 - val_accuracy: 0.5982 - val_loss: 0.6114 - val_precision: 0.5845 - val_recall: 0.6792\n",
      "Epoch 1683/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6232 - loss: 0.3367 - precision: 0.6081 - recall: 0.7015\n",
      "Epoch 1683 - Train Recall: 0.6784 - Val Recall: 0.6837\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6220 - loss: 0.3373 - precision: 0.6073 - recall: 0.6985 - val_accuracy: 0.6034 - val_loss: 0.6813 - val_precision: 0.5891 - val_recall: 0.6837\n",
      "Epoch 1684/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6227 - loss: 0.3383 - precision: 0.6221 - recall: 0.6453\n",
      "Epoch 1684 - Train Recall: 0.6473 - Val Recall: 0.6762\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6224 - loss: 0.3383 - precision: 0.6213 - recall: 0.6454 - val_accuracy: 0.5997 - val_loss: 0.6836 - val_precision: 0.5865 - val_recall: 0.6762\n",
      "Epoch 1685/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6168 - loss: 0.3467 - precision: 0.6045 - recall: 0.6326\n",
      "Epoch 1685 - Train Recall: 0.6154 - Val Recall: 0.5787\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6164 - loss: 0.3469 - precision: 0.6054 - recall: 0.6304 - val_accuracy: 0.6087 - val_loss: 0.6985 - val_precision: 0.6156 - val_recall: 0.5787\n",
      "Epoch 1686/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6245 - loss: 0.3273 - precision: 0.6312 - recall: 0.6335\n",
      "Epoch 1686 - Train Recall: 0.6379 - Val Recall: 0.6132\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6241 - loss: 0.3274 - precision: 0.6301 - recall: 0.6337 - val_accuracy: 0.6192 - val_loss: 0.6533 - val_precision: 0.6206 - val_recall: 0.6132\n",
      "Epoch 1687/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6044 - loss: 0.3340 - precision: 0.5937 - recall: 0.6232\n",
      "Epoch 1687 - Train Recall: 0.6353 - Val Recall: 0.6987\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6067 - loss: 0.3335 - precision: 0.5972 - recall: 0.6246 - val_accuracy: 0.6109 - val_loss: 0.6616 - val_precision: 0.5944 - val_recall: 0.6987\n",
      "Epoch 1688/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6236 - loss: 0.3544 - precision: 0.6112 - recall: 0.6492\n",
      "Epoch 1688 - Train Recall: 0.6136 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6220 - loss: 0.3546 - precision: 0.6109 - recall: 0.6452 - val_accuracy: 0.5900 - val_loss: 0.7129 - val_precision: 0.5877 - val_recall: 0.6027\n",
      "Epoch 1689/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6278 - loss: 0.3332 - precision: 0.6374 - recall: 0.6189\n",
      "Epoch 1689 - Train Recall: 0.6241 - Val Recall: 0.5862\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6276 - loss: 0.3332 - precision: 0.6369 - recall: 0.6190 - val_accuracy: 0.6049 - val_loss: 0.6736 - val_precision: 0.6090 - val_recall: 0.5862\n",
      "Epoch 1690/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6085 - loss: 0.3275 - precision: 0.6009 - recall: 0.6531\n",
      "Epoch 1690 - Train Recall: 0.6548 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6087 - loss: 0.3276 - precision: 0.6010 - recall: 0.6532 - val_accuracy: 0.6139 - val_loss: 0.6516 - val_precision: 0.6053 - val_recall: 0.6552\n",
      "Epoch 1691/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6253 - loss: 0.3362 - precision: 0.6224 - recall: 0.6445\n",
      "Epoch 1691 - Train Recall: 0.6518 - Val Recall: 0.6972\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6245 - loss: 0.3364 - precision: 0.6213 - recall: 0.6452 - val_accuracy: 0.6154 - val_loss: 0.6761 - val_precision: 0.5992 - val_recall: 0.6972\n",
      "Epoch 1692/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6264 - loss: 0.3472 - precision: 0.6286 - recall: 0.6441\n",
      "Epoch 1692 - Train Recall: 0.6353 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6261 - loss: 0.3474 - precision: 0.6279 - recall: 0.6435 - val_accuracy: 0.6034 - val_loss: 0.7020 - val_precision: 0.5969 - val_recall: 0.6372\n",
      "Epoch 1693/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6241 - loss: 0.3360 - precision: 0.6205 - recall: 0.5957\n",
      "Epoch 1693 - Train Recall: 0.5960 - Val Recall: 0.6837\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6236 - loss: 0.3361 - precision: 0.6204 - recall: 0.5957 - val_accuracy: 0.6192 - val_loss: 0.6757 - val_precision: 0.6056 - val_recall: 0.6837\n",
      "Epoch 1694/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6125 - loss: 0.3626 - precision: 0.6101 - recall: 0.6115\n",
      "Epoch 1694 - Train Recall: 0.5900 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6125 - loss: 0.3626 - precision: 0.6102 - recall: 0.6112 - val_accuracy: 0.5967 - val_loss: 0.7207 - val_precision: 0.6042 - val_recall: 0.5607\n",
      "Epoch 1695/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6356 - loss: 0.3267 - precision: 0.6335 - recall: 0.6149\n",
      "Epoch 1695 - Train Recall: 0.6064 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6347 - loss: 0.3269 - precision: 0.6331 - recall: 0.6144 - val_accuracy: 0.6079 - val_loss: 0.6681 - val_precision: 0.6017 - val_recall: 0.6387\n",
      "Epoch 1696/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6201 - loss: 0.3483 - precision: 0.6167 - recall: 0.6428\n",
      "Epoch 1696 - Train Recall: 0.6338 - Val Recall: 0.7031\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6198 - loss: 0.3483 - precision: 0.6163 - recall: 0.6425 - val_accuracy: 0.6102 - val_loss: 0.6922 - val_precision: 0.5929 - val_recall: 0.7031\n",
      "Epoch 1697/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6212 - loss: 0.3531 - precision: 0.6293 - recall: 0.6172\n",
      "Epoch 1697 - Train Recall: 0.6031 - Val Recall: 0.5337\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6206 - loss: 0.3533 - precision: 0.6284 - recall: 0.6161 - val_accuracy: 0.6072 - val_loss: 0.7079 - val_precision: 0.6257 - val_recall: 0.5337\n",
      "Epoch 1698/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6259 - loss: 0.3182 - precision: 0.6256 - recall: 0.6028\n",
      "Epoch 1698 - Train Recall: 0.6233 - Val Recall: 0.6717\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6256 - loss: 0.3183 - precision: 0.6252 - recall: 0.6045 - val_accuracy: 0.6049 - val_loss: 0.6380 - val_precision: 0.5926 - val_recall: 0.6717\n",
      "Epoch 1699/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6293 - loss: 0.3464 - precision: 0.6085 - recall: 0.6432\n",
      "Epoch 1699 - Train Recall: 0.6151 - Val Recall: 0.5772\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6281 - loss: 0.3469 - precision: 0.6100 - recall: 0.6399 - val_accuracy: 0.5885 - val_loss: 0.7095 - val_precision: 0.5905 - val_recall: 0.5772\n",
      "Epoch 1700/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6135 - loss: 0.3275 - precision: 0.6058 - recall: 0.6268\n",
      "Epoch 1700 - Train Recall: 0.6376 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6136 - loss: 0.3275 - precision: 0.6059 - recall: 0.6273 - val_accuracy: 0.6102 - val_loss: 0.6589 - val_precision: 0.6028 - val_recall: 0.6462\n",
      "Epoch 1701/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6161 - loss: 0.3429 - precision: 0.6171 - recall: 0.6438\n",
      "Epoch 1701 - Train Recall: 0.6439 - Val Recall: 0.6222\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6164 - loss: 0.3427 - precision: 0.6166 - recall: 0.6439 - val_accuracy: 0.6162 - val_loss: 0.6835 - val_precision: 0.6148 - val_recall: 0.6222\n",
      "Epoch 1702/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6243 - loss: 0.3311 - precision: 0.6199 - recall: 0.6412\n",
      "Epoch 1702 - Train Recall: 0.6312 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6243 - loss: 0.3311 - precision: 0.6199 - recall: 0.6411 - val_accuracy: 0.6004 - val_loss: 0.6696 - val_precision: 0.5925 - val_recall: 0.6432\n",
      "Epoch 1703/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6080 - loss: 0.3408 - precision: 0.6094 - recall: 0.6241\n",
      "Epoch 1703 - Train Recall: 0.6248 - Val Recall: 0.6957\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6083 - loss: 0.3409 - precision: 0.6093 - recall: 0.6243 - val_accuracy: 0.6169 - val_loss: 0.6853 - val_precision: 0.6010 - val_recall: 0.6957\n",
      "Epoch 1704/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6152 - loss: 0.3558 - precision: 0.6247 - recall: 0.6237\n",
      "Epoch 1704 - Train Recall: 0.6042 - Val Recall: 0.5427\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6152 - loss: 0.3558 - precision: 0.6244 - recall: 0.6233 - val_accuracy: 0.5990 - val_loss: 0.7211 - val_precision: 0.6115 - val_recall: 0.5427\n",
      "Epoch 1705/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6225 - loss: 0.3204 - precision: 0.6289 - recall: 0.6110\n",
      "Epoch 1705 - Train Recall: 0.6338 - Val Recall: 0.7166\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6222 - loss: 0.3206 - precision: 0.6278 - recall: 0.6129 - val_accuracy: 0.5975 - val_loss: 0.6442 - val_precision: 0.5787 - val_recall: 0.7166\n",
      "Epoch 1706/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6211 - loss: 0.3586 - precision: 0.6145 - recall: 0.6395\n",
      "Epoch 1706 - Train Recall: 0.6211 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6208 - loss: 0.3586 - precision: 0.6145 - recall: 0.6386 - val_accuracy: 0.6042 - val_loss: 0.7260 - val_precision: 0.5925 - val_recall: 0.6672\n",
      "Epoch 1707/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6167 - loss: 0.3500 - precision: 0.6093 - recall: 0.6165\n",
      "Epoch 1707 - Train Recall: 0.5975 - Val Recall: 0.6177\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6160 - loss: 0.3501 - precision: 0.6100 - recall: 0.6142 - val_accuracy: 0.6027 - val_loss: 0.6999 - val_precision: 0.5997 - val_recall: 0.6177\n",
      "Epoch 1708/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6323 - loss: 0.3391 - precision: 0.6313 - recall: 0.6061\n",
      "Epoch 1708 - Train Recall: 0.5978 - Val Recall: 0.5892\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6314 - loss: 0.3394 - precision: 0.6310 - recall: 0.6055 - val_accuracy: 0.6042 - val_loss: 0.6975 - val_precision: 0.6074 - val_recall: 0.5892\n",
      "Epoch 1709/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6166 - loss: 0.3361 - precision: 0.6139 - recall: 0.6034\n",
      "Epoch 1709 - Train Recall: 0.6016 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6163 - loss: 0.3361 - precision: 0.6140 - recall: 0.6033 - val_accuracy: 0.6079 - val_loss: 0.6715 - val_precision: 0.5994 - val_recall: 0.6507\n",
      "Epoch 1710/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6065 - loss: 0.3520 - precision: 0.6110 - recall: 0.6268\n",
      "Epoch 1710 - Train Recall: 0.6117 - Val Recall: 0.4873\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6067 - loss: 0.3520 - precision: 0.6110 - recall: 0.6264 - val_accuracy: 0.5817 - val_loss: 0.7108 - val_precision: 0.6007 - val_recall: 0.4873\n",
      "Epoch 1711/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6282 - loss: 0.3046 - precision: 0.6195 - recall: 0.6111\n",
      "Epoch 1711 - Train Recall: 0.6552 - Val Recall: 0.7361\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6276 - loss: 0.3046 - precision: 0.6191 - recall: 0.6157 - val_accuracy: 0.6049 - val_loss: 0.6089 - val_precision: 0.5831 - val_recall: 0.7361\n",
      "Epoch 1712/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6375 - loss: 0.3490 - precision: 0.6235 - recall: 0.7068\n",
      "Epoch 1712 - Train Recall: 0.6522 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6363 - loss: 0.3494 - precision: 0.6225 - recall: 0.7043 - val_accuracy: 0.6072 - val_loss: 0.7252 - val_precision: 0.6044 - val_recall: 0.6207\n",
      "Epoch 1713/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6141 - loss: 0.3300 - precision: 0.6121 - recall: 0.6061\n",
      "Epoch 1713 - Train Recall: 0.6267 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6142 - loss: 0.3300 - precision: 0.6121 - recall: 0.6065 - val_accuracy: 0.6019 - val_loss: 0.6677 - val_precision: 0.5902 - val_recall: 0.6672\n",
      "Epoch 1714/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6235 - loss: 0.3454 - precision: 0.6065 - recall: 0.6607\n",
      "Epoch 1714 - Train Recall: 0.6316 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6229 - loss: 0.3456 - precision: 0.6067 - recall: 0.6589 - val_accuracy: 0.5997 - val_loss: 0.7041 - val_precision: 0.6028 - val_recall: 0.5847\n",
      "Epoch 1715/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6171 - loss: 0.3264 - precision: 0.6161 - recall: 0.6253\n",
      "Epoch 1715 - Train Recall: 0.6387 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6174 - loss: 0.3264 - precision: 0.6160 - recall: 0.6266 - val_accuracy: 0.5975 - val_loss: 0.6515 - val_precision: 0.6052 - val_recall: 0.5607\n",
      "Epoch 1716/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6416 - loss: 0.3120 - precision: 0.6291 - recall: 0.6869\n",
      "Epoch 1716 - Train Recall: 0.6702 - Val Recall: 0.7211\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6402 - loss: 0.3124 - precision: 0.6278 - recall: 0.6859 - val_accuracy: 0.6132 - val_loss: 0.6316 - val_precision: 0.5931 - val_recall: 0.7211\n",
      "Epoch 1717/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6153 - loss: 0.3513 - precision: 0.6066 - recall: 0.6769\n",
      "Epoch 1717 - Train Recall: 0.6533 - Val Recall: 0.5457\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6148 - loss: 0.3513 - precision: 0.6064 - recall: 0.6744 - val_accuracy: 0.5817 - val_loss: 0.7122 - val_precision: 0.5880 - val_recall: 0.5457\n",
      "Epoch 1718/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6309 - loss: 0.3064 - precision: 0.6245 - recall: 0.6828\n",
      "Epoch 1718 - Train Recall: 0.6859 - Val Recall: 0.6837\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6297 - loss: 0.3066 - precision: 0.6227 - recall: 0.6831 - val_accuracy: 0.5997 - val_loss: 0.6227 - val_precision: 0.5854 - val_recall: 0.6837\n",
      "Epoch 1719/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6289 - loss: 0.3370 - precision: 0.6081 - recall: 0.6899\n",
      "Epoch 1719 - Train Recall: 0.6645 - Val Recall: 0.7856\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6288 - loss: 0.3370 - precision: 0.6082 - recall: 0.6896 - val_accuracy: 0.6117 - val_loss: 0.6804 - val_precision: 0.5829 - val_recall: 0.7856\n",
      "Epoch 1720/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6020 - loss: 0.3725 - precision: 0.5964 - recall: 0.6417\n",
      "Epoch 1720 - Train Recall: 0.6319 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6028 - loss: 0.3722 - precision: 0.5974 - recall: 0.6407 - val_accuracy: 0.6094 - val_loss: 0.7394 - val_precision: 0.6055 - val_recall: 0.6282\n",
      "Epoch 1721/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5999 - loss: 0.3406 - precision: 0.6010 - recall: 0.5885\n",
      "Epoch 1721 - Train Recall: 0.6038 - Val Recall: 0.6957\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6006 - loss: 0.3405 - precision: 0.6016 - recall: 0.5898 - val_accuracy: 0.5787 - val_loss: 0.6842 - val_precision: 0.5638 - val_recall: 0.6957\n",
      "Epoch 1722/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6296 - loss: 0.3618 - precision: 0.6262 - recall: 0.6078\n",
      "Epoch 1722 - Train Recall: 0.5761 - Val Recall: 0.4783\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6288 - loss: 0.3619 - precision: 0.6264 - recall: 0.6058 - val_accuracy: 0.5825 - val_loss: 0.7344 - val_precision: 0.6042 - val_recall: 0.4783\n",
      "Epoch 1723/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6289 - loss: 0.3082 - precision: 0.6406 - recall: 0.6230\n",
      "Epoch 1723 - Train Recall: 0.6503 - Val Recall: 0.6777\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6289 - loss: 0.3083 - precision: 0.6405 - recall: 0.6232 - val_accuracy: 0.6192 - val_loss: 0.6176 - val_precision: 0.6067 - val_recall: 0.6777\n",
      "Epoch 1724/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6070 - loss: 0.3466 - precision: 0.5932 - recall: 0.6600\n",
      "Epoch 1724 - Train Recall: 0.6544 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6076 - loss: 0.3465 - precision: 0.5943 - recall: 0.6598 - val_accuracy: 0.6027 - val_loss: 0.6953 - val_precision: 0.6021 - val_recall: 0.6057\n",
      "Epoch 1725/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6140 - loss: 0.3266 - precision: 0.6118 - recall: 0.6278\n",
      "Epoch 1725 - Train Recall: 0.6289 - Val Recall: 0.6402\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6138 - loss: 0.3266 - precision: 0.6116 - recall: 0.6279 - val_accuracy: 0.6087 - val_loss: 0.6467 - val_precision: 0.6023 - val_recall: 0.6402\n",
      "Epoch 1726/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6275 - loss: 0.3396 - precision: 0.6296 - recall: 0.6623\n",
      "Epoch 1726 - Train Recall: 0.6552 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6264 - loss: 0.3398 - precision: 0.6274 - recall: 0.6617 - val_accuracy: 0.5922 - val_loss: 0.6865 - val_precision: 0.5834 - val_recall: 0.6447\n",
      "Epoch 1727/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6135 - loss: 0.3332 - precision: 0.6139 - recall: 0.6405\n",
      "Epoch 1727 - Train Recall: 0.6323 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6134 - loss: 0.3333 - precision: 0.6136 - recall: 0.6402 - val_accuracy: 0.6064 - val_loss: 0.6728 - val_precision: 0.6035 - val_recall: 0.6207\n",
      "Epoch 1728/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6124 - loss: 0.3377 - precision: 0.6077 - recall: 0.6535\n",
      "Epoch 1728 - Train Recall: 0.6492 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6127 - loss: 0.3374 - precision: 0.6078 - recall: 0.6531 - val_accuracy: 0.5960 - val_loss: 0.6790 - val_precision: 0.5877 - val_recall: 0.6432\n",
      "Epoch 1729/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6318 - loss: 0.3337 - precision: 0.6272 - recall: 0.6285\n",
      "Epoch 1729 - Train Recall: 0.6192 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6308 - loss: 0.3340 - precision: 0.6273 - recall: 0.6270 - val_accuracy: 0.5975 - val_loss: 0.6843 - val_precision: 0.5976 - val_recall: 0.5967\n",
      "Epoch 1730/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6288 - loss: 0.3270 - precision: 0.6298 - recall: 0.6502\n",
      "Epoch 1730 - Train Recall: 0.6447 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6286 - loss: 0.3271 - precision: 0.6295 - recall: 0.6501 - val_accuracy: 0.5862 - val_loss: 0.6684 - val_precision: 0.5746 - val_recall: 0.6642\n",
      "Epoch 1731/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6175 - loss: 0.3407 - precision: 0.6066 - recall: 0.6292\n",
      "Epoch 1731 - Train Recall: 0.6166 - Val Recall: 0.6222\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6173 - loss: 0.3409 - precision: 0.6070 - recall: 0.6286 - val_accuracy: 0.6117 - val_loss: 0.6868 - val_precision: 0.6094 - val_recall: 0.6222\n",
      "Epoch 1732/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.3378 - precision: 0.6245 - recall: 0.6191\n",
      "Epoch 1732 - Train Recall: 0.6286 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6249 - loss: 0.3380 - precision: 0.6245 - recall: 0.6200 - val_accuracy: 0.5967 - val_loss: 0.6929 - val_precision: 0.5902 - val_recall: 0.6327\n",
      "Epoch 1733/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6238 - loss: 0.3372 - precision: 0.6153 - recall: 0.6227\n",
      "Epoch 1733 - Train Recall: 0.6256 - Val Recall: 0.5982\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6237 - loss: 0.3374 - precision: 0.6158 - recall: 0.6230 - val_accuracy: 0.5975 - val_loss: 0.6891 - val_precision: 0.5973 - val_recall: 0.5982\n",
      "Epoch 1734/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6215 - loss: 0.3319 - precision: 0.6102 - recall: 0.6256\n",
      "Epoch 1734 - Train Recall: 0.6342 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6215 - loss: 0.3319 - precision: 0.6108 - recall: 0.6262 - val_accuracy: 0.5937 - val_loss: 0.6689 - val_precision: 0.5915 - val_recall: 0.6057\n",
      "Epoch 1735/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6137 - loss: 0.3326 - precision: 0.6056 - recall: 0.6439\n",
      "Epoch 1735 - Train Recall: 0.6488 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6140 - loss: 0.3325 - precision: 0.6060 - recall: 0.6442 - val_accuracy: 0.6064 - val_loss: 0.6606 - val_precision: 0.6073 - val_recall: 0.6027\n",
      "Epoch 1736/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6139 - loss: 0.3277 - precision: 0.6081 - recall: 0.6554\n",
      "Epoch 1736 - Train Recall: 0.6675 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6143 - loss: 0.3274 - precision: 0.6078 - recall: 0.6570 - val_accuracy: 0.5922 - val_loss: 0.6604 - val_precision: 0.5751 - val_recall: 0.7061\n",
      "Epoch 1737/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6147 - loss: 0.3483 - precision: 0.6075 - recall: 0.6319\n",
      "Epoch 1737 - Train Recall: 0.6353 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6149 - loss: 0.3485 - precision: 0.6079 - recall: 0.6326 - val_accuracy: 0.6027 - val_loss: 0.6966 - val_precision: 0.5937 - val_recall: 0.6507\n",
      "Epoch 1738/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6326 - loss: 0.3378 - precision: 0.6255 - recall: 0.6566\n",
      "Epoch 1738 - Train Recall: 0.6409 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6322 - loss: 0.3379 - precision: 0.6252 - recall: 0.6561 - val_accuracy: 0.6064 - val_loss: 0.6851 - val_precision: 0.6073 - val_recall: 0.6027\n",
      "Epoch 1739/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6288 - loss: 0.3268 - precision: 0.6191 - recall: 0.6586\n",
      "Epoch 1739 - Train Recall: 0.6458 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6278 - loss: 0.3270 - precision: 0.6184 - recall: 0.6575 - val_accuracy: 0.6124 - val_loss: 0.6567 - val_precision: 0.6045 - val_recall: 0.6507\n",
      "Epoch 1740/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6125 - loss: 0.3399 - precision: 0.5996 - recall: 0.6377\n",
      "Epoch 1740 - Train Recall: 0.6301 - Val Recall: 0.5652\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6125 - loss: 0.3399 - precision: 0.6000 - recall: 0.6374 - val_accuracy: 0.6027 - val_loss: 0.6812 - val_precision: 0.6110 - val_recall: 0.5652\n",
      "Epoch 1741/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6179 - loss: 0.3205 - precision: 0.6229 - recall: 0.6414\n",
      "Epoch 1741 - Train Recall: 0.6728 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6182 - loss: 0.3205 - precision: 0.6215 - recall: 0.6447 - val_accuracy: 0.6094 - val_loss: 0.6461 - val_precision: 0.5948 - val_recall: 0.6867\n",
      "Epoch 1742/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6199 - loss: 0.3413 - precision: 0.5912 - recall: 0.6808\n",
      "Epoch 1742 - Train Recall: 0.6507 - Val Recall: 0.6897\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6193 - loss: 0.3415 - precision: 0.5937 - recall: 0.6766 - val_accuracy: 0.6072 - val_loss: 0.6872 - val_precision: 0.5920 - val_recall: 0.6897\n",
      "Epoch 1743/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6068 - loss: 0.3484 - precision: 0.5967 - recall: 0.6442\n",
      "Epoch 1743 - Train Recall: 0.6417 - Val Recall: 0.5397\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6069 - loss: 0.3484 - precision: 0.5969 - recall: 0.6442 - val_accuracy: 0.5915 - val_loss: 0.7092 - val_precision: 0.6020 - val_recall: 0.5397\n",
      "Epoch 1744/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6256 - loss: 0.3100 - precision: 0.6204 - recall: 0.6424\n",
      "Epoch 1744 - Train Recall: 0.6578 - Val Recall: 0.7151\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6242 - loss: 0.3102 - precision: 0.6186 - recall: 0.6440 - val_accuracy: 0.6154 - val_loss: 0.6232 - val_precision: 0.5962 - val_recall: 0.7151\n",
      "Epoch 1745/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6354 - loss: 0.3496 - precision: 0.6168 - recall: 0.6910\n",
      "Epoch 1745 - Train Recall: 0.6424 - Val Recall: 0.5652\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6338 - loss: 0.3501 - precision: 0.6163 - recall: 0.6867 - val_accuracy: 0.5922 - val_loss: 0.7059 - val_precision: 0.5975 - val_recall: 0.5652\n",
      "Epoch 1746/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6202 - loss: 0.3144 - precision: 0.6154 - recall: 0.6458\n",
      "Epoch 1746 - Train Recall: 0.6518 - Val Recall: 0.7121\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6201 - loss: 0.3144 - precision: 0.6152 - recall: 0.6459 - val_accuracy: 0.6147 - val_loss: 0.6355 - val_precision: 0.5960 - val_recall: 0.7121\n",
      "Epoch 1747/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6195 - loss: 0.3519 - precision: 0.6143 - recall: 0.6321\n",
      "Epoch 1747 - Train Recall: 0.6252 - Val Recall: 0.6762\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6195 - loss: 0.3521 - precision: 0.6145 - recall: 0.6311 - val_accuracy: 0.6132 - val_loss: 0.7103 - val_precision: 0.6005 - val_recall: 0.6762\n",
      "Epoch 1748/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6191 - loss: 0.3532 - precision: 0.6221 - recall: 0.6152\n",
      "Epoch 1748 - Train Recall: 0.6012 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.3532 - precision: 0.6217 - recall: 0.6141 - val_accuracy: 0.6019 - val_loss: 0.7103 - val_precision: 0.5937 - val_recall: 0.6462\n",
      "Epoch 1749/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6238 - loss: 0.3474 - precision: 0.6318 - recall: 0.6104\n",
      "Epoch 1749 - Train Recall: 0.5933 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6237 - loss: 0.3475 - precision: 0.6316 - recall: 0.6102 - val_accuracy: 0.6057 - val_loss: 0.7043 - val_precision: 0.6057 - val_recall: 0.6057\n",
      "Epoch 1750/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6207 - loss: 0.3387 - precision: 0.6346 - recall: 0.6104\n",
      "Epoch 1750 - Train Recall: 0.6012 - Val Recall: 0.5742\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6205 - loss: 0.3388 - precision: 0.6342 - recall: 0.6102 - val_accuracy: 0.6004 - val_loss: 0.6842 - val_precision: 0.6060 - val_recall: 0.5742\n",
      "Epoch 1751/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6195 - loss: 0.3307 - precision: 0.6169 - recall: 0.6225\n",
      "Epoch 1751 - Train Recall: 0.6293 - Val Recall: 0.5337\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6199 - loss: 0.3306 - precision: 0.6174 - recall: 0.6234 - val_accuracy: 0.5765 - val_loss: 0.6761 - val_precision: 0.5836 - val_recall: 0.5337\n",
      "Epoch 1752/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6255 - loss: 0.3105 - precision: 0.6182 - recall: 0.6733\n",
      "Epoch 1752 - Train Recall: 0.6837 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6251 - loss: 0.3105 - precision: 0.6175 - recall: 0.6738 - val_accuracy: 0.5982 - val_loss: 0.6267 - val_precision: 0.5911 - val_recall: 0.6372\n",
      "Epoch 1753/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6183 - loss: 0.3247 - precision: 0.5900 - recall: 0.6914\n",
      "Epoch 1753 - Train Recall: 0.6792 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6188 - loss: 0.3248 - precision: 0.5921 - recall: 0.6902 - val_accuracy: 0.5930 - val_loss: 0.6599 - val_precision: 0.5881 - val_recall: 0.6207\n",
      "Epoch 1754/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6143 - loss: 0.3224 - precision: 0.6078 - recall: 0.6737\n",
      "Epoch 1754 - Train Recall: 0.6818 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6142 - loss: 0.3225 - precision: 0.6073 - recall: 0.6743 - val_accuracy: 0.5975 - val_loss: 0.6519 - val_precision: 0.5874 - val_recall: 0.6552\n",
      "Epoch 1755/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6253 - loss: 0.3290 - precision: 0.6135 - recall: 0.6976\n",
      "Epoch 1755 - Train Recall: 0.6848 - Val Recall: 0.6522\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6243 - loss: 0.3293 - precision: 0.6122 - recall: 0.6964 - val_accuracy: 0.6184 - val_loss: 0.6561 - val_precision: 0.6110 - val_recall: 0.6522\n",
      "Epoch 1756/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6083 - loss: 0.3317 - precision: 0.5843 - recall: 0.6743\n",
      "Epoch 1756 - Train Recall: 0.6672 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6087 - loss: 0.3316 - precision: 0.5858 - recall: 0.6737 - val_accuracy: 0.6087 - val_loss: 0.6611 - val_precision: 0.5995 - val_recall: 0.6552\n",
      "Epoch 1757/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6077 - loss: 0.3350 - precision: 0.6064 - recall: 0.6690\n",
      "Epoch 1757 - Train Recall: 0.6638 - Val Recall: 0.6297\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6083 - loss: 0.3350 - precision: 0.6058 - recall: 0.6687 - val_accuracy: 0.5922 - val_loss: 0.6780 - val_precision: 0.5858 - val_recall: 0.6297\n",
      "Epoch 1758/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6160 - loss: 0.3302 - precision: 0.6039 - recall: 0.6626\n",
      "Epoch 1758 - Train Recall: 0.6585 - Val Recall: 0.6657\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6160 - loss: 0.3302 - precision: 0.6040 - recall: 0.6624 - val_accuracy: 0.6079 - val_loss: 0.6628 - val_precision: 0.5968 - val_recall: 0.6657\n",
      "Epoch 1759/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6313 - loss: 0.3350 - precision: 0.6211 - recall: 0.6721\n",
      "Epoch 1759 - Train Recall: 0.6559 - Val Recall: 0.5652\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6300 - loss: 0.3355 - precision: 0.6198 - recall: 0.6710 - val_accuracy: 0.5952 - val_loss: 0.6833 - val_precision: 0.6013 - val_recall: 0.5652\n",
      "Epoch 1760/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6208 - loss: 0.3126 - precision: 0.6146 - recall: 0.6659\n",
      "Epoch 1760 - Train Recall: 0.6792 - Val Recall: 0.7076\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6200 - loss: 0.3128 - precision: 0.6127 - recall: 0.6677 - val_accuracy: 0.5922 - val_loss: 0.6279 - val_precision: 0.5749 - val_recall: 0.7076\n",
      "Epoch 1761/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6257 - loss: 0.3453 - precision: 0.6099 - recall: 0.6820\n",
      "Epoch 1761 - Train Recall: 0.6653 - Val Recall: 0.6357\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6254 - loss: 0.3453 - precision: 0.6098 - recall: 0.6811 - val_accuracy: 0.6034 - val_loss: 0.6918 - val_precision: 0.5972 - val_recall: 0.6357\n",
      "Epoch 1762/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6219 - loss: 0.3306 - precision: 0.6161 - recall: 0.6606\n",
      "Epoch 1762 - Train Recall: 0.6563 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6216 - loss: 0.3307 - precision: 0.6157 - recall: 0.6604 - val_accuracy: 0.6057 - val_loss: 0.6642 - val_precision: 0.6020 - val_recall: 0.6237\n",
      "Epoch 1763/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6205 - loss: 0.3268 - precision: 0.6094 - recall: 0.6761\n",
      "Epoch 1763 - Train Recall: 0.6788 - Val Recall: 0.6567\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6203 - loss: 0.3270 - precision: 0.6090 - recall: 0.6764 - val_accuracy: 0.6124 - val_loss: 0.6590 - val_precision: 0.6033 - val_recall: 0.6567\n",
      "Epoch 1764/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6290 - loss: 0.3283 - precision: 0.6108 - recall: 0.6748\n",
      "Epoch 1764 - Train Recall: 0.6735 - Val Recall: 0.6072\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6290 - loss: 0.3283 - precision: 0.6108 - recall: 0.6748 - val_accuracy: 0.6154 - val_loss: 0.6664 - val_precision: 0.6174 - val_recall: 0.6072\n",
      "Epoch 1765/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6127 - loss: 0.3219 - precision: 0.6051 - recall: 0.6508\n",
      "Epoch 1765 - Train Recall: 0.6762 - Val Recall: 0.5697\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6128 - loss: 0.3220 - precision: 0.6046 - recall: 0.6533 - val_accuracy: 0.5982 - val_loss: 0.6519 - val_precision: 0.6041 - val_recall: 0.5697\n",
      "Epoch 1766/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6157 - loss: 0.3109 - precision: 0.6034 - recall: 0.6800\n",
      "Epoch 1766 - Train Recall: 0.6983 - Val Recall: 0.7286\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6159 - loss: 0.3108 - precision: 0.6033 - recall: 0.6810 - val_accuracy: 0.5892 - val_loss: 0.6247 - val_precision: 0.5698 - val_recall: 0.7286\n",
      "Epoch 1767/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6217 - loss: 0.3467 - precision: 0.6041 - recall: 0.6953\n",
      "Epoch 1767 - Train Recall: 0.6750 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6207 - loss: 0.3469 - precision: 0.6039 - recall: 0.6928 - val_accuracy: 0.6072 - val_loss: 0.6891 - val_precision: 0.6017 - val_recall: 0.6342\n",
      "Epoch 1768/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6191 - loss: 0.3259 - precision: 0.6083 - recall: 0.6503\n",
      "Epoch 1768 - Train Recall: 0.6612 - Val Recall: 0.6882\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6191 - loss: 0.3261 - precision: 0.6086 - recall: 0.6512 - val_accuracy: 0.6184 - val_loss: 0.6591 - val_precision: 0.6039 - val_recall: 0.6882\n",
      "Epoch 1769/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6287 - loss: 0.3436 - precision: 0.6246 - recall: 0.6666\n",
      "Epoch 1769 - Train Recall: 0.6514 - Val Recall: 0.5967\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6284 - loss: 0.3436 - precision: 0.6242 - recall: 0.6660 - val_accuracy: 0.6004 - val_loss: 0.6969 - val_precision: 0.6012 - val_recall: 0.5967\n",
      "Epoch 1770/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6217 - loss: 0.3200 - precision: 0.6210 - recall: 0.6430\n",
      "Epoch 1770 - Train Recall: 0.6364 - Val Recall: 0.6267\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6211 - loss: 0.3204 - precision: 0.6202 - recall: 0.6423 - val_accuracy: 0.6207 - val_loss: 0.6492 - val_precision: 0.6193 - val_recall: 0.6267\n",
      "Epoch 1771/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6169 - loss: 0.3345 - precision: 0.5998 - recall: 0.6538\n",
      "Epoch 1771 - Train Recall: 0.6510 - Val Recall: 0.6837\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6169 - loss: 0.3345 - precision: 0.5998 - recall: 0.6538 - val_accuracy: 0.6154 - val_loss: 0.6717 - val_precision: 0.6016 - val_recall: 0.6837\n",
      "Epoch 1772/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6214 - loss: 0.3458 - precision: 0.6125 - recall: 0.6319\n",
      "Epoch 1772 - Train Recall: 0.6289 - Val Recall: 0.6357\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6206 - loss: 0.3461 - precision: 0.6124 - recall: 0.6314 - val_accuracy: 0.5982 - val_loss: 0.6923 - val_precision: 0.5914 - val_recall: 0.6357\n",
      "Epoch 1773/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6118 - loss: 0.3400 - precision: 0.6073 - recall: 0.6231\n",
      "Epoch 1773 - Train Recall: 0.6263 - Val Recall: 0.5817\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6118 - loss: 0.3401 - precision: 0.6075 - recall: 0.6233 - val_accuracy: 0.6132 - val_loss: 0.6777 - val_precision: 0.6208 - val_recall: 0.5817\n",
      "Epoch 1774/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6355 - loss: 0.3213 - precision: 0.6415 - recall: 0.6422\n",
      "Epoch 1774 - Train Recall: 0.6368 - Val Recall: 0.7241\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6337 - loss: 0.3217 - precision: 0.6387 - recall: 0.6415 - val_accuracy: 0.6057 - val_loss: 0.6551 - val_precision: 0.5855 - val_recall: 0.7241\n",
      "Epoch 1775/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6289 - loss: 0.3605 - precision: 0.6199 - recall: 0.6574\n",
      "Epoch 1775 - Train Recall: 0.6334 - Val Recall: 0.4738\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6287 - loss: 0.3605 - precision: 0.6198 - recall: 0.6567 - val_accuracy: 0.5832 - val_loss: 0.7228 - val_precision: 0.6065 - val_recall: 0.4738\n",
      "Epoch 1776/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6257 - loss: 0.2962 - precision: 0.6193 - recall: 0.6563\n",
      "Epoch 1776 - Train Recall: 0.6803 - Val Recall: 0.6942\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6250 - loss: 0.2960 - precision: 0.6178 - recall: 0.6589 - val_accuracy: 0.6012 - val_loss: 0.5888 - val_precision: 0.5853 - val_recall: 0.6942\n",
      "Epoch 1777/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6120 - loss: 0.3419 - precision: 0.5904 - recall: 0.7144\n",
      "Epoch 1777 - Train Recall: 0.6897 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6129 - loss: 0.3419 - precision: 0.5921 - recall: 0.7112 - val_accuracy: 0.6102 - val_loss: 0.6853 - val_precision: 0.5958 - val_recall: 0.6852\n",
      "Epoch 1778/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6354 - loss: 0.3315 - precision: 0.6337 - recall: 0.6873\n",
      "Epoch 1778 - Train Recall: 0.6653 - Val Recall: 0.6312\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6346 - loss: 0.3317 - precision: 0.6325 - recall: 0.6861 - val_accuracy: 0.6064 - val_loss: 0.6744 - val_precision: 0.6014 - val_recall: 0.6312\n",
      "Epoch 1779/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6273 - loss: 0.3248 - precision: 0.6176 - recall: 0.6435\n",
      "Epoch 1779 - Train Recall: 0.6417 - Val Recall: 0.6972\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6265 - loss: 0.3250 - precision: 0.6170 - recall: 0.6434 - val_accuracy: 0.5915 - val_loss: 0.6637 - val_precision: 0.5755 - val_recall: 0.6972\n",
      "Epoch 1780/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6120 - loss: 0.3525 - precision: 0.6006 - recall: 0.6277\n",
      "Epoch 1780 - Train Recall: 0.6222 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6121 - loss: 0.3525 - precision: 0.6011 - recall: 0.6274 - val_accuracy: 0.5922 - val_loss: 0.7080 - val_precision: 0.5819 - val_recall: 0.6552\n",
      "Epoch 1781/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6195 - loss: 0.3465 - precision: 0.6082 - recall: 0.6281\n",
      "Epoch 1781 - Train Recall: 0.6166 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6196 - loss: 0.3465 - precision: 0.6083 - recall: 0.6280 - val_accuracy: 0.6012 - val_loss: 0.6953 - val_precision: 0.5952 - val_recall: 0.6327\n",
      "Epoch 1782/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6102 - loss: 0.3450 - precision: 0.6038 - recall: 0.6244\n",
      "Epoch 1782 - Train Recall: 0.6248 - Val Recall: 0.5082\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6108 - loss: 0.3449 - precision: 0.6047 - recall: 0.6245 - val_accuracy: 0.5937 - val_loss: 0.6928 - val_precision: 0.6130 - val_recall: 0.5082\n",
      "Epoch 1783/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6281 - loss: 0.3075 - precision: 0.6290 - recall: 0.6403\n",
      "Epoch 1783 - Train Recall: 0.6724 - Val Recall: 0.6717\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6279 - loss: 0.3074 - precision: 0.6284 - recall: 0.6413 - val_accuracy: 0.6057 - val_loss: 0.6119 - val_precision: 0.5934 - val_recall: 0.6717\n",
      "Epoch 1784/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6339 - loss: 0.3340 - precision: 0.6230 - recall: 0.6935\n",
      "Epoch 1784 - Train Recall: 0.6732 - Val Recall: 0.7511\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6325 - loss: 0.3345 - precision: 0.6217 - recall: 0.6912 - val_accuracy: 0.6034 - val_loss: 0.6786 - val_precision: 0.5799 - val_recall: 0.7511\n",
      "Epoch 1785/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6305 - loss: 0.3530 - precision: 0.6369 - recall: 0.6513\n",
      "Epoch 1785 - Train Recall: 0.6259 - Val Recall: 0.6357\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6297 - loss: 0.3535 - precision: 0.6352 - recall: 0.6487 - val_accuracy: 0.6079 - val_loss: 0.7174 - val_precision: 0.6023 - val_recall: 0.6357\n",
      "Epoch 1786/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6098 - loss: 0.3398 - precision: 0.6146 - recall: 0.5796\n",
      "Epoch 1786 - Train Recall: 0.5817 - Val Recall: 0.6567\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6099 - loss: 0.3399 - precision: 0.6148 - recall: 0.5797 - val_accuracy: 0.6087 - val_loss: 0.6797 - val_precision: 0.5992 - val_recall: 0.6567\n",
      "Epoch 1787/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6151 - loss: 0.3600 - precision: 0.6217 - recall: 0.5963\n",
      "Epoch 1787 - Train Recall: 0.5941 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6158 - loss: 0.3600 - precision: 0.6222 - recall: 0.5965 - val_accuracy: 0.5990 - val_loss: 0.7271 - val_precision: 0.6071 - val_recall: 0.5607\n",
      "Epoch 1788/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6204 - loss: 0.3307 - precision: 0.6236 - recall: 0.5950\n",
      "Epoch 1788 - Train Recall: 0.6079 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6202 - loss: 0.3306 - precision: 0.6232 - recall: 0.5964 - val_accuracy: 0.5952 - val_loss: 0.6627 - val_precision: 0.5924 - val_recall: 0.6102\n",
      "Epoch 1789/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6140 - loss: 0.3383 - precision: 0.6114 - recall: 0.6269\n",
      "Epoch 1789 - Train Recall: 0.6282 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6140 - loss: 0.3383 - precision: 0.6113 - recall: 0.6270 - val_accuracy: 0.5960 - val_loss: 0.6875 - val_precision: 0.5872 - val_recall: 0.6462\n",
      "Epoch 1790/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.3412 - precision: 0.6220 - recall: 0.6470\n",
      "Epoch 1790 - Train Recall: 0.6207 - Val Recall: 0.5577\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6244 - loss: 0.3413 - precision: 0.6216 - recall: 0.6454 - val_accuracy: 0.5930 - val_loss: 0.6926 - val_precision: 0.6000 - val_recall: 0.5577\n",
      "Epoch 1791/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6269 - loss: 0.3203 - precision: 0.6244 - recall: 0.6325\n",
      "Epoch 1791 - Train Recall: 0.6466 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6267 - loss: 0.3204 - precision: 0.6241 - recall: 0.6329 - val_accuracy: 0.6034 - val_loss: 0.6452 - val_precision: 0.5958 - val_recall: 0.6432\n",
      "Epoch 1792/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6410 - loss: 0.3311 - precision: 0.6332 - recall: 0.6954\n",
      "Epoch 1792 - Train Recall: 0.6762 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6392 - loss: 0.3316 - precision: 0.6310 - recall: 0.6938 - val_accuracy: 0.5915 - val_loss: 0.6839 - val_precision: 0.5859 - val_recall: 0.6237\n",
      "Epoch 1793/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6283 - loss: 0.3195 - precision: 0.6139 - recall: 0.6644\n",
      "Epoch 1793 - Train Recall: 0.6604 - Val Recall: 0.6642\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6269 - loss: 0.3201 - precision: 0.6132 - recall: 0.6634 - val_accuracy: 0.6064 - val_loss: 0.6550 - val_precision: 0.5954 - val_recall: 0.6642\n",
      "Epoch 1794/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6361 - loss: 0.3380 - precision: 0.6259 - recall: 0.6957\n",
      "Epoch 1794 - Train Recall: 0.6728 - Val Recall: 0.6627\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6347 - loss: 0.3383 - precision: 0.6245 - recall: 0.6933 - val_accuracy: 0.6094 - val_loss: 0.6800 - val_precision: 0.5989 - val_recall: 0.6627\n",
      "Epoch 1795/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6402 - loss: 0.3267 - precision: 0.6228 - recall: 0.6975\n",
      "Epoch 1795 - Train Recall: 0.6488 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6398 - loss: 0.3269 - precision: 0.6225 - recall: 0.6966 - val_accuracy: 0.5990 - val_loss: 0.6768 - val_precision: 0.5897 - val_recall: 0.6507\n",
      "Epoch 1796/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6328 - loss: 0.3337 - precision: 0.6261 - recall: 0.6573\n",
      "Epoch 1796 - Train Recall: 0.6503 - Val Recall: 0.6012\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6322 - loss: 0.3340 - precision: 0.6254 - recall: 0.6568 - val_accuracy: 0.5892 - val_loss: 0.6895 - val_precision: 0.5871 - val_recall: 0.6012\n",
      "Epoch 1797/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6334 - loss: 0.3208 - precision: 0.6193 - recall: 0.6745\n",
      "Epoch 1797 - Train Recall: 0.6589 - Val Recall: 0.6417\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6328 - loss: 0.3210 - precision: 0.6191 - recall: 0.6737 - val_accuracy: 0.5960 - val_loss: 0.6584 - val_precision: 0.5879 - val_recall: 0.6417\n",
      "Epoch 1798/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6251 - loss: 0.3273 - precision: 0.6126 - recall: 0.6777\n",
      "Epoch 1798 - Train Recall: 0.6409 - Val Recall: 0.5877\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6237 - loss: 0.3280 - precision: 0.6119 - recall: 0.6742 - val_accuracy: 0.6004 - val_loss: 0.6708 - val_precision: 0.6031 - val_recall: 0.5877\n",
      "Epoch 1799/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6072 - loss: 0.3256 - precision: 0.5938 - recall: 0.6227\n",
      "Epoch 1799 - Train Recall: 0.6473 - Val Recall: 0.6657\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6073 - loss: 0.3256 - precision: 0.5941 - recall: 0.6234 - val_accuracy: 0.6079 - val_loss: 0.6544 - val_precision: 0.5968 - val_recall: 0.6657\n",
      "Epoch 1800/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6173 - loss: 0.3428 - precision: 0.5954 - recall: 0.6809\n",
      "Epoch 1800 - Train Recall: 0.6484 - Val Recall: 0.5802\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6174 - loss: 0.3429 - precision: 0.5970 - recall: 0.6773 - val_accuracy: 0.5907 - val_loss: 0.6921 - val_precision: 0.5926 - val_recall: 0.5802\n",
      "Epoch 1801/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6127 - loss: 0.3213 - precision: 0.6057 - recall: 0.6247\n",
      "Epoch 1801 - Train Recall: 0.6570 - Val Recall: 0.7271\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6137 - loss: 0.3210 - precision: 0.6066 - recall: 0.6290 - val_accuracy: 0.6072 - val_loss: 0.6412 - val_precision: 0.5865 - val_recall: 0.7271\n",
      "Epoch 1802/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6070 - loss: 0.3587 - precision: 0.5938 - recall: 0.6307\n",
      "Epoch 1802 - Train Recall: 0.6012 - Val Recall: 0.5892\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6069 - loss: 0.3586 - precision: 0.5948 - recall: 0.6282 - val_accuracy: 0.6139 - val_loss: 0.7108 - val_precision: 0.6199 - val_recall: 0.5892\n",
      "Epoch 1803/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6139 - loss: 0.3351 - precision: 0.6060 - recall: 0.6272\n",
      "Epoch 1803 - Train Recall: 0.6267 - Val Recall: 0.6402\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6138 - loss: 0.3351 - precision: 0.6060 - recall: 0.6272 - val_accuracy: 0.6049 - val_loss: 0.6749 - val_precision: 0.5980 - val_recall: 0.6402\n",
      "Epoch 1804/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6205 - loss: 0.3404 - precision: 0.6170 - recall: 0.6516\n",
      "Epoch 1804 - Train Recall: 0.6406 - Val Recall: 0.5397\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6206 - loss: 0.3405 - precision: 0.6169 - recall: 0.6508 - val_accuracy: 0.5907 - val_loss: 0.6864 - val_precision: 0.6010 - val_recall: 0.5397\n",
      "Epoch 1805/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6214 - loss: 0.3104 - precision: 0.6230 - recall: 0.6277\n",
      "Epoch 1805 - Train Recall: 0.6589 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6213 - loss: 0.3104 - precision: 0.6229 - recall: 0.6278 - val_accuracy: 0.6012 - val_loss: 0.6262 - val_precision: 0.5873 - val_recall: 0.6807\n",
      "Epoch 1806/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6363 - loss: 0.3390 - precision: 0.6229 - recall: 0.7056\n",
      "Epoch 1806 - Train Recall: 0.6754 - Val Recall: 0.7106\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6351 - loss: 0.3394 - precision: 0.6218 - recall: 0.7031 - val_accuracy: 0.6192 - val_loss: 0.6866 - val_precision: 0.6008 - val_recall: 0.7106\n",
      "Epoch 1807/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6236 - loss: 0.3435 - precision: 0.6116 - recall: 0.6443\n",
      "Epoch 1807 - Train Recall: 0.6128 - Val Recall: 0.5637\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6222 - loss: 0.3439 - precision: 0.6116 - recall: 0.6400 - val_accuracy: 0.5967 - val_loss: 0.7082 - val_precision: 0.6035 - val_recall: 0.5637\n",
      "Epoch 1808/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6235 - loss: 0.3205 - precision: 0.6224 - recall: 0.6312\n",
      "Epoch 1808 - Train Recall: 0.6406 - Val Recall: 0.6837\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6227 - loss: 0.3209 - precision: 0.6210 - recall: 0.6321 - val_accuracy: 0.5975 - val_loss: 0.6528 - val_precision: 0.5831 - val_recall: 0.6837\n",
      "Epoch 1809/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6262 - loss: 0.3470 - precision: 0.6156 - recall: 0.6487\n",
      "Epoch 1809 - Train Recall: 0.6289 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6257 - loss: 0.3471 - precision: 0.6158 - recall: 0.6474 - val_accuracy: 0.6019 - val_loss: 0.7023 - val_precision: 0.5939 - val_recall: 0.6447\n",
      "Epoch 1810/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6190 - loss: 0.3426 - precision: 0.6103 - recall: 0.6209\n",
      "Epoch 1810 - Train Recall: 0.6192 - Val Recall: 0.5577\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6189 - loss: 0.3426 - precision: 0.6107 - recall: 0.6207 - val_accuracy: 0.5997 - val_loss: 0.6902 - val_precision: 0.6088 - val_recall: 0.5577\n",
      "Epoch 1811/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6297 - loss: 0.3197 - precision: 0.6164 - recall: 0.6542\n",
      "Epoch 1811 - Train Recall: 0.6544 - Val Recall: 0.5787\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6295 - loss: 0.3198 - precision: 0.6164 - recall: 0.6542 - val_accuracy: 0.5885 - val_loss: 0.6595 - val_precision: 0.5902 - val_recall: 0.5787\n",
      "Epoch 1812/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6248 - loss: 0.3158 - precision: 0.6069 - recall: 0.6704\n",
      "Epoch 1812 - Train Recall: 0.6795 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6249 - loss: 0.3158 - precision: 0.6074 - recall: 0.6709 - val_accuracy: 0.6079 - val_loss: 0.6391 - val_precision: 0.5902 - val_recall: 0.7061\n",
      "Epoch 1813/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6152 - loss: 0.3441 - precision: 0.6093 - recall: 0.6791\n",
      "Epoch 1813 - Train Recall: 0.6672 - Val Recall: 0.6177\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6154 - loss: 0.3442 - precision: 0.6093 - recall: 0.6787 - val_accuracy: 0.6124 - val_loss: 0.6917 - val_precision: 0.6113 - val_recall: 0.6177\n",
      "Epoch 1814/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6238 - loss: 0.3237 - precision: 0.6137 - recall: 0.6573\n",
      "Epoch 1814 - Train Recall: 0.6484 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6237 - loss: 0.3238 - precision: 0.6139 - recall: 0.6568 - val_accuracy: 0.5915 - val_loss: 0.6599 - val_precision: 0.5882 - val_recall: 0.6102\n",
      "Epoch 1815/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6223 - loss: 0.3257 - precision: 0.6142 - recall: 0.6634\n",
      "Epoch 1815 - Train Recall: 0.6657 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6222 - loss: 0.3257 - precision: 0.6141 - recall: 0.6635 - val_accuracy: 0.5960 - val_loss: 0.6584 - val_precision: 0.5884 - val_recall: 0.6387\n",
      "Epoch 1816/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6138 - loss: 0.3308 - precision: 0.6056 - recall: 0.6530\n",
      "Epoch 1816 - Train Recall: 0.6544 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6137 - loss: 0.3309 - precision: 0.6055 - recall: 0.6531 - val_accuracy: 0.5870 - val_loss: 0.6763 - val_precision: 0.5815 - val_recall: 0.6207\n",
      "Epoch 1817/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6294 - loss: 0.3258 - precision: 0.6298 - recall: 0.6815\n",
      "Epoch 1817 - Train Recall: 0.6735 - Val Recall: 0.6357\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6291 - loss: 0.3259 - precision: 0.6291 - recall: 0.6813 - val_accuracy: 0.5915 - val_loss: 0.6631 - val_precision: 0.5840 - val_recall: 0.6357\n",
      "Epoch 1818/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6143 - loss: 0.3288 - precision: 0.6002 - recall: 0.6484\n",
      "Epoch 1818 - Train Recall: 0.6544 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6145 - loss: 0.3288 - precision: 0.6010 - recall: 0.6491 - val_accuracy: 0.6222 - val_loss: 0.6570 - val_precision: 0.6046 - val_recall: 0.7061\n",
      "Epoch 1819/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6137 - loss: 0.3508 - precision: 0.6080 - recall: 0.6376\n",
      "Epoch 1819 - Train Recall: 0.6271 - Val Recall: 0.5577\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6138 - loss: 0.3509 - precision: 0.6081 - recall: 0.6372 - val_accuracy: 0.5997 - val_loss: 0.7119 - val_precision: 0.6088 - val_recall: 0.5577\n",
      "Epoch 1820/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6204 - loss: 0.3180 - precision: 0.6105 - recall: 0.6439\n",
      "Epoch 1820 - Train Recall: 0.6578 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6210 - loss: 0.3181 - precision: 0.6113 - recall: 0.6453 - val_accuracy: 0.6132 - val_loss: 0.6384 - val_precision: 0.6056 - val_recall: 0.6492\n",
      "Epoch 1821/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6327 - loss: 0.3308 - precision: 0.6220 - recall: 0.6936\n",
      "Epoch 1821 - Train Recall: 0.6765 - Val Recall: 0.6117\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6320 - loss: 0.3314 - precision: 0.6212 - recall: 0.6921 - val_accuracy: 0.6042 - val_loss: 0.6737 - val_precision: 0.6027 - val_recall: 0.6117\n",
      "Epoch 1822/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6250 - loss: 0.3187 - precision: 0.6214 - recall: 0.6821\n",
      "Epoch 1822 - Train Recall: 0.6773 - Val Recall: 0.6582\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6250 - loss: 0.3187 - precision: 0.6212 - recall: 0.6820 - val_accuracy: 0.5930 - val_loss: 0.6474 - val_precision: 0.5822 - val_recall: 0.6582\n",
      "Epoch 1823/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6070 - loss: 0.3340 - precision: 0.6018 - recall: 0.6449\n",
      "Epoch 1823 - Train Recall: 0.6627 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6074 - loss: 0.3340 - precision: 0.6020 - recall: 0.6455 - val_accuracy: 0.6004 - val_loss: 0.6749 - val_precision: 0.5994 - val_recall: 0.6057\n",
      "Epoch 1824/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6308 - loss: 0.3207 - precision: 0.6224 - recall: 0.6692\n",
      "Epoch 1824 - Train Recall: 0.6739 - Val Recall: 0.6777\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6297 - loss: 0.3211 - precision: 0.6210 - recall: 0.6695 - val_accuracy: 0.6192 - val_loss: 0.6449 - val_precision: 0.6067 - val_recall: 0.6777\n",
      "Epoch 1825/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6335 - loss: 0.3348 - precision: 0.6216 - recall: 0.6731\n",
      "Epoch 1825 - Train Recall: 0.6582 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6323 - loss: 0.3353 - precision: 0.6205 - recall: 0.6716 - val_accuracy: 0.5990 - val_loss: 0.6862 - val_precision: 0.5948 - val_recall: 0.6207\n",
      "Epoch 1826/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6148 - loss: 0.3287 - precision: 0.6049 - recall: 0.6576\n",
      "Epoch 1826 - Train Recall: 0.6679 - Val Recall: 0.6717\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6152 - loss: 0.3287 - precision: 0.6052 - recall: 0.6585 - val_accuracy: 0.6229 - val_loss: 0.6541 - val_precision: 0.6120 - val_recall: 0.6717\n",
      "Epoch 1827/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6297 - loss: 0.3381 - precision: 0.6248 - recall: 0.6748\n",
      "Epoch 1827 - Train Recall: 0.6522 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6295 - loss: 0.3382 - precision: 0.6245 - recall: 0.6741 - val_accuracy: 0.5937 - val_loss: 0.6911 - val_precision: 0.5790 - val_recall: 0.6867\n",
      "Epoch 1828/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6188 - loss: 0.3497 - precision: 0.6214 - recall: 0.6378\n",
      "Epoch 1828 - Train Recall: 0.6361 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6188 - loss: 0.3496 - precision: 0.6208 - recall: 0.6378 - val_accuracy: 0.5967 - val_loss: 0.6977 - val_precision: 0.5917 - val_recall: 0.6237\n",
      "Epoch 1829/2000\n",
      "\u001b[1m143/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6297 - loss: 0.3359 - precision: 0.6277 - recall: 0.6491\n",
      "Epoch 1829 - Train Recall: 0.6387 - Val Recall: 0.7001\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6295 - loss: 0.3357 - precision: 0.6274 - recall: 0.6477 - val_accuracy: 0.6169 - val_loss: 0.6680 - val_precision: 0.6003 - val_recall: 0.7001\n",
      "Epoch 1830/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6190 - loss: 0.3557 - precision: 0.6165 - recall: 0.6054\n",
      "Epoch 1830 - Train Recall: 0.6068 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6192 - loss: 0.3556 - precision: 0.6171 - recall: 0.6055 - val_accuracy: 0.6057 - val_loss: 0.7093 - val_precision: 0.5972 - val_recall: 0.6492\n",
      "Epoch 1831/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6192 - loss: 0.3495 - precision: 0.6093 - recall: 0.6064\n",
      "Epoch 1831 - Train Recall: 0.5933 - Val Recall: 0.5667\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6192 - loss: 0.3496 - precision: 0.6101 - recall: 0.6057 - val_accuracy: 0.6154 - val_loss: 0.7022 - val_precision: 0.6279 - val_recall: 0.5667\n",
      "Epoch 1832/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6228 - loss: 0.3310 - precision: 0.6147 - recall: 0.6133\n",
      "Epoch 1832 - Train Recall: 0.6162 - Val Recall: 0.6492\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6223 - loss: 0.3311 - precision: 0.6149 - recall: 0.6136 - val_accuracy: 0.6252 - val_loss: 0.6591 - val_precision: 0.6195 - val_recall: 0.6492\n",
      "Epoch 1833/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6287 - loss: 0.3444 - precision: 0.6253 - recall: 0.6356\n",
      "Epoch 1833 - Train Recall: 0.6316 - Val Recall: 0.5487\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6284 - loss: 0.3446 - precision: 0.6252 - recall: 0.6353 - val_accuracy: 0.5885 - val_loss: 0.7054 - val_precision: 0.5961 - val_recall: 0.5487\n",
      "Epoch 1834/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6097 - loss: 0.3153 - precision: 0.5980 - recall: 0.6104\n",
      "Epoch 1834 - Train Recall: 0.6406 - Val Recall: 0.7331\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6101 - loss: 0.3154 - precision: 0.5989 - recall: 0.6125 - val_accuracy: 0.6034 - val_loss: 0.6363 - val_precision: 0.5821 - val_recall: 0.7331\n",
      "Epoch 1835/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6279 - loss: 0.3604 - precision: 0.6241 - recall: 0.6741\n",
      "Epoch 1835 - Train Recall: 0.6387 - Val Recall: 0.5637\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6277 - loss: 0.3604 - precision: 0.6238 - recall: 0.6728 - val_accuracy: 0.6079 - val_loss: 0.7247 - val_precision: 0.6184 - val_recall: 0.5637\n",
      "Epoch 1836/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6383 - loss: 0.3173 - precision: 0.6465 - recall: 0.6286\n",
      "Epoch 1836 - Train Recall: 0.6289 - Val Recall: 0.7031\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6368 - loss: 0.3176 - precision: 0.6441 - recall: 0.6285 - val_accuracy: 0.6072 - val_loss: 0.6366 - val_precision: 0.5899 - val_recall: 0.7031\n",
      "Epoch 1837/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6240 - loss: 0.3554 - precision: 0.6210 - recall: 0.6543\n",
      "Epoch 1837 - Train Recall: 0.6409 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6238 - loss: 0.3555 - precision: 0.6207 - recall: 0.6535 - val_accuracy: 0.6042 - val_loss: 0.7189 - val_precision: 0.5983 - val_recall: 0.6342\n",
      "Epoch 1838/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6154 - loss: 0.3352 - precision: 0.6235 - recall: 0.5922\n",
      "Epoch 1838 - Train Recall: 0.6053 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6151 - loss: 0.3353 - precision: 0.6228 - recall: 0.5931 - val_accuracy: 0.5990 - val_loss: 0.6798 - val_precision: 0.5982 - val_recall: 0.6027\n",
      "Epoch 1839/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6287 - loss: 0.3352 - precision: 0.6118 - recall: 0.6357\n",
      "Epoch 1839 - Train Recall: 0.6267 - Val Recall: 0.5772\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6286 - loss: 0.3352 - precision: 0.6119 - recall: 0.6356 - val_accuracy: 0.5990 - val_loss: 0.6752 - val_precision: 0.6034 - val_recall: 0.5772\n",
      "Epoch 1840/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6308 - loss: 0.3207 - precision: 0.6294 - recall: 0.6510\n",
      "Epoch 1840 - Train Recall: 0.6608 - Val Recall: 0.6267\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6300 - loss: 0.3210 - precision: 0.6279 - recall: 0.6521 - val_accuracy: 0.6004 - val_loss: 0.6518 - val_precision: 0.5954 - val_recall: 0.6267\n",
      "Epoch 1841/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6236 - loss: 0.3289 - precision: 0.6193 - recall: 0.6636\n",
      "Epoch 1841 - Train Recall: 0.6589 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6233 - loss: 0.3289 - precision: 0.6188 - recall: 0.6635 - val_accuracy: 0.6124 - val_loss: 0.6604 - val_precision: 0.6081 - val_recall: 0.6327\n",
      "Epoch 1842/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6163 - loss: 0.3314 - precision: 0.6018 - recall: 0.6649\n",
      "Epoch 1842 - Train Recall: 0.6675 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6170 - loss: 0.3313 - precision: 0.6029 - recall: 0.6653 - val_accuracy: 0.6072 - val_loss: 0.6684 - val_precision: 0.5978 - val_recall: 0.6552\n",
      "Epoch 1843/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6249 - loss: 0.3341 - precision: 0.6135 - recall: 0.6618\n",
      "Epoch 1843 - Train Recall: 0.6653 - Val Recall: 0.6927\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6249 - loss: 0.3341 - precision: 0.6134 - recall: 0.6618 - val_accuracy: 0.6147 - val_loss: 0.6709 - val_precision: 0.5992 - val_recall: 0.6927\n",
      "Epoch 1844/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6202 - loss: 0.3426 - precision: 0.6155 - recall: 0.6644\n",
      "Epoch 1844 - Train Recall: 0.6574 - Val Recall: 0.5937\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6202 - loss: 0.3426 - precision: 0.6155 - recall: 0.6644 - val_accuracy: 0.5930 - val_loss: 0.7028 - val_precision: 0.5928 - val_recall: 0.5937\n",
      "Epoch 1845/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6132 - loss: 0.3236 - precision: 0.6072 - recall: 0.6426\n",
      "Epoch 1845 - Train Recall: 0.6548 - Val Recall: 0.6612\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6133 - loss: 0.3236 - precision: 0.6072 - recall: 0.6429 - val_accuracy: 0.5810 - val_loss: 0.6567 - val_precision: 0.5698 - val_recall: 0.6612\n",
      "Epoch 1846/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6178 - loss: 0.3395 - precision: 0.6139 - recall: 0.6723\n",
      "Epoch 1846 - Train Recall: 0.6507 - Val Recall: 0.5232\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6179 - loss: 0.3396 - precision: 0.6138 - recall: 0.6719 - val_accuracy: 0.5930 - val_loss: 0.6814 - val_precision: 0.6080 - val_recall: 0.5232\n",
      "Epoch 1847/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6333 - loss: 0.3021 - precision: 0.6235 - recall: 0.6769\n",
      "Epoch 1847 - Train Recall: 0.6848 - Val Recall: 0.7106\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6329 - loss: 0.3022 - precision: 0.6230 - recall: 0.6772 - val_accuracy: 0.6064 - val_loss: 0.6130 - val_precision: 0.5881 - val_recall: 0.7106\n",
      "Epoch 1848/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6295 - loss: 0.3414 - precision: 0.6070 - recall: 0.7147\n",
      "Epoch 1848 - Train Recall: 0.6859 - Val Recall: 0.6732\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6284 - loss: 0.3417 - precision: 0.6066 - recall: 0.7120 - val_accuracy: 0.6087 - val_loss: 0.6948 - val_precision: 0.5963 - val_recall: 0.6732\n",
      "Epoch 1849/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6094 - loss: 0.3360 - precision: 0.6020 - recall: 0.6581\n",
      "Epoch 1849 - Train Recall: 0.6675 - Val Recall: 0.6057\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6095 - loss: 0.3360 - precision: 0.6020 - recall: 0.6582 - val_accuracy: 0.5817 - val_loss: 0.6768 - val_precision: 0.5780 - val_recall: 0.6057\n",
      "Epoch 1850/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6203 - loss: 0.3214 - precision: 0.6130 - recall: 0.6646\n",
      "Epoch 1850 - Train Recall: 0.6762 - Val Recall: 0.5622\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6205 - loss: 0.3215 - precision: 0.6128 - recall: 0.6653 - val_accuracy: 0.5855 - val_loss: 0.6659 - val_precision: 0.5896 - val_recall: 0.5622\n",
      "Epoch 1851/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6234 - loss: 0.3087 - precision: 0.6060 - recall: 0.7036\n",
      "Epoch 1851 - Train Recall: 0.7140 - Val Recall: 0.7001\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6230 - loss: 0.3087 - precision: 0.6056 - recall: 0.7044 - val_accuracy: 0.5907 - val_loss: 0.6251 - val_precision: 0.5744 - val_recall: 0.7001\n",
      "Epoch 1852/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6190 - loss: 0.3328 - precision: 0.5893 - recall: 0.7167\n",
      "Epoch 1852 - Train Recall: 0.7013 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6194 - loss: 0.3329 - precision: 0.5905 - recall: 0.7156 - val_accuracy: 0.6064 - val_loss: 0.6720 - val_precision: 0.5978 - val_recall: 0.6507\n",
      "Epoch 1853/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6266 - loss: 0.3223 - precision: 0.6166 - recall: 0.7053\n",
      "Epoch 1853 - Train Recall: 0.6927 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6263 - loss: 0.3226 - precision: 0.6158 - recall: 0.7042 - val_accuracy: 0.5975 - val_loss: 0.6649 - val_precision: 0.5855 - val_recall: 0.6672\n",
      "Epoch 1854/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6243 - loss: 0.3315 - precision: 0.6033 - recall: 0.6847\n",
      "Epoch 1854 - Train Recall: 0.6769 - Val Recall: 0.6537\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6238 - loss: 0.3315 - precision: 0.6036 - recall: 0.6840 - val_accuracy: 0.6087 - val_loss: 0.6680 - val_precision: 0.5997 - val_recall: 0.6537\n",
      "Epoch 1855/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6389 - loss: 0.3297 - precision: 0.6253 - recall: 0.6940\n",
      "Epoch 1855 - Train Recall: 0.6874 - Val Recall: 0.5622\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6388 - loss: 0.3297 - precision: 0.6252 - recall: 0.6939 - val_accuracy: 0.5922 - val_loss: 0.6815 - val_precision: 0.5981 - val_recall: 0.5622\n",
      "Epoch 1856/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6182 - loss: 0.3081 - precision: 0.6069 - recall: 0.6854\n",
      "Epoch 1856 - Train Recall: 0.6994 - Val Recall: 0.7151\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6185 - loss: 0.3081 - precision: 0.6070 - recall: 0.6859 - val_accuracy: 0.6004 - val_loss: 0.6206 - val_precision: 0.5817 - val_recall: 0.7151\n",
      "Epoch 1857/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6110 - loss: 0.3444 - precision: 0.5874 - recall: 0.6853\n",
      "Epoch 1857 - Train Recall: 0.6810 - Val Recall: 0.6267\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6116 - loss: 0.3444 - precision: 0.5886 - recall: 0.6850 - val_accuracy: 0.5990 - val_loss: 0.6845 - val_precision: 0.5938 - val_recall: 0.6267\n",
      "Epoch 1858/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6283 - loss: 0.3228 - precision: 0.6242 - recall: 0.6786\n",
      "Epoch 1858 - Train Recall: 0.6762 - Val Recall: 0.7271\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6280 - loss: 0.3229 - precision: 0.6233 - recall: 0.6783 - val_accuracy: 0.6012 - val_loss: 0.6554 - val_precision: 0.5808 - val_recall: 0.7271\n",
      "Epoch 1859/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6287 - loss: 0.3469 - precision: 0.6133 - recall: 0.6841\n",
      "Epoch 1859 - Train Recall: 0.6484 - Val Recall: 0.5667\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6285 - loss: 0.3470 - precision: 0.6134 - recall: 0.6831 - val_accuracy: 0.5937 - val_loss: 0.7085 - val_precision: 0.5990 - val_recall: 0.5667\n",
      "Epoch 1860/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6412 - loss: 0.3103 - precision: 0.6388 - recall: 0.6454\n",
      "Epoch 1860 - Train Recall: 0.6481 - Val Recall: 0.6267\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6399 - loss: 0.3108 - precision: 0.6372 - recall: 0.6454 - val_accuracy: 0.6049 - val_loss: 0.6367 - val_precision: 0.6006 - val_recall: 0.6267\n",
      "Epoch 1861/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6181 - loss: 0.3331 - precision: 0.5982 - recall: 0.6989\n",
      "Epoch 1861 - Train Recall: 0.6859 - Val Recall: 0.6657\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6182 - loss: 0.3330 - precision: 0.5985 - recall: 0.6982 - val_accuracy: 0.6057 - val_loss: 0.6674 - val_precision: 0.5944 - val_recall: 0.6657\n",
      "Epoch 1862/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6115 - loss: 0.3325 - precision: 0.6007 - recall: 0.6501\n",
      "Epoch 1862 - Train Recall: 0.6657 - Val Recall: 0.7061\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6122 - loss: 0.3325 - precision: 0.6015 - recall: 0.6512 - val_accuracy: 0.6034 - val_loss: 0.6720 - val_precision: 0.5858 - val_recall: 0.7061\n",
      "Epoch 1863/2000\n",
      "\u001b[1m141/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6342 - loss: 0.3407 - precision: 0.6334 - recall: 0.6722\n",
      "Epoch 1863 - Train Recall: 0.6503 - Val Recall: 0.6897\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6315 - loss: 0.3419 - precision: 0.6298 - recall: 0.6691 - val_accuracy: 0.6042 - val_loss: 0.7073 - val_precision: 0.5890 - val_recall: 0.6897\n",
      "Epoch 1864/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6273 - loss: 0.3469 - precision: 0.6308 - recall: 0.6151\n",
      "Epoch 1864 - Train Recall: 0.6001 - Val Recall: 0.5142\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6271 - loss: 0.3470 - precision: 0.6307 - recall: 0.6137 - val_accuracy: 0.5915 - val_loss: 0.7045 - val_precision: 0.6082 - val_recall: 0.5142\n",
      "Epoch 1865/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6243 - loss: 0.3143 - precision: 0.6251 - recall: 0.6207\n",
      "Epoch 1865 - Train Recall: 0.6507 - Val Recall: 0.7106\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6246 - loss: 0.3143 - precision: 0.6251 - recall: 0.6220 - val_accuracy: 0.6184 - val_loss: 0.6263 - val_precision: 0.6000 - val_recall: 0.7106\n",
      "Epoch 1866/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6177 - loss: 0.3552 - precision: 0.6006 - recall: 0.6655\n",
      "Epoch 1866 - Train Recall: 0.6413 - Val Recall: 0.5217\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6176 - loss: 0.3551 - precision: 0.6018 - recall: 0.6623 - val_accuracy: 0.5885 - val_loss: 0.7149 - val_precision: 0.6021 - val_recall: 0.5217\n",
      "Epoch 1867/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6220 - loss: 0.3076 - precision: 0.6219 - recall: 0.6448\n",
      "Epoch 1867 - Train Recall: 0.6645 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6220 - loss: 0.3075 - precision: 0.6216 - recall: 0.6454 - val_accuracy: 0.5907 - val_loss: 0.6212 - val_precision: 0.5866 - val_recall: 0.6147\n",
      "Epoch 1868/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6240 - loss: 0.3223 - precision: 0.6105 - recall: 0.7199\n",
      "Epoch 1868 - Train Recall: 0.6968 - Val Recall: 0.7091\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6236 - loss: 0.3224 - precision: 0.6099 - recall: 0.7183 - val_accuracy: 0.5885 - val_loss: 0.6602 - val_precision: 0.5713 - val_recall: 0.7091\n",
      "Epoch 1869/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6286 - loss: 0.3371 - precision: 0.6133 - recall: 0.6846\n",
      "Epoch 1869 - Train Recall: 0.6750 - Val Recall: 0.5607\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6283 - loss: 0.3372 - precision: 0.6131 - recall: 0.6841 - val_accuracy: 0.5892 - val_loss: 0.6924 - val_precision: 0.5946 - val_recall: 0.5607\n",
      "Epoch 1870/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6252 - loss: 0.3090 - precision: 0.6198 - recall: 0.6481\n",
      "Epoch 1870 - Train Recall: 0.6724 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6252 - loss: 0.3091 - precision: 0.6193 - recall: 0.6501 - val_accuracy: 0.6117 - val_loss: 0.6170 - val_precision: 0.5984 - val_recall: 0.6792\n",
      "Epoch 1871/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6231 - loss: 0.3392 - precision: 0.6099 - recall: 0.6864\n",
      "Epoch 1871 - Train Recall: 0.6679 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6231 - loss: 0.3392 - precision: 0.6099 - recall: 0.6863 - val_accuracy: 0.6004 - val_loss: 0.6844 - val_precision: 0.5905 - val_recall: 0.6552\n",
      "Epoch 1872/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6330 - loss: 0.3327 - precision: 0.6216 - recall: 0.6721\n",
      "Epoch 1872 - Train Recall: 0.6529 - Val Recall: 0.6507\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6321 - loss: 0.3329 - precision: 0.6209 - recall: 0.6708 - val_accuracy: 0.6057 - val_loss: 0.6874 - val_precision: 0.5970 - val_recall: 0.6507\n",
      "Epoch 1873/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6133 - loss: 0.3384 - precision: 0.5920 - recall: 0.6673\n",
      "Epoch 1873 - Train Recall: 0.6698 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6147 - loss: 0.3383 - precision: 0.5945 - recall: 0.6676 - val_accuracy: 0.6034 - val_loss: 0.6781 - val_precision: 0.6000 - val_recall: 0.6207\n",
      "Epoch 1874/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6213 - loss: 0.3243 - precision: 0.6062 - recall: 0.6715\n",
      "Epoch 1874 - Train Recall: 0.6724 - Val Recall: 0.6897\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6212 - loss: 0.3243 - precision: 0.6063 - recall: 0.6715 - val_accuracy: 0.6199 - val_loss: 0.6499 - val_precision: 0.6053 - val_recall: 0.6897\n",
      "Epoch 1875/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6333 - loss: 0.3374 - precision: 0.6242 - recall: 0.6655\n",
      "Epoch 1875 - Train Recall: 0.6436 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6327 - loss: 0.3376 - precision: 0.6237 - recall: 0.6646 - val_accuracy: 0.6064 - val_loss: 0.6934 - val_precision: 0.5986 - val_recall: 0.6462\n",
      "Epoch 1876/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6200 - loss: 0.3400 - precision: 0.6255 - recall: 0.6305\n",
      "Epoch 1876 - Train Recall: 0.6406 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6201 - loss: 0.3400 - precision: 0.6254 - recall: 0.6307 - val_accuracy: 0.6147 - val_loss: 0.6849 - val_precision: 0.6147 - val_recall: 0.6147\n",
      "Epoch 1877/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6219 - loss: 0.3320 - precision: 0.6156 - recall: 0.6394\n",
      "Epoch 1877 - Train Recall: 0.6454 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6214 - loss: 0.3321 - precision: 0.6150 - recall: 0.6397 - val_accuracy: 0.5907 - val_loss: 0.6716 - val_precision: 0.5816 - val_recall: 0.6462\n",
      "Epoch 1878/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.3349 - precision: 0.6132 - recall: 0.6705\n",
      "Epoch 1878 - Train Recall: 0.6548 - Val Recall: 0.6432\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6245 - loss: 0.3352 - precision: 0.6130 - recall: 0.6694 - val_accuracy: 0.5915 - val_loss: 0.6904 - val_precision: 0.5829 - val_recall: 0.6432\n",
      "Epoch 1879/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6259 - loss: 0.3329 - precision: 0.6176 - recall: 0.6522\n",
      "Epoch 1879 - Train Recall: 0.6402 - Val Recall: 0.7376\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6255 - loss: 0.3331 - precision: 0.6174 - recall: 0.6516 - val_accuracy: 0.5975 - val_loss: 0.6802 - val_precision: 0.5761 - val_recall: 0.7376\n",
      "Epoch 1880/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6217 - loss: 0.3595 - precision: 0.6149 - recall: 0.6285\n",
      "Epoch 1880 - Train Recall: 0.6023 - Val Recall: 0.5232\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6216 - loss: 0.3595 - precision: 0.6150 - recall: 0.6281 - val_accuracy: 0.5915 - val_loss: 0.7354 - val_precision: 0.6059 - val_recall: 0.5232\n",
      "Epoch 1881/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6300 - loss: 0.3177 - precision: 0.6432 - recall: 0.5943\n",
      "Epoch 1881 - Train Recall: 0.6286 - Val Recall: 0.6567\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6297 - loss: 0.3176 - precision: 0.6420 - recall: 0.5968 - val_accuracy: 0.6057 - val_loss: 0.6381 - val_precision: 0.5959 - val_recall: 0.6567\n",
      "Epoch 1882/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6314 - loss: 0.3416 - precision: 0.6220 - recall: 0.6779\n",
      "Epoch 1882 - Train Recall: 0.6544 - Val Recall: 0.5982\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6313 - loss: 0.3417 - precision: 0.6219 - recall: 0.6775 - val_accuracy: 0.5907 - val_loss: 0.7004 - val_precision: 0.5894 - val_recall: 0.5982\n",
      "Epoch 1883/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6199 - loss: 0.3238 - precision: 0.6237 - recall: 0.6515\n",
      "Epoch 1883 - Train Recall: 0.6585 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6197 - loss: 0.3238 - precision: 0.6228 - recall: 0.6519 - val_accuracy: 0.5915 - val_loss: 0.6655 - val_precision: 0.5882 - val_recall: 0.6102\n",
      "Epoch 1884/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6166 - loss: 0.3240 - precision: 0.6038 - recall: 0.6805\n",
      "Epoch 1884 - Train Recall: 0.6822 - Val Recall: 0.7256\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6166 - loss: 0.3240 - precision: 0.6038 - recall: 0.6805 - val_accuracy: 0.6102 - val_loss: 0.6647 - val_precision: 0.5895 - val_recall: 0.7256\n",
      "Epoch 1885/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.3464 - precision: 0.6076 - recall: 0.6772\n",
      "Epoch 1885 - Train Recall: 0.6409 - Val Recall: 0.6597\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6244 - loss: 0.3465 - precision: 0.6075 - recall: 0.6753 - val_accuracy: 0.6079 - val_loss: 0.7111 - val_precision: 0.5978 - val_recall: 0.6597\n",
      "Epoch 1886/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6184 - loss: 0.3420 - precision: 0.6268 - recall: 0.6099\n",
      "Epoch 1886 - Train Recall: 0.6181 - Val Recall: 0.5787\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6177 - loss: 0.3422 - precision: 0.6249 - recall: 0.6108 - val_accuracy: 0.6049 - val_loss: 0.6922 - val_precision: 0.6108 - val_recall: 0.5787\n",
      "Epoch 1887/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6315 - loss: 0.3244 - precision: 0.6357 - recall: 0.6602\n",
      "Epoch 1887 - Train Recall: 0.6544 - Val Recall: 0.5037\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6307 - loss: 0.3247 - precision: 0.6337 - recall: 0.6598 - val_accuracy: 0.5757 - val_loss: 0.6661 - val_precision: 0.5884 - val_recall: 0.5037\n",
      "Epoch 1888/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6232 - loss: 0.2994 - precision: 0.6179 - recall: 0.6658\n",
      "Epoch 1888 - Train Recall: 0.6994 - Val Recall: 0.6897\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6232 - loss: 0.2993 - precision: 0.6176 - recall: 0.6668 - val_accuracy: 0.6087 - val_loss: 0.5974 - val_precision: 0.5935 - val_recall: 0.6897\n",
      "Epoch 1889/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6246 - loss: 0.3349 - precision: 0.5960 - recall: 0.7158\n",
      "Epoch 1889 - Train Recall: 0.6912 - Val Recall: 0.6732\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6237 - loss: 0.3350 - precision: 0.5964 - recall: 0.7128 - val_accuracy: 0.6139 - val_loss: 0.6805 - val_precision: 0.6019 - val_recall: 0.6732\n",
      "Epoch 1890/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6377 - loss: 0.3306 - precision: 0.6243 - recall: 0.6838\n",
      "Epoch 1890 - Train Recall: 0.6743 - Val Recall: 0.5727\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6375 - loss: 0.3307 - precision: 0.6241 - recall: 0.6836 - val_accuracy: 0.6019 - val_loss: 0.6781 - val_precision: 0.6083 - val_recall: 0.5727\n",
      "Epoch 1891/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6533 - loss: 0.3069 - precision: 0.6531 - recall: 0.7039\n",
      "Epoch 1891 - Train Recall: 0.7058 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6532 - loss: 0.3069 - precision: 0.6528 - recall: 0.7039 - val_accuracy: 0.5892 - val_loss: 0.6326 - val_precision: 0.5788 - val_recall: 0.6552\n",
      "Epoch 1892/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6242 - loss: 0.3229 - precision: 0.6102 - recall: 0.7141\n",
      "Epoch 1892 - Train Recall: 0.7091 - Val Recall: 0.7181\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6240 - loss: 0.3231 - precision: 0.6096 - recall: 0.7137 - val_accuracy: 0.5997 - val_loss: 0.6562 - val_precision: 0.5806 - val_recall: 0.7181\n",
      "Epoch 1893/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6318 - loss: 0.3343 - precision: 0.6190 - recall: 0.7026\n",
      "Epoch 1893 - Train Recall: 0.6672 - Val Recall: 0.6912\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6312 - loss: 0.3346 - precision: 0.6187 - recall: 0.7004 - val_accuracy: 0.6042 - val_loss: 0.6859 - val_precision: 0.5888 - val_recall: 0.6912\n",
      "Epoch 1894/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6146 - loss: 0.3434 - precision: 0.6086 - recall: 0.6352\n",
      "Epoch 1894 - Train Recall: 0.6274 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6146 - loss: 0.3435 - precision: 0.6086 - recall: 0.6351 - val_accuracy: 0.6012 - val_loss: 0.6951 - val_precision: 0.5926 - val_recall: 0.6477\n",
      "Epoch 1895/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6008 - loss: 0.3475 - precision: 0.5928 - recall: 0.6194\n",
      "Epoch 1895 - Train Recall: 0.6263 - Val Recall: 0.6417\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6020 - loss: 0.3472 - precision: 0.5945 - recall: 0.6199 - val_accuracy: 0.6252 - val_loss: 0.6856 - val_precision: 0.6212 - val_recall: 0.6417\n",
      "Epoch 1896/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6173 - loss: 0.3441 - precision: 0.6135 - recall: 0.6036\n",
      "Epoch 1896 - Train Recall: 0.6128 - Val Recall: 0.5427\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6172 - loss: 0.3441 - precision: 0.6136 - recall: 0.6039 - val_accuracy: 0.6117 - val_loss: 0.6901 - val_precision: 0.6296 - val_recall: 0.5427\n",
      "Epoch 1897/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6365 - loss: 0.3145 - precision: 0.6250 - recall: 0.6725\n",
      "Epoch 1897 - Train Recall: 0.6675 - Val Recall: 0.6942\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6359 - loss: 0.3147 - precision: 0.6246 - recall: 0.6721 - val_accuracy: 0.5840 - val_loss: 0.6429 - val_precision: 0.5688 - val_recall: 0.6942\n",
      "Epoch 1898/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6339 - loss: 0.3414 - precision: 0.6258 - recall: 0.6681\n",
      "Epoch 1898 - Train Recall: 0.6567 - Val Recall: 0.5067\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6338 - loss: 0.3414 - precision: 0.6258 - recall: 0.6678 - val_accuracy: 0.5840 - val_loss: 0.7046 - val_precision: 0.5993 - val_recall: 0.5067\n",
      "Epoch 1899/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6300 - loss: 0.2974 - precision: 0.6371 - recall: 0.6497\n",
      "Epoch 1899 - Train Recall: 0.6852 - Val Recall: 0.7196\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6295 - loss: 0.2975 - precision: 0.6357 - recall: 0.6512 - val_accuracy: 0.6064 - val_loss: 0.5985 - val_precision: 0.5868 - val_recall: 0.7196\n",
      "Epoch 1900/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6342 - loss: 0.3403 - precision: 0.6124 - recall: 0.7164\n",
      "Epoch 1900 - Train Recall: 0.6855 - Val Recall: 0.5847\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6330 - loss: 0.3409 - precision: 0.6124 - recall: 0.7130 - val_accuracy: 0.5997 - val_loss: 0.7006 - val_precision: 0.6028 - val_recall: 0.5847\n",
      "Epoch 1901/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6174 - loss: 0.3138 - precision: 0.6106 - recall: 0.6815\n",
      "Epoch 1901 - Train Recall: 0.6938 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6177 - loss: 0.3136 - precision: 0.6103 - recall: 0.6825 - val_accuracy: 0.6049 - val_loss: 0.6362 - val_precision: 0.5972 - val_recall: 0.6447\n",
      "Epoch 1902/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6350 - loss: 0.3242 - precision: 0.6168 - recall: 0.7070\n",
      "Epoch 1902 - Train Recall: 0.6975 - Val Recall: 0.6342\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6343 - loss: 0.3244 - precision: 0.6163 - recall: 0.7063 - val_accuracy: 0.5885 - val_loss: 0.6582 - val_precision: 0.5810 - val_recall: 0.6342\n",
      "Epoch 1903/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6236 - loss: 0.3219 - precision: 0.6046 - recall: 0.6917\n",
      "Epoch 1903 - Train Recall: 0.7005 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6238 - loss: 0.3219 - precision: 0.6050 - recall: 0.6921 - val_accuracy: 0.6192 - val_loss: 0.6476 - val_precision: 0.6064 - val_recall: 0.6792\n",
      "Epoch 1904/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6232 - loss: 0.3305 - precision: 0.6167 - recall: 0.6919\n",
      "Epoch 1904 - Train Recall: 0.6822 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6227 - loss: 0.3308 - precision: 0.6153 - recall: 0.6908 - val_accuracy: 0.5982 - val_loss: 0.6811 - val_precision: 0.5908 - val_recall: 0.6387\n",
      "Epoch 1905/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6261 - loss: 0.3266 - precision: 0.6119 - recall: 0.6912\n",
      "Epoch 1905 - Train Recall: 0.6818 - Val Recall: 0.6162\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6260 - loss: 0.3267 - precision: 0.6118 - recall: 0.6910 - val_accuracy: 0.6004 - val_loss: 0.6581 - val_precision: 0.5974 - val_recall: 0.6162\n",
      "Epoch 1906/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6458 - loss: 0.3156 - precision: 0.6286 - recall: 0.7178\n",
      "Epoch 1906 - Train Recall: 0.7110 - Val Recall: 0.7181\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6446 - loss: 0.3160 - precision: 0.6274 - recall: 0.7171 - val_accuracy: 0.6087 - val_loss: 0.6473 - val_precision: 0.5892 - val_recall: 0.7181\n",
      "Epoch 1907/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6308 - loss: 0.3337 - precision: 0.6088 - recall: 0.7106\n",
      "Epoch 1907 - Train Recall: 0.6769 - Val Recall: 0.7091\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6291 - loss: 0.3343 - precision: 0.6079 - recall: 0.7071 - val_accuracy: 0.6109 - val_loss: 0.6899 - val_precision: 0.5927 - val_recall: 0.7091\n",
      "Epoch 1908/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6220 - loss: 0.3471 - precision: 0.6102 - recall: 0.6693\n",
      "Epoch 1908 - Train Recall: 0.6683 - Val Recall: 0.5772\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6218 - loss: 0.3471 - precision: 0.6102 - recall: 0.6692 - val_accuracy: 0.6102 - val_loss: 0.7037 - val_precision: 0.6180 - val_recall: 0.5772\n",
      "Epoch 1909/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6232 - loss: 0.3155 - precision: 0.6238 - recall: 0.6638\n",
      "Epoch 1909 - Train Recall: 0.6732 - Val Recall: 0.6732\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6228 - loss: 0.3155 - precision: 0.6221 - recall: 0.6650 - val_accuracy: 0.5997 - val_loss: 0.6389 - val_precision: 0.5869 - val_recall: 0.6732\n",
      "Epoch 1910/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6246 - loss: 0.3336 - precision: 0.6065 - recall: 0.6939\n",
      "Epoch 1910 - Train Recall: 0.6732 - Val Recall: 0.5457\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6245 - loss: 0.3340 - precision: 0.6070 - recall: 0.6921 - val_accuracy: 0.5907 - val_loss: 0.6795 - val_precision: 0.5997 - val_recall: 0.5457\n",
      "Epoch 1911/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6351 - loss: 0.3036 - precision: 0.6264 - recall: 0.6841\n",
      "Epoch 1911 - Train Recall: 0.7065 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6340 - loss: 0.3037 - precision: 0.6244 - recall: 0.6868 - val_accuracy: 0.5922 - val_loss: 0.6214 - val_precision: 0.5785 - val_recall: 0.6792\n",
      "Epoch 1912/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6224 - loss: 0.3296 - precision: 0.6054 - recall: 0.7071\n",
      "Epoch 1912 - Train Recall: 0.7076 - Val Recall: 0.7106\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6223 - loss: 0.3297 - precision: 0.6053 - recall: 0.7071 - val_accuracy: 0.6042 - val_loss: 0.6701 - val_precision: 0.5859 - val_recall: 0.7106\n",
      "Epoch 1913/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6210 - loss: 0.3424 - precision: 0.6053 - recall: 0.6736\n",
      "Epoch 1913 - Train Recall: 0.6660 - Val Recall: 0.6207\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6210 - loss: 0.3423 - precision: 0.6055 - recall: 0.6733 - val_accuracy: 0.6079 - val_loss: 0.6812 - val_precision: 0.6053 - val_recall: 0.6207\n",
      "Epoch 1914/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6294 - loss: 0.3228 - precision: 0.6138 - recall: 0.6872\n",
      "Epoch 1914 - Train Recall: 0.6694 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6280 - loss: 0.3233 - precision: 0.6129 - recall: 0.6851 - val_accuracy: 0.6184 - val_loss: 0.6545 - val_precision: 0.6125 - val_recall: 0.6447\n",
      "Epoch 1915/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6335 - loss: 0.3297 - precision: 0.6291 - recall: 0.6618\n",
      "Epoch 1915 - Train Recall: 0.6597 - Val Recall: 0.6852\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6329 - loss: 0.3298 - precision: 0.6283 - recall: 0.6617 - val_accuracy: 0.5960 - val_loss: 0.6687 - val_precision: 0.5814 - val_recall: 0.6852\n",
      "Epoch 1916/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6249 - loss: 0.3434 - precision: 0.6074 - recall: 0.6560\n",
      "Epoch 1916 - Train Recall: 0.6481 - Val Recall: 0.6297\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6246 - loss: 0.3437 - precision: 0.6083 - recall: 0.6553 - val_accuracy: 0.5825 - val_loss: 0.6980 - val_precision: 0.5753 - val_recall: 0.6297\n",
      "Epoch 1917/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6260 - loss: 0.3284 - precision: 0.6109 - recall: 0.6661\n",
      "Epoch 1917 - Train Recall: 0.6525 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6260 - loss: 0.3284 - precision: 0.6110 - recall: 0.6659 - val_accuracy: 0.6049 - val_loss: 0.6714 - val_precision: 0.6029 - val_recall: 0.6147\n",
      "Epoch 1918/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6252 - loss: 0.3262 - precision: 0.6123 - recall: 0.6594\n",
      "Epoch 1918 - Train Recall: 0.6623 - Val Recall: 0.6447\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6245 - loss: 0.3264 - precision: 0.6120 - recall: 0.6599 - val_accuracy: 0.6072 - val_loss: 0.6638 - val_precision: 0.5997 - val_recall: 0.6447\n",
      "Epoch 1919/2000\n",
      "\u001b[1m165/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6170 - loss: 0.3331 - precision: 0.5997 - recall: 0.6912\n",
      "Epoch 1919 - Train Recall: 0.6844 - Val Recall: 0.7136\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6171 - loss: 0.3331 - precision: 0.5999 - recall: 0.6910 - val_accuracy: 0.6147 - val_loss: 0.6758 - val_precision: 0.5957 - val_recall: 0.7136\n",
      "Epoch 1920/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6193 - loss: 0.3451 - precision: 0.6077 - recall: 0.6576\n",
      "Epoch 1920 - Train Recall: 0.6454 - Val Recall: 0.5457\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6194 - loss: 0.3451 - precision: 0.6083 - recall: 0.6566 - val_accuracy: 0.5892 - val_loss: 0.6990 - val_precision: 0.5977 - val_recall: 0.5457\n",
      "Epoch 1921/2000\n",
      "\u001b[1m142/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6306 - loss: 0.3063 - precision: 0.6169 - recall: 0.6545\n",
      "Epoch 1921 - Train Recall: 0.6668 - Val Recall: 0.6882\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6298 - loss: 0.3069 - precision: 0.6168 - recall: 0.6560 - val_accuracy: 0.6057 - val_loss: 0.6275 - val_precision: 0.5907 - val_recall: 0.6882\n",
      "Epoch 1922/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6322 - loss: 0.3393 - precision: 0.6132 - recall: 0.6924\n",
      "Epoch 1922 - Train Recall: 0.6765 - Val Recall: 0.5982\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6313 - loss: 0.3397 - precision: 0.6132 - recall: 0.6906 - val_accuracy: 0.5952 - val_loss: 0.7003 - val_precision: 0.5946 - val_recall: 0.5982\n",
      "Epoch 1923/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6161 - loss: 0.3214 - precision: 0.6018 - recall: 0.6671\n",
      "Epoch 1923 - Train Recall: 0.6840 - Val Recall: 0.7031\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6165 - loss: 0.3213 - precision: 0.6022 - recall: 0.6677 - val_accuracy: 0.6019 - val_loss: 0.6405 - val_precision: 0.5848 - val_recall: 0.7031\n",
      "Epoch 1924/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6294 - loss: 0.3399 - precision: 0.6120 - recall: 0.6969\n",
      "Epoch 1924 - Train Recall: 0.6627 - Val Recall: 0.4183\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6289 - loss: 0.3401 - precision: 0.6123 - recall: 0.6936 - val_accuracy: 0.5742 - val_loss: 0.7123 - val_precision: 0.6078 - val_recall: 0.4183\n",
      "Epoch 1925/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6222 - loss: 0.2737 - precision: 0.6062 - recall: 0.6850\n",
      "Epoch 1925 - Train Recall: 0.7230 - Val Recall: 0.7646\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6222 - loss: 0.2736 - precision: 0.6061 - recall: 0.6863 - val_accuracy: 0.6064 - val_loss: 0.5446 - val_precision: 0.5809 - val_recall: 0.7646\n",
      "Epoch 1926/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6197 - loss: 0.3489 - precision: 0.5966 - recall: 0.7570\n",
      "Epoch 1926 - Train Recall: 0.7208 - Val Recall: 0.6027\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6190 - loss: 0.3488 - precision: 0.5962 - recall: 0.7530 - val_accuracy: 0.5937 - val_loss: 0.7024 - val_precision: 0.5920 - val_recall: 0.6027\n",
      "Epoch 1927/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6342 - loss: 0.3043 - precision: 0.6214 - recall: 0.6980\n",
      "Epoch 1927 - Train Recall: 0.7031 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6324 - loss: 0.3047 - precision: 0.6189 - recall: 0.6989 - val_accuracy: 0.5870 - val_loss: 0.6300 - val_precision: 0.5732 - val_recall: 0.6807\n",
      "Epoch 1928/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6265 - loss: 0.3291 - precision: 0.6114 - recall: 0.7235\n",
      "Epoch 1928 - Train Recall: 0.6927 - Val Recall: 0.7721\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6255 - loss: 0.3296 - precision: 0.6102 - recall: 0.7207 - val_accuracy: 0.5892 - val_loss: 0.6755 - val_precision: 0.5653 - val_recall: 0.7721\n",
      "Epoch 1929/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6328 - loss: 0.3525 - precision: 0.6291 - recall: 0.6707\n",
      "Epoch 1929 - Train Recall: 0.6334 - Val Recall: 0.5817\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6311 - loss: 0.3531 - precision: 0.6273 - recall: 0.6664 - val_accuracy: 0.6019 - val_loss: 0.7198 - val_precision: 0.6062 - val_recall: 0.5817\n",
      "Epoch 1930/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6298 - loss: 0.3238 - precision: 0.6274 - recall: 0.6359\n",
      "Epoch 1930 - Train Recall: 0.6447 - Val Recall: 0.5832\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6298 - loss: 0.3239 - precision: 0.6272 - recall: 0.6371 - val_accuracy: 0.6004 - val_loss: 0.6588 - val_precision: 0.6040 - val_recall: 0.5832\n",
      "Epoch 1931/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6375 - loss: 0.3193 - precision: 0.6354 - recall: 0.6866\n",
      "Epoch 1931 - Train Recall: 0.6893 - Val Recall: 0.6627\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6373 - loss: 0.3194 - precision: 0.6348 - recall: 0.6867 - val_accuracy: 0.6072 - val_loss: 0.6498 - val_precision: 0.5965 - val_recall: 0.6627\n",
      "Epoch 1932/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6169 - loss: 0.3319 - precision: 0.6066 - recall: 0.6722\n",
      "Epoch 1932 - Train Recall: 0.6777 - Val Recall: 0.6312\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6176 - loss: 0.3318 - precision: 0.6070 - recall: 0.6729 - val_accuracy: 0.5900 - val_loss: 0.6789 - val_precision: 0.5831 - val_recall: 0.6312\n",
      "Epoch 1933/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6272 - loss: 0.3254 - precision: 0.6098 - recall: 0.6825\n",
      "Epoch 1933 - Train Recall: 0.6777 - Val Recall: 0.7241\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6272 - loss: 0.3254 - precision: 0.6098 - recall: 0.6825 - val_accuracy: 0.5832 - val_loss: 0.6653 - val_precision: 0.5649 - val_recall: 0.7241\n",
      "Epoch 1934/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6232 - loss: 0.3485 - precision: 0.6188 - recall: 0.6707\n",
      "Epoch 1934 - Train Recall: 0.6597 - Val Recall: 0.5637\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6230 - loss: 0.3487 - precision: 0.6183 - recall: 0.6701 - val_accuracy: 0.5982 - val_loss: 0.7042 - val_precision: 0.6055 - val_recall: 0.5637\n",
      "Epoch 1935/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6302 - loss: 0.3144 - precision: 0.6292 - recall: 0.6500\n",
      "Epoch 1935 - Train Recall: 0.6612 - Val Recall: 0.6582\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6300 - loss: 0.3143 - precision: 0.6286 - recall: 0.6504 - val_accuracy: 0.6049 - val_loss: 0.6310 - val_precision: 0.5949 - val_recall: 0.6582\n",
      "Epoch 1936/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6301 - loss: 0.3368 - precision: 0.6279 - recall: 0.6825\n",
      "Epoch 1936 - Train Recall: 0.6822 - Val Recall: 0.6297\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6298 - loss: 0.3369 - precision: 0.6270 - recall: 0.6824 - val_accuracy: 0.5780 - val_loss: 0.6956 - val_precision: 0.5707 - val_recall: 0.6297\n",
      "Epoch 1937/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6197 - loss: 0.3236 - precision: 0.6082 - recall: 0.6779\n",
      "Epoch 1937 - Train Recall: 0.6687 - Val Recall: 0.6762\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6198 - loss: 0.3237 - precision: 0.6083 - recall: 0.6775 - val_accuracy: 0.6027 - val_loss: 0.6579 - val_precision: 0.5895 - val_recall: 0.6762\n",
      "Epoch 1938/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6300 - loss: 0.3341 - precision: 0.6209 - recall: 0.6851\n",
      "Epoch 1938 - Train Recall: 0.6664 - Val Recall: 0.5532\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6294 - loss: 0.3343 - precision: 0.6203 - recall: 0.6842 - val_accuracy: 0.5840 - val_loss: 0.6906 - val_precision: 0.5895 - val_recall: 0.5532\n",
      "Epoch 1939/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.3071 - precision: 0.6063 - recall: 0.6773\n",
      "Epoch 1939 - Train Recall: 0.6803 - Val Recall: 0.6792\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6257 - loss: 0.3071 - precision: 0.6079 - recall: 0.6777 - val_accuracy: 0.5967 - val_loss: 0.6226 - val_precision: 0.5830 - val_recall: 0.6792\n",
      "Epoch 1940/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6387 - loss: 0.3306 - precision: 0.6240 - recall: 0.7057\n",
      "Epoch 1940 - Train Recall: 0.6908 - Val Recall: 0.7106\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6387 - loss: 0.3307 - precision: 0.6239 - recall: 0.7056 - val_accuracy: 0.6057 - val_loss: 0.6866 - val_precision: 0.5874 - val_recall: 0.7106\n",
      "Epoch 1941/2000\n",
      "\u001b[1m150/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6331 - loss: 0.3382 - precision: 0.6210 - recall: 0.6683\n",
      "Epoch 1941 - Train Recall: 0.6451 - Val Recall: 0.5502\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6313 - loss: 0.3386 - precision: 0.6199 - recall: 0.6658 - val_accuracy: 0.5990 - val_loss: 0.6967 - val_precision: 0.6096 - val_recall: 0.5502\n",
      "Epoch 1942/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6281 - loss: 0.3118 - precision: 0.6264 - recall: 0.6608\n",
      "Epoch 1942 - Train Recall: 0.6694 - Val Recall: 0.7136\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6270 - loss: 0.3118 - precision: 0.6243 - recall: 0.6615 - val_accuracy: 0.6087 - val_loss: 0.6292 - val_precision: 0.5898 - val_recall: 0.7136\n",
      "Epoch 1943/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6259 - loss: 0.3480 - precision: 0.6128 - recall: 0.7037\n",
      "Epoch 1943 - Train Recall: 0.6765 - Val Recall: 0.6627\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6253 - loss: 0.3481 - precision: 0.6123 - recall: 0.7016 - val_accuracy: 0.6012 - val_loss: 0.7127 - val_precision: 0.5901 - val_recall: 0.6627\n",
      "Epoch 1944/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6293 - loss: 0.3326 - precision: 0.6172 - recall: 0.6448\n",
      "Epoch 1944 - Train Recall: 0.6507 - Val Recall: 0.6567\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6290 - loss: 0.3328 - precision: 0.6174 - recall: 0.6451 - val_accuracy: 0.5990 - val_loss: 0.6778 - val_precision: 0.5887 - val_recall: 0.6567\n",
      "Epoch 1945/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6313 - loss: 0.3368 - precision: 0.6268 - recall: 0.6567\n",
      "Epoch 1945 - Train Recall: 0.6499 - Val Recall: 0.5367\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6301 - loss: 0.3371 - precision: 0.6252 - recall: 0.6564 - val_accuracy: 0.5952 - val_loss: 0.6909 - val_precision: 0.6078 - val_recall: 0.5367\n",
      "Epoch 1946/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6394 - loss: 0.3060 - precision: 0.6328 - recall: 0.6891\n",
      "Epoch 1946 - Train Recall: 0.6949 - Val Recall: 0.6297\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6390 - loss: 0.3060 - precision: 0.6321 - recall: 0.6894 - val_accuracy: 0.5840 - val_loss: 0.6298 - val_precision: 0.5769 - val_recall: 0.6297\n",
      "Epoch 1947/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6363 - loss: 0.3174 - precision: 0.6149 - recall: 0.7072\n",
      "Epoch 1947 - Train Recall: 0.6960 - Val Recall: 0.6747\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6351 - loss: 0.3178 - precision: 0.6141 - recall: 0.7061 - val_accuracy: 0.6049 - val_loss: 0.6499 - val_precision: 0.5921 - val_recall: 0.6747\n",
      "Epoch 1948/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6221 - loss: 0.3322 - precision: 0.6048 - recall: 0.7186\n",
      "Epoch 1948 - Train Recall: 0.7223 - Val Recall: 0.6087\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6221 - loss: 0.3322 - precision: 0.6049 - recall: 0.7187 - val_accuracy: 0.5832 - val_loss: 0.6821 - val_precision: 0.5792 - val_recall: 0.6087\n",
      "Epoch 1949/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6389 - loss: 0.3075 - precision: 0.6272 - recall: 0.6957\n",
      "Epoch 1949 - Train Recall: 0.7140 - Val Recall: 0.6942\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6382 - loss: 0.3078 - precision: 0.6258 - recall: 0.6974 - val_accuracy: 0.5937 - val_loss: 0.6339 - val_precision: 0.5780 - val_recall: 0.6942\n",
      "Epoch 1950/2000\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6245 - loss: 0.3303 - precision: 0.6021 - recall: 0.7157\n",
      "Epoch 1950 - Train Recall: 0.6983 - Val Recall: 0.6282\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6245 - loss: 0.3303 - precision: 0.6021 - recall: 0.7156 - val_accuracy: 0.5720 - val_loss: 0.6822 - val_precision: 0.5647 - val_recall: 0.6282\n",
      "Epoch 1951/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6334 - loss: 0.3164 - precision: 0.6180 - recall: 0.6904\n",
      "Epoch 1951 - Train Recall: 0.6859 - Val Recall: 0.6687\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6326 - loss: 0.3167 - precision: 0.6173 - recall: 0.6897 - val_accuracy: 0.5967 - val_loss: 0.6454 - val_precision: 0.5845 - val_recall: 0.6687\n",
      "Epoch 1952/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6345 - loss: 0.3302 - precision: 0.6136 - recall: 0.6913\n",
      "Epoch 1952 - Train Recall: 0.6743 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6344 - loss: 0.3303 - precision: 0.6137 - recall: 0.6909 - val_accuracy: 0.5982 - val_loss: 0.6749 - val_precision: 0.5894 - val_recall: 0.6477\n",
      "Epoch 1953/2000\n",
      "\u001b[1m159/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6424 - loss: 0.3233 - precision: 0.6307 - recall: 0.6936\n",
      "Epoch 1953 - Train Recall: 0.6758 - Val Recall: 0.6477\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6412 - loss: 0.3237 - precision: 0.6294 - recall: 0.6926 - val_accuracy: 0.6072 - val_loss: 0.6681 - val_precision: 0.5992 - val_recall: 0.6477\n",
      "Epoch 1954/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6321 - loss: 0.3280 - precision: 0.6152 - recall: 0.6927\n",
      "Epoch 1954 - Train Recall: 0.6844 - Val Recall: 0.6837\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6318 - loss: 0.3282 - precision: 0.6152 - recall: 0.6917 - val_accuracy: 0.5997 - val_loss: 0.6686 - val_precision: 0.5854 - val_recall: 0.6837\n",
      "Epoch 1955/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6275 - loss: 0.3383 - precision: 0.6124 - recall: 0.6806\n",
      "Epoch 1955 - Train Recall: 0.6698 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6279 - loss: 0.3380 - precision: 0.6133 - recall: 0.6798 - val_accuracy: 0.6177 - val_loss: 0.6779 - val_precision: 0.6045 - val_recall: 0.6807\n",
      "Epoch 1956/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6272 - loss: 0.3386 - precision: 0.6257 - recall: 0.6538\n",
      "Epoch 1956 - Train Recall: 0.6357 - Val Recall: 0.5292\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6264 - loss: 0.3389 - precision: 0.6246 - recall: 0.6520 - val_accuracy: 0.6019 - val_loss: 0.6900 - val_precision: 0.6193 - val_recall: 0.5292\n",
      "Epoch 1957/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6374 - loss: 0.3059 - precision: 0.6249 - recall: 0.6596\n",
      "Epoch 1957 - Train Recall: 0.6642 - Val Recall: 0.7106\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6366 - loss: 0.3061 - precision: 0.6242 - recall: 0.6598 - val_accuracy: 0.5982 - val_loss: 0.6247 - val_precision: 0.5802 - val_recall: 0.7106\n",
      "Epoch 1958/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6167 - loss: 0.3489 - precision: 0.6170 - recall: 0.6710\n",
      "Epoch 1958 - Train Recall: 0.6522 - Val Recall: 0.5757\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6164 - loss: 0.3489 - precision: 0.6158 - recall: 0.6695 - val_accuracy: 0.6072 - val_loss: 0.7023 - val_precision: 0.6144 - val_recall: 0.5757\n",
      "Epoch 1959/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6299 - loss: 0.3178 - precision: 0.6343 - recall: 0.6574\n",
      "Epoch 1959 - Train Recall: 0.6732 - Val Recall: 0.6702\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6293 - loss: 0.3179 - precision: 0.6327 - recall: 0.6582 - val_accuracy: 0.5952 - val_loss: 0.6412 - val_precision: 0.5828 - val_recall: 0.6702\n",
      "Epoch 1960/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6368 - loss: 0.3347 - precision: 0.6285 - recall: 0.7003\n",
      "Epoch 1960 - Train Recall: 0.6762 - Val Recall: 0.6627\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6363 - loss: 0.3348 - precision: 0.6277 - recall: 0.6982 - val_accuracy: 0.6057 - val_loss: 0.6911 - val_precision: 0.5949 - val_recall: 0.6627\n",
      "Epoch 1961/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6292 - loss: 0.3303 - precision: 0.6126 - recall: 0.6752\n",
      "Epoch 1961 - Train Recall: 0.6537 - Val Recall: 0.5922\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6290 - loss: 0.3304 - precision: 0.6127 - recall: 0.6745 - val_accuracy: 0.6049 - val_loss: 0.6721 - val_precision: 0.6077 - val_recall: 0.5922\n",
      "Epoch 1962/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6249 - loss: 0.3214 - precision: 0.6224 - recall: 0.6546\n",
      "Epoch 1962 - Train Recall: 0.6694 - Val Recall: 0.6552\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6249 - loss: 0.3215 - precision: 0.6217 - recall: 0.6560 - val_accuracy: 0.6079 - val_loss: 0.6485 - val_precision: 0.5986 - val_recall: 0.6552\n",
      "Epoch 1963/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6216 - loss: 0.3316 - precision: 0.6074 - recall: 0.6828\n",
      "Epoch 1963 - Train Recall: 0.6735 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6216 - loss: 0.3317 - precision: 0.6076 - recall: 0.6821 - val_accuracy: 0.6049 - val_loss: 0.6794 - val_precision: 0.5983 - val_recall: 0.6387\n",
      "Epoch 1964/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6300 - loss: 0.3270 - precision: 0.6133 - recall: 0.6934\n",
      "Epoch 1964 - Train Recall: 0.6769 - Val Recall: 0.6042\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6292 - loss: 0.3273 - precision: 0.6131 - recall: 0.6913 - val_accuracy: 0.5892 - val_loss: 0.6677 - val_precision: 0.5866 - val_recall: 0.6042\n",
      "Epoch 1965/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6266 - loss: 0.3159 - precision: 0.6129 - recall: 0.6772\n",
      "Epoch 1965 - Train Recall: 0.6923 - Val Recall: 0.7151\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6265 - loss: 0.3160 - precision: 0.6127 - recall: 0.6778 - val_accuracy: 0.6079 - val_loss: 0.6498 - val_precision: 0.5889 - val_recall: 0.7151\n",
      "Epoch 1966/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6266 - loss: 0.3436 - precision: 0.6171 - recall: 0.7061\n",
      "Epoch 1966 - Train Recall: 0.6983 - Val Recall: 0.5397\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6269 - loss: 0.3437 - precision: 0.6166 - recall: 0.7055 - val_accuracy: 0.5840 - val_loss: 0.7005 - val_precision: 0.5921 - val_recall: 0.5397\n",
      "Epoch 1967/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6304 - loss: 0.3001 - precision: 0.6267 - recall: 0.6995\n",
      "Epoch 1967 - Train Recall: 0.7061 - Val Recall: 0.7331\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6296 - loss: 0.2999 - precision: 0.6243 - recall: 0.7003 - val_accuracy: 0.6064 - val_loss: 0.6028 - val_precision: 0.5849 - val_recall: 0.7331\n",
      "Epoch 1968/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6303 - loss: 0.3430 - precision: 0.6165 - recall: 0.7027\n",
      "Epoch 1968 - Train Recall: 0.6855 - Val Recall: 0.5502\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6296 - loss: 0.3432 - precision: 0.6160 - recall: 0.7011 - val_accuracy: 0.5885 - val_loss: 0.7015 - val_precision: 0.5958 - val_recall: 0.5502\n",
      "Epoch 1969/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6297 - loss: 0.3026 - precision: 0.6271 - recall: 0.6765\n",
      "Epoch 1969 - Train Recall: 0.7013 - Val Recall: 0.6867\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6292 - loss: 0.3027 - precision: 0.6253 - recall: 0.6789 - val_accuracy: 0.6049 - val_loss: 0.6130 - val_precision: 0.5902 - val_recall: 0.6867\n",
      "Epoch 1970/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6324 - loss: 0.3341 - precision: 0.6048 - recall: 0.7202\n",
      "Epoch 1970 - Train Recall: 0.6945 - Val Recall: 0.6177\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6320 - loss: 0.3342 - precision: 0.6059 - recall: 0.7173 - val_accuracy: 0.5855 - val_loss: 0.6819 - val_precision: 0.5803 - val_recall: 0.6177\n",
      "Epoch 1971/2000\n",
      "\u001b[1m154/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6262 - loss: 0.3167 - precision: 0.6176 - recall: 0.6806\n",
      "Epoch 1971 - Train Recall: 0.6784 - Val Recall: 0.7376\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6263 - loss: 0.3167 - precision: 0.6173 - recall: 0.6804 - val_accuracy: 0.5997 - val_loss: 0.6490 - val_precision: 0.5781 - val_recall: 0.7376\n",
      "Epoch 1972/2000\n",
      "\u001b[1m161/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6235 - loss: 0.3522 - precision: 0.6100 - recall: 0.6809\n",
      "Epoch 1972 - Train Recall: 0.6593 - Val Recall: 0.5952\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6234 - loss: 0.3522 - precision: 0.6100 - recall: 0.6800 - val_accuracy: 0.5922 - val_loss: 0.7201 - val_precision: 0.5917 - val_recall: 0.5952\n",
      "Epoch 1973/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6258 - loss: 0.3225 - precision: 0.6161 - recall: 0.6663\n",
      "Epoch 1973 - Train Recall: 0.6574 - Val Recall: 0.6462\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6247 - loss: 0.3226 - precision: 0.6151 - recall: 0.6648 - val_accuracy: 0.5945 - val_loss: 0.6548 - val_precision: 0.5856 - val_recall: 0.6462\n",
      "Epoch 1974/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6321 - loss: 0.3327 - precision: 0.6177 - recall: 0.6925\n",
      "Epoch 1974 - Train Recall: 0.6803 - Val Recall: 0.7271\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6311 - loss: 0.3329 - precision: 0.6170 - recall: 0.6912 - val_accuracy: 0.6192 - val_loss: 0.6785 - val_precision: 0.5980 - val_recall: 0.7271\n",
      "Epoch 1975/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6388 - loss: 0.3430 - precision: 0.6333 - recall: 0.6727\n",
      "Epoch 1975 - Train Recall: 0.6439 - Val Recall: 0.6252\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6366 - loss: 0.3439 - precision: 0.6311 - recall: 0.6693 - val_accuracy: 0.6034 - val_loss: 0.7068 - val_precision: 0.5991 - val_recall: 0.6252\n",
      "Epoch 1976/2000\n",
      "\u001b[1m147/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6416 - loss: 0.3276 - precision: 0.6320 - recall: 0.6812\n",
      "Epoch 1976 - Train Recall: 0.6481 - Val Recall: 0.6672\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6388 - loss: 0.3282 - precision: 0.6295 - recall: 0.6772 - val_accuracy: 0.6049 - val_loss: 0.6776 - val_precision: 0.5933 - val_recall: 0.6672\n",
      "Epoch 1977/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6309 - loss: 0.3399 - precision: 0.6247 - recall: 0.6419\n",
      "Epoch 1977 - Train Recall: 0.6181 - Val Recall: 0.6777\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6301 - loss: 0.3401 - precision: 0.6243 - recall: 0.6403 - val_accuracy: 0.6064 - val_loss: 0.6921 - val_precision: 0.5932 - val_recall: 0.6777\n",
      "Epoch 1978/2000\n",
      "\u001b[1m149/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6353 - loss: 0.3526 - precision: 0.6346 - recall: 0.6418\n",
      "Epoch 1978 - Train Recall: 0.6282 - Val Recall: 0.5652\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6349 - loss: 0.3527 - precision: 0.6344 - recall: 0.6404 - val_accuracy: 0.5810 - val_loss: 0.7179 - val_precision: 0.5836 - val_recall: 0.5652\n",
      "Epoch 1979/2000\n",
      "\u001b[1m164/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6225 - loss: 0.3231 - precision: 0.6187 - recall: 0.6423\n",
      "Epoch 1979 - Train Recall: 0.6451 - Val Recall: 0.6192\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6225 - loss: 0.3231 - precision: 0.6187 - recall: 0.6423 - val_accuracy: 0.5982 - val_loss: 0.6531 - val_precision: 0.5942 - val_recall: 0.6192\n",
      "Epoch 1980/2000\n",
      "\u001b[1m162/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6333 - loss: 0.3295 - precision: 0.6198 - recall: 0.6830\n",
      "Epoch 1980 - Train Recall: 0.6758 - Val Recall: 0.7226\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6329 - loss: 0.3296 - precision: 0.6195 - recall: 0.6828 - val_accuracy: 0.6027 - val_loss: 0.6752 - val_precision: 0.5828 - val_recall: 0.7226\n",
      "Epoch 1981/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6397 - loss: 0.3429 - precision: 0.6430 - recall: 0.6616\n",
      "Epoch 1981 - Train Recall: 0.6492 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6392 - loss: 0.3432 - precision: 0.6419 - recall: 0.6609 - val_accuracy: 0.5997 - val_loss: 0.7114 - val_precision: 0.5977 - val_recall: 0.6102\n",
      "Epoch 1982/2000\n",
      "\u001b[1m157/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6468 - loss: 0.3231 - precision: 0.6483 - recall: 0.6539\n",
      "Epoch 1982 - Train Recall: 0.6443 - Val Recall: 0.6927\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6460 - loss: 0.3233 - precision: 0.6472 - recall: 0.6532 - val_accuracy: 0.5990 - val_loss: 0.6693 - val_precision: 0.5833 - val_recall: 0.6927\n",
      "Epoch 1983/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6185 - loss: 0.3498 - precision: 0.6214 - recall: 0.6437\n",
      "Epoch 1983 - Train Recall: 0.6409 - Val Recall: 0.6237\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6185 - loss: 0.3499 - precision: 0.6206 - recall: 0.6435 - val_accuracy: 0.6042 - val_loss: 0.7088 - val_precision: 0.6003 - val_recall: 0.6237\n",
      "Epoch 1984/2000\n",
      "\u001b[1m163/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6157 - loss: 0.3340 - precision: 0.6066 - recall: 0.6305\n",
      "Epoch 1984 - Train Recall: 0.6413 - Val Recall: 0.5022\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6160 - loss: 0.3340 - precision: 0.6071 - recall: 0.6308 - val_accuracy: 0.5900 - val_loss: 0.6855 - val_precision: 0.6091 - val_recall: 0.5022\n",
      "Epoch 1985/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6237 - loss: 0.3008 - precision: 0.6182 - recall: 0.6697\n",
      "Epoch 1985 - Train Recall: 0.6957 - Val Recall: 0.7406\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6238 - loss: 0.3007 - precision: 0.6173 - recall: 0.6726 - val_accuracy: 0.5982 - val_loss: 0.6086 - val_precision: 0.5764 - val_recall: 0.7406\n",
      "Epoch 1986/2000\n",
      "\u001b[1m156/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6316 - loss: 0.3468 - precision: 0.6152 - recall: 0.7119\n",
      "Epoch 1986 - Train Recall: 0.6825 - Val Recall: 0.6702\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6310 - loss: 0.3470 - precision: 0.6150 - recall: 0.7098 - val_accuracy: 0.6042 - val_loss: 0.7111 - val_precision: 0.5921 - val_recall: 0.6702\n",
      "Epoch 1987/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6361 - loss: 0.3351 - precision: 0.6260 - recall: 0.6778\n",
      "Epoch 1987 - Train Recall: 0.6653 - Val Recall: 0.6387\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6357 - loss: 0.3351 - precision: 0.6256 - recall: 0.6771 - val_accuracy: 0.5930 - val_loss: 0.6855 - val_precision: 0.5852 - val_recall: 0.6387\n",
      "Epoch 1988/2000\n",
      "\u001b[1m160/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6326 - loss: 0.3266 - precision: 0.6201 - recall: 0.6762\n",
      "Epoch 1988 - Train Recall: 0.6702 - Val Recall: 0.6042\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6323 - loss: 0.3268 - precision: 0.6200 - recall: 0.6760 - val_accuracy: 0.6019 - val_loss: 0.6794 - val_precision: 0.6015 - val_recall: 0.6042\n",
      "Epoch 1989/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6402 - loss: 0.3191 - precision: 0.6219 - recall: 0.6918\n",
      "Epoch 1989 - Train Recall: 0.6784 - Val Recall: 0.6627\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6396 - loss: 0.3192 - precision: 0.6216 - recall: 0.6910 - val_accuracy: 0.5997 - val_loss: 0.6494 - val_precision: 0.5885 - val_recall: 0.6627\n",
      "Epoch 1990/2000\n",
      "\u001b[1m152/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6448 - loss: 0.3277 - precision: 0.6239 - recall: 0.7076\n",
      "Epoch 1990 - Train Recall: 0.6863 - Val Recall: 0.6807\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6436 - loss: 0.3281 - precision: 0.6234 - recall: 0.7058 - val_accuracy: 0.6072 - val_loss: 0.6766 - val_precision: 0.5935 - val_recall: 0.6807\n",
      "Epoch 1991/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6253 - loss: 0.3352 - precision: 0.6289 - recall: 0.6475\n",
      "Epoch 1991 - Train Recall: 0.6514 - Val Recall: 0.6102\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6253 - loss: 0.3352 - precision: 0.6288 - recall: 0.6476 - val_accuracy: 0.5952 - val_loss: 0.6941 - val_precision: 0.5924 - val_recall: 0.6102\n",
      "Epoch 1992/2000\n",
      "\u001b[1m151/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6337 - loss: 0.3260 - precision: 0.6171 - recall: 0.7146\n",
      "Epoch 1992 - Train Recall: 0.6938 - Val Recall: 0.7151\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6328 - loss: 0.3262 - precision: 0.6164 - recall: 0.7125 - val_accuracy: 0.6034 - val_loss: 0.6600 - val_precision: 0.5846 - val_recall: 0.7151\n",
      "Epoch 1993/2000\n",
      "\u001b[1m148/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6155 - loss: 0.3422 - precision: 0.6006 - recall: 0.6753\n",
      "Epoch 1993 - Train Recall: 0.6649 - Val Recall: 0.6327\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6157 - loss: 0.3426 - precision: 0.6013 - recall: 0.6740 - val_accuracy: 0.5870 - val_loss: 0.7021 - val_precision: 0.5797 - val_recall: 0.6327\n",
      "Epoch 1994/2000\n",
      "\u001b[1m146/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6350 - loss: 0.3266 - precision: 0.6233 - recall: 0.6672\n",
      "Epoch 1994 - Train Recall: 0.6638 - Val Recall: 0.5502\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6340 - loss: 0.3269 - precision: 0.6223 - recall: 0.6671 - val_accuracy: 0.5975 - val_loss: 0.6781 - val_precision: 0.6076 - val_recall: 0.5502\n",
      "Epoch 1995/2000\n",
      "\u001b[1m145/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6290 - loss: 0.3056 - precision: 0.6090 - recall: 0.7041\n",
      "Epoch 1995 - Train Recall: 0.7013 - Val Recall: 0.6372\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6283 - loss: 0.3060 - precision: 0.6091 - recall: 0.7037 - val_accuracy: 0.5915 - val_loss: 0.6308 - val_precision: 0.5838 - val_recall: 0.6372\n",
      "Epoch 1996/2000\n",
      "\u001b[1m153/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6125 - loss: 0.3234 - precision: 0.6008 - recall: 0.7007\n",
      "Epoch 1996 - Train Recall: 0.7076 - Val Recall: 0.6627\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6132 - loss: 0.3232 - precision: 0.6010 - recall: 0.7013 - val_accuracy: 0.6004 - val_loss: 0.6562 - val_precision: 0.5893 - val_recall: 0.6627\n",
      "Epoch 1997/2000\n",
      "\u001b[1m166/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6266 - loss: 0.3265 - precision: 0.6084 - recall: 0.6910\n",
      "Epoch 1997 - Train Recall: 0.6942 - Val Recall: 0.6147\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6266 - loss: 0.3265 - precision: 0.6084 - recall: 0.6910 - val_accuracy: 0.6049 - val_loss: 0.6612 - val_precision: 0.6029 - val_recall: 0.6147\n",
      "Epoch 1998/2000\n",
      "\u001b[1m155/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6141 - loss: 0.3206 - precision: 0.5901 - recall: 0.6831\n",
      "Epoch 1998 - Train Recall: 0.6964 - Val Recall: 0.7091\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6151 - loss: 0.3203 - precision: 0.5916 - recall: 0.6842 - val_accuracy: 0.5885 - val_loss: 0.6497 - val_precision: 0.5713 - val_recall: 0.7091\n",
      "Epoch 1999/2000\n",
      "\u001b[1m144/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6279 - loss: 0.3392 - precision: 0.6115 - recall: 0.7095\n",
      "Epoch 1999 - Train Recall: 0.6964 - Val Recall: 0.6192\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6281 - loss: 0.3393 - precision: 0.6121 - recall: 0.7079 - val_accuracy: 0.5832 - val_loss: 0.6950 - val_precision: 0.5776 - val_recall: 0.6192\n",
      "Epoch 2000/2000\n",
      "\u001b[1m158/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6150 - loss: 0.3207 - precision: 0.6050 - recall: 0.6710\n",
      "Epoch 2000 - Train Recall: 0.6930 - Val Recall: 0.6012\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6155 - loss: 0.3207 - precision: 0.6052 - recall: 0.6723 - val_accuracy: 0.5915 - val_loss: 0.6572 - val_precision: 0.5897 - val_recall: 0.6012\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/IAAAIhCAYAAADtv4ENAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACEjUlEQVR4nOzdd3wU1f7/8fdsyqYnBEiD0FGkSFOaSrFQrNgrRbH39hNRESxX1Hv1eu16r4BevWJBEb/YQCkqKChFVKQoTSBCgPS2yZ7fH8NusqQCaZt9PR+PhezMmZkzc2Zm9zOnrGWMMQIAAAAAAH7B0dAZAAAAAAAANUcgDwAAAACAHyGQBwAAAADAjxDIAwAAAADgRwjkAQAAAADwIwTyAAAAAAD4EQJ5AAAAAAD8CIE8AAAAAAB+hEAeAAAAAAA/QiAPAGhwlmXV6LVo0aIj2s7UqVNlWdZhLbto0aJayUNjN378eLVr167S+Xv27FFoaKguueSSStNkZWUpIiJCZ599do23O3PmTFmWpS1bttQ4L2VZlqWpU6fWeHseO3fu1NSpU7V69epy847kfDlS7dq105lnntkg2wYANH7BDZ0BAACWLVvm8/6RRx7RwoUL9dVXX/lM79q16xFt5+qrr9bIkSMPa9k+ffpo2bJlR5wHf9eyZUudffbZmjNnjvbv369mzZqVSzNr1izl5+drwoQJR7StyZMn67bbbjuidVRn586deuihh9SuXTv16tXLZ96RnC8AANQlAnkAQIMbMGCAz/uWLVvK4XCUm36wvLw8RURE1Hg7rVu3VuvWrQ8rjzExMdXmJ1BMmDBBs2fP1ltvvaWbb7653Pzp06crMTFRZ5xxxhFtp2PHjke0/JE6kvMFAIC6RNN6AIBfGDp0qLp3764lS5Zo0KBBioiI0FVXXSVJeueddzR8+HAlJycrPDxcxxxzjO69917l5ub6rKOiptKeJsyfffaZ+vTpo/DwcHXp0kXTp0/3SVdR0/rx48crKipKmzZt0umnn66oqCilpqbqrrvuUmFhoc/yf/75py644AJFR0crLi5Ol19+uVasWCHLsjRz5swq933Pnj268cYb1bVrV0VFRSkhIUEnn3yyvv76a590W7ZskWVZ+sc//qGnn35a7du3V1RUlAYOHKjvvvuu3Hpnzpypo48+Wk6nU8ccc4zeeOONKvPhMWLECLVu3VozZswoN2/dunX6/vvvNXbsWAUHB2v+/Pk655xz1Lp1a4WFhalTp0667rrrlJ6eXu12Kmpan5WVpWuuuUbNmzdXVFSURo4cqQ0bNpRbdtOmTbryyivVuXNnRUREqFWrVjrrrLO0du1ab5pFixbp+OOPlyRdeeWV3i4cnib6FZ0vbrdbTz75pLp06SKn06mEhASNHTtWf/75p086z/m6YsUKnXTSSYqIiFCHDh30+OOPy+12V7vvNVFQUKBJkyapffv2Cg0NVatWrXTTTTcpIyPDJ91XX32loUOHqnnz5goPD1ebNm10/vnnKy8vz5vmpZdeUs+ePRUVFaXo6Gh16dJF9913X63kEwBQ+6iRBwD4jV27dumKK67QPffco8cee0wOh/08euPGjTr99NN1++23KzIyUr/99pueeOIJLV++vFzz/IqsWbNGd911l+69914lJibqP//5jyZMmKBOnTpp8ODBVS7rcrl09tlna8KECbrrrru0ZMkSPfLII4qNjdWDDz4oScrNzdWwYcO0b98+PfHEE+rUqZM+++wzXXzxxTXa73379kmSpkyZoqSkJOXk5OjDDz/U0KFD9eWXX2ro0KE+6V944QV16dJFzzzzjCS7ifrpp5+uzZs3KzY2VpIdxF955ZU655xz9NRTTykzM1NTp05VYWGh97hWxuFwaPz48Xr00Ue1Zs0a9ezZ0zvPE9x7HrL8/vvvGjhwoK6++mrFxsZqy5Ytevrpp3XiiSdq7dq1CgkJqdExkCRjjEaPHq2lS5fqwQcf1PHHH69vv/1Wo0aNKpd2586dat68uR5//HG1bNlS+/bt0+uvv67+/ftr1apVOvroo9WnTx/NmDFDV155pR544AFvC4KqauFvuOEGvfrqq7r55pt15plnasuWLZo8ebIWLVqklStXqkWLFt60aWlpuvzyy3XXXXdpypQp+vDDDzVp0iSlpKRo7NixNd7vqo7Fl19+qUmTJumkk07STz/9pClTpmjZsmVatmyZnE6ntmzZojPOOEMnnXSSpk+frri4OO3YsUOfffaZioqKFBERoVmzZunGG2/ULbfcon/84x9yOBzatGmTfv311yPKIwCgDhkAABqZcePGmcjISJ9pQ4YMMZLMl19+WeWybrfbuFwus3jxYiPJrFmzxjtvypQp5uCPvrZt25qwsDCzdetW77T8/HwTHx9vrrvuOu+0hQsXGklm4cKFPvmUZN59912fdZ5++unm6KOP9r5/4YUXjCTz6aef+qS77rrrjCQzY8aMKvfpYMXFxcblcplTTjnFnHvuud7pmzdvNpJMjx49THFxsXf68uXLjSTz9ttvG2OMKSkpMSkpKaZPnz7G7XZ7023ZssWEhISYtm3bVpuHP/74w1iWZW699VbvNJfLZZKSkswJJ5xQ4TKestm6dauRZD766CPvvBkzZhhJZvPmzd5p48aN88nLp59+aiSZf/3rXz7r/dvf/mYkmSlTplSa3+LiYlNUVGQ6d+5s7rjjDu/0FStWVFoGB58v69atM5LMjTfe6JPu+++/N5LMfffd553mOV+///57n7Rdu3Y1I0aMqDSfHm3btjVnnHFGpfM/++wzI8k8+eSTPtPfeecdI8m8+uqrxhhj3n//fSPJrF69utJ13XzzzSYuLq7aPAEAGg+a1gMA/EazZs108sknl5v+xx9/6LLLLlNSUpKCgoIUEhKiIUOGSLKbelenV69eatOmjfd9WFiYjjrqKG3durXaZS3L0llnneUz7dhjj/VZdvHixYqOji43cNqll15a7fo9Xn75ZfXp00dhYWEKDg5WSEiIvvzyywr374wzzlBQUJBPfiR587R+/Xrt3LlTl112mU/T8bZt22rQoEE1yk/79u01bNgwvfXWWyoqKpIkffrpp0pLS/PWxkvS7t27df311ys1NdWb77Zt20qqWdmUtXDhQknS5Zdf7jP9sssuK5e2uLhYjz32mLp27arQ0FAFBwcrNDRUGzduPOTtHrz98ePH+0zv16+fjjnmGH355Zc+05OSktSvXz+faQefG4fL09Lk4LxceOGFioyM9OalV69eCg0N1bXXXqvXX39df/zxR7l19evXTxkZGbr00kv10Ucf1ajbAwCgYRHIAwD8RnJycrlpOTk5Oumkk/T999/r0Ucf1aJFi7RixQp98MEHkqT8/Pxq19u8efNy05xOZ42WjYiIUFhYWLllCwoKvO/37t2rxMTEcstWNK0iTz/9tG644Qb1799fs2fP1nfffacVK1Zo5MiRFebx4P1xOp2SSo/F3r17JdmB5sEqmlaZCRMmaO/evZo7d64ku1l9VFSULrroIkl2f/Lhw4frgw8+0D333KMvv/xSy5cv9/bXr8nxLWvv3r0KDg4ut38V5fnOO+/U5MmTNXr0aH388cf6/vvvtWLFCvXs2fOQt1t2+1LF52FKSop3vseRnFc1yUtwcLBatmzpM92yLCUlJXnz0rFjRy1YsEAJCQm66aab1LFjR3Xs2FH/+te/vMuMGTNG06dP19atW3X++ecrISFB/fv31/z58484nwCAukEfeQCA36joN72/+uor7dy5U4sWLfLWwksqN+BXQ2revLmWL19ebnpaWlqNln/zzTc1dOhQvfTSSz7Ts7OzDzs/lW2/pnmSpPPOO0/NmjXT9OnTNWTIEP3f//2fxo4dq6ioKEnSzz//rDVr1mjmzJkaN26cd7lNmzYddr6Li4u1d+9enyC5ojy/+eabGjt2rB577DGf6enp6YqLizvs7Uv2WA0H96PfuXOnT//4uuY5Fnv27PEJ5o0xSktL8w7iJ0knnXSSTjrpJJWUlOiHH37Qc889p9tvv12JiYm65JJLJNmD/V155ZXKzc3VkiVLNGXKFJ155pnasGGDtwUFAKDxoEYeAODXPMG9p9bZ45VXXmmI7FRoyJAhys7O1qeffuozfdasWTVa3rKscvv3008/admyZYeVn6OPPlrJycl6++23ZYzxTt+6dauWLl1a4/WEhYXpsssu0xdffKEnnnhCLpfLp1l9bZfNsGHDJElvvfWWz/T//e9/5dJWdMzmzZunHTt2+Ew7uLVCVTzdOt58802f6StWrNC6det0yimnVLuO2uLZ1sF5mT17tnJzcyvMS1BQkPr3768XXnhBkrRy5cpyaSIjIzVq1Cjdf//9Kioq0i+//FIHuQcAHClq5AEAfm3QoEFq1qyZrr/+ek2ZMkUhISF66623tGbNmobOmte4ceP0z3/+U1dccYUeffRRderUSZ9++qk+//xzSap2lPgzzzxTjzzyiKZMmaIhQ4Zo/fr1evjhh9W+fXsVFxcfcn4cDoceeeQRXX311Tr33HN1zTXXKCMjQ1OnTj2kpvWS3bz+hRde0NNPP60uXbr49LHv0qWLOnbsqHvvvVfGGMXHx+vjjz8+7Cbbw4cP1+DBg3XPPfcoNzdXxx13nL799lv997//LZf2zDPP1MyZM9WlSxcde+yx+vHHH/X3v/+9XE16x44dFR4errfeekvHHHOMoqKilJKSopSUlHLrPProo3Xttdfqueeek8Ph0KhRo7yj1qempuqOO+44rP2qTFpamt5///1y09u1a6fTTjtNI0aM0MSJE5WVlaUTTjjBO2p97969NWbMGEn22ApfffWVzjjjDLVp00YFBQXen1Y89dRTJUnXXHONwsPDdcIJJyg5OVlpaWmaNm2aYmNjfWr2AQCNB4E8AMCvNW/eXPPmzdNdd92lK664QpGRkTrnnHP0zjvvqE+fPg2dPUl2LedXX32l22+/Xffcc48sy9Lw4cP14osv6vTTT6+2qff999+vvLw8vfbaa3ryySfVtWtXvfzyy/rwww99ftf+UEyYMEGS9MQTT+i8885Tu3btdN9992nx4sWHtM7evXurd+/eWrVqlU9tvCSFhITo448/1m233abrrrtOwcHBOvXUU7VgwQKfwQVryuFwaO7cubrzzjv15JNPqqioSCeccII++eQTdenSxSftv/71L4WEhGjatGnKyclRnz599MEHH+iBBx7wSRcREaHp06froYce0vDhw+VyuTRlyhTvb8kf7KWXXlLHjh312muv6YUXXlBsbKxGjhypadOmVdgn/kj8+OOPuvDCC8tNHzdunGbOnKk5c+Zo6tSpmjFjhv72t7+pRYsWGjNmjB577DFvS4NevXrpiy++0JQpU5SWlqaoqCh1795dc+fO1fDhwyXZTe9nzpypd999V/v371eLFi104okn6o033ijXBx8A0DhYpmybOgAAUG8ee+wxPfDAA9q2bVuVv10OAABQFjXyAADUg+eff16S3dzc5XLpq6++0rPPPqsrrriCIB4AABwSAnkAAOpBRESE/vnPf2rLli0qLCxUmzZtNHHixHJNvQEAAKpD03oAAAAAAPwIPz8HAAAAAIAfIZAHAAAAAMCPEMgDAAAAAOBHGOyuAm63Wzt37lR0dLQsy2ro7AAAAAAAmjhjjLKzs5WSkiKHo+o6dwL5CuzcuVOpqakNnQ0AAAAAQIDZvn17tT9NSyBfgejoaEn2AYyJiWng3AAAAAAAmrqsrCylpqZ649GqEMhXwNOcPiYmhkAeAAAAAFBvatK9m8HuAAAAAADwIwTyAAAAAAD4EQJ5AAAAAAD8CH3kAQAAAKARMsaouLhYJSUlDZ0V1JKQkBAFBQUd8XoI5AEAAACgkSkqKtKuXbuUl5fX0FlBLbIsS61bt1ZUVNQRrYdAHgAAAAAaEbfbrc2bNysoKEgpKSkKDQ2t0UjmaNyMMdqzZ4/+/PNPde7c+Yhq5gnkAQAAAKARKSoqktvtVmpqqiIiIho6O6hFLVu21JYtW+RyuY4okGewOwAAAABohBwOwrWmprZaVnBmAAAAAADgRwjkAQAAAADwIwTyAAAAAIBGa+jQobr99tsbOhuNCoPdAQAAAACOWHX9v8eNG6eZM2ce8no/+OADhYSEHGaumiYCeQAAAADAEdu1a5f373feeUcPPvig1q9f750WHh7uk97lctUoQI+Pj6+9TDYRDdq0fsmSJTrrrLOUkpIiy7I0Z84cn/mWZVX4+vvf/17pOmfOnFnhMgUFBXW8NwAAAABQN4wxKinJbZCXMaZGeUxKSvK+YmNjZVmW931BQYHi4uL07rvvaujQoQoLC9Obb76pvXv36tJLL1Xr1q0VERGhHj166O233/ZZ78FN69u1a6fHHntMV111laKjo9WmTRu9+uqrtXm4G70GrZHPzc1Vz549deWVV+r8888vN7/sEx1J+vTTTzVhwoQK05YVExPj8+RHksLCwo48wwAAAADQANzuPH39dVSDbPukk3IUFBRZK+uaOHGinnrqKc2YMUNOp1MFBQXq27evJk6cqJiYGM2bN09jxoxRhw4d1L9//0rX89RTT+mRRx7Rfffdp/fff1833HCDBg8erC5dutRKPhu7Bg3kR40apVGjRlU6Pykpyef9Rx99pGHDhqlDhw5Vrtfz5AcAAAAA0HjcfvvtOu+883ym3X333d6/b7nlFn322Wd67733qgzkTz/9dN14442S7IcD//znP7Vo0SIC+cbmr7/+0rx58/T6669XmzYnJ0dt27ZVSUmJevXqpUceeUS9e/euNH1hYaEKCwu977Oysmolz3UtN3ed8vLWKSysvaKjK98/AAAAAP7N4YjQSSflNNi2a8txxx3n876kpESPP/643nnnHe3YscMbm0VGVt0C4Nhjj/X+7anI3b17d63ls7Hzm0D+9ddfV3R0dLmnNwfr0qWLZs6cqR49eigrK0v/+te/dMIJJ2jNmjXq3LlzhctMmzZNDz30UF1ku07t2fOetmyZopSU6xUd/VJDZwcAAABAHbEsq9aatzekgwP0p556Sv/85z/1zDPPqEePHoqMjNTtt9+uoqKiKtdz8CB5lmXJ7XbXen4bK78J5KdPn67LL7+82r7uAwYM0IABA7zvTzjhBPXp00fPPfecnn322QqXmTRpku68807v+6ysLKWmptZOxgEAAAAAFfr66691zjnn6IorrpAkud1ubdy4Ucccc0wD56xx84tA/uuvv9b69ev1zjvvHPKyDodDxx9/vDZu3FhpGqfTKafTeSRZbFA1HUUSAAAAABqTTp06afbs2Vq6dKmaNWump59+WmlpaQTy1WjQn5+rqddee019+/ZVz549D3lZY4xWr16t5OTkOshZQ7MaOgMAAAAAcNgmT56sPn36aMSIERo6dKiSkpI0evTohs5Wo9egNfI5OTnatGmT9/3mzZu1evVqxcfHq02bNpLsZu7vvfeennrqqQrXMXbsWLVq1UrTpk2TJD300EMaMGCAOnfurKysLD377LNavXq1XnjhhbrfIQAAAACAxo8fr/Hjx3vft2vXrsKWxPHx8ZozZ06V61q0aJHP+y1btpRLs3r16kPPpB9r0ED+hx9+0LBhw7zvPf3Ux40bp5kzZ0qSZs2aJWOMLr300grXsW3bNjkcpQ0LMjIydO211yotLU2xsbHq3bu3lixZon79+tXdjjQ4mtYDAAAAQKCwDB2sy8nKylJsbKwyMzMVExPT0Nmp1JYtj2rLlslKTr5WRx/9SkNnBwAAAEAtKCgo0ObNm9W+fftqB/uGf6mqbA8lDvWLPvKoDs9iAAAAACBQEMj7MctisDsAAAAACDQE8gAAAAAA+BEC+SaBpvUAAAAAECgI5P0aTesBAAAAINAQyAMAAAAA4EcI5JsAfkEQAAAAAAIHgbxfo2k9AAAAgKZj6NChuv32273v27Vrp2eeeabKZSzL0pw5c45427W1nvpAIA8AAAAAOGJnnXWWTj311ArnLVu2TJZlaeXKlYe0zhUrVujaa6+tjex5TZ06Vb169So3fdeuXRo1alStbquuEMg3CTStBwAAANCwJkyYoK+++kpbt24tN2/69Onq1auX+vTpc0jrbNmypSIiImori1VKSkqS0+msl20dKQJ5v0bTegAAACAgGCPl5jbMq4Zjcp155plKSEjQzJkzfabn5eXpnXfe0ejRo3XppZeqdevWioiIUI8ePfT2229Xuc6Dm9Zv3LhRgwcPVlhYmLp27ar58+eXW2bixIk66qijFBERoQ4dOmjy5MlyuVySpJkzZ+qhhx7SmjVrZFmWLMvy5vfgpvVr167VySefrPDwcDVv3lzXXnutcnJyvPPHjx+v0aNH6x//+IeSk5PVvHlz3XTTTd5t1aXgOt8C6gE18gAAAECTlpcnRUU1zLZzcqTIyGqTBQcHa+zYsZo5c6YefPBBWZZd8fjee++pqKhIV199td5++21NnDhRMTExmjdvnsaMGaMOHTqof//+1a7f7XbrvPPOU4sWLfTdd98pKyvLpz+9R3R0tGbOnKmUlBStXbtW11xzjaKjo3XPPffo4osv1s8//6zPPvtMCxYskCTFxsaWW0deXp5GjhypAQMGaMWKFdq9e7euvvpq3XzzzT4PKhYuXKjk5GQtXLhQmzZt0sUXX6xevXrpmmuuqXZ/jgQ18n7Mc2EAAAAAQGNw1VVXacuWLVq0aJF32vTp03XeeeepVatWuvvuu9WrVy916NBBt9xyi0aMGKH33nuvRutesGCB1q1bp//+97/q1auXBg8erMcee6xcugceeECDBg1Su3btdNZZZ+muu+7Su+++K0kKDw9XVFSUgoODlZSUpKSkJIWHh5dbx1tvvaX8/Hy98cYb6t69u04++WQ9//zz+u9//6u//vrLm65Zs2Z6/vnn1aVLF5155pk644wz9OWXXx7iUTt01MgDAAAAQGMXEWHXjDfUtmuoS5cuGjRokKZPn65hw4bp999/19dff60vvvhCJSUlevzxx/XOO+9ox44dKiwsVGFhoSJrUNsvSevWrVObNm3UunVr77SBAweWS/f+++/rmWee0aZNm5STk6Pi4mLFxMTUeB882+rZs6dP3k444QS53W6tX79eiYmJkqRu3bopKCjImyY5OVlr1649pG0dDgL5JoGm9QAAAECTZlk1at7eGEyYMEE333yzXnjhBc2YMUNt27bVKaecor///e/65z//qWeeeUY9evRQZGSkbr/9dhUVFdVovaaCvvoHt1L+7rvvdMkll+ihhx7SiBEjFBsbq1mzZumpp546pH0wxlTaArrs9JCQkHLz3G73IW3rcNC03q/RtB4AAABA43LRRRcpKChI//vf//T666/ryiuvlGVZ+vrrr3XOOefoiiuuUM+ePdWhQwdt3Lixxuvt2rWrtm3bpp07d3qnLVu2zCfNt99+q7Zt2+r+++/Xcccdp86dO5cbRT80NFQlJSXVbmv16tXKzc31WbfD4dBRRx1V4zzXFQJ5AAAAAECtiYqK0sUXX6z77rtPO3fu1Pjx4yVJnTp10vz587V06VKtW7dO1113ndLS0mq83lNPPVVHH320xo4dqzVr1ujrr7/W/fff75OmU6dO2rZtm2bNmqXff/9dzz77rD788EOfNO3atdPmzZu1evVqpaenq7CwsNy2Lr/8coWFhWncuHH6+eeftXDhQt1yyy0aM2aMt1l9QyKQbwIqamICAAAAAA1lwoQJ2r9/v0499VS1adNGkjR58mT16dNHI0aM0NChQ5WUlKTRo0fXeJ0Oh0MffvihCgsL1a9fP1199dX629/+5pPmnHPO0R133KGbb75ZvXr10tKlSzV58mSfNOeff75GjhypYcOGqWXLlhX+BF5ERIQ+//xz7du3T8cff7wuuOACnXLKKXr++ecP/WDUAcsQBZaTlZWl2NhYZWZmHvKgCPVp27a/648/7lFi4jgdc8zMhs4OAAAAgFpQUFCgzZs3q3379goLC2vo7KAWVVW2hxKHUiMPAAAAAIAfIZBvEmhUAQAAAACBgkDerzFqPQAAAAAEGgJ5AAAAAAD8CIF8k0DTegAAAKCpYVzypqe2ypRA3o9ZFk3rAQAAgKYmJCREkpSXl9fAOUFtKyoqkiQFBQUd0XqCayMzaGg8qQMAAACaiqCgIMXFxWn37t2S7N80pxLP/7ndbu3Zs0cREREKDj6yUJxA3q9xMQMAAABNUVJSkiR5g3k0DQ6HQ23atDniBzME8gAAAADQyFiWpeTkZCUkJMjlcjV0dlBLQkND5XAceQ93AvkmgEEwAAAAgKYpKCjoiPtTo+lhsDu/RtN6AAAAAAg0BPIAAAAAAPgRAvkmgab1AAAAABAoCOT9Gk3rAQAAACDQEMgDAAAAAOBHCOSbBJrWAwAAAECgIJD3Y5ZF03oAAAAACDQE8k0CNfIAAAAAECgI5P0aNfIAAAAAEGgI5AEAAAAA8CME8k2AMTStBwAAAIBAQSDv12haDwAAAACBhkAeAAAAAAA/QiDfJNC0HgAAAAACBYG8X6NpPQAAAAAEGgJ5AAAAAAD8CIF8k0DTegAAAAAIFATyfsyyaFoPAAAAAIGGQL5JoEYeAAAAAAIFgbxfo0YeAAAAAAJNgwbyS5Ys0VlnnaWUlBRZlqU5c+b4zB8/frwsy/J5DRgwoNr1zp49W127dpXT6VTXrl314Ycf1tEeAAAAAABQvxo0kM/NzVXPnj31/PPPV5pm5MiR2rVrl/f1ySefVLnOZcuW6eKLL9aYMWO0Zs0ajRkzRhdddJG+//772s5+o2EMTesBAAAAIFAEN+TGR40apVGjRlWZxul0KikpqcbrfOaZZ3Taaadp0qRJkqRJkyZp8eLFeuaZZ/T2228fUX4bH5rWAwAAAECgafR95BctWqSEhAQdddRRuuaaa7R79+4q0y9btkzDhw/3mTZixAgtXbq00mUKCwuVlZXl8wIAAAAAoDFq1IH8qFGj9NZbb+mrr77SU089pRUrVujkk09WYWFhpcukpaUpMTHRZ1piYqLS0tIqXWbatGmKjY31vlJTU2ttH+oHTesBAAAAIFA0aNP66lx88cXev7t3767jjjtObdu21bx583TeeedVutzBv69ujKnyN9cnTZqkO++80/s+KyvLT4J5mtYDAAAAQKBp1IH8wZKTk9W2bVtt3Lix0jRJSUnlat93795drpa+LKfTKafTWWv5BAAAAACgrjTqpvUH27t3r7Zv367k5ORK0wwcOFDz58/3mfbFF19o0KBBdZ29BkTTegAAAAAIFA1aI5+Tk6NNmzZ532/evFmrV69WfHy84uPjNXXqVJ1//vlKTk7Wli1bdN9996lFixY699xzvcuMHTtWrVq10rRp0yRJt912mwYPHqwnnnhC55xzjj766CMtWLBA33zzTb3vX12rqrsAAAAAAKBpatBA/ocfftCwYcO87z391MeNG6eXXnpJa9eu1RtvvKGMjAwlJydr2LBheueddxQdHe1dZtu2bXI4ShsWDBo0SLNmzdIDDzygyZMnq2PHjnrnnXfUv3//+tuxekeNPAAAAAAECssYQxR4kKysLMXGxiozM1MxMTENnZ1K7dz5qjZsuE4tWoxW9+4fNnR2AAAAAACH6VDiUL/qIw8AAAAAQKAjkG8CaFQBAAAAAIGDQN6vMdgdAAAAAAQaAnkAAAAAAPwIgXyTQNN6AAAAAAgUBPJ+jab1AAAAABBoCOQBAAAAAPAjBPJNAk3rAQAAACBQEMj7McuiaT0AAAAABBoC+SaBGnkAAAAACBQE8n6NGnkAAAAACDQE8gAAAAAA+BEC+SbAGJrWAwAAAECgIJD3azStBwAAAIBAQyAPAAAAAIAfIZBvEmhaDwAAAACBgkDer9G0HgAAAAACDYE8AAAAAAB+hEC+SaBpPQAAAAAECgJ5P2ZZNK0HAAAAgEBDIN8kUCMPAAAAAIGCQN6vUSMPAAAAAIGGQB4AAAAAAD9CIN8EGEPTegAAAAAIFATyfo2m9QAAAAAQaAjkAQAAAADwIwTyTQJN6wEAAAAgUBDI+zWa1gMAAABAoCGQBwAAAADAjxDINwk0rQcAAACAQEEg78csi6b1AAAAABBoCOSbBGrkAQAAACBQEMgDAAAAAOBHCOT9Gk3rAQAAACDQEMg3AcbQtB4AAAAAAgWBvF+jRh4AAAAAAg2BPAAAAAAAfoRAvkmgaT0AAAAABAoCeb9G03oAAAAACDQE8gAAAAAA+BEC+SaBpvUAAAAAECgI5P2YZdG0HgAAAAACDYE8AAAAAAB+hEC+SaBpPQAAAAAECgJ5v0bTegAAAAAINATyTYAx1MgDAAAAQKAgkPdr1MgDAAAAQKAhkAcAAAAAwI8QyDcJNK0HAAAAgEBBIO/XaFoPAAAAAIGmQQP5JUuW6KyzzlJKSoosy9KcOXO881wulyZOnKgePXooMjJSKSkpGjt2rHbu3FnlOmfOnCnLssq9CgoK6nhvAAAAAACoew0ayOfm5qpnz556/vnny83Ly8vTypUrNXnyZK1cuVIffPCBNmzYoLPPPrva9cbExGjXrl0+r7CwsLrYhUaCpvUAAAAAECiCG3Ljo0aN0qhRoyqcFxsbq/nz5/tMe+6559SvXz9t27ZNbdq0qXS9lmUpKSmpVvPaGFkWTesBAAAAIND4VR/5zMxMWZaluLi4KtPl5OSobdu2at26tc4880ytWrWqyvSFhYXKysryeQEAAAAA0Bj5TSBfUFCge++9V5dddpliYmIqTdelSxfNnDlTc+fO1dtvv62wsDCdcMIJ2rhxY6XLTJs2TbGxsd5XampqXexCHaJpPQAAAAAECr8I5F0uly655BK53W69+OKLVaYdMGCArrjiCvXs2VMnnXSS3n33XR111FF67rnnKl1m0qRJyszM9L62b99e27tQR2haDwAAAACBpkH7yNeEy+XSRRddpM2bN+urr76qsja+Ig6HQ8cff3yVNfJOp1NOp/NIs9pgjKFGHgAAAAACRaOukfcE8Rs3btSCBQvUvHnzQ16HMUarV69WcnJyHeSwoVEjDwAAAACBpkFr5HNycrRp0ybv+82bN2v16tWKj49XSkqKLrjgAq1cuVL/93//p5KSEqWlpUmS4uPjFRoaKkkaO3asWrVqpWnTpkmSHnroIQ0YMECdO3dWVlaWnn32Wa1evVovvPBC/e8gAAAAAAC1rEED+R9++EHDhg3zvr/zzjslSePGjdPUqVM1d+5cSVKvXr18llu4cKGGDh0qSdq2bZscjtKGBRkZGbr22muVlpam2NhY9e7dW0uWLFG/fv3qdmcaFE3rAQAAACBQWIYO1uVkZWUpNjZWmZmZh9wnvz7t2TNHv/xyrmJiBqlPn28bOjsAAAAAgMN0KHFoo+4jDwAAAAAAfBHINwk0qgAAAACAQEEg78csi1HrAQAAACDQEMgDAAAAAOBHCOSbBJrWAwAAAECgIJD3azStBwAAAIBAQyDfBPALggAAAAAQOAjk/Ro18gAAAAAQaAjkAQAAAADwIwTyTQJN6wEAAAAgUBDI+zWa1gMAAABAoCGQBwAAAADAjxDINwk0rQcAAACAQEEg78csi6b1AAAAABBoCOQBAAAAAPAjBPJNAk3rAQAAACBQEMj7NZrWAwAAAECgIZBvAoyhRh4AAAAAAgWBvF+jRh4AAAAAAg2BPAAAAAAAfoRAvkmgaT0AAAAABAoCeb9G03oAAAAACDQE8gAAAAAA+BEC+SaBpvUAAAAAECgI5P2YZdG0HgAAAAACDYE8AAAAAAB+hEC+SaBpPQAAAAAECgJ5v0bTegAAAAAINATyTYAx1MgDAAAAQKAgkPdr1MgDAAAAQKAhkAcAAAAAwI8QyDcJNK0HAAAAgEBBIO/XaFoPAAAAAIGGQB4AAAAAAD9CIN8k0LQeAAAAAAIFgbwfsyya1gMAAABAoCGQBwAAAADAjxDINwk0rQcAAACAQEEg79doWg8AAAAAgYZAvgkwhhp5AAAAAAgUBPJ+jRp5AAAAAAg0BPIAAAAAAPgRAvkmgab1AAAAABAoCOT9Gk3rAQAAACDQEMgDAAAAAOBHCOSbBJrWAwAAAECgIJD3Y5ZF03oAAAAACDQE8gAAAAAA+BEC+SaBpvUAAAAAECgI5P0aTesBAAAAINA0aCC/ZMkSnXXWWUpJSZFlWZozZ47PfGOMpk6dqpSUFIWHh2vo0KH65Zdfql3v7Nmz1bVrVzmdTnXt2lUffvhhHe0BAAAAAAD1q0ED+dzcXPXs2VPPP/98hfOffPJJPf3003r++ee1YsUKJSUl6bTTTlN2dnal61y2bJkuvvhijRkzRmvWrNGYMWN00UUX6fvvv6+r3WhwxtC0HgAAAAAChWUaSRRoWZY+/PBDjR49WpIdnKakpOj222/XxIkTJUmFhYVKTEzUE088oeuuu67C9Vx88cXKysrSp59+6p02cuRINWvWTG+//XaFyxQWFqqwsND7PisrS6mpqcrMzFRMTEwt7WHty8j4WqtXD1Z4+NHq3/+3hs4OAAAAAOAwZWVlKTY2tkZxaKPtI79582alpaVp+PDh3mlOp1NDhgzR0qVLK11u2bJlPstI0ogRI6pcZtq0aYqNjfW+UlNTj3wH6lWjeBYDAAAAAKgHjTaQT0tLkyQlJib6TE9MTPTOq2y5Q11m0qRJyszM9L62b99+BDmvTwx2BwAAAACBJrihM1Ady/INVo0x5aYd6TJOp1NOp/PwMwkAAAAAQD1ptDXySUlJklSuJn337t3latwPXu5Ql/F/NK0HAAAAgEDRaAP59u3bKykpSfPnz/dOKyoq0uLFizVo0KBKlxs4cKDPMpL0xRdfVLmMv6quZQIAAAAAoOlp0Kb1OTk52rRpk/f95s2btXr1asXHx6tNmza6/fbb9dhjj6lz587q3LmzHnvsMUVEROiyyy7zLjN27Fi1atVK06ZNkyTddtttGjx4sJ544gmdc845+uijj7RgwQJ988039b5/AAAAAADUtgYN5H/44QcNGzbM+/7OO++UJI0bN04zZ87UPffco/z8fN14443av3+/+vfvry+++ELR0dHeZbZt2yaHo7RhwaBBgzRr1iw98MADmjx5sjp27Kh33nlH/fv3r78dq3c0rQcAAACAQNFofke+MTmU3+9rSJmZS7Vq1QkKD++k/v03NnR2AAAAAACHqUn8jjwAAAAAACiPQL4JoFEFAAAAAAQOAnm/xqj1AAAAABBoCOSbBGrkAQAAACBQEMj7NWrkAQAAACDQEMgDAAAAAOBHCOSbBJrWAwAAAECgIJD3Y5ZF03oAAAAACDQE8gAAAAAA+BEC+SaBpvUAAAAAECgOK5Dfvn27/vzzT+/75cuX6/bbb9err75aaxlDTdC0HgAAAAACzWEF8pdddpkWLlwoSUpLS9Npp52m5cuX67777tPDDz9cqxkEAAAAAAClDiuQ//nnn9WvXz9J0rvvvqvu3btr6dKl+t///qeZM2fWZv5QA8bQtB4AAAAAAsVhBfIul0tOp1OStGDBAp199tmSpC5dumjXrl21lztUg6b1AAAAABBoDiuQ79atm15++WV9/fXXmj9/vkaOHClJ2rlzp5o3b16rGURNUCMPAAAAAIHisAL5J554Qq+88oqGDh2qSy+9VD179pQkzZ0719vkHvWBGnkAAAAACDTBh7PQ0KFDlZ6erqysLDVr1sw7/dprr1VEREStZQ4AAAAAAPg6rBr5/Px8FRYWeoP4rVu36plnntH69euVkJBQqxlETdC0HgAAAAACxWEF8uecc47eeOMNSVJGRob69++vp556SqNHj9ZLL71UqxlE5SyLpvUAAAAAEGgOK5BfuXKlTjrpJEnS+++/r8TERG3dulVvvPGGnn322VrNICoX/P7n6n6/lPhBTkNnBQAAAABQTw6rj3xeXp6io6MlSV988YXOO+88ORwODRgwQFu3bq3VDKJyjo1b1WKpVJxQ1NBZAQAAAADUk8Oqke/UqZPmzJmj7du36/PPP9fw4cMlSbt371ZMTEytZhBVONC03qKLPAAAAAAEjMMK5B988EHdfffdateunfr166eBAwdKsmvne/fuXasZRBXoIw8AAAAAAeewmtZfcMEFOvHEE7Vr1y7vb8hL0imnnKJzzz231jKHmjGGKnkAAAAACBSHFchLUlJSkpKSkvTnn3/Ksiy1atVK/fr1q828oTqW3aCCpvUAAAAAEDgOq2m92+3Www8/rNjYWLVt21Zt2rRRXFycHnnkEbnd7trOIyrjaVlPIA8AAAAAAeOwauTvv/9+vfbaa3r88cd1wgknyBijb7/9VlOnTlVBQYH+9re/1XY+URHrsJ7DAAAAAAD82GEF8q+//rr+85//6Oyzz/ZO69mzp1q1aqUbb7yRQL6+MNYdAAAAAAScw6rS3bdvn7p06VJuepcuXbRv374jzhQOEYPdAQAAAEDAOKxAvmfPnnr++efLTX/++ed17LHHHnGmUEMMdgcAAAAAAeewmtY/+eSTOuOMM7RgwQINHDhQlmVp6dKl2r59uz755JPaziMq4/kdeQJ5AAAAAAgYh1UjP2TIEG3YsEHnnnuuMjIytG/fPp133nn65ZdfNGPGjNrOIyrj7SNPJA8AAAAAgeKwf0c+JSWl3KB2a9as0euvv67p06cfccZQA55R64njAQAAACBg8PtlAAAAAAD4EQJ5f0YfeQAAAAAIOATy/oxAHgAAAAACziH1kT/vvPOqnJ+RkXEkecGh8gTyRPIAAAAAEDAOKZCPjY2tdv7YsWOPKEM4BAcCeX5HHgAAAAACxyEF8vy0XCNFIA8AAAAAAYM+8v6MPvIAAAAAEHAI5P2Zt488AAAAACBQEMj7MwJ5AAAAAAg4BPJNgGVoWw8AAAAAgYJA3p9ZB4qPOB4AAAAAAgaBvD/jZ+QBAAAAIOAQyPsz+sgDAAAAQMAhkPdnNK0HAAAAgIBDIN8kEMkDAAAAQKAgkPdnnqb1xPEAAAAAEDAafSDfrl07WZZV7nXTTTdVmH7RokUVpv/tt9/qOef14EAgbxHIAwAAAEDACG7oDFRnxYoVKikp8b7/+eefddppp+nCCy+scrn169crJibG+75ly5Z1lscGw2B3AAAAABBwGn0gf3AA/vjjj6tjx44aMmRIlcslJCQoLi6uDnPWCDhoWg8AAAAAgabRN60vq6ioSG+++aauuuoqWdXURvfu3VvJyck65ZRTtHDhwirTFhYWKisry+cFAAAAAEBj5FeB/Jw5c5SRkaHx48dXmiY5OVmvvvqqZs+erQ8++EBHH320TjnlFC1ZsqTSZaZNm6bY2FjvKzU1tQ5yXwe8g91RJQ8AAAAAgcIyxn+iwBEjRig0NFQff/zxIS131llnybIszZ07t8L5hYWFKiws9L7PyspSamqqMjMzffrZNzaFL/5Nzpse0L5BwYr/1tXQ2QEAAAAAHKasrCzFxsbWKA5t9H3kPbZu3aoFCxbogw8+OORlBwwYoDfffLPS+U6nU06n80iy1zAY6w4AAAAAAo7fNK2fMWOGEhISdMYZZxzysqtWrVJycnId5Kqh2ZG8/7SpAAAAAAAcKb+okXe73ZoxY4bGjRun4GDfLE+aNEk7duzQG2+8IUl65pln1K5dO3Xr1s07ON7s2bM1e/bshsh6HeN35AEAAAAg0PhFIL9gwQJt27ZNV111Vbl5u3bt0rZt27zvi4qKdPfdd2vHjh0KDw9Xt27dNG/ePJ1++un1meX6YfHzcwAAAAAQaPxqsLv6ciiDDDSkwleekPP6e7Wvf7Div2OwOwAAAADwV4cSh/pNH3lUwFMjT5U8AAAAAAQMAnl/RtN6AAAAAAg4BPJ+zLIY7A4AAAAAAg2BvD+jZT0AAAAABBwCeX/m7SMPAAAAAAgUBPL+zKL4AAAAACDQEAn6Mwa7AwAAAICAQyDfFBgieQAAAAAIFATy/oxR6wEAAAAg4BDI+zMGuwMAAACAgEMg78/oIw8AAAAAAYdA3q9RIw8AAAAAgYZA3p954nhq5AEAAAAgYBDI+zN+Rx4AAAAAAg6RoD9j1HoAAAAACDgE8v7MO9gdkTwAAAAABAoCeQAAAAAA/AiBvD/j5+cAAAAAIOAQyPszi5+fAwAAAIBAQyDvzzyj1lMjDwAAAAABg0DenzFqPQAAAAAEHAL5poBAHgAAAAACBoG8P6OPPAAAAAAEHAJ5f0YgDwAAAAABh0Dej1kOBrsDAAAAgEBDIO/P+B15AAAAAAg4BPJNgGWI5AEAAAAgUBDI+zP6yAMAAABAwCGQ92cE8gAAAAAQcAjk/ZihjzwAAAAABBwCeX9mMWo9AAAAAAQaAvkmwCKQBwAAAICAQSAPAAAAAIAfIZD3ZzStBwAAAICAQyDvzxi1HgAAAAACDoG8H7Mc1MgDAAAAQKAhkG8CGOwOAAAAAAIHgbw/o2k9AAAAAAQcAnl/5gnkqZEHAAAAgIBBIO/PqJEHAAAAgIBDIN8UUCMPAAAAAAGDQN6fWRQfAAAAAAQaIkF/dqBpPaPWAwAAAEDgIJD3Z2X6yBtDNA8AAAAAgYBA3p8xaj0AAAAABBwC+abAeP8BAAAAADRxBPJ+zHJQfAAAAAAQaIgE/RmD3QEAAABAwCGQ92dlBrujaT0AAAAABAYCeX/GYHcAAAAAEHAadSA/depUWZbl80pKSqpymcWLF6tv374KCwtThw4d9PLLL9dTbhsQgTwAAAAABIzghs5Adbp166YFCxZ43wcFBVWadvPmzTr99NN1zTXX6M0339S3336rG2+8US1bttT5559fH9mtXwf9jrxPS3sAAAAAQJPU6AP54ODgamvhPV5++WW1adNGzzzzjCTpmGOO0Q8//KB//OMfTTSQtx9qWPz8HAAAAAAEjEbdtF6SNm7cqJSUFLVv316XXHKJ/vjjj0rTLlu2TMOHD/eZNmLECP3www9yuVyVLldYWKisrCyfl1+wyhafu8GyAQAAAACoP406kO/fv7/eeOMNff755/r3v/+ttLQ0DRo0SHv37q0wfVpamhITE32mJSYmqri4WOnp6ZVuZ9q0aYqNjfW+UlNTa3U/6ownkDd203oAAAAAQNPXqAP5UaNG6fzzz1ePHj106qmnat68eZKk119/vdJlrIM6insC3IOnlzVp0iRlZmZ6X9u3b6+F3NeHsvtEjTwAAAAABIJG30e+rMjISPXo0UMbN26scH5SUpLS0tJ8pu3evVvBwcFq3rx5pet1Op1yOp21mtf6YDlKa+TpIw8AAAAAgaFR18gfrLCwUOvWrVNycnKF8wcOHKj58+f7TPviiy903HHHKSQkpD6yWL8ONK23aFoPAAAAAAGjUQfyd999txYvXqzNmzfr+++/1wUXXKCsrCyNGzdOkt0kfuzYsd70119/vbZu3ao777xT69at0/Tp0/Xaa6/p7rvvbqhdqFsMdgcAAAAAAadRN63/888/demllyo9PV0tW7bUgAED9N1336lt27aSpF27dmnbtm3e9O3bt9cnn3yiO+64Qy+88IJSUlL07LPPNs2fnhNN6wEAAAAgEFmGNtnlZGVlKTY2VpmZmYqJiWno7FTKvXKFHH37qbC55Ni1XyEhcQ2dJQAAAADAYTiUOLRRN61HNayyNfI0rQcAAACAQEAg78csR5D9P03rAQAAACBgEMj7szKD3RlDjTwAAAAABAICeT/GYHcAAAAAEHgI5JsMAnkAAAAACAQE8v7Msuz/DU3rAQAAACBQEMj7swOBPIPdAQAAAEDgIJD3Z54aeVEjDwAAAACBgkC+yaBGHgAAAAACAYG8PyvTR55AHgAAAAACA4G8P2OwOwAAAAAIOATy/ozB7gAAAAAg4BDI+7Myg91J1MgDAAAAQCAgkG8ijKFGHgAAAAACAYG8P2OwOwAAAAAIOATy/swnkKdpPQAAAAAEAgJ5f1ZmsDua1gMAAABAYCCQ92c+g90RyAMAAABAICCQbzJoWg8AAAAAgYBA3p+V6SNP03oAAAAACAwE8v6Mwe4AAAAAIOAQyPuzMoPd0UceAAAAAAIDgbw/KzPYHU3rAQAAACAwEMg3GTStBwAAAIBAQCDvz3z6yFMjDwAAAACBgEDen/mMWk+NPAAAAAAEAgJ5f8ZgdwAAAAAQcAjk/VmZwe4I5AEAAAAgMBDINxE0rQcAAACAwEAg788Y7A4AAAAAAg6BvD8r00eeGnkAAAAACAwE8v6MPvIAAAAAEHAI5P0ZgTwAAAAABBwC+SbCuEsaOgsAAAAAgHpAIO/PytbI00ceAAAAAAICgbw/8wnkqZEHAAAAgEBAIO/PygTyxk0feQAAAAAIBATy/qxsjTx95AEAAAAgIBDI+7Pg4NK/S4obLh8AAAAAgHpDIO/PgoK8f5piauQBAAAAIBAQyPuzMoG8RdN6AAAAAAgIBPL+rEwgT9N6AAAAAAgMBPL+jKb1AAAAABBwCOT9mWXJeAaup0YeAAAAAAICgby/c9iRPH3kAQAAACAwEMj7OXOgdT1N6wEAAAAgMBDI+zlzoEaepvUAAAAAEBgI5P1dkCeQp0YeAAAAAAIBgbyfK62RJ5AHAAAAgEDQqAP5adOm6fjjj1d0dLQSEhI0evRorV+/vsplFi1aJMuyyr1+++23esp1PfP8Ah2BPAAAAAAEhEYdyC9evFg33XSTvvvuO82fP1/FxcUaPny4cnNzq112/fr12rVrl/fVuXPneshx/aNGHgAAAAACS3BDZ6Aqn332mc/7GTNmKCEhQT/++KMGDx5c5bIJCQmKi4urw9w1Egx2BwAAAAABpVHXyB8sMzNTkhQfH19t2t69eys5OVmnnHKKFi5cWGXawsJCZWVl+bz8hfEOdudu2IwAAAAAAOqF3wTyxhjdeeedOvHEE9W9e/dK0yUnJ+vVV1/V7Nmz9cEHH+joo4/WKaecoiVLllS6zLRp0xQbG+t9paam1sUu1A1q5AEAAAAgoFjGGNPQmaiJm266SfPmzdM333yj1q1bH9KyZ511lizL0ty5cyucX1hYqMLCQu/7rKwspaamKjMzUzExMUeU77pWmBoh55/52vvxZDU/8+GGzg4AAAAA4DBkZWUpNja2RnGoX9TI33LLLZo7d64WLlx4yEG8JA0YMEAbN26sdL7T6VRMTIzPy284aFoPAAAAAIGkUQ92Z4zRLbfcog8//FCLFi1S+/btD2s9q1atUnJyci3nrnEo7SNP03oAAAAACASNOpC/6aab9L///U8fffSRoqOjlZaWJkmKjY1VeHi4JGnSpEnasWOH3njjDUnSM888o3bt2qlbt24qKirSm2++qdmzZ2v27NkNth91ihp5AAAAAAgojTqQf+mllyRJQ4cO9Zk+Y8YMjR8/XpK0a9cubdu2zTuvqKhId999t3bs2KHw8HB169ZN8+bN0+mnn15f2a5X1MgDAAAAQGDxm8Hu6tOhDDLQ0PKPiVX4b1na++Ztan75Mw2dHQAAAADAYWhyg92hciboQBGWlDRsRgAAAAAA9YJA3t95mta7CeQBAAAAIBAQyPs54xnsrpjB7gAAAAAgEBDI+zsHTesBAAAAIJAQyPu7A03rLZrWAwAAAEBAIJD3c56fnzM0rQcAAACAgEAg7+8ONK2nRh4AAAAAAgOBvJ/z1MjTRx4AAAAAAgOBvL9jsDsAAAAACCgE8v4uyC5CU1LcwBkBAAAAANQHAnl/dyCQVzE18gAAAAAQCAjk/ZzxBPLUyAMAAABAQCCQ93fBQZIki0AeAAAAAAICgby/C7IDecNgdwAAAAAQEAjk/d2BGnkVUyMPAAAAAIGAQN7PGQJ5AAAAAAgoBPL+LihYkmS5COQBAAAAIBAQyPs7b418FX3k162TXn6ZWnsAAAAAaAKCGzoDOEIhB4qwqkC+a9fSv6+/vm7zAwAAAACoU9TI+7tD6SO/fHnd5gUAAAAAUOcI5P1d8IEa+Zr8/FxoaN3mBQAAAABQ5wjk/d2BQN7yNK3PzJSmTLH7xR+MQB4AAAAA/B6BvL/z1Mi7DgTyEydKDz8s9ehRPq3TWX/5AgAAAADUCQJ5P2cOblr/7be+78s2uadGHgAAAAD8HoG8vwsOkVSmaX3wQT9EkJdX+nfZQL6gQHK56jhzAAAAAIDaRiDv77w/P+c+8D7Ed35OTunfjgPFnZsrJSRI/fvXff4AAAAAALWKQN7fHdy0vmyN/J9/StnZpe+Liuz/v/vOnr5qVf3k0ZOX44+XZs6sv20CAAAAQBNEIO/nLE/TelcFgXxqqjR3bul7TyCflVU6rSY/W1cbbrhB+uEH6cor62d7AAAAANBEEcj7O8/Pz5W4fd573Xdf6d8VBfKeaXVtzZr62Q4AAAAANHEE8v7O0yfe00feGN/5ZQe0a8hAfvv2+tnOwb74QvrlF/vvmTOl5csbJh8AAAAAUEuCq0+CRi34wEj0nhr53NzK02ZmShddVPoTdVL1gbzL5TuA3t690sqV0qmnSpZ1eHkuLi7fcqA20h5szRppxAj77y++KG3Wf/DDjvqUni5t2iQNGNBweQAAAADg16iR93cHgtyY7/ZLbreUkVF52rfekt57T9q5s3RaZmbl6efNk5o1k6ZNK512yinS8OHS//5nv1+0SHrzzarzWFDg+/6EE6pO77F7t5SUJF19dc3SH+ybb0r/Xrbs8NZR2/r2lQYObDz5AQAAAOB3COT9XXCZ34afOVP6/fdDW75zZ3v0+mOOkf7xD995Z55p1/CXne7p637TTVJ+vjRsmDRmjLRkSeXbWLTI9/3y5XZNe1XWrpUSE+0WAK+9VnXajz6Snnmm/PT09NK/9+2reh31IT9f2rbN/vvLLytPZ4x0223SpEn1k6+6smlTabeGxiorS9qzp6FzAQAAABwSAnk/Z4WUaXb+2GN2rfyh6tNH+u036f/9P2nCBLvG+K+/Sufv2ye98YZvM/zMTDvY9Dg4WP/+eyk+Xjr9dGnixPLbPLiWXrKb/L/+uj1A37HH+s6rLPDftUsaPVq64w5p/Xpp/nypUydp4ULfQH737tK/f/7Z3saff1a8zrpS9uf+oqLs/wsLyx+Ln36Snn1WevxxKS+v/vLnsWuXdNJJdguOw1VcbD8k6t5dWr360Jevj+4PbrfUvr19vjTEcQYAAAAOE4G8vwspUyN/qLXxFZk+3f6d+Rtv9J0+bpx03HG+0/7979K/f/vNd96pp0r790uffmoHpgc7OHjNypJOPFEaP963Kb/HNdfYQfr27Xbt+6232v+fdFJpmi1b7Gb/v/8unXeebxeCzZtL/+7Rw95GaqodUP/6q92iYOZMu2tC2QECJfv9iy9KO3bYNeoXXSQtXixNmSKtWFGaLj1devfd8g9T9uyxa+B//rl02t699vE59lg7kMzIkDZskIYMkXr18l22rN9/t/Nwzz3SpZdKaWm+84uLy/+k4LvvSjffbAfmmZl2y4B777XL5ZdfpOxs3/R33213S7jiCjvfxtgPZn79VTV2/vmlf/fuXfq3y1V+e5J9zFavth8WnXGGFBEhLV1a8+1J9kOR8ePtcrnqKrtFgGTnv6IHQRs32g+psrKkP/6oet01fbDgKfvs7MofquXm2sf4P/+xH5517lx9i5G1a6UHHrDXu2mT9MordjlWJj+/4QaY3LZNOvdcu0VJfQ2m2VjMnSu9/HL16XbtknJy6j4/qFhFD5IPV0mJ3dXM09qqOjt32veqw7Fnj/Txxw07zktNFRWV/ywNJC7X4VWsBJrqWmc2FLfbP64zwKCczMxMI8lkZmY2dFaqlfX2w8bYt5uGfR1/vDE7dxpTUmLMhx+Wn9+tm+/7e+4xZvt2eycmTWrYvA8c6Ps+OtqYnj2NiYkxZtw4Y266qerl8/ON2bev9H1ysjFvvmlMaGj59ZZ9//TT1edtwABjnE7776ioyvM/YkTp+06djPn2WztPX31V9foty07/+efG3HyzMYMHV53+ttuM+fVXY5KS7PcrVxrz0kvGPPigvT9ffGHMpZeWX659e2MuuMCYuDh7P95+2z5uDz1kzN13G3PJJRVvb8sWYwoKjPl//8+Y8ePtfdq715jvvjPmrruMOfdcY/7v/4yZM8eYG27wXbZ7d2N+/92YFi3sY/joo/b+3nefMXl5vmmTkoxZtszOz6WX2vmZMsWYF1805uKLjYmIMObKK+08e/z5pzGzZhnzcCXX4DnnGON2G+NyGfP993aen3zSPoYVpb/kEmP+/W9jfvqpdNqDD9rH2PP+rruMOemk0veXX27MVVfZ198FFxgzcaIxF15oTMeO9vzffjPmlVeMuf56O++bNhmzbp0xP/9szJAhdpo+fYwZNMiYN94w5rTT7Gl9+9rnxLRpxoSF2dNeesmYzZuN+fJLYxYtMub++32PR3Gxvb+tW5fmr0sXe78//dR+P2GCneb33405+WT79eef9vJpacYsWGDM8uXGvPWWMZmZxsycaR9fl8te/+TJdpnv2VP+ZlhUZJ8rxtjzS0qMmT3bLv8XX7T374EH7GvjjjuMWbjQTp+XZ5eVZMy999rb+usve31//WVfFwsX2svPmGHnv6ySEmO++cb3nOrZ05jXXzdm7FhjRo405vHH7bIoKrLLICzMPv4LF9r3mFWr7Hkec+bY6zn9dDu/nv0tLravgbJyc41Zs8Yu07lz7TIyxt7eNdcY07atvX8jRtj7u3KlMa++am93yBBjPv7YLuu0NHs5t9uYtWvt8+jCC+2yNsaY7GxjNmwwZvp0Y/73P/t+/7e/GfPee8ZMnWpfh57jdMMNdll9/bUxL79sTGGhfTx+/dWYFSt8j+FLLxnzyCP2tF27jHntNXs9xtj///57adp9++y8Bgcbc/XVdll5jsvEica8/77vsXnhBWM++si+tr/5xp7297/bx/ayy4x57jl7uwsXGtO7t32sPWU6fbpdVk8+aUz//qXnhMtl3+vati1/DU+dal9rX3xhr6Ps9ZGTY9/PJWOuu843n5s2GfOvf9n3wq++spctLraX//RTe9mSktJr68or7XPq559Npb791s5Lerp9bhYWlp4va9f6pi0utte/YYNdRpXJyrLLoLDQPl/+9S9j5s2zr9V9++xlv/vOvkd37156H3z+eXsf33rLvmf+4x/GDB1qpysstJf973/tZT3y8+1zY9Ei+/N01y67LDdtsvPrctnn1L/+Zcyzz9rne26unfaaa4zZts1ez5499jWxbp393u227zFz5pRO27jRvrZ37LDPlT17jFmyxN7Wzz/b26vODz8YM2yYfZ5lZxuTmmrv/zff2Pe42bPt62/cOGOeeMI+ZmWv+cJCez+efbb0fBo3zj42X35p7+v+/fY5NnNm6XLvvWfMLbfY5bx2rX1sf/rJLs8ffrC3sW6db5m73fY+vfyy/ZmSkWGv/9NP7fU89JB9r1y0yF6PMfb1fdZZ9nH5/ntjLrrInp+WZn+Xe+45+++D748excXG/PKL77GcPdv+bP7f/0rLYdcuuxw83w899u61y/yXX4x59117WkmJnfd9+4z54w87D//4h70P+/bZ5/3y5cYsXmzv/80329893nrLvp5vvdWYyEhj/vMfY8aMsfdp+XI7nacMVqwovy+efdy/387L7Nn2fW/v3srPD7fbfpWU2N8tPvjA3t/Nm+17cGys/Xl7sB07jJk/3z63P/3Udxs5Oca8807pte12G7N+vf05+uij9j3qlVdK87pvX/nyycmxj8/mzfa1M316aZl7PPigva5ly+x8lz1v3W47jzt2lN6P9+8v/Vw3xr6Wi4vt+8fnn9v3pldftct93z67zD2+/NI+fw9WUOD7uZ+Zab//4gv7Xjh/vv3/v/9t3zfmzzdm6dLStAd/bjZyhxKHqh7y43f8KZDP/vf9dRvk1tbr1lsrD3YaOm+18erZs+HzwKv+Xk6nHdxXl65Ll4bPa1N93XWXHdDcf7/vl9+6foWEGHPFFcY89pgxxxzT8MehPl6VPXw6ktcJJxjTsmX16WJj7WDtkUcqnn/qqeXfh4cbExRUPm1F0xISfN97HpxW9mrR4tD2s6JtSvbDs8GDSx+oHe6rWTP7QWnZfA8fXv1yoaEVP3SVjDn22IofVNTX66ijamc9KSnVpwkOrj5NeLgxnTuXPkzv1s0Oxp59tvz5c6iv5OTDWy411Q7YDnW5YcOMad780Ja54opD386tt9oPmCs6xp4HzWVfFV1XRx9tr8fzMLmhXrGxpX936GB/BlSUrlUr+0Hcxx+XXveDB9sPPA91m9Vdf4mJNV/XJZf4HsNzzrEfUJ5wwuEfk3PPLX99de9uP6DzvO/Ro3yFVk1fnuPXt6/94LPsPM9DskN9PfSQ/eDm1VcbKmSrsUOJQy1jjGnYNgGNT1ZWlmJjY5WZmamYmJiGzk6V8p65WxF3PFW/G332WbtpuyRde6306qvVL/P663bz/Jp6+mnpzjvtvyMi6MMMAGgcmjWzf33l//6voXMCADhUeXlSeHhD56JShxKH0kfez7nbtvKdUNdfLI49VurYsfR92f7cZT36qO9o9wf3r69O2Z+ou/VW+3na3Ln2QHzduh3auqoyenTp38OHH9m6LrvM7qd/uA4e4M/j0ksPf51V6dGj/LTx48v3YT/11LrZ/sH69q2f7RyKcePs8QjKjsVwsAEDDn29/ftXPb+mDxDj4qSvv5aOOsrul15TXbtKzZuXn/755/Z4EbNm2QMVVqZbN/tXJSqTkiI9VeYB4+DBNctXRITUqpX9axiVadvW3t/zz7fHcWjWrGbrlioeePOFF3wH7qwPt94qnXWWXX733FPz5R58UBo06Mi3fyjHLCKi+jQdO9qDc5b18MPSOef4nmdnnlnz7daXs8+2/580STr66OrTP/+8Pf7Exx/b115diYqSrrzS/lUWj7ZtfT+z6oPDYY/jUpEzzqh8uY4d7V+o2bDB/lUcjxNPlK6/vvby5ym/Q3HUUbW3/TZtpMsvP7RlqvtMbd7cHsehonv6weMXHa6RI6VHHrHPsYgIKTZWGjrUvh8eXK41+W507rl22XokJBxafmpy7VWmTRupXbuq0wQF+Z6Hh+rMM+2xbSq7/7Zte/jrrk0pKeWnWVbdbS8ysu7WfShOO01KTq5Z2rCwI/uu3tjUefsAP+RPTetzsn/1bTpiTN02McrKsvsTet6/917F6dassZueHXifm7OhfJoRI+wmPp7+1q+9VjovM9OY1avtvpYZGeV3vLLmiof6Gjeu9G+3u3w/9LL9ru++2+5b5Xl//PF2357u3e0mvp6+R3Pm2E1G//Y3u8/RxReXLvPvf/uuf9Ysu3njfff5lt2pp9r9XT39ySrK++zZdj/Vxx+3+39VlMbTBGnUqNJpn39eehyvuqp0+s6dpX2cPNM6drTf793ru94JE+y+1X37+k7/4Qe7j9aPP9r92//zH7tv3Usvlaa59FJjnnmm9P1pp5Xmp7DQ7k9Zdp0Hb9vzCgmxt7dmjf33yJF2P/GD0z3yiDF33mn/fcYZdv+vH3805sYb7X5xnnRXXGH3qfK8v+qq0nx5+tFmZ9vbS0015tprS8vnjjt8t3nHHXYfP09/XM/r2GPtfZw/v3w+162zX9dfb8zu3fZ5dNxxdr/VrCy7SeRTT9l9+Mpef2WtWmWfC+HhdtPdzEz7/bff2ukvucTuv+bhWU9ysjFbt5a/zrZs8c3jN9/YzTlzc+35v/1mN+m96KLScrvggtL+gPPn28fMGLuf3KJFdnk8/7x9HP7xD/s+4enb7lFSYjddnzvX7mt91VV2X8SK+l9mZpbmZ8MGux/yQw+Vb3r4/fely2zaVDrd04/5hx/sPnvff2/nKT/fd/ktW3y3/+uvvv1OXS57/s6d9rwPPrD/f+opu//gK6/Y51hFnytFRXZfv7Vr7etjyBC7zDMySsdZqGjf9+0r7ftX9l68bp2d/o03yp9nnvW43fY5LNnNhrOz7fP2lVfscU6ee84+V9xuu//p8cfb/UuNsfP1zDN238qMjNI+3D/+aPdb/OWX0jzm5tpNTT3Xyt699j1x8uTSc+bkk0v7ZZaU2OvLy7OXXb/e7j/966/2e8/5m51t9+G/5BJjPvnEPpcGDPDtm/ncc/Y1N2yYvZ158+z1ecZseeKJ8sfz3ntLrznPuj7/3L7mP/20fBmsWGE3t731Vvv62LHD/lzo2dOY0aPtfd+7174277vPLuNrrrHvjevX28f3m2/sc9bzuXhwn+xNm3w/B9PSjPnnP32v37LXUG6uvc2JE+17yM6d9lgDeXl2P3PJ/tzdu9detzH2vCeesM9zl6vi8/S33+xz4Jxz7GObnm5flw8+aC/jctnn4Rdf+J6vnvECsrLs9263fV2kptrXREGB3WfZGPu+8OOPpcexT5/y49R4vlucd17pvebNN41p186+Pw4dao8v8eefdj/kl17yHa/AGPuzPzzcLo8VK+yxRz7+uLS/8YQJ9ufKihV23/1hw+zP5ZUr7c/tVavs4+HZz1Wr7Dx16OB7Ld5zj52HX3+198tj4UL7OG7fbi/bqZOdPiWl9H5mjF1uF11kL1v2GvL0a1+2rPT+MGeOXdaFhfaxTk+3y9FznUt23+my98LKjBhhN8Hfvdt+f+KJpes44QR72x99ZDefXrWq4nVkZdljDxx3nP19LiPDPhdWrbLzumeP/Tnl+az97jv7u8ojj9j3oe+/t6/36dPt7SYm2scyL8/u1tCxo/29MS+v9Dwwxs5XcHDpmBmFhaX3lz//tMvZGDs/GzbYx9jptO9L06bZ4xnNnGl/NxkzpvznkzH2+lassD/vTj/d3pfp0+3xfHJz7c/TG26wx2qYMsW+9vfsscvQcxyffNLuj5+YWDqmw88/l/ZBLymxz7elS+3zdf16+974/vul58iiRfb1tnx56fc3Y+x7+JQp9jXkOfcfesjuCnLFFfZ58OCD9jg777xjn8t3312at3PPtc8zz9g3c+bY12jZ+868eXZePe/POMM+X7Zutb8TDx5s30+MsddV9vumZJ+bO3fanwXTptmfezfcYJ8zN91k588zfsxNN9lN7Lds8R2T6vjjffe7uNg+j4KCSo+5222fL++/bx/fg8cAaIToI3+E/CmQLykpMvv6WN6Teu3acysOemrrZYx9kXjef/aZ7/zeve0vxMbYg2ckJhpz//1m5coh5dd1662lO5KTY///8cf2zaE6ZfssSXafujlzSgeJqu7Vv7/dT6Zs31pjfD+sXnzRvuBffNH+cPHk8Zdf7A+lmrrsMt8v0Qcfz7I80++/33f6hAn2h4tngJSDuVzl9zEhwTfNF1/Yg9uUlZ5u39TLDjJkjD3A2EUX+Q5qMn++PVjcww+XTsvMLA0SHY7Kb5AvvliaL8+Xkb/+sgNdzxcFj5dfLk3recDx1FP2B6SnvC65xHcZz4eNMfYXDMlOu2NH6fZycsoHQ/n59nEp+0FdUmIHKBV9eFclI8PebkyM73YWLSofRGVmlu9jfyj+8x/7nCj7AVZWRftaEc+2r7yy8jRz59rX29/+Vv368vIqz1N927rV90uHZxA4jxdesL+QV+XTT+1zraJrrjEqLCw/4JLLZX8BHDnSPq8bm+zsuv9i5Xbb52ZjVzaAq6nMzIqD7qosW+b7QM8fLF5sBwaegc48D1sOV2UPKzwKC8t/NlVn/37fBy41uQeX5Xl4V9vy8uyHUTUZtM+jsND3fExPt4PDhrq/l5TU7bYzM+svwPvmG/u7jeehkT9xu+3vBGU/Z3btsr+3H8p3jilTjiwfnkEWK5Ob6xcBe2UI5I+QPwXyxhiz76TS0dAXLpRZ+7BMYaxMztO3H37A/umn5YPixx6zN1h2VG1PEOd5HTzi7YELe8mSKLPi5YO28eKLh7/TZWvOPU8yjbG/oFSwPyWnlxnV/YILStMXFdmj5ntGSd60yQ5gKxqp9HCVGVAoO3uNKex+oJa8U6fyaT/91A6qPLWYZVX3IXb++XYt0N69ds2Kp6alNlX2JWP79tIalYp4aitqErCuWFF52uJieyTsw/nCWx/S0sp/QXa77QcWn3ziO33vXmPatDm8QL62LF5sj6xe0SjwTYHbbdeoXHjhoX+pBgAAtWf+fLtm3VMxhgox2N0R8qfB7iRp3f+doDY3L1XG1cdp44k/2BONFLpfGnR++fR/nSolLqhmpW63THaWrNg4+/1nn0kjRmjLloe0e+nj6ne5/Tu8f35ynVqf/oqdJjbW/j30g2Rnr9SPP9r9n4eW7fpaVCSFhHjfGuOWZMmyLOXk/KSNG29Shw5PKjZ2YPn8/e9/dr+0qVOVeftpKir6Sy1bnmvn+7JLZR11tHaeXKCWZ/1dITnS3sdHq/m9c+xlL79cJa//R0FBYdUchFpyySXSO+9IkhYtlMJ2ST2/GKHw+5+vtO9hcXGmLCtYQUGH2P/ImLrtD3UISkrsAQqDgg70sV20yO7L1qFD9Qt//rnUvn3t9mWsgMu1T8aUKDS0ZZ1up1IzZ9p9FM8/X3r//YbJAwAAABqFQ4lDg+spT6hDpkMbrZi5VNIPpRMtyV1J6a67v3wg/9t7x8v6foWOPjA+3Z70D7X9j7+rz4H5hcV7lLvvc23ZMlWhoaXL/Zn5ilp73pQZ3GTfvs/1008jK89zm9ayDgTxhYU7ZYxLGzZcr/37v1JQUKSKi/dLklatsgcWSU29W2FhHRUTM0AZGV+pqP9fil77vKI7nK5Vy+3AsE+f5crLW6/frn9XnTr9Szk5q7VluhSzTioYtkWeIZfSMz/Tz1+HKzZ2sGJjT1Lr1rfI4YhQVtZShYW1V0TEUXK59isoKEIOh9POr3HLshzKz9+i9PTZSki4VEVFaQoP76jg4FhJUkHBVu3fv0CJiWNkjFs5OasUHByrCHeJyobWBcnSzgd6qH37tvpr12tyOMLUrNlwFRWlKS3tdeXnb9K+ffPkdKaqX7/fVFT0lxyOMAUHxykra5mCgqKUl/eb4uNPV0hInHe9Ltdeud2FcjgifKbv379Ikltud4EiI7srJKSltm9/Ui1bXqCiot0KCWmpqKjuMsbI7c7zHguns60KC7cqJmaQMjOXyO12KS5usByOUBUUbFVISIKCgioe9TMnZ41++KGXJKlVq1vUvv2jsk7qL8tyKCfre0VHHyfLCjpwbI0ko4KCrQoLa6vt2/+u7NYr1bnds/Kcap40luU7Pqfb7ZLDEeJNs2vXq4qI6CaXK13Nm58uhyNUxcU5crvzFRraUiUl+XI4wmRZlvLzt2jlyv4yxqUBAzZ7y7EiRUV/KTg4zns+lFX2WWh+/iaFhDSXy5WusLAOcjjKX4TGuLVr12sKCopUxHk9lZNyu5oNuFnOA+eYvV9FKizcqbCwtrIsSwUF27R37zwlJ1+joqId2rdvvpo1O1lhYe1lWZaKivbIsoJkWUFyuwtlTImKinYqOrpvpceuqChdbneBwsJay+Xar+DgWLndhSopyZVlORQSEi/Jfqjkcu2X09nKe6w9+21V8NCosHCHtmyZqujo45SUNMF7DEpKCmRZDjkcodWuozJut0tud76Cg2v+gNXl2qfg4GayLKvK7bndLllWcLn5bnfxgWNbfT5LSvJlTLGCg6OrXNbtLq7w3KhtbnehJMvnmHt4zttDOf6NWU3PJfva2C2nM7ncdM89yXe6W8a4Krz2S0py5XBEKDt7ucLDj/a571bGvgc5y12PNVFYuEsZGYvUsuWF9XL+HAm32yVjiiv9jGjqXK59sqwQ773gUJSU5KqkJF8hIc2bzPXpb4qLsxQUFM3xR6NHjXwF/K1G/rffrlRa2szyM9zScVdLVokU8adkue3JixZKURuk464rTbpooZTwpdT10dL3MtLQk+33q/8pZfSy/w7JkE44MJjq0tmltf55qdKOL289EIh+4pOVoKBYlZRkemvk81Oknz7orNTUu7Rx480ypvgIj0L1PNvecLu085zaW29ERBe1aHGutm2b5p0WGpqsoqJdkqROz0qtP7SnL1pYupzDESG3+8h+Vi88/Gjl568vN92ynAoLa6P8/I1HtP66YlmhMqao2nROZ6osK1gFBZslScHBcSouzvBJU9kxqEx4eCdFRh6r9PQPqkzncITL7c73mWY/TDpeQUHRKi7O1J4971a5jvbt/6Y9e95XTs6qGuWtov2rOYck90Hriz+wPrf3YVBRUdohrNOSVPoRERLSQi5XuoKDm6u4eK8iIroqOvo4BQc3U3HxXpWU5Co9/UOfNcTFDVVm5lJvebdocb4KCrYoJ+dHb5rExLHavXuWjCmRVKKIiGMUGdldhYXbDzwU6aiiojTl5q6V5FZc3DDFxQ078PChQJYVrPT0ucrJWa34+JFyudIVFdVD6elzVFCwRZIUGpokKUhFRTu82w0NbaXo6OO0d2/pyOBOZ2sZU6yQkASVlOSqoOB3n/1p2/YBhYQkyrIcKi7OUHr6XOXnb1B8/Onas+ddGeMqfxQtpywrWCEhzRUR0UX793+h4OBmkhwqLt7rTRcV1VehoUnat2+ez/JBQdFyOMIVFzdExcVZKi7eq9DQFBUW7vAeg+LifcrL+03h4UcpOrqvsrK+V0HBHz7rSU6+Ri7XHqWnzymXx7i4oSouzpJlOZSd/aO33Js3P0dxcSfp99/vUWRktwNlUCoi4hgFBUWrpCRbeXnrvNdNeHgnFRRsU0TEMQf2IUL5+RsVFdVboaEpiorqqfz8jdq586UDebtahYU7lJ+/SUVFfykubpjy8n5RfPzpiokZIJdrt3bvnqWsrO/KHK9eio4+Ti7XPqWnfyDLClG7dlNVVJQmY1zaufPlA3nsory839Sq1S3aseO5g8pzivbt+0TZ2T+oZcsLZFkhsqwQ7d//uSIje6ikJE85OavUsuX5KijYpvDwjsrMXKL8/E3ljqGHfZ/oJ4fDqYiIbkpP/1BZWUu985s3P1sJCRcrP/8PFRWlqahop/bu/dj7OdiixfnKzv5eERHdVFSUptDQJDmdrZSWNv2gY99VzZqdLMsKkeRQXt46SW41azZc+/Z9qqys7xUXN1j5+ZsVFBShyMjuKinJUV7eBiUmXqbg4HhlZX2rnJyfZFkOuVzpKijYojZtJqmkJFsZGV+rRYvRBx5khCkj4yuFhibJ4QhTSUme8vLWqaBgi5KSrpTLla49e2bLmMIKjoglp7O1Cgu3y+lMVWHh9gPl11slJTmKjOym9PQ5iorqq+DgGLVocY7y8tZ7zw2nM1WhoUnKz/9D4eEd5XLtUVzcySos3KqcnDVyufYoOfk6lZRkavfuWZKkVq1uU1BQlLKzv5fLtV85OT8qIeFSuVz7VFy8X8XFmXI6UxQV1Vv793+p3Nw1Cg1tJZfrL4WEJCg+3q6IyMtbr7i4IQoNTZAxJXK7CxQamiKns7Xc7nylp38oY0q0b9/ncrn+UmLiFQceuHzp3feEhEuVl7debne+8vJ+lcMRoRYtzpbLtVfNmp0ml2uPcnN/1r59n5Y7cuHhRys4OFYu114FBUXK5dojhyNMyclXKzn5am3YcIPS0z9QdPTxkixlZy9XUtIEOZ0p2r79aUVF9ZDDEam8vHVKTp6gsLD2ys/fpJKSXKWlTZcxxYqNHaz9+z9XREQ3OZ0p2r9/vnf7SUlXKi7uZO3e/b9y+bMsp0JDExUd3Vdud6FiYweppCRXbneRoqN7y+Xar+zs7xUefrSysr5VQcF2OZ2tlJJyvfbt+1x5eb8oM/MbxcQMVGLiGOXm/qTMzKWKiRmokpIsxcWdrNDQBLlc6dq581WFhrZUVtZ3Ki7OVkLChbKsUOXkrFFMTD9lZX2nnJxVcjrbKD5+pNzuPIWEtFRm5jdyOlspL2/9gevDFh8/Snl5G1RQ8Luiovp6P49iY09STs5PKinJlCQFBzdX+/aPKigoXEVFf8npbKPMzMWSgmRZwdqz5z0VFe1Us2anKj7+dCUljVN+/kbl5a1XZuY3iosbIqezrbZtmyaHI1wOR4h2756l0NBkhYd3VFhYB+XnbzxQSROt1q3vUHBwzIHPn2zt3PmyXK49iozsqZKSLEVEHCOns7UiIo5SUFCs0tJmqlmzUxUUFKXc3DXavv2fcjpTvNdYZOSx6tDhMblc+5SdvUKWFaKWLc8/8ICyWGlp01VU9Jeio/to9+53FBzcTMnJV0nyPAh2aO/eucrIWKiWLS9UaGiK4uJOUkhIggoLtys391cVF+9VcXGmUlJulMMRouzsH5Wbu1axsUNUUPC7jCmW09lGGRkLZVkhKipKU2HhNkVHH6fQ0BTl5f2qZs2GS3Jr377PFR7eUUlJ4yUFyRiXiov3KS3tv7Ish1q0OEfBwXHau/cTuVx7ZUyxcnPXKCgoRsYUKSgoWnl56xQR0U3R0X0UHz9K+/d/qcjIbmre/Azt3z9fcXFDq6y4aQwOJQ4lkK+AvwXyP/98nvfLc6dO/9KmTbeVziyxv4qfNEJylNiTPMHk8VdKkVtKp1lF0rH3SpnHSlvG29MHD5ccLumbuVKx58Gy217WckvLZ0pDD/ySSl6qtPyNivPYsePT+v33O73BdG47acWMI971QxK1UYpbJf15vqTyFS91JjhTOmaalDZS2jO0/rYLAAAAwBYV1Uu9en2t4OCohs5Kpfgd+QBTtjlg69a3Kjn5Wkn2k0UFSSZIsip6XHPQNBMqrXm6NIiXpG/nSN9+UBrEd+s2Wz17f6kfpksrZkpde7xX4fo6dnxaLVte5H2fnDxBkrT+bqmombRuUtX7NGDAFrVt+6CkIPXo8anatLlXycnXqkWL0UpMvKLqhSuR01n68yL5BPH2Uz9bq1a3HNZ6bZZSUm7SMce8WW5Ocay09nE7iPeUjUdQkH0jCQ1NUXz8qHLrDAqKVUxMBWME1IK4uJPLTWvd+k4de+x8n2nx8afX6nYdjvL9/mNiBqpFi/MqWaLypy5OZ+tK53mXDvK9CXpqCGsiMXGc2radotat76o0zaGszyMqqlclc+xbcnR0v0qXjYzs4f07JCRR3bvPUULCpUpOvq7C9HZtna9mzUYoIqKLz7SIiG5q3/5RtW8/Tamp96h587NU2UdEs2anKiKia6V5jI8fpW7dPvRu/+BtVSQ0tJUku/atsv0PDz9a4eFHq3nzs5SUdJVatrxYUVF9FBnZs9r1S1JCwmUKDfX9nd1WrW5VXNwpNVpess/V8PDyYzc4HDVrQhwR0UXNm5+j+PiRiow8VuHh1f9+sl2TE6mWLS9WWFi7g+cqLKx9jbbtERzcXA5HRLlpFXE621S7PqczVS1a+A7Ikpp6t+Ljz1BwcLyCg+1uGjUtp+DguAMtFkpVdB5XJiqqt8LDO9cobbNmpyk6ut+Be5DvPgQFRZe7x7RqdZu6d5+rXr2+Vmrq3RWu0+E48vFXHI4wNW9+ltq1e8h7/Dx5qoplORUe3rnceRIamqSQkPK/7V3R+jznckhIouLjT1d8/BkKC+tYLl1UVO9K8xESkqC2bR9UfPwon3MoMrJ7je7bNXVwmZVV/pyx72dlj2dFDr42qhIeflS5z/XqhIQkVpsmNfXuCq4BZ4VleDhCQ5MUFdVLwcFx3ntiUFC0kpKuVFiY7zg2sbEnVrQKH5GRPRQZ2UPBwXGSVMF9qmqVnUtBQTWrOS3//cnXoeanLIcjUmFh7Q9cVxWP8RMS0sJ7LVV1/Xu+89WVgz/fDmz1sNfndKZWOs+yQuV0tj3sdTeUnJzV5Vra+TNq5CvgbzXyeXnr9dNPI5Wa+v/UqtWNKinJV2bmEoWFtdPy5fYX6L7XStEbpRKn9PVn9nKps6SOr0iZXaVVL/iuMzn5WhlTorS017zTWrW6VZ07/0s5OT/phx/sL2R9+nynmNgBdj5aS8v/K7Vv/6jatr1fLleG1q27VC1bXqzk5PHaufNVbdhwnR3wW3awHxqaqKioPpLciog45kBTZYcSEi6UVHlf0mXL2qqwcJu9H6n/Tw5HhBISLlRm5lJt2FD9h2pq6t1q3vxsOZ2t9OOP/ZSYeIU6d35G6ekf6+efz1Zy8jWKjj5eyclXKz19jjIzl6hDhydlWcHavv0fys5erk6d/iWnM0X5+ZtlWUEKC7O/rBhTotzcXxUZ2U2S0S+/XORtxj14cKFWrz5ZWVnfKjz8aPXrt05ud74sK1gOR6g2b56inTtfUp8+38npTPX2Sd6y5SHt2fO+oqP7y+lspdTUu3z6CRtj9O23LVRcvE+xsUOUnf2DOnZ8UrGxJygkJEEhIS2Unv6h8vM3qU2bSd5+XwUF27V+/dVKTb1T8fEjvOvbsOEm7dv3uXr2nK/w8PYH0m7Thg03KjX1DkVF9VVJSbYkKTt7hXbtek3BwbE65pi3yvUpM8YoO3uFVq7sL0kaNOgvORwRKizcqszMb5SQcLnPk9HMzGXesRG6dn1PCQkX6K+/Zqm4eK9iY4fo118vVmLiGCUkXKKwsFRZVpAyMr5RZGRXlZTkKidntbZte0ypqf9PYWHtDpSDpT173lN8/BkKCYmT212sgoLf5XSmKj19riIjuyoysocsy1Jh4U7t3fuJEhIurLD5lTFGGRmLFBMzwNv/s7g4S4WFf2rbtmkKDo5Tu3ZTFRwcL7c7X4WFf2r16iEqKclR//5/KDS0pdzuIv3yywXau/dj73qHDjUyxhxovpckt9ul3NxfFBXV05uv4OBmCgoK119/vaXs7JXq2PHJCvv17t//1YEvHanevsPZ2asVGpogp7P0g/6PP+7Xtm2Pq3fvbyoeVFL2eBcbN96s1q1vV6tWN/mMSyBJWVnfKzQ0WaGhKdq//3OFhx+liAg7iHK7iw7qE+9WSUmejClScHAzuVy7ZUyJT5487GbjzVVY+KccjlDv9VWdnJy1cjpTVFycob1752n79qckudWv3/rSgRclpaX9V8HBsWrR4uwDeSs50LQ5SC5XupzOJO3fv1B//vmMWre+Tc2a+T74qmzsAc+67Cb/ISoq2q2wsNZyu4tUXJyh0NCKv4h7PooLC3dIKlFYWOVfkCrqD+52Fx1o+mqpefOzZFmWSkoKDjSHTtT27U8rNfVuRUf3PmiZzxQV1VthYakqKtpz4KGBpw+3w7udvLz1CgtrV2bcELtP+cF5McbImOKDxlNw+xynzMxliozsqqCgKO3b95liYgZ6x2Qov6+V91HPy9uk4OA4hYTEq7g4U4WF2xUVdax3flFRunJyVio29gRlZCxWfPwIlZTkqajoL+Xl/arY2JMUEuIbLBUXZ5Ubg6GkJF/793+pZs1OKdfn2zOeRXBwtEJCSh+GZGYuU1hYG4WEtJTDESpjjIqLMxQcHKfc3LUKD+8ohyNcluWQMUYlJTlKT/9ALVqMLnffqai8Xa69ysz8RkVFfyksrL3i40+r4PhsUH7+RsXHn+5d3u0u0p9/PqPY2BO9D4k98woLdyo0NLHCe4q9bKFKSvJUWLhNERFd5HA4VVT0l1yufYqMPMabV2OKKiyvsrKzV6uoaJeio49XaGgLFRfneD8H3O6iA+NVOJSTs1ahoQnav/9Lbdp0uxITr1D79o9o585XFBc3RNHRfQ8cj30H7tsXKzd3rRyOCEVGdpExbrlce8sNaJqb+6uys1coMXGM7CbpPygysru3fHNzf1Vm5tdKSrpKxcX7lJ//u4xxKyamv9zuAjkcYT7jdRjj1t69/yeHw6lmzU5VevrHkoyaNTvZW55ly7GkJF+5uWsVHX38gebBPyk3d53CwtoqLu6kMmXvVnb2CkVF9SkzHow9MHBx8T4FBcV6vyO53YWyrNBy54o9bsnDio7uo5iYQQoLa1Nt0+Lc3N9UVLRLzZoNO/D+F23f/pRatBityMhjFRraUpYVrMzMbxUXN7TS+2BxcbZyclYpLm6oJHnHKjHGHj8kN/dXBQWFKzy8o9zuQuXm/nxgbIFmCg1NkMPhlMu1Tzt3viqns7USEy8/MG7MdmVkLFbz5qMUHBzvs8/FxVlKS5uhxMRx5catcLuLVVKSpZCQ+AP3lhJZVrDS0l5XdHTfA10LFig29kQVFGw50AS+4uC9uDhHublrZFkhio4+ToWFfx44p/tJMsrO/lHR0X0PdK2zFBXVS5blUHr6/2nv3o/UsePTKirapdzctWrR4jxZlnWgOXuQHI7gA/eMTDkcocrIWOIti/z8TYqIOOZA964sSQ4FBYX7XLf5+VtkWY4DXcXccjiClZ29WpmZXys6us+Brp2FcrnSFR3dRyEhLVVYuE179ryv0NBWiog4+sBYRtaB9f2u0NAklZTkaPPmyYqK6qn4+JEKC+twoNvF50pJuU7R0cerpCRHWVnfKT//DyUnT1BQULiMcWvfvk+1YcMNKizcrjZt7lebNvfK4QhTVtYyhYS0UF7erwfu54nKzf1JwcHxiorqKaczWRkZ3yg4OEYREcfImBLt3PmCdu9+V61b36oWLc5VUFDEgetCKinJ0bZt09Sy5YUKD++k4OAY7d9vN+svLt6ryMjuCg8v/2CyMaFp/RHyt0C+Mi7Xfn37rf3lKGyX1G6GtP1iqaRbRxUUbJFVUqK4VVLWMZIV21xBQVEqLNwqyQ4qSkoK9PXX9ofascd+4f2iUFi4U8uW2bVnAwZsUdq17dTuv9KaJ6Se91R9Oi1aVHqzHTy4sMJBmGoiI2Oxfv75PHXq9IySksZ4pxtjtHnzAwoLa6fo6L7Kzf1Fu3f/T8cc86a+/baFJKl16zvUqdPTla67tgc5+fXXS7399oYONSos3KmtWx9TmzYTFRZW+dPOQ1VYmHagb+qh1c7Vl337vpDTmer9wleV3bvfPdDXt1fdZ6weeD5gDv6yk5//h3777Sqlpt6tFi3ObIB8laikJPeQBo/zNy5XhiR3pYEiAACoey5XhgoKNvs8UEZ5BPJHqKkE8pL0229Xy5hi/fXXG/K0fbdr/tz65ps4b63q0KFGxcXZ+vHHPoqNHaIuXf4jqTTwHjBgu8LC7OZwbnexli1LljHFGjRot5YsCVVQnhTavJP69696cLWlS5NVVJSmlJQbdNRRLx7Rvh3qiNc7d76itLT/qkePufX6pT4vb4N+/LGfWre+Ve3bP1xv2wUAAADgP5pcH/kXX3xR7du3V1hYmPr27auvv/66yvSLFy9W3759FRYWpg4dOujll1+up5w2Pl26/EfHHDNT7dpNkWSPQCrZNYMdOjwpSYqPP0OSFBwcrX79NniDeEk6/vhf1Lv3t94gXpIcjmD1779ZAwZs9zb1KomoWV/h3r2/UYcOT3i3fSQOtcY8JeU69enzTb3XzEVEHKUTT9xLEA8AAACgVjT6Gvl33nlHY8aM0YsvvqgTTjhBr7zyiv7zn//o119/VZs25ftMbt68Wd27d9c111yj6667Tt9++61uvPFGvf322zr//MoHRSmrKdXIe7jdxcrOXnGgb0zpb6NnZS1XVNSxPn1HD1VGxtfaseM5der0TzmdrWorywAAAAAQMJpU0/r+/furT58+eumll7zTjjnmGI0ePVrTpk0rl37ixImaO3eu1q0r/b3I66+/XmvWrNGyZctqtM2mGMgDAAAAABqvJtO0vqioSD/++KOGDx/uM3348OFaunRphcssW7asXPoRI0bohx9+kMvlqnCZwsJCZWVl+bwAAAAAAGiMGnUgn56erpKSEiUm+v7mZmJiotLS0ipcJi0trcL0xcXFSk9Pr3CZadOmKTY21vtKTa29kcQBAAAAAKhNjTqQ96jod6mrGuisovQVTfeYNGmSMjMzva/t27cfYY4BAAAAAKgbwQ2dgaq0aNFCQUFB5Wrfd+/eXa7W3SMpKanC9MHBwWrevHmFyzidTjmdztrJNAAAAAAAdahR18iHhoaqb9++mj9/vs/0+fPna9CgQRUuM3DgwHLpv/jiCx133HEKCQmps7wCAAAAAFAfGnUgL0l33nmn/vOf/2j69Olat26d7rjjDm3btk3XX3+9JLtZ/NixY73pr7/+em3dulV33nmn1q1bp+nTp+u1117T3Xff3VC7AAAAAABArWnUTesl6eKLL9bevXv18MMPa9euXerevbs++eQTtW3bVpK0a9cubdu2zZu+ffv2+uSTT3THHXfohRdeUEpKip599tka/4Y8AAAAAACNWaP/HfmGwO/IAwAAAADqU5P5HXkAAAAAAOCLQB4AAAAAAD9CIA8AAAAAgB8hkAcAAAAAwI8QyAMAAAAA4EcI5AEAAAAA8CME8gAAAAAA+BECeQAAAAAA/AiBPAAAAAAAfoRAHgAAAAAAPxLc0BlojIwxkqSsrKwGzgkAAAAAIBB44k9PPFoVAvkKZGdnS5JSU1MbOCcAAAAAgECSnZ2t2NjYKtNYpibhfoBxu93auXOnoqOjZVlWQ2enUllZWUpNTdX27dsVExPT0NlBJSgn/0A5NX6UkX+gnPwD5eQfKKfGjzLyD/5STsYYZWdnKyUlRQ5H1b3gqZGvgMPhUOvWrRs6GzUWExPTqE9I2Cgn/0A5NX6UkX+gnPwD5eQfKKfGjzLyD/5QTtXVxHsw2B0AAAAAAH6EQB4AAAAAAD9CIO/HnE6npkyZIqfT2dBZQRUoJ/9AOTV+lJF/oJz8A+XkHyinxo8y8g9NsZwY7A4AAAAAAD9CjTwAAAAAAH6EQB4AAAAAAD9CIA8AAAAAgB8hkAcAAAAAwI8QyPuxF198Ue3bt1dYWJj69u2rr7/+uqGzFDCmTZum448/XtHR0UpISNDo0aO1fv16nzTjx4+XZVk+rwEDBvikKSws1C233KIWLVooMjJSZ599tv7888/63JUma+rUqeWOf1JSkne+MUZTp05VSkqKwsPDNXToUP3yyy8+66B86l67du3KlZNlWbrpppskcR01lCVLluiss85SSkqKLMvSnDlzfObX1vWzf/9+jRkzRrGxsYqNjdWYMWOUkZFRx3vXdFRVTi6XSxMnTlSPHj0UGRmplJQUjR07Vjt37vRZx9ChQ8tdY5dccolPGsrp8FV3LdXWPY4yOjLVlVNFn1OWZenvf/+7Nw3XUt2qyXfvQPtsIpD3U++8845uv/123X///Vq1apVOOukkjRo1Stu2bWvorAWExYsX66abbtJ3332n+fPnq7i4WMOHD1dubq5PupEjR2rXrl3e1yeffOIz//bbb9eHH36oWbNm6ZtvvlFOTo7OPPNMlZSU1OfuNFndunXzOf5r1671znvyySf19NNP6/nnn9eKFSuUlJSk0047TdnZ2d40lE/dW7FihU8ZzZ8/X5J04YUXetNwHdW/3Nxc9ezZU88//3yF82vr+rnsssu0evVqffbZZ/rss8+0evVqjRkzps73r6moqpzy8vK0cuVKTZ48WStXrtQHH3ygDRs26Oyzzy6X9pprrvG5xl555RWf+ZTT4avuWpJq5x5HGR2Z6sqpbPns2rVL06dPl2VZOv/8833ScS3VnZp89w64zyYDv9SvXz9z/fXX+0zr0qWLuffeexsoR4Ft9+7dRpJZvHixd9q4cePMOeecU+kyGRkZJiQkxMyaNcs7bceOHcbhcJjPPvusLrMbEKZMmWJ69uxZ4Ty3222SkpLM448/7p1WUFBgYmNjzcsvv2yMoXwaym233WY6duxo3G63MYbrqDGQZD788EPv+9q6fn799VcjyXz33XfeNMuWLTOSzG+//VbHe9X0HFxOFVm+fLmRZLZu3eqdNmTIEHPbbbdVugzlVHsqKqPauMdRRrWrJtfSOeecY04++WSfaVxL9evg796B+NlEjbwfKioq0o8//qjhw4f7TB8+fLiWLl3aQLkKbJmZmZKk+Ph4n+mLFi1SQkKCjjrqKF1zzTXavXu3d96PP/4ol8vlU44pKSnq3r075VhLNm7cqJSUFLVv316XXHKJ/vjjD0nS5s2blZaW5nPsnU6nhgwZ4j32lE/9Kyoq0ptvvqmrrrpKlmV5p3MdNS61df0sW7ZMsbGx6t+/vzfNgAEDFBsbS9nVkczMTFmWpbi4OJ/pb731llq0aKFu3brp7rvv9qm9opzq3pHe4yij+vXXX39p3rx5mjBhQrl5XEv15+Dv3oH42RTc0BnAoUtPT1dJSYkSExN9picmJiotLa2BchW4jDG68847deKJJ6p79+7e6aNGjdKFF16otm3bavPmzZo8ebJOPvlk/fjjj3I6nUpLS1NoaKiaNWvmsz7KsXb0799fb7zxho466ij99ddfevTRRzVo0CD98ssv3uNb0TW0detWSaJ8GsCcOXOUkZGh8ePHe6dxHTU+tXX9pKWlKSEhodz6ExISKLs6UFBQoHvvvVeXXXaZYmJivNMvv/xytW/fXklJSfr55581adIkrVmzxtvNhXKqW7Vxj6OM6tfrr7+u6OhonXfeeT7TuZbqT0XfvQPxs4lA3o+VrbGS7JP64GmoezfffLN++uknffPNNz7TL774Yu/f3bt313HHHae2bdtq3rx55W7+ZVGOtWPUqFHev3v06KGBAweqY8eOev31170DCR3ONUT51J3XXntNo0aNUkpKinca11HjVRvXT0XpKbva53K5dMkll8jtduvFF1/0mXfNNdd4/+7evbs6d+6s4447TitXrlSfPn0kUU51qbbucZRR/Zk+fbouv/xyhYWF+UznWqo/lX33lgLrs4mm9X6oRYsWCgoKKvdUaPfu3eWeQqFu3XLLLZo7d64WLlyo1q1bV5k2OTlZbdu21caNGyVJSUlJKioq0v79+33SUY51IzIyUj169NDGjRu9o9dXdQ1RPvVr69atWrBgga6++uoq03EdNbzaun6SkpL0119/lVv/nj17KLta5HK5dNFFF2nz5s2aP3++T218Rfr06aOQkBCfa4xyqj+Hc4+jjOrP119/rfXr11f7WSVxLdWVyr57B+JnE4G8HwoNDVXfvn29TXU85s+fr0GDBjVQrgKLMUY333yzPvjgA3311Vdq3759tcvs3btX27dvV3JysiSpb9++CgkJ8SnHXbt26eeff6Yc60BhYaHWrVun5ORkb9O3sse+qKhIixcv9h57yqd+zZgxQwkJCTrjjDOqTMd11PBq6/oZOHCgMjMztXz5cm+a77//XpmZmZRdLfEE8Rs3btSCBQvUvHnzapf55Zdf5HK5vNcY5VS/DuceRxnVn9dee019+/ZVz549q03LtVS7qvvuHZCfTfU8uB5qyaxZs0xISIh57bXXzK+//mpuv/12ExkZabZs2dLQWQsIN9xwg4mNjTWLFi0yu3bt8r7y8vKMMcZkZ2ebu+66yyxdutRs3rzZLFy40AwcONC0atXKZGVleddz/fXXm9atW5sFCxaYlStXmpNPPtn07NnTFBcXN9SuNRl33XWXWbRokfnjjz/Md999Z84880wTHR3tvUYef/xxExsbaz744AOzdu1ac+mll5rk5GTKpwGUlJSYNm3amIkTJ/pM5zpqONnZ2WbVqlVm1apVRpJ5+umnzapVq7yjndfW9TNy5Ehz7LHHmmXLlplly5aZHj16mDPPPLPe99dfVVVOLpfLnH322aZ169Zm9erVPp9VhYWFxhhjNm3aZB566CGzYsUKs3nzZjNv3jzTpUsX07t3b8qpllRVRrV5j6OMjkx19zxjjMnMzDQRERHmpZdeKrc811Ldq+67tzGB99lEIO/HXnjhBdO2bVsTGhpq+vTp4/PTZ6hbkip8zZgxwxhjTF5enhk+fLhp2bKlCQkJMW3atDHjxo0z27Zt81lPfn6+ufnmm018fLwJDw83Z555Zrk0ODwXX3yxSU5ONiEhISYlJcWcd9555pdffvHOd7vdZsqUKSYpKck4nU4zePBgs3btWp91UD714/PPPzeSzPr1632mcx01nIULF1Z4jxs3bpwxpvaun71795rLL7/cREdHm+joaHP55Zeb/fv319Ne+r+qymnz5s2VflYtXLjQGGPMtm3bzODBg018fLwJDQ01HTt2NLfeeqvZu3evz3Yop8NXVRnV5j2OMjoy1d3zjDHmlVdeMeHh4SYjI6Pc8lxLda+6797GBN5nk2WMMXVU2Q8AAAAAAGoZfeQBAAAAAPAjBPIAAAAAAPgRAnkAAAAAAPwIgTwAAAAAAH6EQB4AAAAAAD9CIA8AAAAAgB8hkAcAAAAAwI8QyAMAAAAA4EcI5AEAQIOzLEtz5sxp6GwAAOAXCOQBAAhw48ePl2VZ5V4jR45s6KwBAIAKBDd0BgAAQMMbOXKkZsyY4TPN6XQ2UG4AAEBVqJEHAAByOp1KSkryeTVr1kyS3ez9pZde0qhRoxQeHq727dvrvffe81l+7dq1OvnkkxUeHq7mzZvr2muvVU5Ojk+a6dOnq1u3bnI6nUpOTtbNN9/sMz89PV3nnnuuIiIi1LlzZ82dO7dudxoAAD9FIA8AAKo1efJknX/++VqzZo2uuOIKXXrppVq3bp0kKS8vTyNHjlSzZs20YsUKvffee1qwYIFPoP7SSy/ppptu0rXXXqu1a9dq7ty56tSpk882HnroIV100UX66aefdPrpp+vyyy/Xvn376nU/AQDwB5YxxjR0JgAAQMMZP3683nzzTYWFhflMnzhxoiZPnizLsnT99dfrpZde8s4bMGCA+vTpoxdffFH//ve/NXHiRG3fvl2RkZGSpE8++URnnXWWdu7cqcTERLVq1UpXXnmlHn300QrzYFmWHnjgAT3yyCOSpNzcXEVHR+uTTz6hrz4AAAehjzwAANCwYcN8AnVJio+P9/49cOBAn3kDBw7U6tWrJUnr1q1Tz549vUG8JJ1wwglyu91av369LMvSzp07dcopp1SZh2OPPdb7d2RkpKKjo7V79+7D3SUAAJosAnkAAKDIyMhyTd2rY1mWJMkY4/27ojTh4eE1Wl9ISEi5Zd1u9yHlCQCAQEAfeQAAUK3vvvuu3PsuXbpIkrp27arVq1crNzfXO//bb7+Vw+HQUUcdpejoaLVr105ffvllveYZAICmihp5AACgwsJCpaWl+UwLDg5WixYtJEnvvfeejjvuOJ144ol66623tHz5cr322muSpMsvv1xTpkzRuHHjNHXqVO3Zs0e33HKLxowZo8TEREnS1KlTdf311yshIUGjRo1Sdna2vv32W91yyy31u6MAADQBBPIAAECfffaZkpOTfaYdffTR+u233yTZI8rPmjVLN954o5KSkvTWW2+pa9eukqSIiAh9/vnnuu2223T88ccrIiJC559/vp5++mnvusaNG6eCggL985//1N13360WLVroggsuqL8dBACgCWHUegAAUCXLsvThhx9q9OjRDZ0VAAAg+sgDAAAAAOBXCOQBAAAAAPAj9JEHAABVohfe/2/PDkgAAAAYhPVv/RoXthYiAHxx5AEAACBEyAMAAECIkAcAAIAQIQ8AAAAhQh4AAABChDwAAACECHkAAAAIEfIAAAAQMsw1JJoLkHRGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#JJ McCauley + LOGAN KELSCH \n",
    "#TEST NN 1\n",
    "\n",
    "#IMPORT LIBRARIES-------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#hahaha dont turn this on with high epoch or else\n",
    "#tf.config.experimental.set_memory_growth\n",
    "\n",
    "#LOAD DATA FROM CSV-------------------------------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('catted_1n.csv')\n",
    "\n",
    "#testing random feature drops\n",
    "#TREND\n",
    "'''\n",
    "\n",
    "data = data.drop(columns='vel5')\n",
    "data = data.drop(columns='vel10')\n",
    "data = data.drop(columns='vel15')\n",
    "data = data.drop(columns='vel30')\n",
    "data = data.drop(columns='vel60')\n",
    "data = data.drop(columns='acc5')\n",
    "data = data.drop(columns='acc10')\n",
    "data = data.drop(columns='acc15')\n",
    "data = data.drop(columns='acc30')\n",
    "data = data.drop(columns='acc60')\n",
    "data = data.drop(columns='stoch12')\n",
    "data = data.drop(columns='stochDiff6012')\n",
    "data = data.drop(columns='RSIhl_diff')\n",
    "data = data.drop(columns='RSIhl_diffROC')\n",
    "data = data.drop(columns='YM_diff')\n",
    "data = data.drop(columns='NQ_diff')\n",
    "'''\n",
    "#PARTICIPATION\n",
    "\n",
    "\n",
    "#data = data.drop(columns='vol')\n",
    "data = data.drop(columns='vol10')\n",
    "data = data.drop(columns='vol15')\n",
    "data = data.drop(columns='vol30')\n",
    "data = data.drop(columns='vol60')\n",
    "data = data.drop(columns='volD10')\n",
    "data = data.drop(columns='volD15')\n",
    "data = data.drop(columns='volD30')\n",
    "data = data.drop(columns='volD60')\n",
    "data = data.drop(columns='volNQdiff')\n",
    "data = data.drop(columns='volYMdiff')\n",
    "data = data.drop(columns='vpm5')\n",
    "data = data.drop(columns='vpm10')\n",
    "data = data.drop(columns='vpm15')\n",
    "data = data.drop(columns='vpm30')\n",
    "data = data.drop(columns='vpm60')\n",
    "\n",
    "#CALENDAR\n",
    "\n",
    "#data = data.drop(columns='ToD')\n",
    "#data = data.drop(columns='DoW')\n",
    "#--------------------------------------\n",
    "#SOLUTION------------------------------\n",
    "data = data.drop(columns='DIR')\n",
    "#data = data.drop(columns='MOVE')\n",
    "#--------------------------------------\n",
    "#--------------------------------------\n",
    "data = data.drop(columns='FT')\n",
    "data = data.drop(columns='FT.1')\n",
    "data = data.drop(columns='FT.2')\n",
    "#TEMP DROP PRE-DUAL-OUTPUT NN\n",
    "\n",
    "#data = data.drop(columns='CLASS')\n",
    "\n",
    "\n",
    "#confirming X and Y features post training\n",
    "Xfeatures = data.columns[:-1]\n",
    "Yfeatures = data.columns[-1]\n",
    "print(\"TESTED FEATURES: \")\n",
    "print(Xfeatures)\n",
    "print(\"TESTING FOR: \")\n",
    "print(Yfeatures)\n",
    "\n",
    "#DATA OPTIMIZATION------------------------------------------------------\n",
    "\n",
    "print(\"OCCURANCES IN RAW DATA FOR \", Yfeatures, \": \", sep='')\n",
    "unique, counts = np.unique(data.iloc[:, -1].values, return_counts=True)\n",
    "print(dict(zip(unique,counts)))\n",
    "\n",
    "#filtering before splitting could be useful if ABSOLUTELY mostly comprised of 'in'\n",
    "#MARKET HOURS!\n",
    "#data = data.drop(data[data['ToD'] > 950].index)\n",
    "#data = data.drop(data[data['ToD'] < 560].index)\n",
    "#OTHER MODIFICATIONS\n",
    "#data = data.drop(data[data['feature'] condition].index)\n",
    "data = data.drop(data[data['MO'] < 1].index)\n",
    "\n",
    "#upRows = data.drop(data[data['DIR'] != 'up'].index)\n",
    "#dnRows = data.drop(data[data['DIR'] != 'dn'].index)\n",
    "mvRows = data.drop(data[data['MOVE'] != 'mv'].index)\n",
    "nmRows = data.drop(data[data['MOVE'] != 'nm'].index)\n",
    "\n",
    "smallestClass = min(mvRows.index.size, nmRows.index.size)\n",
    "#smallestClass = min(upRows.index.size, dnRows.index.size)\n",
    "print('Smallest Class Size:',smallestClass,'\\n')\n",
    "\n",
    "#upRows = upRows.iloc[0:smallestClass]\n",
    "#dnRows = dnRows.iloc[0:smallestClass]\n",
    "mvRows = mvRows.iloc[0:smallestClass]#-2500]\n",
    "nmRows = nmRows.iloc[0:smallestClass]#-2500]\n",
    "\n",
    "#optData = pd.concat([upRows, dnRows],axis=0)\n",
    "optData = pd.concat([mvRows, nmRows],axis=0)\n",
    "\n",
    "print(\"OCCURANCES IN OPT DATA FOR \", Yfeatures, \": \", sep='')\n",
    "unique, counts = np.unique(optData.iloc[:, -1].values, return_counts=True)\n",
    "print(dict(zip(unique,counts)))\n",
    "\n",
    "\n",
    "#percIn = data.size/(mvRows.size*2)\n",
    "#percNin = data.size/(nmRows.size*2)\n",
    "weight_for_0 = .5\n",
    "weight_for_1 = .5\n",
    "cw = {0: weight_for_0, 1: weight_for_1}\n",
    "classWeights = list(cw.values())\n",
    "\n",
    "#PROCESS THE DATA-------------------------------------------------------\n",
    "\n",
    "# Separate features and target\n",
    "X = optData.iloc[:, :-1].values\n",
    "y = optData.iloc[:, -1].values\n",
    "\n",
    "#SMOTE OVERSAMPLING________________\n",
    "\n",
    "#smote = SMOTE()\n",
    "#X, y = smote.fit_resample(X,y)\n",
    "#print('\\n[PRE-SPLIT] Resampled Data size:',X.size,'--',y.size)\n",
    "\n",
    "#__________________________________\n",
    "\n",
    "#Encoding data\n",
    "labelencoder = LabelBinarizer()\n",
    "y = labelencoder.fit_transform(y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# one-hot encode ? \n",
    "\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "#y_train = to_categorical(y_train, num_classes=4)\n",
    "#y_test = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "#RESAMPLED DATA- POST SPLIT---------------------------------------------------------\n",
    "\n",
    "#smote = SMOTE()\n",
    "#X_resampled, y_resampled = smote.fit_resample(X_train,y_train)\n",
    "#print('\\nResampled Data size:',X_resampled.size)\n",
    "\n",
    "#BUILD THE NEURAL NETWORK MODEL-------------------------------------------------------\n",
    "\n",
    "#CUSTOM CALLBACK FOR PRECISION RATIO TRAINING VS VALIDATION--------------------------------------------------\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "metric_ratio = tf.Variable(1.0, dtype=tf.float32, name=\"metric_ratio\")\n",
    "\n",
    "class MetricBalancingCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, metric='accuracy'):\n",
    "        super(MetricBalancingCallback, self).__init__()\n",
    "        self.metric = metric\n",
    "        self.train_metric = 0\n",
    "        self.val_metric = 0\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Based on the metric, get corresponding values from logs\n",
    "        #print(f\"\\nEpoch {epoch + 1} logs: {logs}\")\n",
    "        if self.metric == 'precision':\n",
    "            self.train_metric = logs.get('precision')\n",
    "            self.val_metric = logs.get('val_precision')\n",
    "        elif self.metric == 'recall':\n",
    "            self.train_metric = logs.get('recall')\n",
    "            self.val_metric = logs.get('val_recall')\n",
    "        elif self.metric == 'accuracy':\n",
    "            self.train_metric = logs.get('accuracy')\n",
    "            self.val_metric = logs.get('val_accuracy')\n",
    "        \n",
    "        # Optionally print the values for monitoring\n",
    "        print(f\"\\nEpoch {epoch + 1} - Train {self.metric.capitalize()}: {self.train_metric:.4f} - Val {self.metric.capitalize()}: {self.val_metric:.4f}\")\n",
    "        # Dynamically adjust the metric ratio\n",
    "        #global metric_ratio\n",
    "        if self.val_metric and self.train_metric:\n",
    "            ratio = self.train_metric / (self.val_metric + 1e-7)\n",
    "        else:\n",
    "            ratio = 1.0  # Fallback in case metrics aren't available\n",
    "\n",
    "        # Store metric_ratio globally using Keras backend\n",
    "        K.set_value(metric_ratio,ratio)\n",
    "        #K.set_value(self.metric_ratio_var, ratio)\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        # Initialize the metric_ratio variable in the backend at the beginning of training\n",
    "        self.metric_ratio_var = K.variable(1.0, name=\"metric_ratio\")\n",
    "        \n",
    "\n",
    "from keras.saving import get_custom_objects\n",
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "get_custom_objects().clear()\n",
    "@register_keras_serializable(name=\"loss_PunishReward\")\n",
    "def loss_PunishReward(y_true, y_pred):\n",
    "        \n",
    "    # Standard binary cross-entropy\n",
    "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        \n",
    "    # Define penalties for false negatives (y_true = 1, y_pred = 0)\n",
    "    false_negatives_penalty = 2.0  # Penalty for false negatives\n",
    "    false_positives_penalty = 2.0  # Penalty for false positives\n",
    "        \n",
    "    # Define reward for true positives (y_true = 1, y_pred = 1)\n",
    "    true_positives_reward = -1.0  # Negative value to reduce the loss when TP happens\n",
    "\n",
    "    # Calculate false negatives and false positives\n",
    "    false_negatives = y_true * (1 - y_pred)\n",
    "    false_positives = (1 - y_true) * y_pred\n",
    "        \n",
    "    # Calculate true positives\n",
    "    true_positives = y_true * y_pred\n",
    "        \n",
    "    # Apply penalties and rewards\n",
    "    penalties = false_negatives_penalty * false_negatives + false_positives_penalty * false_positives\n",
    "    rewards = true_positives_reward * true_positives\n",
    "        \n",
    "    # Return combined loss (penalize FNs and FPs, reward TPs)\n",
    "    return bce + penalties + rewards\n",
    "'''\n",
    "#CUSTOM LOSS 2____________________________________________________________________________________________________\n",
    "@register_keras_serializable(name=\"focal_loss\")\n",
    "def focal_loss(gamma=2.0):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - gamma: Focusing parameter that adjusts the rate at which easy examples are down-weighted.\n",
    "             Default value is 2. Higher values make the loss more focused on hard examples.\n",
    "             \n",
    "    - alpha: Class balancing factor to balance the loss for each class. Default is 0.25.\n",
    "             Adjust this to address class imbalance. Can be a scalar or a list of weights\n",
    "             per class.\n",
    "    \"\"\"\n",
    "    #gamma = 2.0\n",
    "    alpha = classWeights\n",
    " \n",
    "    @register_keras_serializable(name=\"focal_loss_fixed\")\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute the focal loss between ground truth (y_true) and predicted values (y_pred).\n",
    "        \n",
    "        Arguments:\n",
    "        - y_true: Tensor of true labels (one-hot encoded, shape = [batch_size, num_classes]).\n",
    "        - y_pred: Tensor of predicted probabilities (shape = [batch_size, num_classes]).\n",
    "        \n",
    "        Returns:\n",
    "        - loss: A scalar tensor representing the computed focal loss.\n",
    "        \"\"\"\n",
    "        # Clip predictions to prevent log(0) or division by zero\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1. - tf.keras.backend.epsilon())\n",
    "        \n",
    "        # Compute the cross-entropy loss (standard loss component)\n",
    "        cross_entropy_loss = -y_true * tf.math.log(y_pred)\n",
    "        \n",
    "        # Compute the modulating factor: (1 - p_t)^gamma\n",
    "        # where p_t is the predicted probability for the true class\n",
    "        modulating_factor = tf.pow(1. - y_pred, gamma)\n",
    "        \n",
    "        # Compute the final focal loss: alpha * modulating_factor * cross_entropy_loss\n",
    "        loss = alpha * modulating_factor * cross_entropy_loss\n",
    "        \n",
    "        # Reduce the loss along the batch dimension\n",
    "        return tf.reduce_mean(tf.reduce_sum(loss, axis=-1))\n",
    "    \n",
    "    return focal_loss_fixed\n",
    "#CUSTOM LOSS 3_____________________________________________________________________________________________\n",
    "@register_keras_serializable(name=\"weighted_rec_pre_loss\")\n",
    "def weighted_rec_pre_loss(func='wr',weight=5.0):\n",
    "    \"\"\"\n",
    "    Custom loss function to optimize for recall OR for precision.\n",
    "    func should equal wr or wp\n",
    "    for weighted recall or weighted precision\n",
    "    \"\"\"\n",
    "    @register_keras_serializable(name='wp_loss')\n",
    "    def wp_loss(y_true, y_pred):\n",
    "        # Clip predictions to prevent log(0) or division by zero\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "        # Standard binary cross-entropy\n",
    "        base_loss = -y_true * tf.math.log(y_pred) - (1 - y_true) * tf.math.log(1 - y_pred)\n",
    "        # Apply higher weight to positive samples (to penalize false negatives more)\n",
    "        loss = (1 - y_true) * weight * base_loss + y_true * base_loss\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    @register_keras_serializable(name=\"wr_loss\")\n",
    "    def wr_loss(y_true, y_pred):\n",
    "        # Clip predictions to prevent log(0) or division by zero\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "        # Standard binary cross-entropy\n",
    "        base_loss = -y_true * tf.math.log(y_pred) - (1 - y_true) * tf.math.log(1 - y_pred)\n",
    "        # Apply higher weight to positive samples (to penalize false negatives more)\n",
    "        loss = weight * y_true * base_loss + (1 - y_true) * base_loss\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(func=='wr'):\n",
    "        return wr_loss\n",
    "    else:\n",
    "        return wp_loss\n",
    "'''\n",
    "#CUSTOM LOSS 4_____________________________________________________________________________________________\n",
    "#metric_ratio = 1.0  # Initialize globally\n",
    "@register_keras_serializable(name=\"met_ratio\")\n",
    "def met_ratio(y_true, y_pred, base_weight=1.0):\n",
    "    crnt_metric_ratio = metric_ratio\n",
    "    \n",
    "    # Clip predictions to prevent log(0) or division by zero\n",
    "    y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "    \n",
    "    # Standard binary cross-entropy loss\n",
    "    base_loss = -y_true * tf.math.log(y_pred) - (1 - y_true) * tf.math.log(1 - y_pred)\n",
    "    \n",
    "    # Adjust weight using precision_ratio (balance training and validation precision)\n",
    "    adjusted_weight = base_weight / (crnt_metric_ratio + 1e-7)\n",
    "    \n",
    "    # Apply the dynamic weight to false positives\n",
    "    weighted_loss = (1 - y_true) * adjusted_weight * base_loss + y_true * base_loss\n",
    "    \n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "#END CUSTOM LOSSES__________________________________________________________________________________________\n",
    "\n",
    "#LEARNING RATES____________________________________________________________________________________________\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "lr_schedule = ExponentialDecay(\n",
    "    #good rough val to start, .25, good val to end at .0015.\n",
    "    #5k epoch should be: .25, 8565, .9995, true\n",
    "    0.2,\n",
    "    decay_steps=160,\n",
    "    decay_rate=.999,\n",
    "    staircase=True)\n",
    "\n",
    "opt1 = SGD(learning_rate=0.0001)\n",
    "opt2  = tf.keras.optimizers.Adam(clipnorm=0.01)\n",
    "opt3 = SGD(learning_rate=lr_schedule)\n",
    "\n",
    "#BUILD AND LOAD MODEL__________________________________________________________________________________________\n",
    "\n",
    "metric_callback = MetricBalancingCallback(metric='recall')\n",
    "\n",
    "def build_model():\n",
    "    model = tf.keras.Sequential([#currently 17 total features\n",
    "        tf.keras.layers.Dense(512,kernel_initializer='he_normal',kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Dropout(0.20),\n",
    "        tf.keras.layers.Dense(512,kernel_initializer='he_normal',kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Dropout(0.20),\n",
    "        tf.keras.layers.Dense(512,kernel_initializer='he_normal',kernel_regularizer=tf.keras.regularizers.l2(0.01)),#,  kernel_regularizer=tf.keras.regularizers.l2(0.05)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Dropout(0.20),\n",
    "        #tf.keras.layers.Dense(64),#, kernel_regularizer=tf.keras.regularizers.l2(0.05)),\n",
    "        #tf.keras.layers.BatchNormalization(),\n",
    "        #tf.keras.layers.Activation('leaky_relu'),\n",
    "        #tf.keras.layers.Dropout(0.04),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    #AUC=tf.keras.metrics.AUC(curve='PR')\n",
    "    met = ['precision','recall','accuracy']\n",
    "    model.compile(optimizer=opt3,\n",
    "                  loss=met_ratio\n",
    "                  ,metrics=met)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    #loaded_model = tf.keras.models.load_model('tupleTrain.keras', custom_objects={'custom_loss':custom_loss})\n",
    "    loaded_model = tf.keras.models.load_model('multi_test1.keras')\n",
    "    met = ['accuracy','precision','recall']\n",
    "    loaded_model.compile(optimizer=opt3,\n",
    "                         loss='mse'\n",
    "                         , metrics=met)\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "#TRAIN THE MODEL WITH CUSTOMIZABLE EPOCHS-------------------------------------------------------\n",
    "\n",
    "epochs = 2000\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_recall', patience=250, mode='max', restore_best_weights=True)\n",
    "\n",
    "model = build_model()\n",
    "#loaded_model = load_model()\n",
    "history = model.fit(X_train, y_train, epochs=epochs, validation_split=0.2,\\\n",
    "                    shuffle=True, verbose=1, validation_data=(X_test, y_test),\\\n",
    "                    class_weight=cw, callbacks=[metric_callback])\n",
    "\n",
    "#EVALUATE THE MODEL AND VISUALIZE RESULTS-------------------------------------------------------\n",
    "\n",
    "#_, acc = model.evaluate(X_test, y_test)\n",
    "#print(\"Accuracy = \", (acc * 100.0), \"%\")\n",
    "\n",
    "# LOSS\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, history.history['loss'], 'y', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "# ACCURACY\n",
    "plt.plot(epochs, history.history['accuracy'], 'y', label='Training acc')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r', label='Validation acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "'''\n",
    "# AUC\n",
    "plt.plot(epochs, history.history['AUC'], 'y', label='Training AUC')\n",
    "plt.plot(epochs, history.history['val_AUC'], 'r', label='Validation AUC')\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "'''\n",
    "# PRECISION\n",
    "plt.plot(epochs, history.history['precision'], 'y', label='Training Precision')\n",
    "plt.plot(epochs, history.history['val_precision'], 'r', label='Validation Precision')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "# RECALL\n",
    "plt.plot(epochs, history.history['recall'], 'y', label='Training Recall')\n",
    "plt.plot(epochs, history.history['val_recall'], 'r', label='Validation Recall')\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "# TPR\n",
    "'''\n",
    "TPR = history.history['TruePositives']/(history.history['TruePositives']+history.history['TrueNegatives'])\n",
    "val_TPR = history.history['val_TruePositives']/(history.history['val_TruePositives']+history.history['val_TrueNegatives'])\n",
    "plt.plot(epochs, TPR, 'y', label='Training TPR')\n",
    "plt.plot(epochs, val_TPR, 'r', label='Validation TPR')\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('TP Rate')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = model.predict(X_test) \n",
    "y_pred = y_pred > 0.5 # Predictions to class indices\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d',cmap='Greens')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix for Direction Classification')\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "#model.save('epoch15k.keras')\n",
    "# Load the model\n",
    "#loaded_model = tf.keras.models.load_model('my_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('dm_DIR_1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.97195556 -0.00408942 -0.39446173 -0.08356085 -0.91451578 -0.63588848\n",
      "  0.3737884  -0.13449907  0.7981276  -0.40741038 -0.45716194 -1.49270001\n",
      " -0.31298629  1.48191754 -0.01422969  0.37569669 -0.19858359 -0.74333582]\n",
      "[ 1.49217188e+00  2.66737000e-01 -2.21463041e-03  4.03728139e-01\n",
      "  1.04248556e-01  3.07783903e-01  3.73788401e-01  1.46388686e-03\n",
      "  2.87053937e-01 -1.67196904e-01  5.67684603e-01  1.13792970e+00\n",
      "  1.45646971e+00  6.71344374e-01 -9.47560007e-02  1.81155898e-01\n",
      "  2.10342354e-01 -2.54478876e-01]\n",
      "[ 0.3955989  -0.9519819   0.39003247  0.40372814  0.78342478  1.25145629\n",
      " -1.60516561  0.2733898  -0.22401973 -0.40741038  1.25091563  0.81992649\n",
      "  0.98172568  0.11667741  0.06456486  0.1811559   0.21034235 -0.29300947]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])\n",
    "print(X_test[1])\n",
    "print(X_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d',cmap='Greens')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix for Volatility Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dn' 'up']\n",
      "['nm' 'mv']\n"
     ]
    }
   ],
   "source": [
    "data2 = pd.read_csv('catted_1.csv')\n",
    "print(data2['DIR'].unique())\n",
    "print(data2['MOVE'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
