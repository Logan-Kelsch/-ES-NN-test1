{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTED FEATURES: \n",
      "Index(['vel5', 'vel10', 'vel15', 'vel30', 'vel60', 'acc5', 'acc10', 'acc15',\n",
      "       'acc30', 'acc60', 'stoch12', 'stochDiff6012', 'RSIhl_diff',\n",
      "       'RSIhl_diffROC', 'YM_diff', 'NQ_diff', 'vol', 'vol10', 'vol15', 'vol30',\n",
      "       'vol60', 'volD10', 'volD15', 'volD30', 'volD60', 'volNQdiff',\n",
      "       'volYMdiff', 'vpm5', 'vpm10', 'vpm15', 'vpm30', 'vpm60', 'ToD', 'DoW',\n",
      "       'MO'],\n",
      "      dtype='object')\n",
      "TESTING FOR: \n",
      "Mr3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 849\n'y' sizes: 5943\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 257\u001b[0m\n\u001b[0;32m    255\u001b[0m model \u001b[38;5;241m=\u001b[39m build_LSTM_model()\n\u001b[0;32m    256\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m load_model()\n\u001b[1;32m--> 257\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39mepochs, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\\\n\u001b[0;32m    258\u001b[0m                     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test),\\\n\u001b[0;32m    259\u001b[0m                     )\u001b[38;5;66;03m#batch_size=849)#callbacks=[metric_callback])\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m#EVALUATE THE MODEL AND VISUALIZE RESULTS-------------------------------------------------------\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m#_, acc = model.evaluate(X_test, y_test)\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m#print(\"Accuracy = \", (acc * 100.0), \"%\")\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# LOSS\u001b[39;00m\n\u001b[0;32m    267\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\logan\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\logan\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\data_adapter_utils.py:114\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    110\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 849\n'y' sizes: 5943\n"
     ]
    }
   ],
   "source": [
    "#JJ McCauley + LOGAN KELSCH \n",
    "#TEST NN 1\n",
    "\n",
    "#IMPORT LIBRARIES-------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#hahaha dont turn this on with high epoch or else\n",
    "#tf.config.experimental.set_memory_growth\n",
    "\n",
    "#LOAD DATA FROM CSV-------------------------------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('catted_1.csv')\n",
    "\n",
    "#      'Dr1' 'Dr3' 'Mr1' 'Mr3' \n",
    "testFor = 'Mr3'\n",
    "#testing random feature drops\n",
    "#TREND\n",
    "\n",
    "data = data.drop(columns='FT')\n",
    "#data = data.drop(columns='vel5')\n",
    "#data = data.drop(columns='vel10')\n",
    "#data = data.drop(columns='vel15')\n",
    "#data = data.drop(columns='vel30')\n",
    "#data = data.drop(columns='vel60')\n",
    "#data = data.drop(columns='acc5')\n",
    "#data = data.drop(columns='acc10')\n",
    "#data = data.drop(columns='acc15')\n",
    "#data = data.drop(columns='acc30')\n",
    "#data = data.drop(columns='acc60')\n",
    "#data = data.drop(columns='stoch12')\n",
    "#data = data.drop(columns='stochDiff6012')\n",
    "#data = data.drop(columns='RSIhl_diff')\n",
    "#data = data.drop(columns='RSIhl_diffROC')\n",
    "#data = data.drop(columns='YM_diff')\n",
    "#data = data.drop(columns='NQ_diff')\n",
    "\n",
    "#PARTICIPATION\n",
    "\n",
    "\n",
    "#data = data.drop(columns='vol')\n",
    "#data = data.drop(columns='vol10')\n",
    "#data = data.drop(columns='vol15')\n",
    "#data = data.drop(columns='vol30')\n",
    "#data = data.drop(columns='vol60')\n",
    "#data = data.drop(columns='volD10')\n",
    "#data = data.drop(columns='volD15')\n",
    "#data = data.drop(columns='volD30')\n",
    "#data = data.drop(columns='volD60')\n",
    "#data = data.drop(columns='volNQdiff')\n",
    "#data = data.drop(columns='volYMdiff')\n",
    "#data = data.drop(columns='vpm5')\n",
    "#data = data.drop(columns='vpm10')\n",
    "#data = data.drop(columns='vpm15')\n",
    "#data = data.drop(columns='ToD')\n",
    "#data = data.drop(columns='DoW')\n",
    "\n",
    "#CALENDAR\n",
    "\n",
    "\n",
    "#--------------------------------------\n",
    "#SOLUTION------------------------------\n",
    "data = data.drop(columns=['Mc1','Mc3','Dc1','Dc3'])\n",
    "match testFor:\n",
    "    case 'Dr1':\n",
    "        data = data.drop(columns='Dr3')\n",
    "        data = data.drop(columns='Mr1')\n",
    "        data = data.drop(columns='Mr3')\n",
    "    case 'Dr3':\n",
    "        data = data.drop(columns='Dr1')\n",
    "        data = data.drop(columns='Mr1')\n",
    "        data = data.drop(columns='Mr3')\n",
    "    case 'Mr1':\n",
    "        data = data.drop(columns='Dr1')\n",
    "        data = data.drop(columns='Dr3')\n",
    "        data = data.drop(columns='Mr3')\n",
    "    case 'Mr3':\n",
    "        data = data.drop(columns='Dr1')\n",
    "        data = data.drop(columns='Dr3')\n",
    "        data = data.drop(columns='Mr1')\n",
    "\n",
    "\n",
    "data = data.drop(columns='FT.1')\n",
    "data = data.drop(columns='FT.2')\n",
    "\n",
    "\n",
    "\n",
    "#confirming X and Y features post training\n",
    "Xfeatures = data.columns[:-1]\n",
    "Yfeatures = data.columns[-1]\n",
    "print(\"TESTED FEATURES: \")\n",
    "print(Xfeatures)\n",
    "print(\"TESTING FOR: \")\n",
    "print(Yfeatures)\n",
    "\n",
    "#DATA OPTIMIZATION------------------------------------------------------\n",
    "\n",
    "#print(\"OCCURANCES IN RAW DATA FOR \", Yfeatures, \": \", sep='')\n",
    "#unique, counts = np.unique(data.iloc[:, -1].values, return_counts=True)\n",
    "#print(dict(zip(unique,counts)))\n",
    "\n",
    "#filtering before splitting could be useful if ABSOLUTELY mostly comprised of 'in'\n",
    "#MARKET HOURS!\n",
    "#data = data.drop(data[data['ToD'] > 950].index)\n",
    "#data = data.drop(data[data['ToD'] < 560].index)\n",
    "#OTHER MODIFICATIONS\n",
    "#data = data.drop(data[data['feature'] condition].index)\n",
    "data = data.drop(data[data['MO'] < 1].index)\n",
    "\n",
    "\n",
    "\n",
    "#PROCESS THE DATA-------------------------------------------------------\n",
    "\n",
    "# Separate features and target\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "#Encoding data\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = np.reshape(X_train, (int(X_train.shape[0]/7), 7, X_train.shape[1]))\n",
    "\n",
    "# one-hot encode ? \n",
    "\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "#y_train = to_categorical(y_train, num_classes=4)\n",
    "#y_test = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "#RESAMPLED DATA- POST SPLIT---------------------------------------------------------\n",
    "\n",
    "#smote = SMOTE()\n",
    "#X_resampled, y_resampled = smote.fit_resample(X_train,y_train)\n",
    "#print('\\nResampled Data size:',X_resampled.size)\n",
    "\n",
    "#BUILD THE NEURAL NETWORK MODEL-------------------------------------------------------\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # Calculate the absolute error\n",
    "    error = tf.abs(y_true - y_pred)\n",
    "    \n",
    "    # Define conditions for different error ranges\n",
    "    is_large_error = tf.greater(error, 1.0)       # Error > 1.0\n",
    "    is_small_error = tf.less_equal(error, 0.25)   # Error <= 0.25\n",
    "    \n",
    "    # Apply penalties for large errors: penalize more for errors > 1.0\n",
    "    large_error_penalty = tf.where(is_large_error, error ** 2, 0.0)\n",
    "    \n",
    "    # Apply reward for small errors: reward by reducing loss for errors <= 0.25\n",
    "    small_error_reward = tf.where(is_small_error, -0.1 * error, 0.0)  # Reward by reducing the loss\n",
    "    \n",
    "    # Neutral loss for errors in between (0.25 < error <= 1.0)\n",
    "    neutral_loss = tf.where(~is_large_error & ~is_small_error, error, 0.0)\n",
    "    \n",
    "    # Combine penalties and rewards\n",
    "    total_loss = large_error_penalty + small_error_reward + neutral_loss\n",
    "    \n",
    "    # Return the average loss over the batch\n",
    "    return tf.reduce_mean(total_loss)\n",
    "\n",
    "\n",
    "\n",
    "#LEARNING RATES____________________________________________________________________________________________\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "lr_schedule = ExponentialDecay(\n",
    "    #good rough val to start, .25, good val to end at .0015.\n",
    "    #5k epoch should be: .25, 8565, .9995, true\n",
    "    0.1,\n",
    "    decay_steps=186,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "\n",
    "opt1 = SGD(learning_rate=0.0001)\n",
    "opt2  = tf.keras.optimizers.Adam(clipnorm=0.01)\n",
    "opt3 = SGD(learning_rate=lr_schedule)\n",
    "\n",
    "#BUILD AND LOAD MODEL__________________________________________________________________________________________\n",
    "\n",
    "\n",
    "#print(X_train.shape[0]/time_steps)\n",
    "#X_train = np.reshape(X_train,((X_train.shape[0]//time_steps), time_steps, 35))  # Reshape to (batch_size, 5 time steps, 35 features)\n",
    "#y_train = y.reshape(1,-1)\n",
    "\n",
    "def build_LSTM_model():\n",
    "    time_steps=5\n",
    "    n_features=len(Xfeatures)\n",
    "    output_unit=1\n",
    "    lstm_activation='tanh'\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        #tf.keras.layers.Input(shape=(35,)),\n",
    "        tf.keras.layers.LSTM(64, activation=lstm_activation),#, input_shape=(time_steps, n_features)),\n",
    "        #tf.keras.layers.Activation('leaky_relu'),\n",
    "        #tf.keras.layers.Dense(2048),#,kernel_initializer='he_normal',kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        #tf.keras.layers.BatchNormalization(),\n",
    "        #tf.keras.layers.Activation('leaky_relu'),\n",
    "        #tf.keras.layers.Dropout(0.20),\n",
    "        #tf.keras.layers.Dense(1024),#,kernel_initializer='he_normal',kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        #tf.keras.layers.BatchNormalization(),\n",
    "        #tf.keras.layers.Activation('leaky_relu'),\n",
    "        #tf.keras.layers.Dropout(0.20),\n",
    "        tf.keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    #AUC=tf.keras.metrics.AUC(curve='PR')\n",
    "    met = ['precision','recall','accuracy']\n",
    "    model.compile(optimizer=opt3,\n",
    "                  loss='binary_crossentropy'\n",
    "                  ,metrics=['R2Score','mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    #loaded_model = tf.keras.models.load_model('tupleTrain.keras', custom_objects={'custom_loss':custom_loss})\n",
    "    loaded_model = tf.keras.models.load_model('dmReg_rec1.keras')\n",
    "    loaded_model.compile(optimizer=opt3,\n",
    "                         loss='mae'\n",
    "                         , metrics=['R2Score','mse'])\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "#TRAIN THE MODEL WITH CUSTOMIZABLE EPOCHS-------------------------------------------------------\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_recall', patience=250, mode='max', restore_best_weights=True)\n",
    "\n",
    "model = build_LSTM_model()\n",
    "loaded_model = load_model()\n",
    "history = model.fit(X_train, y_train, epochs=epochs, validation_split=0.2,\\\n",
    "                    shuffle=True, verbose=1, validation_data=(X_test, y_test),\\\n",
    "                    )#batch_size=849)#callbacks=[metric_callback])\n",
    "\n",
    "#EVALUATE THE MODEL AND VISUALIZE RESULTS-------------------------------------------------------\n",
    "\n",
    "#_, acc = model.evaluate(X_test, y_test)\n",
    "#print(\"Accuracy = \", (acc * 100.0), \"%\")\n",
    "\n",
    "# LOSS\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, history.history['loss'], 'y', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "# ACCURACY\n",
    "\n",
    "plt.plot(epochs, history.history['R2Score'], 'y', label='Training R2')\n",
    "plt.plot(epochs, history.history['val_R2Score'], 'r', label='Validation R2')\n",
    "plt.title('Training and Validation R2Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R2Score')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "'''\n",
    "# AUC\n",
    "plt.plot(epochs, history.history['AUC'], 'y', label='Training AUC')\n",
    "plt.plot(epochs, history.history['val_AUC'], 'r', label='Validation AUC')\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# PRECISION\n",
    "plt.plot(epochs, history.history['precision'], 'y', label='Training Precision')\n",
    "plt.plot(epochs, history.history['val_precision'], 'r', label='Validation Precision')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "# RECALL\n",
    "plt.plot(epochs, history.history['recall'], 'y', label='Training Recall')\n",
    "plt.plot(epochs, history.history['val_recall'], 'r', label='Validation Recall')\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "# TPR\n",
    "\n",
    "\n",
    "TPR = history.history['TruePositives']/(history.history['TruePositives']+history.history['TrueNegatives'])\n",
    "val_TPR = history.history['val_TruePositives']/(history.history['val_TruePositives']+history.history['val_TrueNegatives'])\n",
    "plt.plot(epochs, TPR, 'y', label='Training TPR')\n",
    "plt.plot(epochs, val_TPR, 'r', label='Validation TPR')\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('TP Rate')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = model.predict(X_test) \n",
    "#y_pred = y_pred > 0.5 # Predictions to class indices\n",
    "'''\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d',cmap='Greens')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix for Direction Classification')\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "plt.scatter(y_pred, y_test, s=1)\n",
    "plt.axis('tight')\n",
    "plt.title('Testing Outputs')\n",
    "plt.xlabel('y_pred')\n",
    "plt.xlim(0,5)\n",
    "plt.ylim(0,5)\n",
    "plt.ylabel('y_test')\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "#model.save('epoch15k.keras')\n",
    "# Load the model\n",
    "#loaded_model = tf.keras.models.load_model('my_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "loaded_model.save('dmReg_rec1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70300716]\n",
      " [0.59242254]\n",
      " [0.986246  ]\n",
      " ...\n",
      " [1.1672951 ]\n",
      " [1.7254387 ]\n",
      " [0.7041494 ]]\t[0.4084 0.2077 2.0762 ... 2.2549 4.0791 0.1497]\n",
      "[-0.30909206 -0.00482098  0.06859997 -0.19255195 -0.18555097 -0.42193071\n",
      " -0.05724611  0.28148903 -0.08353789 -0.25489117 -0.40555301 -0.10895216\n",
      "  0.55159307  0.13936676  0.5793675  -0.36031629 -0.4030192  -0.39647853\n",
      " -0.33207338 -0.39678441 -0.19869235 -0.15392743 -0.34861774 -0.17834132\n",
      " -0.37716372 -0.01312875  0.45894897 -0.30360586 -0.05855382 -0.06432187\n",
      " -0.06458413 -0.06693589 -0.09441513 -0.00260275  0.        ]\n",
      "[ 2.3030512   1.89345973  2.50232183  1.4656017  -0.05650354  1.38807449\n",
      "  0.46435495  2.00877617  2.12087228  0.89781393  0.41108756  1.59327848\n",
      " -1.29548405 -1.8300144   0.16864088  0.35564027  1.07815112  0.8990935\n",
      "  0.78458171  1.15414436  1.40391868  0.56137875  0.61949629  0.04151975\n",
      " -0.13240182  1.05253998  0.70461834  1.02057559  1.08613482  1.3745672\n",
      "  0.61959318 -0.06693589 -0.13589888  1.40359361  0.        ]\n",
      "[-1.27465457  0.2270601  -0.04532924 -0.3553155  -0.22856678 -1.97922524\n",
      "  1.48980623  0.28985767 -0.27241902 -0.75962594 -1.16170338 -1.26878321\n",
      " -0.82063581  0.15421783 -0.37899462  0.09218435  0.92639054  1.21970089\n",
      "  1.72471086  2.53450195  1.99889388 -0.44186883 -0.79503387 -0.82657871\n",
      " -0.44072253 -0.25350242 -0.15854349 -0.56844215 -0.05855382 -0.06432187\n",
      " -0.06458413 -0.06693589 -0.92409002 -0.70570093  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred,y_test,sep='\\t')\n",
    "\n",
    "print(X_test[0])\n",
    "print(X_test[1])\n",
    "print(X_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ activation_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ activation_28 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m36,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_29 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_30 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m1,025\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,087,489</span> (4.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,087,489\u001b[0m (4.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,087,489</span> (4.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,087,489\u001b[0m (4.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: dmRec_rec1.keras (of type <class 'str'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m----> 2\u001b[0m lm \u001b[38;5;241m=\u001b[39m loaded_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdmRec_rec1.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m lm\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\logan\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\logan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:789\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(args):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    785\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, KerasTensor)\n\u001b[0;32m    786\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mis_tensor(arg)\n\u001b[0;32m    787\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m         ):\n\u001b[1;32m--> 789\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    790\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly input tensors may be passed as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    791\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional arguments. The following argument value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    792\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be passed as a keyword argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    793\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    794\u001b[0m             )\n\u001b[0;32m    796\u001b[0m \u001b[38;5;66;03m# Caches info about `call()` signature, args, kwargs.\u001b[39;00m\n\u001b[0;32m    797\u001b[0m call_spec \u001b[38;5;241m=\u001b[39m CallSpec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_signature, args, kwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: dmRec_rec1.keras (of type <class 'str'>)"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "lm = load_model('dmRec_rec1.keras')\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_pred, y_test, s=1)\n",
    "plt.axis('tight')\n",
    "plt.title('Testing Outputs')\n",
    "plt.xlabel('y_pred')\n",
    "plt.xlim(0,5)\n",
    "plt.ylim(0,5)\n",
    "plt.ylabel('y_test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - R2Score: -5940.4028 - loss: 8.5924 - mse: 6786.3228  \n",
      "Epoch 2/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -5.7757 - loss: 1.1279 - mse: 7.4655\n",
      "Epoch 3/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -5.6082 - loss: 1.1206 - mse: 7.4288\n",
      "Epoch 4/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -3.0662 - loss: 1.0886 - mse: 4.7600\n",
      "Epoch 5/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.8574 - loss: 1.0890 - mse: 3.6314\n",
      "Epoch 6/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.5030 - loss: 1.0595 - mse: 3.0816\n",
      "Epoch 7/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.1574 - loss: 1.0336 - mse: 2.4377\n",
      "Epoch 8/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8773 - loss: 1.0381 - mse: 2.3616\n",
      "Epoch 9/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0153 - loss: 1.0374 - mse: 2.4283\n",
      "Epoch 10/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.5800 - loss: 1.0607 - mse: 3.1622\n",
      "Epoch 11/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.9419 - loss: 1.0666 - mse: 3.3759\n",
      "Epoch 12/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8823 - loss: 1.0415 - mse: 2.3237\n",
      "Epoch 13/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.5598 - loss: 1.0773 - mse: 3.2773\n",
      "Epoch 14/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -7.7569 - loss: 1.0889 - mse: 10.1244\n",
      "Epoch 15/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.5964 - loss: 1.0567 - mse: 3.0076\n",
      "Epoch 16/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9967 - loss: 1.0371 - mse: 2.3846\n",
      "Epoch 17/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.4602 - loss: 1.0357 - mse: 2.7357\n",
      "Epoch 18/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.1544 - loss: 1.0621 - mse: 2.7360\n",
      "Epoch 19/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9716 - loss: 1.0463 - mse: 2.3626\n",
      "Epoch 20/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9382 - loss: 1.0253 - mse: 2.1885\n",
      "Epoch 21/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.4794 - loss: 1.0788 - mse: 3.2829\n",
      "Epoch 22/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0367 - loss: 1.0138 - mse: 2.3436\n",
      "Epoch 23/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.6677 - loss: 1.0345 - mse: 3.0597\n",
      "Epoch 24/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9343 - loss: 1.0482 - mse: 2.3289\n",
      "Epoch 25/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9264 - loss: 0.9998 - mse: 2.1018\n",
      "Epoch 26/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9034 - loss: 1.0305 - mse: 2.2531\n",
      "Epoch 27/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9287 - loss: 1.0241 - mse: 2.2665\n",
      "Epoch 28/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.2071 - loss: 1.0401 - mse: 2.5052\n",
      "Epoch 29/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.5604 - loss: 1.0489 - mse: 2.8885\n",
      "Epoch 30/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8992 - loss: 1.0484 - mse: 2.3342\n",
      "Epoch 31/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8616 - loss: 1.0705 - mse: 2.5089\n",
      "Epoch 32/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9839 - loss: 1.0368 - mse: 2.1805\n",
      "Epoch 33/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9003 - loss: 1.0534 - mse: 2.3677\n",
      "Epoch 34/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9890 - loss: 1.0387 - mse: 2.4149\n",
      "Epoch 35/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9505 - loss: 1.0053 - mse: 2.0890\n",
      "Epoch 36/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9060 - loss: 1.0522 - mse: 2.3382\n",
      "Epoch 37/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.2286 - loss: 1.0586 - mse: 2.5579\n",
      "Epoch 38/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9220 - loss: 1.0168 - mse: 2.1603\n",
      "Epoch 39/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9549 - loss: 1.0304 - mse: 2.2415\n",
      "Epoch 40/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9450 - loss: 1.0157 - mse: 2.1348\n",
      "Epoch 41/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8733 - loss: 1.0352 - mse: 2.3080\n",
      "Epoch 42/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9445 - loss: 1.0124 - mse: 2.1164\n",
      "Epoch 43/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9453 - loss: 1.0435 - mse: 2.3009\n",
      "Epoch 44/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9295 - loss: 1.0498 - mse: 2.4248\n",
      "Epoch 45/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8630 - loss: 1.0482 - mse: 2.4389\n",
      "Epoch 46/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8861 - loss: 1.0547 - mse: 2.3891\n",
      "Epoch 47/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0482 - loss: 1.0325 - mse: 2.1708\n",
      "Epoch 48/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8685 - loss: 1.0237 - mse: 2.2596\n",
      "Epoch 49/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8591 - loss: 1.0384 - mse: 2.3558\n",
      "Epoch 50/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8550 - loss: 1.0303 - mse: 2.3167\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.1229 - loss: 1.0164 - mse: 2.2515\n",
      "Epoch 2/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.2380 - loss: 1.0379 - mse: 2.5449\n",
      "Epoch 3/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8726 - loss: 1.0392 - mse: 2.3294\n",
      "Epoch 4/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9134 - loss: 1.0357 - mse: 2.3970\n",
      "Epoch 5/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9785 - loss: 1.0128 - mse: 2.0831\n",
      "Epoch 6/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9178 - loss: 1.0197 - mse: 2.1913\n",
      "Epoch 7/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9268 - loss: 1.0128 - mse: 2.1415\n",
      "Epoch 8/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8656 - loss: 1.0510 - mse: 2.4045\n",
      "Epoch 9/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9720 - loss: 1.0158 - mse: 2.0988\n",
      "Epoch 10/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8880 - loss: 1.0214 - mse: 2.2280\n",
      "Epoch 11/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9191 - loss: 1.0339 - mse: 2.2398\n",
      "Epoch 12/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.2844 - loss: 1.0206 - mse: 2.7112\n",
      "Epoch 13/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9350 - loss: 1.0137 - mse: 2.1341\n",
      "Epoch 14/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0934 - loss: 0.9911 - mse: 2.0692\n",
      "Epoch 15/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8977 - loss: 1.0063 - mse: 2.1698\n",
      "Epoch 16/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9520 - loss: 1.0348 - mse: 2.2021\n",
      "Epoch 17/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.3554 - loss: 1.0241 - mse: 2.7670\n",
      "Epoch 18/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8951 - loss: 1.0247 - mse: 2.2299\n",
      "Epoch 19/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0859 - loss: 0.9794 - mse: 1.8802\n",
      "Epoch 20/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8861 - loss: 1.0413 - mse: 2.3161\n",
      "Epoch 21/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8982 - loss: 1.0241 - mse: 2.2216\n",
      "Epoch 22/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8357 - loss: 1.0364 - mse: 2.4111\n",
      "Epoch 23/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9383 - loss: 1.0025 - mse: 2.0878\n",
      "Epoch 24/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.6191 - loss: 1.0317 - mse: 2.6729\n",
      "Epoch 25/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9470 - loss: 1.0012 - mse: 2.0636\n",
      "Epoch 26/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0010 - loss: 1.0052 - mse: 2.0235\n",
      "Epoch 27/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0249 - loss: 1.0234 - mse: 2.4145\n",
      "Epoch 28/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0062 - loss: 1.0228 - mse: 2.0949\n",
      "Epoch 29/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8944 - loss: 1.0338 - mse: 2.2776\n",
      "Epoch 30/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.1563 - loss: 1.0305 - mse: 2.4518\n",
      "Epoch 31/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9688 - loss: 1.0024 - mse: 2.0480\n",
      "Epoch 32/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9092 - loss: 1.0134 - mse: 2.1611\n",
      "Epoch 33/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.2732 - loss: 1.0305 - mse: 2.4374\n",
      "Epoch 34/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9892 - loss: 1.0106 - mse: 2.1478\n",
      "Epoch 35/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9206 - loss: 1.0199 - mse: 2.1754\n",
      "Epoch 36/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8747 - loss: 1.0118 - mse: 2.2041\n",
      "Epoch 37/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9780 - loss: 1.0004 - mse: 2.0279\n",
      "Epoch 38/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9693 - loss: 0.9986 - mse: 2.0362\n",
      "Epoch 39/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9486 - loss: 0.9927 - mse: 2.0386\n",
      "Epoch 40/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8783 - loss: 1.0258 - mse: 2.2664\n",
      "Epoch 41/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9019 - loss: 1.0304 - mse: 2.2480\n",
      "Epoch 42/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8972 - loss: 1.0082 - mse: 2.1584\n",
      "Epoch 43/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9078 - loss: 1.0099 - mse: 2.1475\n",
      "Epoch 44/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8948 - loss: 1.0410 - mse: 2.2992\n",
      "Epoch 45/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9392 - loss: 1.0212 - mse: 2.1576\n",
      "Epoch 46/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9783 - loss: 1.0080 - mse: 2.0620\n",
      "Epoch 47/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9403 - loss: 1.0511 - mse: 2.2965\n",
      "Epoch 48/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8882 - loss: 1.0324 - mse: 2.2785\n",
      "Epoch 49/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8906 - loss: 1.0224 - mse: 2.2412\n",
      "Epoch 50/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0308 - loss: 1.0122 - mse: 2.0343\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step\n",
      "Epoch 1/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9637 - loss: 1.0036 - mse: 2.0569\n",
      "Epoch 2/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9736 - loss: 1.0021 - mse: 2.0497\n",
      "Epoch 3/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9959 - loss: 1.0332 - mse: 2.1456\n",
      "Epoch 4/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9438 - loss: 0.9965 - mse: 2.0583\n",
      "Epoch 5/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9510 - loss: 1.0180 - mse: 2.1343\n",
      "Epoch 6/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9920 - loss: 1.0008 - mse: 2.0225\n",
      "Epoch 7/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9367 - loss: 1.0245 - mse: 2.1896\n",
      "Epoch 8/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0159 - loss: 1.0128 - mse: 2.0630\n",
      "Epoch 9/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8996 - loss: 1.0053 - mse: 2.1588\n",
      "Epoch 10/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8713 - loss: 1.0339 - mse: 2.3460\n",
      "Epoch 11/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9939 - loss: 1.0313 - mse: 2.1445\n",
      "Epoch 12/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9223 - loss: 1.0384 - mse: 2.2535\n",
      "Epoch 13/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9886 - loss: 1.0102 - mse: 2.0633\n",
      "Epoch 14/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0591 - loss: 0.9881 - mse: 1.9332\n",
      "Epoch 15/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0045 - loss: 1.0169 - mse: 2.0709\n",
      "Epoch 16/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9694 - loss: 1.0283 - mse: 2.1613\n",
      "Epoch 17/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9517 - loss: 1.0205 - mse: 2.1477\n",
      "Epoch 18/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0106 - loss: 1.0114 - mse: 2.0404\n",
      "Epoch 19/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9558 - loss: 1.0036 - mse: 2.0750\n",
      "Epoch 20/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9030 - loss: 1.0230 - mse: 2.2173\n",
      "Epoch 21/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9210 - loss: 0.9976 - mse: 2.0847\n",
      "Epoch 22/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0001 - loss: 1.0034 - mse: 2.0296\n",
      "Epoch 23/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9511 - loss: 1.0193 - mse: 2.1412\n",
      "Epoch 24/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9133 - loss: 1.0167 - mse: 2.1718\n",
      "Epoch 25/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0046 - loss: 1.0057 - mse: 2.0360\n",
      "Epoch 26/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9206 - loss: 1.0139 - mse: 2.1897\n",
      "Epoch 27/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9903 - loss: 1.0274 - mse: 2.1334\n",
      "Epoch 28/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9827 - loss: 1.0177 - mse: 2.0977\n",
      "Epoch 29/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8748 - loss: 1.0458 - mse: 2.3641\n",
      "Epoch 30/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9866 - loss: 0.9987 - mse: 2.0187\n",
      "Epoch 31/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9800 - loss: 1.0352 - mse: 2.1701\n",
      "Epoch 32/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9489 - loss: 1.0054 - mse: 2.0860\n",
      "Epoch 33/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9179 - loss: 1.0029 - mse: 2.1090\n",
      "Epoch 34/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9677 - loss: 1.0092 - mse: 2.0876\n",
      "Epoch 35/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9673 - loss: 1.0258 - mse: 2.1732\n",
      "Epoch 36/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9504 - loss: 1.0253 - mse: 2.1620\n",
      "Epoch 37/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9589 - loss: 1.0339 - mse: 2.1950\n",
      "Epoch 38/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9401 - loss: 1.0081 - mse: 2.1042\n",
      "Epoch 39/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9425 - loss: 1.0240 - mse: 2.3725\n",
      "Epoch 40/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9392 - loss: 1.0031 - mse: 2.0809\n",
      "Epoch 41/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9553 - loss: 1.0213 - mse: 2.1457\n",
      "Epoch 42/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9725 - loss: 1.0110 - mse: 2.0824\n",
      "Epoch 43/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9745 - loss: 1.0143 - mse: 2.0937\n",
      "Epoch 44/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9260 - loss: 1.0169 - mse: 2.1680\n",
      "Epoch 45/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0087 - loss: 0.9924 - mse: 1.9669\n",
      "Epoch 46/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9395 - loss: 1.0186 - mse: 2.1525\n",
      "Epoch 47/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9999 - loss: 1.0227 - mse: 2.1031\n",
      "Epoch 48/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9930 - loss: 1.0006 - mse: 2.0264\n",
      "Epoch 49/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8913 - loss: 1.0076 - mse: 2.1797\n",
      "Epoch 50/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9710 - loss: 1.0127 - mse: 2.0977\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step\n",
      "Epoch 1/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0167 - loss: 1.0257 - mse: 2.0928\n",
      "Epoch 2/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9455 - loss: 1.0425 - mse: 2.2497\n",
      "Epoch 3/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8612 - loss: 1.0455 - mse: 2.3889\n",
      "Epoch 4/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9273 - loss: 1.0010 - mse: 2.0905\n",
      "Epoch 5/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8842 - loss: 1.0169 - mse: 2.2205\n",
      "Epoch 6/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9031 - loss: 1.0030 - mse: 2.1302\n",
      "Epoch 7/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0179 - loss: 1.0242 - mse: 2.0883\n",
      "Epoch 8/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0316 - loss: 1.0215 - mse: 2.0590\n",
      "Epoch 9/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8948 - loss: 1.0298 - mse: 2.2866\n",
      "Epoch 10/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0258 - loss: 1.0132 - mse: 2.0365\n",
      "Epoch 11/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0047 - loss: 1.0201 - mse: 2.0866\n",
      "Epoch 12/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0146 - loss: 0.9961 - mse: 1.9804\n",
      "Epoch 13/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9982 - loss: 1.0209 - mse: 2.0916\n",
      "Epoch 14/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0086 - loss: 1.0093 - mse: 2.0338\n",
      "Epoch 15/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9329 - loss: 1.0119 - mse: 2.1263\n",
      "Epoch 16/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0464 - loss: 1.0090 - mse: 2.0046\n",
      "Epoch 17/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0206 - loss: 1.0160 - mse: 2.0633\n",
      "Epoch 18/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0054 - loss: 1.0203 - mse: 2.0926\n",
      "Epoch 19/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9936 - loss: 1.0363 - mse: 2.1626\n",
      "Epoch 20/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0001 - loss: 1.0146 - mse: 2.0643\n",
      "Epoch 21/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9440 - loss: 1.0108 - mse: 2.1085\n",
      "Epoch 22/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9195 - loss: 1.0244 - mse: 2.2027\n",
      "Epoch 23/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - R2Score: -0.9703 - loss: 1.0063 - mse: 2.0652\n",
      "Epoch 24/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9982 - loss: 1.0064 - mse: 2.0334\n",
      "Epoch 25/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0109 - loss: 1.0230 - mse: 2.0902\n",
      "Epoch 26/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8986 - loss: 1.0288 - mse: 2.2553\n",
      "Epoch 27/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9926 - loss: 1.0026 - mse: 2.0269\n",
      "Epoch 28/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9654 - loss: 1.0306 - mse: 2.1722\n",
      "Epoch 29/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9550 - loss: 1.0349 - mse: 2.1990\n",
      "Epoch 30/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9265 - loss: 1.0042 - mse: 2.1040\n",
      "Epoch 31/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9662 - loss: 1.0418 - mse: 2.2160\n",
      "Epoch 32/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9562 - loss: 1.0232 - mse: 2.1461\n",
      "Epoch 33/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9225 - loss: 1.0430 - mse: 2.2703\n",
      "Epoch 34/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9267 - loss: 1.0180 - mse: 2.1602\n",
      "Epoch 35/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9686 - loss: 1.0113 - mse: 2.0846\n",
      "Epoch 36/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9523 - loss: 1.0184 - mse: 2.1316\n",
      "Epoch 37/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9150 - loss: 1.0173 - mse: 2.1844\n",
      "Epoch 38/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9307 - loss: 1.0072 - mse: 2.1111\n",
      "Epoch 39/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9434 - loss: 1.0212 - mse: 2.1608\n",
      "Epoch 40/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9755 - loss: 0.9925 - mse: 2.0012\n",
      "Epoch 41/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9341 - loss: 1.0257 - mse: 2.1844\n",
      "Epoch 42/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9182 - loss: 1.0121 - mse: 2.1570\n",
      "Epoch 43/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0444 - loss: 1.0058 - mse: 1.9898\n",
      "Epoch 44/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9405 - loss: 1.0206 - mse: 2.1621\n",
      "Epoch 45/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9964 - loss: 1.0042 - mse: 2.0527\n",
      "Epoch 46/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9179 - loss: 1.0145 - mse: 2.1731\n",
      "Epoch 47/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0219 - loss: 1.0119 - mse: 2.0470\n",
      "Epoch 48/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9283 - loss: 1.0165 - mse: 2.1512\n",
      "Epoch 49/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.8839 - loss: 1.0424 - mse: 2.3218\n",
      "Epoch 50/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9729 - loss: 1.0398 - mse: 2.1989\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9559 - loss: 1.0470 - mse: 2.2495\n",
      "Epoch 2/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9864 - loss: 1.0543 - mse: 2.2469\n",
      "Epoch 3/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0193 - loss: 1.0237 - mse: 2.0775\n",
      "Epoch 4/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9667 - loss: 1.0189 - mse: 2.1199\n",
      "Epoch 5/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0396 - loss: 1.0062 - mse: 1.9960\n",
      "Epoch 6/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0314 - loss: 1.0090 - mse: 2.0123\n",
      "Epoch 7/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0178 - loss: 1.0204 - mse: 2.0676\n",
      "Epoch 8/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0013 - loss: 1.0270 - mse: 2.1119\n",
      "Epoch 9/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0110 - loss: 1.0031 - mse: 2.0252\n",
      "Epoch 10/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9427 - loss: 1.0213 - mse: 2.1624\n",
      "Epoch 11/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9939 - loss: 1.0165 - mse: 2.0778\n",
      "Epoch 12/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9687 - loss: 1.0074 - mse: 2.0769\n",
      "Epoch 13/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9357 - loss: 1.0278 - mse: 2.1946\n",
      "Epoch 14/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0053 - loss: 1.0338 - mse: 2.1353\n",
      "Epoch 15/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9473 - loss: 1.0449 - mse: 2.2582\n",
      "Epoch 16/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9219 - loss: 1.0208 - mse: 2.1767\n",
      "Epoch 17/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0187 - loss: 1.0307 - mse: 2.1166\n",
      "Epoch 18/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9893 - loss: 1.0166 - mse: 2.0822\n",
      "Epoch 19/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9829 - loss: 1.0267 - mse: 2.1317\n",
      "Epoch 20/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.3948 - loss: 1.0233 - mse: 2.5113\n",
      "Epoch 21/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9700 - loss: 1.0245 - mse: 2.1349\n",
      "Epoch 22/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9856 - loss: 1.0268 - mse: 2.1346\n",
      "Epoch 23/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0103 - loss: 1.0134 - mse: 2.0580\n",
      "Epoch 24/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9032 - loss: 1.0350 - mse: 2.2660\n",
      "Epoch 25/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0188 - loss: 1.0217 - mse: 2.0743\n",
      "Epoch 26/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9803 - loss: 1.0217 - mse: 2.1146\n",
      "Epoch 27/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9302 - loss: 1.0297 - mse: 2.2125\n",
      "Epoch 28/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9776 - loss: 1.0333 - mse: 2.1685\n",
      "Epoch 29/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9518 - loss: 1.0232 - mse: 2.1539\n",
      "Epoch 30/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9553 - loss: 1.0343 - mse: 2.1923\n",
      "Epoch 31/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0157 - loss: 1.0344 - mse: 2.1309\n",
      "Epoch 32/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9143 - loss: 1.0197 - mse: 2.1818\n",
      "Epoch 33/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9754 - loss: 1.0107 - mse: 2.0780\n",
      "Epoch 34/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9970 - loss: 1.0168 - mse: 2.0737\n",
      "Epoch 35/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9604 - loss: 1.0071 - mse: 2.0725\n",
      "Epoch 36/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9469 - loss: 1.0260 - mse: 2.1667\n",
      "Epoch 37/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9765 - loss: 1.0147 - mse: 2.0892\n",
      "Epoch 38/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0988 - loss: 1.0580 - mse: 2.5914\n",
      "Epoch 39/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9255 - loss: 1.0104 - mse: 2.1260\n",
      "Epoch 40/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9442 - loss: 1.0390 - mse: 2.2296\n",
      "Epoch 41/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9795 - loss: 1.0136 - mse: 2.0833\n",
      "Epoch 42/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -1.0114 - loss: 1.0201 - mse: 2.0727\n",
      "Epoch 43/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9584 - loss: 1.0226 - mse: 2.1414\n",
      "Epoch 44/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9804 - loss: 1.0163 - mse: 2.0919\n",
      "Epoch 45/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9089 - loss: 1.0236 - mse: 2.2087\n",
      "Epoch 46/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9945 - loss: 1.0173 - mse: 2.0774\n",
      "Epoch 47/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9567 - loss: 1.0590 - mse: 2.2992\n",
      "Epoch 48/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9869 - loss: 1.0339 - mse: 2.1544\n",
      "Epoch 49/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9581 - loss: 1.0366 - mse: 2.2014\n",
      "Epoch 50/50\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - R2Score: -0.9555 - loss: 1.0206 - mse: 2.1370\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step\n",
      "Mean MSE: 1.069487050931453\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Load your pre-trained model\n",
    "model = load_model('dmReg_rec1.keras')\n",
    "\n",
    "# Assuming you have your data and labels as numpy arrays (X, y)\n",
    "# X: Features, y: Labels (binary classification: 0 or 1)\n",
    "\n",
    "# Set the number of folds (e.g., 5-fold cross-validation)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store results\n",
    "mse_scores = []\n",
    "\n",
    "# Perform K-Fold cross-validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[test_index]\n",
    "    y_train, y_val = y[train_index], y[test_index]\n",
    "    \n",
    "    # Optionally, reset the model's weights before each fold\n",
    "    # model.load_weights('path_to_weights') # If you want to use the same weights every time\n",
    "    \n",
    "    # Re-train the model on the fold's training data\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "    # Predict and calculate mean squared error on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calculate average accuracy over all folds\n",
    "mean_mse = np.mean(mse_scores)\n",
    "print(f'Mean MSE: {mean_mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
