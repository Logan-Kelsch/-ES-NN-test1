{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTED FEATURES: \n",
      "Index(['vel5', 'vel10', 'vel15', 'vel30', 'vel60', 'acc5', 'acc10', 'acc15',\n",
      "       'acc30', 'acc60', 'stoch12', 'stochDiff6012', 'RSIhl_diff',\n",
      "       'RSIhl_diffROC', 'vol', 'vol10', 'vol15', 'vol30', 'vol60', 'volD10',\n",
      "       'volD15', 'volD30', 'volD60', 'vpm5', 'vpm10', 'vpm15', 'vpm30',\n",
      "       'vpm60', 'ToD', 'DoW', 'MO'],\n",
      "      dtype='object')\n",
      "TESTING FOR: \n",
      "Dr3\n",
      "X shape == (2800, 6, 31).\n",
      "y shape == (2806,).\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#IMPORT LIBRARIES-------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#LOAD DATA FROM CSV-------------------------------------------------------\n",
    "data = pd.read_csv('dm_LSTM_trade.csv')\n",
    "dataTRAIN = pd.read_csv('catted_1.csv')\n",
    "#      'Dr1' 'Dr3' 'Mr1' 'Mr3' \n",
    "testFor = 'Dr3'\n",
    "timeSteps = 6\n",
    "data = data.drop(columns=['FT','FT.1','FT.2','YM_diff','NQ_diff','volNQdiff',\n",
    "                          'volYMdiff','Mc1','Mc3','Dc1','Dc3','Dr1','Mr1','Mr3'])\n",
    "dataTRAIN = dataTRAIN.drop(columns=['FT','FT.1','FT.2','YM_diff','NQ_diff','volNQdiff',\n",
    "                                    'volYMdiff','Dr1','Mr1','Mr3','Mc1','Mc3','Dc1','Dc3'])\n",
    "\n",
    "Xfeatures = data.columns[:-1]\n",
    "Yfeatures = data.columns[-1]\n",
    "print(\"TESTED FEATURES: \")\n",
    "print(Xfeatures)\n",
    "print(\"TESTING FOR: \")\n",
    "print(Yfeatures)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.iloc[:,:].values\n",
    "\n",
    "XTRAIN = dataTRAIN.iloc[:, :-1].values\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "scaler1.fit(XTRAIN)\n",
    "XTRAIN = scaler1.transform(XTRAIN)\n",
    "X = scaler1.transform(X)\n",
    "\n",
    "def reformat_to_lstm(X, time_steps=timeSteps):\n",
    "    X_lstm = []\n",
    "    for i in range(time_steps, len(X)):\n",
    "        X_lstm.append(X[i-time_steps:i])\n",
    "    X_lstm = np.array(X_lstm)\n",
    "    return X_lstm\n",
    "\n",
    "X = reformat_to_lstm(X, timeSteps)\n",
    "\n",
    "print('X shape == {}.'.format(X.shape))\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('LSTM_Dr3_6step_10.keras')\n",
    "y_pred = loaded_model.predict(X) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
