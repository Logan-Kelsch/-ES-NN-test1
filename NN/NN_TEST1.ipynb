{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGAN KELSCH\n",
    "#TEST NN 1\n",
    "\n",
    "#IMPORT LIBRARIES-------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import GlorotUniform\n",
    "\n",
    "tf.config.experimental.set_memory_growth\n",
    "\n",
    "#LOAD DATA FROM CSV-------------------------------------------------------\n",
    "# 3.0 collected data features:\n",
    "# Symbol: /ES:XCME\n",
    "# Work Time: 4/10/23, 3:05 PM - 9/13/24, 1:55 PM\n",
    "# fulltime- seconds since 1970 (for appending data)\n",
    "# FullK-    fullK plot for Stochastic of past hour\n",
    "# diffKD-   value difference between fullK/fullD of past hour\n",
    "# OB , OS-  boolean if Stoch plots are in top/btm 20% of range\n",
    "# vol-      trade volume of each bar\n",
    "# s15,30,60-Current price/time slope of past n minutes \n",
    "#ToD-       Time of Day in seconds\n",
    "#perc30,60- percentile of low and high of past 30,60 mins and day\n",
    "#RSI-       RSI output of past hour\n",
    "#Wpercent-  William Percent output of past hour\n",
    "#acc-       Rate of acceleration of past hour over half hours\n",
    "################################\n",
    "#DESIRED OUTPUTS\n",
    "#Are formulated by making a bull and bear 0-1 oscillator\n",
    "#standard deviations derived from upcoming 4 hours of movement\n",
    "#Value description:\n",
    "#If value==0\n",
    "#  the conditions are not appealing for next n minutes\n",
    "#If value==1\n",
    "#  the price moves >=1 std. dev. in that direciton for next n mins\n",
    "#else\n",
    "#  price moves y std. dev. in that direction for next n minutes\n",
    "#bull/bear15 - 15 minute direction lookahead\n",
    "#bull/bear30 - 30 minute direction lookahead\n",
    "#bull/bear60 - 60 minute direction lookahead\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('ES_5m_4-10-23_to_9-13-24.csv')\n",
    "\n",
    "#testing random feature drops\n",
    "#data = data.drop(columns='perc30')\n",
    "#data = data.drop(columns='perc60')\n",
    "#data = data.drop(columns='percD')\n",
    "\n",
    "\n",
    "#TEMP DROP PRE-DUAL-OUTPUT NN\n",
    "#data = data.drop(columns='bull15')\n",
    "data = data.drop(columns='bear15')\n",
    "\n",
    "data = data.drop(columns='bull30')\n",
    "data = data.drop(columns='bear30')\n",
    "\n",
    "data = data.drop(columns='bull60')\n",
    "data = data.drop(columns='bear60')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "#PROCESS THE DATA-------------------------------------------------------\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#BUILD THE NEURAL NETWORK MODEL-------------------------------------------------------\n",
    "\n",
    "opt1 = SGD(learning_rate=0.01)\n",
    "opt2  = tf.keras.optimizers.Adam(clipnorm=0.8)\n",
    "\n",
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(16, activation='relu', kernel_initializer=GlorotUniform()),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),  \n",
    "        tf.keras.layers.Dropout(0.9),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),  \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),  \n",
    "        tf.keras.layers.Dropout(0.9),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),  \n",
    "        tf.keras.layers.Dropout(0.9),\n",
    "        tf.keras.layers.Dense(16, activation='sigmoid', kernel_initializer=GlorotUniform()),       \n",
    "        tf.keras.layers.Dense(1)  # Output layer for regression\n",
    "    ])\n",
    "    \n",
    "    rmse='root_mean_squared_error'\n",
    "\n",
    "    model.compile(optimizer=opt2, loss='binary_crossentropy', metrics=['mae','R2Score',rmse])\n",
    "    return model\n",
    "\n",
    "#TRAIN THE MODEL WITH CUSTOMIZABLE EPOCHS-------------------------------------------------------\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "model = build_model()\n",
    "history = model.fit(X_train, y_train, epochs=epochs, validation_split=0.5, verbose=1, shuffle=True)\n",
    "\n",
    "#EVALUATE THE MODEL AND VISUALIZE RESULTS-------------------------------------------------------\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "#R and R^2 calculation attempt in the 3 lines below this\n",
    "\n",
    "#unexplained_error = tf.reduce_sum(tf.square(tf.sub(y, y_pred)))\n",
    "#total_error = tf.reduce_sum(tf.square(tf.sub(y, tf.reduce_mean(y))))\n",
    "#R_squared = tf.sub(1, tf.div(unexplained_error, total_error))\n",
    "\n",
    "#print(f\"R^2: {R_squared}\")\n",
    "\n",
    "# ^ need to figure out how to fit a \"prediction\" variable into first line of this calculation\n",
    "#or just use a tensorflow_addon rsquared formula to calculate this\n",
    "\n",
    "#online source suggests that loss < .22 and R^2 over .9 is good\n",
    "#on a good pace for truly building something here\n",
    "\n",
    "#confirming X and Y features post training\n",
    "Xfeatures = data.columns[:-1]\n",
    "Yfeatures = data.columns[-1]\n",
    "print(\"TESTED FEATURES: \")\n",
    "print(Xfeatures)\n",
    "print(\"TESTING FOR: \")\n",
    "print(Yfeatures)\n",
    "\n",
    "#example prediction outputs, currently first 10 of training set\n",
    "preds = model.predict(X_train)\n",
    "print(preds[0:5])\n",
    "print(preds[10000:10005])\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "model.save('my_model.keras')\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('my_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
