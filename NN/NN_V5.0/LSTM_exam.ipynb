{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JJ McCauley + LOGAN KELSCH \n",
    "#TEST NN 1\n",
    "\n",
    "#IMPORT LIBRARIES-------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from funcs_data_preprocess import *\n",
    "\n",
    "#hahaha dont turn this on with high epoch or else\n",
    "#tf.config.experimental.set_memory_growth\n",
    "\n",
    "#LOAD DATA FROM CSV-------------------------------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('d1_test_.csv')\n",
    "dataTRAIN = pd.read_csv('catted_1-8.csv')\n",
    "\n",
    "#      'Dr1' 'Dr3' 'Mr1' 'Mr3' \n",
    "testFor = 'r30'\n",
    "timeSteps = 10\n",
    "tType = testFor[0]\n",
    "\n",
    "data = data.drop(columns=['FT'])#,'FT.1'])\n",
    "dataTRAIN = dataTRAIN.drop(columns=['FT','FT.1'])\n",
    "#CALENDAR\n",
    "#--------------------------------------\n",
    "#SOLUTION------------------------------\n",
    "match testFor:\n",
    "    case 'r1':\n",
    "        data = data.drop(columns=['r2','r3','r5','r10','r15','r30','r60'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r2','r3','r5','r10','r15','r30','r60'])\n",
    "    case 'r2':\n",
    "        data = data.drop(columns=['r1','r3','r5','r10','r15','r30','r60'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r1','r3','r5','r10','r15','r30','r60'])\n",
    "    case 'r3':\n",
    "        data = data.drop(columns=['r1','r2','r5','r10','r15','r30','r60'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r1','r2','r5','r10','r15','r30','r60'])\n",
    "    case 'r5':\n",
    "        data = data.drop(columns=['r1','r2','r3','r10','r15','r30','r60'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r1','r2','r3','r10','r15','r30','r60'])\n",
    "    case 'r10':\n",
    "        data = data.drop(columns=['r1','r2','r3','r5','r15','r30','r60'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r1','r2','r3','r5','r15','r30','r60'])\n",
    "    case 'r15':\n",
    "        data = data.drop(columns=['r1','r2','r3','r5','r10','r30','r60'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r1','r2','r3','r5','r10','r30','r60'])\n",
    "    case 'r30':\n",
    "        data = data.drop(columns=['r1','r2','r3','r5','r10','r15','r60'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r1','r2','r3','r5','r10','r15','r60'])\n",
    "    case 'r60':\n",
    "        data = data.drop(columns=['r1','r2','r3','r5','r10','r15','r30'])\n",
    "        dataTRAIN = dataTRAIN.drop(columns=['r1','r2','r3','r5','r10','r15','r30'])\n",
    "\n",
    "\n",
    "#confirming X and Y features post training\n",
    "Xfeatures = data.columns[:-1]\n",
    "Yfeatures = data.columns[-1]\n",
    "XTRAINfeatures = dataTRAIN.columns[:-1]\n",
    "YTRAINfeatures = dataTRAIN.columns[-1]\n",
    "print(\"TESTED FEATURES: \")\n",
    "print(Xfeatures)\n",
    "print(\"TESTING FOR: \")\n",
    "print(Yfeatures)\n",
    "print(\"TRAINED FEATURES: \")\n",
    "print(XTRAINfeatures)\n",
    "print(\"TRAINED FOR: \")\n",
    "print(YTRAINfeatures)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "XTRAIN = dataTRAIN.iloc[:, :-1].values\n",
    "yTRAIN = dataTRAIN.iloc[:, -1].values\n",
    "\n",
    "X = normalize_from_tt_split(X, XTRAIN, 0.2)\n",
    "XTRAIN = normalize_from_tt_split(XTRAIN, XTRAIN, 0.2)\n",
    "X = reform_with_PCA_isolated(X, XTRAIN, 0.2, 3, 10)\n",
    "X = reformat_to_lstm(X, timeSteps)\n",
    "\n",
    "y = y[timeSteps:]\n",
    "y = np.array(y)\n",
    "\n",
    "XTRAIN = reformat_to_lstm(XTRAIN, timeSteps)\n",
    "yTRAIN = yTRAIN[timeSteps:]\n",
    "yTRAIN = np.array(yTRAIN)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "t0930 = -0.32007092\n",
    "t1045 = -0.141503587\n",
    "t1200 = 0.03706375\n",
    "t1600 = 10\n",
    "\n",
    "\n",
    "X, y = remove_zero_mo_samples(X, y, timeSteps)\n",
    "X, y = remove_extra_filter(X, y, timeSteps, t0930, t1045)\n",
    "\n",
    "X = X[:,:,:-1]\n",
    "#XTRAIN, yTRAIN = remove_zero_mo_samples(XTRAIN, yTRAIN)\n",
    "\n",
    "print('X shape == {}.'.format(X.shape))\n",
    "print('y shape == {}.'.format(y.shape))\n",
    "\n",
    "from keras.saving import get_custom_objects\n",
    "from keras.saving import register_keras_serializable\n",
    "get_custom_objects().clear()\n",
    "#CUSTOM LOSS 1_______________________________________________________________________________________________\n",
    "from keras.src import ops\n",
    "from keras.src.losses.loss import squeeze_or_expand_to_same_rank\n",
    "@register_keras_serializable(name=\"skew_loss\")\n",
    "def skew_loss(y_true,y_pred,sFact=4):\n",
    "    #return ops.mean(ops.square((y_pred-y_true)*(1+sFact*tf.cast(((y_true>0 & y_pred<y_true) | (y_true<0 & y_pred>y_true)),tf.float32))),axis=-1)\n",
    "    y_pred = ops.convert_to_tensor(y_pred)\n",
    "    y_true = ops.convert_to_tensor(y_true, dtype=y_pred.dtype)\n",
    "    #y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n",
    "    error = ops.subtract(y_pred, y_true)\n",
    "    a = ops.convert_to_tensor(ops.cast(y_pred > 0,tf.float32), dtype=tf.float32)\n",
    "    b = ops.convert_to_tensor(ops.cast(y_pred < 0,tf.float32), dtype=tf.float32)\n",
    "    c = ops.convert_to_tensor(ops.cast(y_true >= y_pred,tf.float32), dtype=tf.float32)\n",
    "    d = ops.convert_to_tensor(ops.cast(y_true <= y_pred,tf.float32), dtype=tf.float32)\n",
    "    h = ops.convert_to_tensor(0.1, dtype=error.dtype)\n",
    "    return ops.mean(\n",
    "        ops.where(\n",
    "            a*c+b*d==1,# or (b and d),\n",
    "            h*ops.square(error),\n",
    "            ops.square(error)\n",
    "        ))\n",
    "\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('r30_PCA10_2.keras')#----------------------------------------------------------------------\n",
    "#loaded_model.compile(optimizer='adam',\n",
    "#                  loss='mse'\n",
    "#                  ,metrics=['R2Score','root_mean_squared_error'])\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = loaded_model.predict(X) \n",
    "\n",
    "s_kws = {'s':2,'color':'maroon'}\n",
    "l_kws = {'lw':1,'color':'maroon'}\n",
    "\n",
    "import seaborn as sns\n",
    "y_pred = np.squeeze(y_pred)\n",
    "y = np.squeeze(y)\n",
    "ys = pd.DataFrame({\"y_pred\":y_pred,\"y_true\":y})\n",
    "#data.insert(1, \"y_pred\", y_pred, True)\n",
    "# plot 1 with axes level-plot\n",
    "'''\n",
    "g = sns.lmplot(data=ys,x=\"y_pred\", y=\"y_true\", scatter_kws=s_kws,line_kws=l_kws)#, hue=\"MO\")\n",
    "plt.axis('tight')\n",
    "plt.grid()\n",
    "plt.title('Testing Outputs')\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel(testFor)\n",
    "plt.xlim(-.25,.25)\n",
    "plt.ylim(-.25,.25)\n",
    "plt.show()\n",
    "'''\n",
    "g = sns.lmplot(data=ys,x=\"y_pred\", y=\"y_true\", scatter_kws=s_kws, line_kws=l_kws)#,hue=\"MO\")\n",
    "plt.title('Zoomed in graph')\n",
    "plt.grid()\n",
    "y_min, y_max = ys['y_true'].min(), ys['y_true'].max()\n",
    "plt.ylim(y_min, y_max)\n",
    "x_center = np.mean(ys['y_pred'])\n",
    "y_range = y_max - y_min\n",
    "x_min = x_center - y_range / 2\n",
    "x_max = x_center + y_range / 2\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.show()\n",
    "\n",
    "#DIRECTIONAL ACCURACY #DIRECTIONAL ACCURACY  #DIRECTIONAL ACCURACY  #DIRECTIONAL ACCURACY  #DIRECTIONAL ACCURACY  \n",
    "specGuess = .35\n",
    "frac = 100\n",
    "fracf = 1/frac\n",
    "specAcc, locSpecAcc = [], []\n",
    "valCount, locValCount = [], []\n",
    "locMean = []\n",
    "locStd = []\n",
    "sameDirAvg, sameDirMax, sameDirMin = [], [], []\n",
    "diffDirAvg, diffDirMax, diffDirMin = [], [], []\n",
    "locSameDirAvg, locSameDirMax, locSameDirMin = [], [], []\n",
    "locDiffDirAvg, locDiffDirMax, locDiffDirMin = [], [], []\n",
    "for v in range(0,int(specGuess*frac)):\n",
    "    tp, fp, tn, fn, tpL, fpL, tnL, fnL = 0, 0, 0, 0, 0, 0, 0, 0\n",
    "    valCnt = 0\n",
    "    locValCnt = 0\n",
    "    allTmp = []\n",
    "    sameTmp, diffTmp = [], []\n",
    "    locSameTmp, locDiffTmp = [], []\n",
    "    y_pred = ys['y_pred']\n",
    "    y_test = ys['y_true']\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i]>=(v/frac)):\n",
    "            valCnt+=1\n",
    "            if(y_test[i]>0):\n",
    "                tp+=1\n",
    "                sameTmp.append(abs(y_test[i]))\n",
    "            if(y_test[i]<0):\n",
    "                fp+=1\n",
    "                diffTmp.append(abs(y_test[i]))\n",
    "            if(y_pred[i]<(v/frac)+(1/frac)):\n",
    "                locValCnt+=1\n",
    "                if(y_test[i]>0):\n",
    "                    tpL+=1\n",
    "                    locSameTmp.append(abs(y_test[i]))\n",
    "                if(y_test[i]<0):\n",
    "                    fpL+=1\n",
    "                    locDiffTmp.append(abs(y_test[i]))\n",
    "        if(y_pred[i]<=-(v/frac)):\n",
    "            valCnt+=1\n",
    "            if(y_test[i]<0):\n",
    "                tn+=1\n",
    "                sameTmp.append(abs(y_test[i]))\n",
    "            if(y_test[i]>0):\n",
    "                fn+=1\n",
    "                diffTmp.append(abs(y_test[i]))\n",
    "            if(y_pred[i]>-(v/frac)-(1/frac)):\n",
    "                locValCnt+=1\n",
    "                if(y_test[i]<0):\n",
    "                    tnL+=1\n",
    "                    locSameTmp.append(abs(y_test[i]))\n",
    "                if(y_test[i]>0):\n",
    "                    fnL+=1\n",
    "                    locDiffTmp.append(abs(y_test[i]))\n",
    "    if((tp+fp+tn+fn)<1):\n",
    "        break\n",
    "    \n",
    "\n",
    "    if(len(sameTmp)>0 and len(diffTmp)>0):\n",
    "        allTmp = locSameTmp.copy()\n",
    "        locDiffTmp = np.multiply(locDiffTmp, -1)\n",
    "        for i in range(len(locDiffTmp)):\n",
    "            allTmp.append(locDiffTmp[i])\n",
    "        locMean.append(np.average(allTmp))\n",
    "        locStd.append(np.std(allTmp))\n",
    "        locDiffTmp = np.multiply(locDiffTmp, -1)\n",
    "    else:\n",
    "        locMean.append(locMean[-1])\n",
    "        locStd.append(locStd[-1])\n",
    "\n",
    "    if(len(locSameTmp)!=0):\n",
    "        sameDirAvg.append(np.average(sameTmp))\n",
    "        sameDirMax.append(np.max(sameTmp))\n",
    "        sameDirMin.append(np.min(sameTmp))\n",
    "        locSameDirAvg.append(np.average(locSameTmp))\n",
    "        locSameDirMax.append(np.max(locSameTmp))\n",
    "        locSameDirMin.append(np.min(locSameTmp))\n",
    "    else:\n",
    "        sameDirAvg.append(0.0)\n",
    "        sameDirMax.append(0.01)\n",
    "        sameDirMin.append(0.01)\n",
    "        locSameDirAvg.append(0.01)\n",
    "        locSameDirMax.append(0.01)\n",
    "        locSameDirMin.append(0.01)\n",
    "    if(len(locDiffTmp)!=0):\n",
    "        diffDirAvg.append(np.average(diffTmp))\n",
    "        diffDirMax.append(np.max(diffTmp))\n",
    "        diffDirMin.append(np.min(diffTmp))\n",
    "        locDiffDirAvg.append(np.average(locDiffTmp))\n",
    "        locDiffDirMax.append(np.max(locDiffTmp))\n",
    "        locDiffDirMin.append(np.min(locDiffTmp))\n",
    "    else:\n",
    "        diffDirAvg.append(0.01)\n",
    "        diffDirMax.append(0.01)\n",
    "        diffDirMin.append(0.01)\n",
    "        locDiffDirAvg.append(0.01)\n",
    "        locDiffDirMax.append(0.01)\n",
    "        locDiffDirMin.append(0.01)\n",
    "    directionalAccuracy = ((tp+tn)/(tp+fp+tn+fn))*10000//1/100\n",
    "    specAcc.append(directionalAccuracy)\n",
    "    valCount.append(valCnt)\n",
    "    if((tpL+fpL+tnL+fnL) > 0):\n",
    "        localDirectionalAccuracy = ((tpL+tnL)/(tpL+fpL+tnL+fnL))*10000//1/100\n",
    "        locSpecAcc.append(localDirectionalAccuracy)\n",
    "        locValCount.append(locValCnt)\n",
    "    else:\n",
    "        locSpecAcc.append(locSpecAcc[-1])\n",
    "        locValCount.append(0)\n",
    "    #print(f'Directional Accuracy >(+/-){v/2}:\\t',directionalAccuracy5guess)\n",
    "#print('Directional Accuracy:\\t\\t',directionalAccuracy)\n",
    "valCount = [x / valCount[0] * 100 for x in valCount]\n",
    "locValCount = [x / locValCount[0] * 100 for x in locValCount]\n",
    "\n",
    "std2 = np.multiply(locStd, 2)\n",
    "std0 = np.multiply(locStd, 0)\n",
    "yerr = [std2,std0]\n",
    "plt.title('Mean Move and Standard Deviations per Predicted Value')\n",
    "plt.xlabel('> (+/-) Prediction Value')\n",
    "plt.errorbar(np.arange(0,(1/frac)*len(specAcc),(1/frac)), locMean, yerr=yerr, capsize=3, ecolor = \"gray\", elinewidth=1, markeredgewidth='1',markersize=2)\n",
    "plt.errorbar(np.arange(0,(1/frac)*len(specAcc),(1/frac)), locMean, locStd, capsize=3, ecolor = \"black\", elinewidth=1, markeredgewidth='1',markersize=2)\n",
    "plt.axhline(0,color='black')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18, 9))\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), specAcc, 'maroon', label='Directional Accuracy')\n",
    "plt.scatter(np.arange(0,(1/frac)*len(specAcc),(1/frac)), specAcc, s=5, color='maroon')\n",
    "plt.plot(np.arange(0,(1/frac)*len(locSpecAcc),(1/frac)), locSpecAcc, 'red', label='Directional Accuracy')\n",
    "plt.scatter(np.arange(0,(1/frac)*len(locSpecAcc),(1/frac)), locSpecAcc, s=5, color='red')\n",
    "plt.title(f'Directional Accuracy Percentage Outside of given Predicted Value\\n(With Percentage of {len(X)} Samples)')\n",
    "plt.xlabel('> (+/-) Prediction Value')\n",
    "plt.ylabel('Percent')\n",
    "plt.grid()\n",
    "plt.legend(['Directional Accuracy','S- Samples\\nA- Accuracy','Local Directional Accuracy'], loc='upper left')\n",
    "for x, y in zip(np.arange(0,(1/frac)*len(specAcc),(1/frac)), specAcc):\n",
    "    plt.annotate(f'{float(valCount[int(x*frac)]*10//1/10)}%S\\n{float(specAcc[int(x*frac)])}%A', color='black', xy=(x, y-2), fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Average Move by Directional Accuracy')\n",
    "plt.xlabel('> (+/-) Prediction Value')\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), locSameDirAvg, '#bbbbbb', label='Directional Accuracy')\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), sameDirAvg, 'maroon', label='Directional Accuracy')\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), locDiffDirAvg, '#bbbbbb', label='Directional Accuracy')\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), diffDirAvg, 'purple', label='Directional Accuracy')\n",
    "plt.grid()\n",
    "plt.legend(['Accurate','Accurate - Local','Inaccurate','Inaccurate - Local'], loc='upper left')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('P/L Ratio')\n",
    "plt.xlabel('> (+/-) Prediction Value')\n",
    "plt.grid()\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)),np.divide(sameDirAvg,diffDirAvg), 'blue')\n",
    "plt.legend(['P/L Ratio'], loc='upper left')\n",
    "plt.ylim(0,6)\n",
    "plt.show()\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Highest and Lowest of\\nDirectionally Accurate Moves')\n",
    "plt.xlabel('> (+/-) Prediction Value')\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), sameDirMax, 'maroon', label='Directional Accuracy')\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), sameDirMin, 'maroon', label='Directional Accuracy')\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Highest and Lowest of\\nDirectionally Inaccurate Moves')\n",
    "plt.xlabel('> (+/-) Prediction Value')\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), diffDirMax, 'purple', label='Directional Accuracy')\n",
    "plt.plot(np.arange(0,(1/frac)*len(specAcc),(1/frac)), diffDirMin, 'purple', label='Directional Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()\n",
    "#print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catReform = pd.read_csv('catted_12day.csv')\n",
    "print(y_pred)\n",
    "print((y_pred.shape))\n",
    "#y_pred = y_pred.to_numpy()\n",
    "print(type(y_pred))\n",
    "y_pred = np.insert(y_pred, 0, 0, axis=0)\n",
    "y_pred = np.insert(y_pred, 0, 0, axis=0)\n",
    "y_pred = np.insert(y_pred, 0, 0, axis=0)\n",
    "y_pred = np.insert(y_pred, 0, 0, axis=0)\n",
    "y_pred = np.insert(y_pred, 0, 0, axis=0)\n",
    "#y_pred = np.append(y_pred, -1, 0, axis=0)\n",
    "y_pred = pd.Series(y_pred)\n",
    "catReform['Dr3_Model'] = y_pred\n",
    "print(catReform.tail(5))\n",
    "catReform.to_csv('catted_12day_Dr3Model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.Series(y_pred)\n",
    "catReform['Dr3_Model'] = y_pred\n",
    "print(catReform.tail(5))\n",
    "catReform.to_csv('catted_1_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catReform.to_csv('catted_12day_Dr3Model.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPolish = pd.read_csv('catted_12day_Dr3Model.csv')\n",
    "cols = ['FT','vel5','vel10','vel15','vel30','vel60','acc5','acc10','acc15','acc30','acc60','stoch12','stochDiff6012','RSIhl_diff','RSIhl_diffROC','vol','vol10','vol15','vol30','vol60','volD10','volD15','volD30','volD60','vpm5','vpm10','vpm15','vpm30','vpm60','ToD','DoW','MO','Dr3_Model','Dr3','Dc1','Dc3','Dr1','Mc1','Mc3','Mr1','Mr3']\n",
    "dataPolish = dataPolish.reindex(columns=cols)\n",
    "#dataPolish = dataPolish.drop(columns=['YM_diff','NQ_diff','volNQdiff','volYMdiff'])\n",
    "dataPolish.to_csv('catted_12day_Dr3Model.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data, diag_kind=\"kde\", plot_kws={'alpha':0.2})  # 'kde' for smoother diagonal plots\n",
    "plt.suptitle('Pairplot of Feature Relationships', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.describe())  # Summary statistics\n",
    "print(data.info())      # Column info, data types, and null counts\n",
    "print(dataTRAIN.describe())  # Summary statistics\n",
    "print(dataTRAIN.info())      # Column info, data types, and null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "\n",
    "X_ = data.iloc[:, :-1].values\n",
    "y_ = data.iloc[:, -1].values\n",
    "\n",
    "X_new = pca.fit_transform(X_)\n",
    "\n",
    "print(pca.get_covariance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.bar(range(36), explained_variance, alpha=0.5, align='center',\n",
    "        label='individual explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "pca = PCA(n_components = 16)\n",
    "pca.fit(X_)\n",
    "X_new = pca.transform(X_)\n",
    "\n",
    "\n",
    "retained_variance = np.sum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Step 3: Calculate percent data loss\n",
    "data_loss = (1 - retained_variance) * 100\n",
    "\n",
    "print(f\"Retained Variance: {retained_variance * 100:.2f}%\")\n",
    "print(f\"Data Loss: {data_loss:.2f}%\")\n",
    "\n",
    "X_train_new, X_test_new, y_train, y_test = \\\n",
    "    train_test_split(X_new, y_, test_size = 0.1, random_state=0, shuffle=False)\n",
    "\n",
    "knn_pca = KNeighborsRegressor(64)\n",
    "knn_pca.fit(X_train_new,y_train)\n",
    "print(\"Train score after PCA\", knn_pca.score(X_train_new,y_train), \"%\")\n",
    "print(\"Test score after PCA\", knn_pca.score(X_test_new,y_test), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler1.fit(X_)\n",
    "#X_ = scaler1.transform(X_)\n",
    "scaler1.fit(X_)\n",
    "X_ = scaler1.transform(X_)\n",
    "\n",
    "data_loss = []\n",
    "for i in range(16):\n",
    "    pca = PCA(n_components = i+1)\n",
    "    pca.fit(X_)\n",
    "    X_new = pca.transform(X_)\n",
    "    retained_variance = np.sum(pca.explained_variance_ratio_)\n",
    "    data_loss.append(retained_variance)\n",
    "\n",
    "plt.plot(range(16), data_loss, color='maroon')\n",
    "plt.grid()\n",
    "plt.ylim(.9,1)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
