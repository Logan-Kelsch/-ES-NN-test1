{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JJ McCauley + LOGAN KELSCH \n",
    "\n",
    "#IMPORT LIBRARIES-------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from funcs_data_preprocess import *\n",
    "\n",
    "#hahaha dont turn this on with high epoch or else\n",
    "#tf.config.experimental.set_memory_growth\n",
    "\n",
    "#LOAD DATA FROM CSV-------------------------------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "data_csv_ripped = pd.read_csv('catted_1-8.csv')\n",
    "\n",
    "print(f\"TEMP CUTOUT:\\n\\tTOTAL FEATURES CUT -\\n\\t\\t{len(data_csv_ripped.iloc[int(len(data_csv_ripped)*.9):])}\")\n",
    "\n",
    "data = data_csv_ripped.iloc[:int(len(data_csv_ripped)*.9)]\n",
    "\n",
    "testFor = 'r30'\n",
    "timeSteps = 10\n",
    "tType = testFor[0]\n",
    "#testing random feature drops\n",
    "#TREND\n",
    "\n",
    "data = data.drop(columns=['FT','FT.1'])\n",
    "#data = data.drop(columns=['FT'])\n",
    "#--------------------------------------\n",
    "#targets-------------------------------\n",
    "#r----  1   2   3   5   10  15  30  60\n",
    "data = target_setter(data, testFor)\n",
    "#data['Dr3_Model'] = 0\n",
    "#confirming X and Y features post training\n",
    "Xfeatures = data.columns[:-1]\n",
    "Yfeatures = data.columns[-1]\n",
    "print(\"TESTED FEATURES: \")\n",
    "print(Xfeatures)\n",
    "print(\"TESTING FOR: \")\n",
    "print(Yfeatures)\n",
    "#PROCESS THE DATA-------------------------------------------------------\n",
    "\n",
    "# Separate features and target\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "'''\n",
    "    here is where I will implement PCA.\n",
    "    This text block is the explanation for the\n",
    "        requirements - of using PCA in this function\n",
    "        Overview - of the rest of data prep in this file\n",
    "\n",
    "    Requirements:\n",
    "        -   we will have to seperate off any time datapoints that are\n",
    "            essential for proper data filtering before testing.\n",
    "            -   This will include market open or time of day,\n",
    "                This is so that the PCA transformation can be\n",
    "                applied to the dataset, tod and mo can be appended back on,\n",
    "                dataset can be normalized.\n",
    "    \n",
    "    Overview:\n",
    "        -   normalize dataset\n",
    "        -   deattach TOD and MO\n",
    "        -   apply PCA function to rest of dataset\n",
    "        -   append TOD and MO to dataset\n",
    "        -   create lstm\n",
    "        -   filter out unwanted data (market closed ,, afternoon)\n",
    "        -   consider shuffling ONLY train data if you can shuffle after each epoch\n",
    "\n",
    "    Logan Kelsch\n",
    "'''\n",
    "test_size       = 0.2\n",
    "num_isol_feats  = 3\n",
    "comps_PCA       = 10\n",
    "\n",
    "#normalized values\n",
    "t0930           = -0.32007092\n",
    "t1045           = -0.141503587\n",
    "t1200           = 0.03706375\n",
    "\n",
    "X = normalize_from_tt_split(X, X, test_size)\n",
    "X = reform_with_PCA_isolated(X, X, test_size, num_isol_feats, comps_PCA)\n",
    "X = reformat_to_lstm(X, timeSteps)\n",
    "\n",
    "y = y[timeSteps:]\n",
    "y = np.array(y)\n",
    "\n",
    "print('\\nX shape == {}.'.format(X.shape))\n",
    "print('y shape == {}.\\n'.format(y.shape))\n",
    "\n",
    "\n",
    "\n",
    "print(f'Raw Sample Count:\\t{len(X)}')\n",
    "X, y = remove_zero_mo_samples(X, y, timeSteps)\n",
    "X, y = remove_extra_filter(X, y, timeSteps, t0930, t1200)\n",
    "print(f'Remaining Sample Count:\\t{len(X)}')\n",
    "\n",
    "X = X[:,:,:-1]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "\n",
    "#to remove overlapping values that were left from training set\n",
    "X_test = X_test[timeSteps:]\n",
    "y_test = y_test[timeSteps:]\n",
    "\n",
    "print('\\nX_train shape == {}.'.format(X_train.shape))\n",
    "print('y_train shape == {}.'.format(y_train.shape))\n",
    "print('X_test shape == {}.'.format(X_test.shape))\n",
    "print('y_test shape == {}.\\n'.format(y_test.shape))\n",
    "\n",
    "\n",
    "#LEARNING RATES____________________________________________________________________________________________\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "lr_schedule = ExponentialDecay(\n",
    "    #good rough val to start, .25, good val to end at .0015.\n",
    "    #5k epoch should be: .25, 8565, .9995, true\n",
    "    0.01,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.997,\n",
    "    staircase=True)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.95, \n",
    "    patience=10, \n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "#LOSS FUNCTION\n",
    "from keras.saving import get_custom_objects\n",
    "from keras.saving import register_keras_serializable\n",
    "get_custom_objects().clear()\n",
    "#CUSTOM LOSS 1_______________________________________________________________________________________________\n",
    "from keras.src import ops\n",
    "from keras.src.losses.loss import squeeze_or_expand_to_same_rank\n",
    "@register_keras_serializable(name=\"skew_loss\")\n",
    "def skew_loss(y_true,y_pred,sFact=4):\n",
    "    #return ops.mean(ops.square((y_pred-y_true)*(1+sFact*tf.cast(((y_true>0 & y_pred<y_true) | (y_true<0 & y_pred>y_true)),tf.float32))),axis=-1)\n",
    "    y_pred = ops.convert_to_tensor(y_pred)\n",
    "    y_true = ops.convert_to_tensor(y_true, dtype=y_pred.dtype)\n",
    "    #y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n",
    "    error = ops.subtract(y_pred, y_true)\n",
    "    a = ops.convert_to_tensor(ops.cast(y_pred > 0,tf.float32), dtype=tf.float32)\n",
    "    b = ops.convert_to_tensor(ops.cast(y_pred < 0,tf.float32), dtype=tf.float32)\n",
    "    c = ops.convert_to_tensor(ops.cast(y_true >= y_pred*.9,tf.float32), dtype=tf.float32)\n",
    "    d = ops.convert_to_tensor(ops.cast(y_true <= y_pred*.9,tf.float32), dtype=tf.float32)\n",
    "    e = ops.convert_to_tensor(ops.cast(y_true > 0,tf.float32), dtype=tf.float32)\n",
    "    f = ops.convert_to_tensor(ops.cast(y_true < 0,tf.float32), dtype=tf.float32)\n",
    "    #e = ops.convert_to_tensor(ops.cast(y_true >= 0.05,tf.float32), dtype=tf.float32)\n",
    "    #f = ops.convert_to_tensor(ops.cast(y_true <= -0.05,tf.float32), dtype=tf.float32)\n",
    "    h = ops.convert_to_tensor(2, dtype=error.dtype)\n",
    "    return ops.mean(\n",
    "        ops.where(\n",
    "            a*f+b*e==1,# or (b and d),\n",
    "            h*ops.square(error),\n",
    "            ops.square(error)\n",
    "        ))\n",
    "\n",
    "opt1 = SGD(learning_rate=0.01)\n",
    "opt2  = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "opt3 = SGD(learning_rate=lr_schedule)\n",
    "opt4 = SGD(learning_rate=0.01, momentum=0.9)\n",
    "opt5 = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#BUILD AND LOAD MODEL__________________________________________________________________________________________\n",
    "\n",
    "\n",
    "#print(X_train.shape[0]/time_steps)\n",
    "#X_train = np.reshape(X_train,((X_train.shape[0]//time_steps), time_steps, 35))  # Reshape to (batch_size, 5 time steps, 35 features)\n",
    "#y_train = y.reshape(1,-1)\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def build_LSTM_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(X_train.shape[1],X_train.shape[2])),\n",
    "        #tf.keras.layers.LSTM(256, activation='tanh', recurrent_dropout=0.3, return_sequences=True),#, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        tf.keras.layers.LSTM(128, activation='tanh', recurrent_dropout=0.2, return_sequences=False),#, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),#,kernel_initializer='he_normal',kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        #tf.keras.layers.Dropout(0.3),\n",
    "        #tf.keras.layers.Dense(32, activation='relu'),#,kernel_initializer='he_normal',kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=opt4,\n",
    "                  loss='mse'\n",
    "                  ,metrics=['R2Score','root_mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "def load_model():\n",
    "    #loaded_model = tf.keras.models.load_model('tupleTrain.keras', custom_objects={'custom_loss':custom_loss})\n",
    "    loaded_model = tf.keras.models.load_model('r30_10s_LSTM_8.keras')\n",
    "    loaded_model.compile(optimizer=opt4,\n",
    "                         loss=skew_loss\n",
    "                         , metrics=['R2Score','root_mean_squared_error'])\n",
    "    return loaded_model\n",
    "\n",
    "#TRAIN THE MODEL WITH CUSTOMIZABLE EPOCHS-------------------------------------------------------\n",
    "\n",
    "epochs = 2000\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=31, mode='min', restore_best_weights=True)\n",
    "\n",
    "cmp = 'C'\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    cmp = 'G'\n",
    "    pass\n",
    "with tf.device('/'+cmp+'PU:0'):\n",
    "    print('Running on: '+cmp+'PU\\n')\n",
    "    model = build_LSTM_model()\n",
    "    #loaded_model = load_model()\n",
    "    used_model = model\n",
    "    history = used_model.fit(X_train, y_train, epochs=epochs,\\\n",
    "                        shuffle=True, verbose=1, validation_data=(X_test, y_test),\\\n",
    "                        batch_size=10,callbacks=[reduce_lr, early_stopping])\n",
    "\n",
    "#EVALUATE THE MODEL AND VISUALIZE RESULTS-------------------------------------------------------\n",
    "\n",
    "#show_all_results(used_model, history, X_test, y_test)\n",
    "\n",
    "# LOSS\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, history.history['loss'], 'y', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "# ACCURACY\n",
    "\n",
    "plt.plot(epochs, history.history['R2Score'], 'y', label='Training R2')\n",
    "plt.plot(epochs, history.history['val_R2Score'], 'r', label='Validation R2')\n",
    "plt.title('Training and Validation R2Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R2Score')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#predicting the test set results\n",
    "y_pred = used_model.predict(X_test) \n",
    "\n",
    "\n",
    "plt.scatter(y_pred, y_test, s=1)\n",
    "plt.axis('tight')\n",
    "plt.title('Testing Outputs')\n",
    "plt.xlabel('y_pred')\n",
    "plt.xlim(-.25,.25)\n",
    "plt.ylim(-.25,.25)\n",
    "plt.ylabel('y_test')\n",
    "ax = plt.gca()\n",
    "x_vals = np.array(ax.get_xlim())\n",
    "y_vals = x_vals  # Since y = x\n",
    "plt.plot(x_vals, y_vals, '-', color='black', label='y = x', linewidth=0.5)\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.axvline(0,color='black',linewidth=0.5)\n",
    "plt.show()\n",
    "\n",
    "#SCATTERPLOT #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  \n",
    "plt.scatter(y_pred, y_test, s=1)\n",
    "plt.grid()\n",
    "plt.axis('tight')\n",
    "plt.title('Testing Outputs')\n",
    "plt.xlabel('y_pred')\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-1,1)\n",
    "plt.ylabel('y_test')\n",
    "ax = plt.gca()\n",
    "x_vals = np.array(ax.get_xlim())\n",
    "y_vals = x_vals  # Since y = x\n",
    "plt.plot(x_vals, y_vals, '-', color='black', label='y = x', linewidth=0.5)\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.axvline(0,color='black',linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_model.save('r30_PCA10_4.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def walk_forward_validation(X, y, model, n_splits=20, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Perform walk-forward validation for an LSTM model.\n",
    "\n",
    "    Parameters:\n",
    "    X (np.ndarray): 3D array of features with shape (n_samples, time_steps, n_features)\n",
    "    y (np.ndarray): 1D array of labels with shape (n_samples,)\n",
    "    model (tf.keras.Model): Compiled LSTM model\n",
    "    n_splits (int): Number of walk-forward splits\n",
    "    test_size (float): Proportion of the data to use as the test set in each split\n",
    "\n",
    "    Returns:\n",
    "    list: MSE scores for each split\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    test_set_size = int(test_size * n_samples)\n",
    "    \n",
    "    mse_scores = []\n",
    "\n",
    "    # Split the data into n_splits segments\n",
    "    for i in range(n_splits):\n",
    "        # Define the index range for the training set (everything before the test set)\n",
    "        train_end = int((i + 1) * (n_samples - test_set_size) / n_splits)\n",
    "\n",
    "        # Define the test set\n",
    "        X_train, X_test = X[:train_end], X[train_end:train_end + test_set_size]\n",
    "        y_train, y_test = y[:train_end], y[train_end:train_end + test_set_size]\n",
    "\n",
    "        # Ensure that your model is recompiled and retrained in each fold\n",
    "        model_copy = tf.keras.models.load_model(model)\n",
    "        model_copy.compile(optimizer='adam', loss='mse')  # Assuming MSE for regression\n",
    "\n",
    "        # Fit the model on the current training set\n",
    "        model_copy.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = model_copy.predict(X_test)\n",
    "\n",
    "        # Calculate the mean squared error for this fold\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "        print(f'Fold {i+1}/{n_splits}, MSE: {mse}')\n",
    "\n",
    "    return mse_scores\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have already defined `X`, `y`, and compiled your LSTM model\n",
    "# mse_scores = walk_forward_validation(X, y, lstm_model, n_splits=5, test_size=0.2)\n",
    "X_vals = X_test\n",
    "y_vals = y_test\n",
    "print('X shape:',X_vals.shape,'\\ny shape:',y_vals.shape)\n",
    "scores = walk_forward_validation(X_test, y_test, 'LSTM_testtest.keras')\n",
    "avgScore = 0\n",
    "for score in scores:\n",
    "    avgScore+=score\n",
    "avgScore/=len(scores)\n",
    "\n",
    "print('Average MSE:',avgScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(\"r30_PCA10_1.keras\")\n",
    "\n",
    "y_pred = new_model.predict(X_test) \n",
    "\n",
    "\n",
    "plt.scatter(y_pred, y_test, s=1)\n",
    "plt.axis('tight')\n",
    "plt.title('Testing Outputs')\n",
    "plt.xlabel('y_pred')\n",
    "plt.xlim(-.25,.25)\n",
    "plt.ylim(-.25,.25)\n",
    "plt.ylabel('y_test')\n",
    "ax = plt.gca()\n",
    "x_vals = np.array(ax.get_xlim())\n",
    "y_vals = x_vals  # Since y = x\n",
    "plt.plot(x_vals, y_vals, '-', color='black', label='y = x', linewidth=0.5)\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.axvline(0,color='black',linewidth=0.5)\n",
    "plt.show()\n",
    "\n",
    "#SCATTERPLOT #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  #SCATTERPLOT  \n",
    "plt.scatter(y_pred, y_test, s=1)\n",
    "plt.grid()\n",
    "plt.axis('tight')\n",
    "plt.title('Testing Outputs')\n",
    "plt.xlabel('y_pred')\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-1,1)\n",
    "plt.ylabel('y_test')\n",
    "ax = plt.gca()\n",
    "x_vals = np.array(ax.get_xlim())\n",
    "y_vals = x_vals  # Since y = x\n",
    "plt.plot(x_vals, y_vals, '-', color='black', label='y = x', linewidth=0.5)\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.axvline(0,color='black',linewidth=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
