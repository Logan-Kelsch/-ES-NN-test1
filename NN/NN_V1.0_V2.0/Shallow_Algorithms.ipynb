{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Stock Market Analyzer (Expirements)\n",
    "Actual trading scripts will be later implemented (potentially through a seperate program). As of right now, this program just aims to use shallow learning models to predict trends of future prices.\n",
    "\n",
    "Potential Limitations/Bottlenecks: Yahoo API support for small intervals & rate limiting for large datasets\n",
    "\n",
    "#### Necessary Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Deep Learning Models - Will be held in a seperate Jupyter Notebook for organizational purposes'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- Data Collection/Cleaning/Preparation -- \n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "''' Shallow Learning Models '''\n",
    "\n",
    "# Testing Accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score #Regression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix #Classification\n",
    "\n",
    "# Simple Linear Regression (Predicting Values)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# SGD Regression (Predicting Values)\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Ridge Regression (Predicting Values, assuming <100k samples)\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "# SVR Regression (Predicting Values, kernel dependant on sample size)\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# SGD Classifier (Classifying movement, assuming >100k samples)\n",
    "from sklearn.linear_model import SGDClassifier #(Be careful with feature scaling)\n",
    "\n",
    "# Kernel Approximation (Classifying movement, assuming >100k samples)\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.kernel_approximation import PolynomialCountSketch #*\n",
    "\n",
    "# Linear SVC (Classifying movement, assuming <100k samples)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# KNeighbors Classification (Classifying Movement, assuming <100k samples)\n",
    "from sklearn.neighbors import KNeighborsClassifier #Could also add regressor\n",
    "\n",
    "#Decision Trees (Predicting Price & Classifying Movement, Good Visual)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "''' Deep Learning Models - Will be held in a seperate Jupyter Notebook for organizational purposes''' \n",
    "#Will utilize tensorflow, will need to learn more about first\n",
    "#Recurrent Neural Network & Convolutional Neural Network Hybrid\n",
    "#Temporal Convolutional Networks\n",
    "#Long Short-Term Memory Networks (Little Data)\n",
    "#Gated Recurrent Unit (GRU) Networks (More Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "historical_data = pd.read_csv('ES5m30d.csv')\n",
    "#TESTING FIRST FOR 15 MINUTE TRADES\n",
    "historical_data = historical_data.drop(columns='30mSD')\n",
    "\n",
    "x = historical_data.iloc[:, :-1].values  # All features\n",
    "target = historical_data.iloc[:, -1].values  # Getting the last value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to numpy array for increased efficiency. Although most models do this internally anyways, explicitly converting can reduce overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ! We could totally convert to numpy array later but for now its fine as a pandas dataframe, \n",
    "tensorflow does it internally anyways !\n",
    " \n",
    "x_df = historical_data[['open', 'prev_high', 'prev_low', 'prev_volume', 'prev_open', 'prev_close']]\n",
    "y_df = historical_data[['Close']] #Target Value to be Specified\n",
    "\n",
    "x = x_df.to_numpy()\n",
    "target = y_df.to_numpy().ravel() #Ensuring it is a 1D array '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Open Price to Predict\n",
    "Here, we will gather the most recent information for us to predict. This will need to be implemented in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Info Here (We have most_recent to work with previous values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Models - Regression\n",
    "\n",
    "#### Benchmarking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into consistent training and testing sets\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "rand_state: int = 42 #Seeding the random state, getting equal splits\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, target, test_size=0.2, random_state=42)\n",
    "def test_model(y_pred):\n",
    "    # start_time = time.time()\n",
    "    # end_time = time.time()\n",
    "    # elasped_time = end_time - start_time\n",
    "    # print(f\"Duration of Execution: {elasped_time} seconds\")\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R-Squared: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.2678294450864929\n",
      "R-Squared: 0.002285095591512021\n"
     ]
    }
   ],
   "source": [
    "#Fitting/Training the model\n",
    "lg_model = LinearRegression()\n",
    "lg_model.fit(x_train, y_train)\n",
    "#Getting & Evaluating Results\n",
    "y_pred = lg_model.predict(x_test)\n",
    "test_model(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.2671357956226852\n",
      "R-Squared: 0.0028309611345138652\n"
     ]
    }
   ],
   "source": [
    "#Creating & Fitting\n",
    "sgd_model = SGDRegressor()\n",
    "sgd_model.fit(x_train, y_train)\n",
    "#Evaluating the Model\n",
    "y_pred = sgd_model.predict(x_test)\n",
    "test_model(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Ridge Model\n",
    "Will very likely not be the best solution, however could serve as an interesting benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.2700943380430596\n",
      "R-Squared: 0.0005027442914896652\n"
     ]
    }
   ],
   "source": [
    "kr_model = KernelRidge()\n",
    "kr_model.fit(x_train, y_train)\n",
    "#Evaluating\n",
    "y_pred = kr_model.predict(x_test)\n",
    "test_model(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR Regression Model\n",
    "Due to computational expendenture ( > O(n^3)), may not be optimal for exceptionally large datasets (>50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.2786741679810647\n",
      "R-Squared: -0.006249129345467619\n"
     ]
    }
   ],
   "source": [
    "svr_model = SVR() #All default values, rbf kernel type\n",
    "svr_model.fit(x_train, y_train)\n",
    "#Evaluation\n",
    "y_pred = svr_model.predict(x_test)\n",
    "test_model(y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Models - Classification\n",
    "# NEEDS REFORMATTED TO WORK WITH NEW DATASET. The way I did it doesnt actually make any sense, let alone work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refining Data for Classification\n",
    "In order to make classification clearer, a column of which can be classified must be added. For this project, I am thinking one of five scenarios:\n",
    "- Neutral (.5% change)\n",
    "- Weak Bullish (.5-4% increase)\n",
    "- Weak Bearish (.5-4% decrease)\n",
    "- Strong Bullish (4%+ increase)\n",
    "- Strong Bearish (4%+ decrease)\n",
    "\n",
    "Therefore, we need to restructure our data to include this. The specific classification conditions will need to be refined based on the interval. For example, a 3% daily movement could be considered strong, while a 3% movement could be weak over a month interval. Additionally, these will likely need to be redefined with things such as average volume, average volatility, etc.\n",
    "\n",
    "--- Dev Note ---\n",
    "\n",
    "Some sort of unsupervised model could be used to group stuff together, which could then potentially be classified? Maybe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Determining classification\n",
    "'''\n",
    "#This will need to be redone based on the ideas outlined above. For now, however, it can just be hardcoded.\n",
    "s_bull_indicator: float = 1.04 #Change needed to be considered strong bullish\n",
    "s_bear_indicator: float = .96\n",
    "w_bull_indicator: float = 1.005\n",
    "w_bear_indicator: float = .995\n",
    "#Any values out of this range will be considered neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>prev_high</th>\n",
       "      <th>prev_low</th>\n",
       "      <th>Close</th>\n",
       "      <th>prev_volume</th>\n",
       "      <th>prev_open</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094211</td>\n",
       "      <td>0.099373</td>\n",
       "      <td>0.098943</td>\n",
       "      <td>0.093781</td>\n",
       "      <td>469033600.0</td>\n",
       "      <td>0.098943</td>\n",
       "      <td>0.098943</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.087328</td>\n",
       "      <td>0.094211</td>\n",
       "      <td>0.093781</td>\n",
       "      <td>0.086898</td>\n",
       "      <td>175884800.0</td>\n",
       "      <td>0.094211</td>\n",
       "      <td>0.093781</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.089049</td>\n",
       "      <td>0.087328</td>\n",
       "      <td>0.086898</td>\n",
       "      <td>0.089049</td>\n",
       "      <td>105728000.0</td>\n",
       "      <td>0.087328</td>\n",
       "      <td>0.086898</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091630</td>\n",
       "      <td>0.089479</td>\n",
       "      <td>0.089049</td>\n",
       "      <td>0.091630</td>\n",
       "      <td>86441600.0</td>\n",
       "      <td>0.089049</td>\n",
       "      <td>0.089049</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.097223</td>\n",
       "      <td>0.092061</td>\n",
       "      <td>0.091630</td>\n",
       "      <td>0.097223</td>\n",
       "      <td>73449600.0</td>\n",
       "      <td>0.091630</td>\n",
       "      <td>0.091630</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.101954</td>\n",
       "      <td>0.097653</td>\n",
       "      <td>0.097223</td>\n",
       "      <td>0.101954</td>\n",
       "      <td>48630400.0</td>\n",
       "      <td>0.097223</td>\n",
       "      <td>0.097223</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.106257</td>\n",
       "      <td>0.102385</td>\n",
       "      <td>0.101954</td>\n",
       "      <td>0.106257</td>\n",
       "      <td>37363200.0</td>\n",
       "      <td>0.101954</td>\n",
       "      <td>0.101954</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.111849</td>\n",
       "      <td>0.106687</td>\n",
       "      <td>0.106257</td>\n",
       "      <td>0.111849</td>\n",
       "      <td>46950400.0</td>\n",
       "      <td>0.106257</td>\n",
       "      <td>0.106257</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.122173</td>\n",
       "      <td>0.112279</td>\n",
       "      <td>0.111849</td>\n",
       "      <td>0.122173</td>\n",
       "      <td>48003200.0</td>\n",
       "      <td>0.111849</td>\n",
       "      <td>0.111849</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.122604</td>\n",
       "      <td>0.122173</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>55574400.0</td>\n",
       "      <td>0.122173</td>\n",
       "      <td>0.122173</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.121313</td>\n",
       "      <td>0.124324</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.120883</td>\n",
       "      <td>93161600.0</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.117872</td>\n",
       "      <td>0.121313</td>\n",
       "      <td>0.120883</td>\n",
       "      <td>0.117442</td>\n",
       "      <td>68880000.0</td>\n",
       "      <td>0.121313</td>\n",
       "      <td>0.120883</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.118732</td>\n",
       "      <td>0.117872</td>\n",
       "      <td>0.117442</td>\n",
       "      <td>0.118732</td>\n",
       "      <td>35750400.0</td>\n",
       "      <td>0.117872</td>\n",
       "      <td>0.117442</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.116581</td>\n",
       "      <td>0.119592</td>\n",
       "      <td>0.118732</td>\n",
       "      <td>0.116151</td>\n",
       "      <td>21660800.0</td>\n",
       "      <td>0.118732</td>\n",
       "      <td>0.118732</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.111419</td>\n",
       "      <td>0.116581</td>\n",
       "      <td>0.116151</td>\n",
       "      <td>0.110988</td>\n",
       "      <td>35728000.0</td>\n",
       "      <td>0.116581</td>\n",
       "      <td>0.116151</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.106687</td>\n",
       "      <td>0.111419</td>\n",
       "      <td>0.110988</td>\n",
       "      <td>0.106257</td>\n",
       "      <td>45158400.0</td>\n",
       "      <td>0.111419</td>\n",
       "      <td>0.110988</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.104536</td>\n",
       "      <td>0.106687</td>\n",
       "      <td>0.106257</td>\n",
       "      <td>0.104106</td>\n",
       "      <td>55686400.0</td>\n",
       "      <td>0.106687</td>\n",
       "      <td>0.106257</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.109698</td>\n",
       "      <td>0.104536</td>\n",
       "      <td>0.104106</td>\n",
       "      <td>0.109698</td>\n",
       "      <td>39827200.0</td>\n",
       "      <td>0.104536</td>\n",
       "      <td>0.104106</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.109698</td>\n",
       "      <td>0.110128</td>\n",
       "      <td>0.109698</td>\n",
       "      <td>0.108838</td>\n",
       "      <td>21504000.0</td>\n",
       "      <td>0.109698</td>\n",
       "      <td>0.109698</td>\n",
       "      <td>w_bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.105396</td>\n",
       "      <td>0.109698</td>\n",
       "      <td>0.108838</td>\n",
       "      <td>0.104966</td>\n",
       "      <td>23699200.0</td>\n",
       "      <td>0.109698</td>\n",
       "      <td>0.108838</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.105396</td>\n",
       "      <td>0.105396</td>\n",
       "      <td>0.104966</td>\n",
       "      <td>0.105396</td>\n",
       "      <td>23049600.0</td>\n",
       "      <td>0.105396</td>\n",
       "      <td>0.104966</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.107547</td>\n",
       "      <td>0.105827</td>\n",
       "      <td>0.105396</td>\n",
       "      <td>0.107547</td>\n",
       "      <td>14291200.0</td>\n",
       "      <td>0.105396</td>\n",
       "      <td>0.105396</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.107117</td>\n",
       "      <td>0.108408</td>\n",
       "      <td>0.107547</td>\n",
       "      <td>0.106687</td>\n",
       "      <td>14067200.0</td>\n",
       "      <td>0.107547</td>\n",
       "      <td>0.107547</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.107117</td>\n",
       "      <td>0.106687</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>13395200.0</td>\n",
       "      <td>0.107117</td>\n",
       "      <td>0.106687</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.110128</td>\n",
       "      <td>0.113569</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.109698</td>\n",
       "      <td>41574400.0</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.111849</td>\n",
       "      <td>0.110128</td>\n",
       "      <td>0.109698</td>\n",
       "      <td>0.111849</td>\n",
       "      <td>30083200.0</td>\n",
       "      <td>0.110128</td>\n",
       "      <td>0.109698</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.112709</td>\n",
       "      <td>0.111849</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>15904000.0</td>\n",
       "      <td>0.111849</td>\n",
       "      <td>0.111849</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.112709</td>\n",
       "      <td>35548800.0</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.111419</td>\n",
       "      <td>0.113570</td>\n",
       "      <td>0.112709</td>\n",
       "      <td>0.110988</td>\n",
       "      <td>11222400.0</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.112709</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.110988</td>\n",
       "      <td>0.111419</td>\n",
       "      <td>0.110988</td>\n",
       "      <td>0.110128</td>\n",
       "      <td>24640000.0</td>\n",
       "      <td>0.111419</td>\n",
       "      <td>0.110988</td>\n",
       "      <td>w_bear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        open  prev_high  prev_low     Close  prev_volume  prev_open  \\\n",
       "1   0.094211   0.099373  0.098943  0.093781  469033600.0   0.098943   \n",
       "2   0.087328   0.094211  0.093781  0.086898  175884800.0   0.094211   \n",
       "3   0.089049   0.087328  0.086898  0.089049  105728000.0   0.087328   \n",
       "4   0.091630   0.089479  0.089049  0.091630   86441600.0   0.089049   \n",
       "5   0.097223   0.092061  0.091630  0.097223   73449600.0   0.091630   \n",
       "6   0.101954   0.097653  0.097223  0.101954   48630400.0   0.097223   \n",
       "7   0.106257   0.102385  0.101954  0.106257   37363200.0   0.101954   \n",
       "8   0.111849   0.106687  0.106257  0.111849   46950400.0   0.106257   \n",
       "9   0.122173   0.112279  0.111849  0.122173   48003200.0   0.111849   \n",
       "10  0.123894   0.122604  0.122173  0.123894   55574400.0   0.122173   \n",
       "11  0.121313   0.124324  0.123894  0.120883   93161600.0   0.123894   \n",
       "12  0.117872   0.121313  0.120883  0.117442   68880000.0   0.121313   \n",
       "13  0.118732   0.117872  0.117442  0.118732   35750400.0   0.117872   \n",
       "14  0.116581   0.119592  0.118732  0.116151   21660800.0   0.118732   \n",
       "15  0.111419   0.116581  0.116151  0.110988   35728000.0   0.116581   \n",
       "16  0.106687   0.111419  0.110988  0.106257   45158400.0   0.111419   \n",
       "17  0.104536   0.106687  0.106257  0.104106   55686400.0   0.106687   \n",
       "18  0.109698   0.104536  0.104106  0.109698   39827200.0   0.104536   \n",
       "19  0.109698   0.110128  0.109698  0.108838   21504000.0   0.109698   \n",
       "20  0.105396   0.109698  0.108838  0.104966   23699200.0   0.109698   \n",
       "21  0.105396   0.105396  0.104966  0.105396   23049600.0   0.105396   \n",
       "22  0.107547   0.105827  0.105396  0.107547   14291200.0   0.105396   \n",
       "23  0.107117   0.108408  0.107547  0.106687   14067200.0   0.107547   \n",
       "24  0.113139   0.107117  0.106687  0.113139   13395200.0   0.107117   \n",
       "25  0.110128   0.113569  0.113139  0.109698   41574400.0   0.113139   \n",
       "26  0.111849   0.110128  0.109698  0.111849   30083200.0   0.110128   \n",
       "27  0.113139   0.112709  0.111849  0.113139   15904000.0   0.111849   \n",
       "28  0.113139   0.114000  0.113139  0.112709   35548800.0   0.113139   \n",
       "29  0.111419   0.113570  0.112709  0.110988   11222400.0   0.113139   \n",
       "30  0.110988   0.111419  0.110988  0.110128   24640000.0   0.111419   \n",
       "\n",
       "    prev_close classifier  \n",
       "1     0.098943          n  \n",
       "2     0.093781          n  \n",
       "3     0.086898          n  \n",
       "4     0.089049          n  \n",
       "5     0.091630          n  \n",
       "6     0.097223          n  \n",
       "7     0.101954          n  \n",
       "8     0.106257          n  \n",
       "9     0.111849          n  \n",
       "10    0.122173          n  \n",
       "11    0.123894          n  \n",
       "12    0.120883          n  \n",
       "13    0.117442          n  \n",
       "14    0.118732          n  \n",
       "15    0.116151          n  \n",
       "16    0.110988          n  \n",
       "17    0.106257          n  \n",
       "18    0.104106          n  \n",
       "19    0.109698     w_bear  \n",
       "20    0.108838          n  \n",
       "21    0.104966          n  \n",
       "22    0.105396          n  \n",
       "23    0.107547          n  \n",
       "24    0.106687          n  \n",
       "25    0.113139          n  \n",
       "26    0.109698          n  \n",
       "27    0.111849          n  \n",
       "28    0.113139          n  \n",
       "29    0.112709          n  \n",
       "30    0.110988     w_bear  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_data = historical_data.copy()\n",
    "def assign_classifier(x) -> str:\n",
    "    percent_change: float = x.Close / x.open\n",
    "    if percent_change >= s_bull_indicator:\n",
    "        return 's_bull'\n",
    "    elif percent_change <= s_bear_indicator:\n",
    "        return 's_bear'\n",
    "    elif percent_change >= w_bull_indicator:\n",
    "        return 'w_bull'\n",
    "    elif percent_change <= w_bear_indicator:\n",
    "        return 'w_bear'\n",
    "    else:\n",
    "        return 'n' #Neutral \n",
    "    \n",
    "classified_data['classifier'] = classified_data.apply(assign_classifier, axis = 1)\n",
    "classified_data.head(30)\n",
    "#classified_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splicing into testing data\n",
    "x_df = classified_data[['open', 'prev_high', 'prev_low', 'prev_volume', 'prev_open', 'prev_close']]\n",
    "y_df = classified_data[['classifier']] #Target Value to be Specified\n",
    "\n",
    "x = x_df.to_numpy()\n",
    "target = y_df.to_numpy().ravel() #Ensuring it is a 1D array\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "rand_state: int = 42 #Seeding the random state, getting equal splits\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, target, test_size=0.2, random_state=42)\n",
    "\n",
    "def test_accuracy(y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC (SVM) Classification Model\n",
    "Notes: Testing shows insanely low accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.44      0.25      0.32       584\n",
      "      s_bear       0.00      0.00      0.00        75\n",
      "      s_bull       0.00      0.00      0.00        80\n",
      "      w_bear       0.35      0.79      0.49       734\n",
      "      w_bull       0.38      0.11      0.17       733\n",
      "\n",
      "    accuracy                           0.37      2206\n",
      "   macro avg       0.23      0.23      0.19      2206\n",
      "weighted avg       0.36      0.37      0.30      2206\n",
      "\n",
      "Confusion Matrix:\n",
      "[[144   0   0 377  63]\n",
      " [  1   0   0  72   2]\n",
      " [  0   0   0  75   5]\n",
      " [ 88   0   0 581  65]\n",
      " [ 96   0   0 556  81]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jairi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jairi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jairi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='rbf', C=1.0, gamma='scale') #Default arguments\n",
    "svc_model.fit(x_train, y_train)\n",
    "#Predict & Test\n",
    "y_pred = svc_model.predict(x_test)\n",
    "test_accuracy(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Neighbors Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.35      0.46      0.39       584\n",
      "      s_bear       0.10      0.05      0.07        75\n",
      "      s_bull       0.04      0.03      0.03        80\n",
      "      w_bear       0.36      0.42      0.39       734\n",
      "      w_bull       0.38      0.25      0.30       733\n",
      "\n",
      "    accuracy                           0.35      2206\n",
      "   macro avg       0.24      0.24      0.24      2206\n",
      "weighted avg       0.34      0.35      0.34      2206\n",
      "\n",
      "Confusion Matrix:\n",
      "[[266   8   8 194 108]\n",
      " [ 16   4   5  35  15]\n",
      " [ 26   3   2  31  18]\n",
      " [235  13  12 307 167]\n",
      " [223  12  24 289 185]]\n"
     ]
    }
   ],
   "source": [
    "k_neighbors_c_model = KNeighborsClassifier()\n",
    "k_neighbors_c_model.fit(x_train, y_train)\n",
    "#Predicting and testing\n",
    "y_pred = k_neighbors_c_model.predict(x_test)\n",
    "test_accuracy(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier & Regressor\n",
    "Can be used as a good aid for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'w_bull'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Regressor (must be moved prior to data manipulation)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m dc_r_model \u001b[38;5;241m=\u001b[39m DecisionTreeRegressor()\n\u001b[1;32m----> 3\u001b[0m dc_r_model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[0;32m      4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m dc_r_model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m      5\u001b[0m test_model(y_pred)\n",
      "File \u001b[1;32mc:\\Users\\jairi\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jairi\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:248\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous:\n\u001b[1;32m--> 248\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(y, dtype\u001b[38;5;241m=\u001b[39mDOUBLE)\n\u001b[0;32m    250\u001b[0m max_depth \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'w_bull'"
     ]
    }
   ],
   "source": [
    "#Regressor (must be moved prior to data manipulation)\n",
    "dc_r_model = DecisionTreeRegressor()\n",
    "dc_r_model.fit(x_train, y_train)\n",
    "y_pred = dc_r_model.predict(x_test)\n",
    "test_model(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.35      0.36      0.36       565\n",
      "      s_bear       0.07      0.07      0.07        85\n",
      "      s_bull       0.02      0.02      0.02        86\n",
      "      w_bear       0.33      0.37      0.35       698\n",
      "      w_bull       0.41      0.35      0.38       762\n",
      "\n",
      "    accuracy                           0.34      2196\n",
      "   macro avg       0.24      0.24      0.24      2196\n",
      "weighted avg       0.34      0.34      0.34      2196\n",
      "\n",
      "Confusion Matrix:\n",
      "[[206  14  13 199 133]\n",
      " [ 17   6  11  28  23]\n",
      " [ 17   6   2  34  27]\n",
      " [173  27  35 259 204]\n",
      " [171  33  30 258 270]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseDecisionTree.decision_path of DecisionTreeClassifier()>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classifier\n",
    "dc_c_model = DecisionTreeClassifier()\n",
    "dc_c_model.fit(x_train, y_train)\n",
    "y_pred = dc_c_model.predict(x_test)\n",
    "test_accuracy(y_pred)\n",
    "#dc_c_model.decision_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
