{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file will use the Rotational Forest Classifier from the Aeon library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Data_Processing\n",
    "from importlib import reload\n",
    "\n",
    "'''\n",
    "this function returns 7 objects:\n",
    "\tdata: sets of data as X_train, X_val, X_ind, y_train, y_val, y_ind\n",
    "\tfeature_list: list of all feature names with a column index (dict)\n",
    "'''\n",
    "\n",
    "reload(_Data_Processing)\n",
    "\n",
    "lstm_format = False\n",
    "\n",
    "X_train, X_val, X_ind,\\\n",
    "y_train, y_val, y_ind,\\\n",
    "feature_subsets =\\\n",
    "_Data_Processing.preprocess_data(\n",
    "\tfile_name   =\t\t'pricearea_c.csv'\n",
    "\t,indp_size  =\t\t0.01\n",
    "\t,test_size  =\t\t0.20\n",
    "\t,shfl_splt\t=\t\tFalse\n",
    "\t,t_start    =\t\t570\n",
    "\t,t_end\t\t=\t\t720\n",
    "\t,mod_type\t=\t\t'Area_Classification'\n",
    "\t,target_t\t=\t\t30\n",
    "\t,num_class\t=\t\t2\n",
    "\t,split_val\t=\t\t5\n",
    "\t,verbose\t=\t\t1\n",
    "\t,scaler\t\t=\t\t'Standard'\n",
    "\t,frmt_lstm\t=\t\tlstm_format\n",
    "\t,time_steps =\t\t5\n",
    "\t,keep_price =\t\tFalse\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Data_Rotating\n",
    "from importlib import reload\n",
    "'''\n",
    "This function returns 4 items.\n",
    "-\t2D array of X partitions, by featurespace and samplespace\n",
    "-\t1D array of index-lists for each featurespace-partition specific features\n",
    "-\t1D array of featurespace-partition specific rotation transformer functions\n",
    "-\t1D array of y partitions for each samplespace partition.\n",
    "'''\n",
    "\n",
    "reload(_Data_Rotating)\n",
    "\n",
    "X_train_parts, X_find_parts, X_trans_parts, y_parts = _Data_Rotating.rotate_partitions(\n",
    "\tX\t\t\t\t=\tX_train\n",
    "    ,y\t\t\t\t=\ty_train\n",
    "\t,n_feat_parts\t=\t1\n",
    "\t,feat_subsets\t=\tfeature_subsets\n",
    "\t,feat_part_type\t=\t'by_subset'\n",
    "\t,fraction_feats\t=\t0.90\n",
    "\t,no_feat_overlap=\tFalse\n",
    "\t,feats_for_all\t=\t[]\n",
    "\t,rotation_type\t=\t'PCA'\n",
    "\t,rotation_filter=\tFalse\n",
    "\t,filter_type\t=\t'Retention'\n",
    "\t,filter_value\t=\t0.95\n",
    "    ,n_sample_parts\t=\t2\n",
    "    ,smpl_part_type\t=\t'Random'\n",
    "    ,sample_overlap\t=\t0.75\n",
    "    ,sample_shuffle\t=\tFalse\n",
    "    ,lstm_format\t=\tlstm_format\n",
    ")\n",
    "\n",
    "'''\n",
    "all partitions\n",
    "\tX_train_parts\n",
    "all sample partitions of THE featurespace partition i\n",
    "\tX_train_parts[i]\n",
    "The single partition of THE samplespace partition j of THE featurespace partition i\n",
    "\tX_train_parts[i][j] -- -- -- This is now a set of trainable data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Modelset_Training\n",
    "reload(_Modelset_Training)\n",
    "\n",
    "_Modelset_Training.show_available_model_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Modelset_Training\n",
    "from importlib import reload\n",
    "\n",
    "'''\n",
    "Function returns a 3D list of trained models that are fit to the resepective dataset.\n",
    "\tDim1:\tFeaturespace, here are the subsetctions/partitions for each unique set of features\n",
    "    Dim2:\tSamplespace, here are the subsetctions/partitions for each unique set of samples\n",
    "    Dim3:\tModelspace, here are the individual models trained on a unique partition\n",
    "'''\n",
    "reload(_Modelset_Training)\n",
    "\n",
    "models = _Modelset_Training.train_models(\n",
    "    model_types\t=\t['nn']\n",
    "    ,data_parts\t=\tX_train_parts\n",
    "    ,findx_parts=\tX_find_parts\n",
    "    ,trans_parts=\tX_trans_parts\n",
    "    ,trgt_parts\t=\ty_parts\n",
    "    ,X_valid\t=\tX_val\n",
    "    ,y_valid\t=\ty_val\n",
    "    ,param_mode\t=\t'custom'\n",
    "    ,cst_mod_prm=\t[{\n",
    "        'optimizer_kwarg':{\n",
    "            'learning_rate'\t:\t0.001\n",
    "            }\n",
    "        ,'time_steps'\t\t:\t5\n",
    "        ,'LSTM'\t\t\t\t:\tFalse\n",
    "        ,'shuffle_train'\t:\tTrue\n",
    "        ,'epochs'\t\t\t:\t1\n",
    "        ,'rlr_patience'\t\t:\t20\n",
    "        ,'architecture'\t:\t'default_deep'\n",
    "        #,'external_cw'\t:\t_Utility.get_class_weights(y_train)\n",
    "        }]\n",
    "    ,tnr_verbose=\tTrue\n",
    "    ,lstm_frmt\t=\tlstm_format\n",
    "    ,use_cls_wt\t=\tTrue\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Model_Evaluation\n",
    "import _Neural_Net\n",
    "\n",
    "reload(_Model_Evaluation)\n",
    "reload(_Neural_Net)\n",
    "\n",
    "_Model_Evaluation.evaluate_models(\n",
    "\t\tmodels=models\n",
    "\t\t,X_findx=X_find_parts\n",
    "\t\t,X_trans=X_trans_parts\n",
    "\t\t,X_train=X_train_parts\n",
    "\t\t,y_train=y_parts\n",
    "\t\t,X_test=X_val\n",
    "\t\t,y_test=y_val\n",
    "\t\t,prfm_gnrl\t=\t'all'\n",
    "\t\t,prfm_stat\t=\t'all'\n",
    "\t\t,disp_mthd\t=\t'as_value'\n",
    "\t\t,test_whch\t=\t'independent'\n",
    "\t\t,pred_type\t=\t'classification'\n",
    "        ,lstm_frmt\t=\tlstm_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Metamodel\n",
    "from importlib import reload\n",
    "import _Utility\n",
    "\n",
    "reload(_Metamodel)\n",
    "metamodel, prediction_set = _Metamodel.train_test_meta_model(\n",
    "\tmodels\t\t=\tmodels\n",
    "\t,X_findx\t=\tX_find_parts\n",
    "\t,X_trans\t=\tX_trans_parts\n",
    "\t,X_test\t\t=\tX_val\n",
    "\t,y_test\t\t=\ty_val\n",
    "\t,val_size\t=\t0.2\n",
    "\t,shuffle\t=\tTrue\n",
    "\t,metam_type =\t'NN'\n",
    "    ,use_cls_wt =\tTrue\n",
    "    ,use_mm_params=\tTrue\n",
    "    ,metam_params={\n",
    "        'optimizer_kwarg':{\n",
    "            'learning_rate'\t:\t0.001\n",
    "            }\n",
    "        ,'time_steps'\t\t:\t5\n",
    "        ,'LSTM'\t\t\t\t:\tFalse\n",
    "        ,'shuffle_train'\t:\tTrue\n",
    "        ,'epochs'\t\t\t:\t2\n",
    "        ,'rlr_patience'\t\t:\t20\n",
    "        #,'architecture'\t:\t'default_deep'\n",
    "        #,'external_cw'\t:\t_Utility.get_class_weights(y_train)\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final connective test will be:\n",
    "-\tcasually train fair/good metamodel\n",
    "-\tload into a master model\n",
    "-\tpredict on X_ind\n",
    "-\tscore model\n",
    "-\tmodel performs at same level\n",
    "-\tsave model\n",
    "-\tload same model\n",
    "-\ttest on X_ind again\n",
    "-\twill have indentical score to pre save/load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Data_Processing\n",
    "from importlib import reload\n",
    "reload(_Data_Processing)\n",
    "lstm_format = False\n",
    "X_test, _, __,\\\n",
    "y_test, ___, ____,\\\n",
    "feature_subsets =\\\n",
    "_Data_Processing.preprocess_data(\n",
    "\tfile_name   =\t\t'pricearea_test.csv'\n",
    "\t,indp_size  =\t\t0.01\n",
    "\t,test_size  =\t\t0.01\n",
    "\t,shfl_splt\t=\t\tFalse\n",
    "\t,t_start    =\t\t645\n",
    "\t,t_end\t\t=\t\t900\n",
    "\t,mod_type\t=\t\t'Area_Classification'\n",
    "\t,target_t\t=\t\t30\n",
    "\t,num_class\t=\t\t2\n",
    "\t,split_val\t=\t\t5\n",
    "\t,verbose\t=\t\t1\n",
    "\t,scaler\t\t=\t\t'Standard'\n",
    "\t,frmt_lstm\t=\t\tlstm_format\n",
    "\t,time_steps =\t\t5\n",
    "\t,keep_price =\t\tFalse\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import _Master_Model\n",
    "reload(_Master_Model)\n",
    "from importlib import reload\n",
    "\n",
    "master = _Master_Model.Master(\n",
    "    model_depth\t\t=\t2\n",
    "    ,all_models \t=\t[models, metamodel]\n",
    "    ,lvl0_formatters=\t[X_find_parts, X_trans_parts]\n",
    ")\n",
    "\n",
    "#\ttrain\tval\t\tind\n",
    "\n",
    "test_on_X = X_test\n",
    "test_on_y = y_test\n",
    "\n",
    "m_pred = master.master_predict(test_on_X, threshold=0.5)\n",
    "print(accuracy_score(test_on_y, m_pred))\n",
    "\n",
    "#master.master_predict_fullth(test_on_X, test_on_y, definition='low')\n",
    "\n",
    "#print((m_pred[0]))\n",
    "\n",
    "#Create the confusion matrix\n",
    "cm = confusion_matrix(test_on_y, m_pred)\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \\\n",
    "\t\t\txticklabels=range(2), yticklabels=range(2))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix for Meta-Model Independent Test')\n",
    "plt.show()\n",
    "\n",
    "master.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Master_Model\n",
    "from importlib import reload\n",
    "master.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Data_Processing\n",
    "from importlib import reload\n",
    "reload(_Data_Processing)\n",
    "lstm_format = False\n",
    "X_test, _, __,\\\n",
    "y_test, ___, ____,\\\n",
    "feature_subsets =\\\n",
    "_Data_Processing.preprocess_data(\n",
    "\tfile_name   =\t\t'pricearea_test.csv'\n",
    "\t,indp_size  =\t\t0.01\n",
    "\t,test_size  =\t\t0.01\n",
    "\t,shfl_splt\t=\t\tFalse\n",
    "\t,t_start    =\t\t645\n",
    "\t,t_end\t\t=\t\t720\n",
    "\t,mod_type\t=\t\t'Area_Classification'\n",
    "\t,target_t\t=\t\t30\n",
    "\t,num_class\t=\t\t2\n",
    "\t,split_val\t=\t\t5\n",
    "\t,verbose\t=\t\t1\n",
    "\t,scaler\t\t=\t\t'Standard'\n",
    "\t,frmt_lstm\t=\t\tlstm_format\n",
    "\t,time_steps =\t\t5\n",
    "\t,keep_price =\t\tFalse\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import _Master_Model\n",
    "from importlib import reload\n",
    "reload(_Master_Model)\n",
    "\n",
    "test_on_X = X_test\n",
    "test_on_y = y_test\n",
    "\n",
    "loadmodel = _Master_Model.Master(\n",
    "    model_depth=2\n",
    ")\n",
    "loadmodel.load_model('fair_model_around54avg')\n",
    "m_pred = loadmodel.master_predict(test_on_X, threshold=0.5)\n",
    "print(accuracy_score(test_on_y, m_pred))\n",
    "\n",
    "#Create the confusion matrix\n",
    "cm = confusion_matrix(test_on_y, m_pred)\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \\\n",
    "\t\t\txticklabels=range(2), yticklabels=range(2))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix for Meta-Model Independent Test')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tf_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
