{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file will use the Rotational Forest Classifier from the Aeon library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Data_Processing\n",
    "from importlib import reload\n",
    "\n",
    "'''\n",
    "this function returns 7 objects:\n",
    "\tdata: sets of data as X_train, X_val, X_ind, y_train, y_val, y_ind\n",
    "\tfeature_list: list of all feature names with a column index (dict)\n",
    "'''\n",
    "\n",
    "reload(_Data_Processing)\n",
    "\n",
    "lstm_format = False\n",
    "\n",
    "X, X_train, X_val, X_ind,\\\n",
    "y, y_train, y_val, y_ind,\\\n",
    "feature_subsets, scaler =\\\n",
    "_Data_Processing.preprocess_data(\n",
    "\tfile_name   =\t\t'spx_ndx_full.csv'\n",
    "\t,indp_size  =\t\t0.01\n",
    "\t,test_size  =\t\t0.20\n",
    "\t,shfl_splt\t=\t\tFalse\n",
    "\t,t_start    =\t\t570\n",
    "\t,t_end\t\t=\t\t720\n",
    "\t,mod_type\t=\t\t'Area_Classification'\n",
    "\t,target_t\t=\t\t30\n",
    "\t,num_class\t=\t\t2\n",
    "\t,split_val\t=\t\t5\n",
    "\t,verbose\t=\t\t1\n",
    "\t,scaler\t\t=\t\t'Standard'\n",
    "\t,frmt_lstm\t=\t\tlstm_format\n",
    "\t,time_steps =\t\t5\n",
    "\t,keep_price =\t\tTrue\n",
    "\t,optm_data\t=\t\tTrue\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, 'scaler/tmp.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Data_Rotating\n",
    "from importlib import reload\n",
    "'''\n",
    "This function returns 4 items.\n",
    "-\t2D array of X partitions, by featurespace and samplespace\n",
    "-\t1D array of index-lists for each featurespace-partition specific features\n",
    "-\t1D array of featurespace-partition specific rotation transformer functions\n",
    "-\t1D array of y partitions for each samplespace partition.\n",
    "'''\n",
    "\n",
    "reload(_Data_Rotating)\n",
    "\n",
    "X_train_parts, X_find_parts, X_trans_parts, y_parts = _Data_Rotating.rotate_partitions(\n",
    "\tX\t\t\t\t=\tX_train\n",
    "\t,y\t\t\t\t=\ty_train\n",
    "\t,n_feat_parts\t=\t8\n",
    "\t,feat_subsets\t=\tfeature_subsets\n",
    "\t,feat_part_type\t=\t'by_subset'\n",
    "\t,fraction_feats\t=\t0.75\n",
    "\t,no_feat_overlap=\tFalse\n",
    "\t,feats_for_all\t=\t[]\n",
    "\t,rotation_type\t=\t'PCA'\n",
    "\t,rotation_filter=\tFalse\n",
    "\t,filter_type\t=\t'Retention'\n",
    "\t,filter_value\t=\t0.95\n",
    "\t,n_sample_parts\t=\t1\n",
    "\t,smpl_part_type\t=\t'Even'\n",
    "\t,sample_overlap\t=\t0.9\n",
    "\t,sample_shuffle\t=\tFalse\n",
    "\t,lstm_format\t=\tlstm_format\n",
    ")\n",
    "\n",
    "'''\n",
    "all partitions\n",
    "\tX_train_parts\n",
    "all sample partitions of THE featurespace partition i\n",
    "\tX_train_parts[i]\n",
    "The single partition of THE samplespace partition j of THE featurespace partition i\n",
    "\tX_train_parts[i][j] -- -- -- This is now a set of trainable data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for featureset in feature_subsets:\n",
    "\tprint(featureset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Modelset_Training\n",
    "reload(_Modelset_Training)\n",
    "\n",
    "_Modelset_Training.show_available_model_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Modelset_Training\n",
    "from importlib import reload\n",
    "\n",
    "'''\n",
    "Function returns a 3D list of trained models that are fit to the resepective dataset.\n",
    "\tDim1:\tFeaturespace, here are the subsetctions/partitions for each unique set of features\n",
    "\tDim2:\tSamplespace, here are the subsetctions/partitions for each unique set of samples\n",
    "\tDim3:\tModelspace, here are the individual models trained on a unique partition\n",
    "'''\n",
    "reload(_Modelset_Training)\n",
    "\n",
    "models = _Modelset_Training.train_models(\n",
    "\tmodel_types\t=\t['nn']\n",
    "\t,data_parts\t=\tX_train_parts\n",
    "\t,findx_parts=\tX_find_parts\n",
    "\t,trans_parts=\tX_trans_parts\n",
    "\t,trgt_parts\t=\ty_parts\n",
    "\t,X_valid\t=\tX_val\n",
    "\t,y_valid\t=\ty_val\n",
    "\t,param_mode\t=\t'custom'\n",
    "\t,cst_mod_prm=\t[{\n",
    "\t\t'optimizer_type'\t:\t'Adam'\n",
    "\t\t,'optimizer_kwarg':{\n",
    "\t\t\t'learning_rate'\t:\t0.0005\n",
    "\t\t\t#,'momentum'\t\t:\t0.9\n",
    "\t\t\t}\n",
    "\t\t,'time_steps'\t\t:\t5\n",
    "\t\t,'LSTM'\t\t\t\t:\tFalse\n",
    "\t\t,'shuffle_train'\t:\tTrue\n",
    "\t\t,'epochs'\t\t\t:\t5\n",
    "\t\t,'rlr_patience'\t\t:\t20\n",
    "\t\t,'architecture'\t:\t'default_deep'\n",
    "\t\t#,'external_cw'\t:\t_Utility.get_class_weights(y_train)\n",
    "\t\t}]\n",
    "\t,tnr_verbose=\tTrue\n",
    "\t,lstm_frmt\t=\tlstm_format\n",
    "\t,use_cls_wt\t=\tTrue\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Model_Evaluation\n",
    "import _Neural_Net\n",
    "\n",
    "reload(_Model_Evaluation)\n",
    "reload(_Neural_Net)\n",
    "\n",
    "_Model_Evaluation.evaluate_models(\n",
    "\t\tmodels=models\n",
    "\t\t,X_findx=X_find_parts\n",
    "\t\t,X_trans=X_trans_parts\n",
    "\t\t,X_train=X_train_parts\n",
    "\t\t,y_train=y_parts\n",
    "\t\t,X_test=X_val\n",
    "\t\t,y_test=y_val\n",
    "\t\t,prfm_gnrl\t=\t'all'\n",
    "\t\t,prfm_stat\t=\t'all'\n",
    "\t\t,disp_mthd\t=\t'as_value'\n",
    "\t\t,test_whch\t=\t'independent'\n",
    "\t\t,pred_type\t=\t'classification'\n",
    "\t\t,lstm_frmt\t=\tlstm_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Metamodel\n",
    "from importlib import reload\n",
    "import _Utility\n",
    "\n",
    "reload(_Metamodel)\n",
    "metamodel, prediction_set = _Metamodel.train_test_meta_model(\n",
    "\tmodels\t\t=\tmodels\n",
    "\t,X_findx\t=\tX_find_parts\n",
    "\t,X_trans\t=\tX_trans_parts\n",
    "\t,X_test\t\t=\tX_val\n",
    "\t,y_test\t\t=\ty_val\n",
    "\t,val_size\t=\t0.2\n",
    "\t,shuffle\t=\tTrue\n",
    "\t,metam_type =\t'NN'\n",
    "\t,use_cls_wt =\tTrue\n",
    "\t,use_mm_params=\tTrue\n",
    "\t,metam_params={\n",
    "\t\t'optimizer_type':\t'Adam'\n",
    "\t\t,'optimizer_kwarg':{\n",
    "\t\t\t'learning_rate'\t:\t0.001\n",
    "\t\t\t#,'momentum':0.9\n",
    "\t\t\t}\n",
    "\t\t,'time_steps'\t\t:\t5\n",
    "\t\t,'LSTM'\t\t\t\t:\tFalse\n",
    "\t\t,'shuffle_train'\t:\tTrue\n",
    "\t\t,'epochs'\t\t\t:\t75\n",
    "\t\t,'batch_size'\t\t:\t30\n",
    "\t\t,'rlr_patience'\t\t:\t10\n",
    "\t\t,'architecture'\t:\t'default_deep'\n",
    "\t\t#,'custom_val_data'\t:\t(X_train, y_train)\n",
    "\t\t}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final connective test will be:\n",
    "-\tcasually train fair/good metamodel\n",
    "-\tload into a master model\n",
    "-\tpredict on X_ind\n",
    "-\tscore model\n",
    "-\tmodel performs at same level\n",
    "-\tsave model\n",
    "-\tload same model\n",
    "-\ttest on X_ind again\n",
    "-\twill have indentical score to pre save/load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Data_Processing\n",
    "from importlib import reload\n",
    "reload(_Data_Processing)\n",
    "lstm_format = False\n",
    "X_tall, X_test, _, __,\\\n",
    "y_tall, y_test, ___, ____,\\\n",
    "feature_subsets =\\\n",
    "_Data_Processing.preprocess_data(\n",
    "\tfile_name   =\t\t'betaset_tmp.csv'\n",
    "\t,indp_size  =\t\t0.01\n",
    "\t,test_size  =\t\t0.01\n",
    "\t,shfl_splt\t=\t\tFalse\n",
    "\t,t_start    =\t\t645\n",
    "\t,t_end\t\t=\t\t900\n",
    "\t,mod_type\t=\t\t'Classification'\n",
    "\t,target_t\t=\t\t5\n",
    "\t,num_class\t=\t\t2\n",
    "\t,split_val\t=\t\t5\n",
    "\t,verbose\t=\t\t1\n",
    "\t,scaler\t\t=\t\t'Standard'\n",
    "\t,frmt_lstm\t=\t\tlstm_format\n",
    "\t,time_steps =\t\t5\n",
    "\t,keep_price =\t\tFalse\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = [0,5]\n",
    "\n",
    "print(i[0])\n",
    "print(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import _Master_Model\n",
    "reload(_Master_Model)\n",
    "from importlib import reload\n",
    "\n",
    "master = _Master_Model.Master(\n",
    "\tmodel_depth\t\t=\t2\n",
    "\t,all_models \t=\t[models, metamodel]\n",
    "\t,lvl0_formatters=\t[X_find_parts, X_trans_parts]\n",
    ")\n",
    "\n",
    "#\ttrain\tval\t\tind\n",
    "\n",
    "test_on_X = X_ind\n",
    "test_on_y = y_ind\n",
    "\n",
    "m_pred = master.master_predict(test_on_X, threshold=0.5)\n",
    "print(accuracy_score(test_on_y, m_pred))\n",
    "\n",
    "#master.master_predict_fullth(test_on_X, test_on_y, definition='min')\n",
    "\n",
    "#print((m_pred[0]))\n",
    "\n",
    "#Create the confusion matrix\n",
    "cm = confusion_matrix(test_on_y, m_pred)\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \\\n",
    "\t\t\txticklabels=range(2), yticklabels=range(2))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix for Meta-Model Independent Test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Data_Processing\n",
    "from importlib import reload\n",
    "import joblib\n",
    "reload(_Data_Processing)\n",
    "lstm_format = False\n",
    "X_test, _, _, __,\\\n",
    "y_test, _, ___, ____,\\\n",
    "feature_subsets, scaler =\\\n",
    "_Data_Processing.preprocess_data(\n",
    "\tfile_name   =\t\t'pricearea_test.csv'\n",
    "\t,indp_size  =\t\t0.01\n",
    "\t,test_size  =\t\t0.01\n",
    "\t,shfl_splt\t=\t\tFalse\n",
    "\t,t_start    =\t\t645\n",
    "\t,t_end\t\t=\t\t800\n",
    "\t,mod_type\t=\t\t'Area_Classification'\n",
    "\t,target_t\t=\t\t45\n",
    "\t,num_class\t=\t\t2\n",
    "\t,split_val\t=\t\t5\n",
    "\t,verbose\t=\t\t1\n",
    "\t,scaler\t\t=\t\t'Custom'\n",
    "\t,cstm_scale\t=\t\tjoblib.load('scaler/tmp.joblib')\n",
    "\t,frmt_lstm\t=\t\tlstm_format\n",
    "\t,time_steps =\t\t5\n",
    "\t,keep_price =\t\tFalse\n",
    "\t,indices\t=\t\t0\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import _Master_Model\n",
    "from importlib import reload\n",
    "reload(_Master_Model)\n",
    "\n",
    "test_on_X = X_test\n",
    "test_on_y = y_test\n",
    "\n",
    "loadmodel = _Master_Model.Master(\n",
    "\tmodel_depth=2\n",
    ")\n",
    "loadmodel.load_model('pred1_63p2_acc-645-800')\n",
    "m_pred = loadmodel.master_predict(test_on_X, threshold=0.5)\n",
    "print(accuracy_score(test_on_y, m_pred))\n",
    "\n",
    "#Create the confusion matrix\n",
    "cm = confusion_matrix(test_on_y, m_pred)\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \\\n",
    "\t\t\txticklabels=range(2), yticklabels=range(2))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix for Meta-Model Independent Test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import _Data_Processing\n",
    "from importlib import reload\n",
    "import joblib\n",
    "reload(_Data_Processing)\n",
    "lstm_format = False\n",
    "X_set, _, _, __,\\\n",
    "y_set, _, ___, ____,\\\n",
    "feature_subsets, scaler =\\\n",
    "_Data_Processing.preprocess_data(\n",
    "\tfile_name   =\t\t'pricearea_c.csv'\n",
    "\t,indp_size  =\t\t0.01\n",
    "\t,test_size  =\t\t0.01\n",
    "\t,shfl_splt\t=\t\tFalse\n",
    "\t,t_start    =\t\t645\n",
    "\t,t_end\t\t=\t\t800\n",
    "\t,mod_type\t=\t\t'Area_Classification'\n",
    "\t,target_t\t=\t\t45\n",
    "\t,num_class\t=\t\t2\n",
    "\t,split_val\t=\t\t5\n",
    "\t,verbose\t=\t\t0\n",
    "\t,scaler\t\t=\t\t'None'\n",
    "\t,cstm_scale\t=\t\tjoblib.load('scaler/tmp.joblib')\n",
    "\t,frmt_lstm\t=\t\tlstm_format\n",
    "\t,time_steps =\t\t5\n",
    "\t,keep_price =\t\tTrue\n",
    "\t,indices\t=\t\t0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_vals = []\n",
    "for i in range(len(m_pred)):\n",
    "\tif(test_on_y[i] == 0):\n",
    "\t\tif(m_pred[i] == 0):\n",
    "\t\t\tcm_vals.append(0)\n",
    "\t\tif(m_pred[i] == 1):\n",
    "\t\t\tcm_vals.append(1)\n",
    "\tif(test_on_y[i] == 1):\n",
    "\t\tif(m_pred[i] == 0):\n",
    "\t\t\tcm_vals.append(2)\n",
    "\t\tif(m_pred[i] == 1):\n",
    "\t\t\tcm_vals.append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(X_set)\n",
    "df['score'] = cm_vals\n",
    "df['mpred'] = m_pred\n",
    "df['target'] = y_set\n",
    "#df = df.drop(df[df['score']%2==0].index)\n",
    "\n",
    "pd.set_option('display.max_rows',None)\n",
    "co = df.corr()['target']\n",
    "print(co.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "df_pair = pd.DataFrame()\n",
    "df_pair['ft'] = df[503].values\n",
    "df_pair['model_prediction'] = m_pred\n",
    "\n",
    "X_svm = df_pair.values\n",
    "y_svm = df['target'].values\n",
    "\n",
    "clf = SVC(kernel='linear',C=1.0).fit(X_svm, y_svm)\n",
    "\n",
    "y_svmpred = clf.predict(X_svm)\n",
    "\n",
    "#Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_svmpred)\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \\\n",
    "\t\t\txticklabels=range(2), yticklabels=range(2))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'asdfasdfasdfasdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplfinance as mpf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print(int(len(X_test[:,0])/155))\n",
    "\n",
    "num_candles = 155\n",
    "\n",
    "for section in range(int(len(X_test[:,0])/num_candles)):\n",
    "\tsection*=num_candles\n",
    "\tsection_end = section+num_candles\n",
    "\tX_thold = X_test[section:section_end,:]\n",
    "\n",
    "\t#custom coloring\n",
    "\tcolor_map = {\n",
    "\t\t0: 'white',\n",
    "\t\t1: 'red',\n",
    "\t\t2: 'white',\n",
    "\t\t3: 'green'\n",
    "\t}\n",
    "\tcolors = [color_map[condition] for condition in cm_vals[section:section_end]]\n",
    "\tmc = mpf.make_marketcolors(up='g',down='r')\n",
    "\tcustom_style = mpf.make_mpf_style(marketcolors=mc)#, gridcolor='lightgray')\n",
    "\n",
    "\th = X_thold[:,0]\n",
    "\tl = X_thold[:,1]\n",
    "\tc = X_thold[:,2]\n",
    "\to = np.roll(X_thold[:,2], shift=1)\n",
    "\n",
    "\t#o,c swapping function for appropriate coloring\n",
    "\tfor i in range(len(c)):\n",
    "\t\tif(cm_vals[section+i]%2==1):\n",
    "\t\t#\tif(c[i]<o[i]):#force green\n",
    "\t\t\tc[i],o[i] = h[i],l[i]\n",
    "\t\t\t#else:\n",
    "\t\t#\t\tpass#is green\n",
    "\t\telse:#force red\n",
    "\t\t\t#if(c[i]>o[i]):\n",
    "\t\t\tc[i],o[i] = l[i],h[i]\n",
    "\n",
    "\tdata = {\n",
    "\t\t'Date':range(0,len(X_thold[:])*1000000000,1000000000),\n",
    "\t\t'Open':o,\n",
    "\t\t'High':h,\n",
    "\t\t'Low':l,\n",
    "\t\t'Close':c\n",
    "\t}\n",
    "\tdf = pd.DataFrame(data)\n",
    "\t#df['color'] = colors\n",
    "\tdf['Date'] = pd.to_datetime(df['Date'])\n",
    "\tdf.set_index('Date',inplace=True)\n",
    "\n",
    "\tdf_NULL = pd.DataFrame\n",
    "\n",
    "\tmpf.plot(df.iloc[10:-10,:], type='candle',style=custom_style,figratio=(20,8))\n",
    "\t#mpf.plot(df, addplot=plot,style=custom_style,figratio=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _Utility\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = _Utility.dummy_predict(X_test=X_train_parts[0][0] , prediction=1)\n",
    "print(accuracy_score(y_parts[0], y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tf_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
