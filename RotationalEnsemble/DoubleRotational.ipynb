{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file will use the Rotational Forest Classifier from the Aeon library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load CSV file into DataFrame...Success.\n",
      "Size of dataset:\t1136505380\n",
      "Size after reduction:\t568252772\n",
      "Trying to drop unused targets...Success.\n",
      "Trying to collect indices of wanted times...Success.\n",
      "Trying to drop price features...Success...\n",
      "\n",
      "# of Samples:\t226576\n",
      "\n",
      "# of Features:\t436\n",
      "\n",
      "Target:\t\ttc_2a_30m\n",
      "\n",
      "Trying to split DataFrame into X and y...<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.float32'>\n",
      "Success.\n",
      "Trying to collect all feature names and indices...Success.\n",
      "Trying to clean up...Success.\n",
      "Trying to encode y and make class weights...Failed [NON-FATAL: NOT IMPLEMENTED]\n",
      "Trying to standardize all featurespace from training featurespace...Success.\n",
      "Trying to drop unwanted time-range samples...Success.\n",
      "\t214004 Samples Dropped.\n",
      "\n",
      "Trying to split X and y into Train/Validation/Independent...Success.\n",
      "Trying to clean up...Success.\n",
      "X_train:\t(9931, 436).\n",
      "y_train:\t(9931,).\n",
      "X_val:  \t(2515, 436).\n",
      "y_val:  \t(2515,).\n",
      "X_ind:  \t(126, 436).\n",
      "y_ind:  \t(126,).\n",
      "Collecting garbage...Success.\n",
      "Terminating.\n"
     ]
    }
   ],
   "source": [
    "import _Data_Processing\n",
    "from importlib import reload\n",
    "\n",
    "'''\n",
    "this function returns 7 objects:\n",
    "\tdata: sets of data as X_train, X_val, X_ind, y_train, y_val, y_ind\n",
    "\tfeature_list: list of all feature names with a column index (dict)\n",
    "'''\n",
    "\n",
    "reload(_Data_Processing)\n",
    "\n",
    "lstm_format = False\n",
    "\n",
    "X_train, X_val, X_ind,\\\n",
    "y_train, y_val, y_ind,\\\n",
    "feature_subsets =\\\n",
    "_Data_Processing.preprocess_data(\n",
    "\tfile_name   =\t\t'pricearea_c.csv'\n",
    "\t,indp_size  =\t\t0.01\n",
    "\t,test_size  =\t\t0.20\n",
    "\t,shfl_splt\t=\t\tFalse\n",
    "\t,t_start    =\t\t570\n",
    "\t,t_end\t\t=\t\t645\n",
    "\t,mod_type\t=\t\t'Area_Classification'\n",
    "\t,target_t\t=\t\t30\n",
    "\t,num_class\t=\t\t2\n",
    "\t,split_val\t=\t\t5\n",
    "\t,verbose\t=\t\t1\n",
    "\t,scaler\t\t=\t\t'Standard'\n",
    "\t,frmt_lstm\t=\t\tlstm_format\n",
    "\t,time_steps =\t\t5\n",
    "\t,keep_price =\t\tFalse\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nall partitions\\n\\tX_train_parts\\nall sample partitions of THE featurespace partition i\\n\\tX_train_parts[i]\\nThe single partition of THE samplespace partition j of THE featurespace partition i\\n\\tX_train_parts[i][j] -- -- -- This is now a set of trainable data\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import _Data_Rotating\n",
    "from importlib import reload\n",
    "'''\n",
    "This function returns 4 items.\n",
    "-\t2D array of X partitions, by featurespace and samplespace\n",
    "-\t1D array of index-lists for each featurespace-partition specific features\n",
    "-\t1D array of featurespace-partition specific rotation transformer functions\n",
    "-\t1D array of y partitions for each samplespace partition.\n",
    "'''\n",
    "\n",
    "reload(_Data_Rotating)\n",
    "\n",
    "X_train_parts, X_find_parts, X_trans_parts, y_parts = _Data_Rotating.rotate_partitions(\n",
    "\tX\t\t\t\t=\tX_train\n",
    "    ,y\t\t\t\t=\ty_train\n",
    "\t,n_feat_parts\t=\t8\n",
    "\t,feat_subsets\t=\tfeature_subsets\n",
    "\t,feat_part_type\t=\t'by_subset'\n",
    "\t,fraction_feats\t=\t0.90\n",
    "\t,no_feat_overlap=\tFalse\n",
    "\t,feats_for_all\t=\t[]\n",
    "\t,rotation_type\t=\t'PCA'\n",
    "\t,rotation_filter=\tFalse\n",
    "\t,filter_type\t=\t'Retention'\n",
    "\t,filter_value\t=\t1.0\n",
    "    ,n_sample_parts\t=\t1\n",
    "    ,smpl_part_type\t=\t'Even'\n",
    "    ,sample_shuffle\t=\tFalse\n",
    "    ,lstm_format\t=\tlstm_format\n",
    ")\n",
    "\n",
    "'''\n",
    "all partitions\n",
    "\tX_train_parts\n",
    "all sample partitions of THE featurespace partition i\n",
    "\tX_train_parts[i]\n",
    "The single partition of THE samplespace partition j of THE featurespace partition i\n",
    "\tX_train_parts[i][j] -- -- -- This is now a set of trainable data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t   'decision_tree'\n",
      "\t   'dt'\n",
      "\t\t-\t-\tSci-Kit Learn DecisionTreeClassifier\n",
      "\t\t-\t-\t{'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
      "\t   \n",
      "\t   'rotation_forest'\n",
      "\t   'aeon_rf'\n",
      "\t\t   -\t-\tAEON Rotation Forest\n",
      "\t\t-\t-\t{'base_estimator': DecisionTreeClassifier(max_depth=4), 'n_estimators': 4, 'min_group': 1, 'max_group': 20, 'remove_proportion': 0.3, 'n_jobs': -1}\n",
      "\t   \n",
      "\t   'continuous_interval_tree'\n",
      "\t   'cit'\n",
      "\t   -\t-\tSci-Kit Learn ContinuousIntervalTreeVectorClassifier\n",
      "\t   -\t-\t{'max_depth': 4, 'thresholds': 20}\n",
      "\t   \n",
      "\t   \n"
     ]
    }
   ],
   "source": [
    "import _Modelset_Training\n",
    "reload(_Modelset_Training)\n",
    "\n",
    "_Modelset_Training.show_available_model_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default parameters selected.\n",
      "dt\t-\t{'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "import _Modelset_Training\n",
    "from importlib import reload\n",
    "\n",
    "'''\n",
    "Function returns a 3D list of trained models that are fit to the resepective dataset.\n",
    "\tDim1:\tFeaturespace, here are the subsetctions/partitions for each unique set of features\n",
    "    Dim2:\tSamplespace, here are the subsetctions/partitions for each unique set of samples\n",
    "    Dim3:\tModelspace, here are the individual models trained on a unique partition\n",
    "'''\n",
    "reload(_Modelset_Training)\n",
    "\n",
    "models = _Modelset_Training.train_models(\n",
    "    model_types\t=\t['dt']\n",
    "    ,data_parts\t=\tX_train_parts\n",
    "    ,trgt_parts\t=\ty_parts\n",
    "    ,param_mode\t=\t'default'\n",
    "    ,cst_mod_prm=\tNone\n",
    "    ,tnr_verbose=\tTrue\n",
    "    ,lstm_frmt\t=\tlstm_format\n",
    "    ,use_cls_wt\t=\tTrue\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Trained Models:\n",
      "\tFeature Space: 8\n",
      "\tSample Space: 1\n",
      "\tModel Space: 1\n",
      "\n",
      "\n",
      "\tDisplaying all performances for all independent samples: (8 cases)\n",
      "\n",
      "4\n",
      "\n",
      "Statistics Overall:\n",
      "\n",
      "\tSplit 0:\n",
      "\t\t\t\tAvg\tSt.Dv.\tLow\tHigh\n",
      "\t\tAccuracy\t0.54\t0.02\t0.5\t0.56\n",
      "\t\tPrecision\t0.57\t0.01\t0.55\t0.59\n",
      "\t\tRecall\t\t0.54\t0.14\t0.2\t0.71\n",
      "\n",
      "Statistics By Feature Space:\n",
      "\n",
      "\tSplit 0:\n",
      "\t\t\t\tAvg\tSt.Dv.\tLow\tHigh\n",
      "\t\tAccuracy\t0.5\t0.0\t0.5\t0.5\n",
      "\t\tPrecision\t0.56\t0.0\t0.56\t0.56\n",
      "\t\tRecall\t\t0.2\t0.0\t0.2\t0.2\n",
      "\tSplit 1:\n",
      "\t\t\t\tAvg\tSt.Dv.\tLow\tHigh\n",
      "\t\tAccuracy\t0.55\t0.0\t0.55\t0.55\n",
      "\t\tPrecision\t0.56\t0.0\t0.56\t0.56\n",
      "\t\tRecall\t\t0.57\t0.0\t0.57\t0.57\n",
      "\tSplit 2:\n",
      "\t\t\t\tAvg\tSt.Dv.\tLow\tHigh\n",
      "\t\tAccuracy\t0.55\t0.0\t0.55\t0.55\n",
      "\t\tPrecision\t0.55\t0.0\t0.55\t0.55\n",
      "\t\tRecall\t\t0.71\t0.0\t0.71\t0.71\n",
      "\tSplit 3:\n",
      "\t\t\t\tAvg\tSt.Dv.\tLow\tHigh\n",
      "\t\tAccuracy\t0.56\t0.0\t0.56\t0.56\n",
      "\t\tPrecision\t0.58\t0.0\t0.58\t0.58\n",
      "\t\tRecall\t\t0.59\t0.0\t0.59\t0.59\n",
      "\tSplit 4:\n",
      "\t\t\t\tAvg\tSt.Dv.\tLow\tHigh\n",
      "\t\tAccuracy\t0.55\t0.0\t0.55\t0.55\n",
      "\t\tPrecision\t0.57\t0.0\t0.57\t0.57\n",
      "\t\tRecall\t\t0.59\t0.0\t0.59\t0.59\n",
      "\tSplit 5:\n",
      "\t\t\t\tAvg\tSt.Dv.\tLow\tHigh\n",
      "\t\tAccuracy\t0.54\t0.0\t0.54\t0.54\n",
      "\t\tPrecision\t0.55\t0.0\t0.55\t0.55\n",
      "\t\tRecall\t\t0.6\t0.0\t0.6\t0.6\n",
      "\tSplit 6:\n",
      "\t\t\t\tAvg\tSt.Dv.\tLow\tHigh\n",
      "\t\tAccuracy\t0.56\t0.0\t0.56\t0.56\n",
      "\t\tPrecision\t0.59\t0.0\t0.59\t0.59\n",
      "\t\tRecall\t\t0.5\t0.0\t0.5\t0.5\n",
      "\tSplit 7:\n",
      "\t\t\t\tAvg\tSt.Dv.\tLow\tHigh\n",
      "\t\tAccuracy\t0.55\t0.0\t0.55\t0.55\n",
      "\t\tPrecision\t0.57\t0.0\t0.57\t0.57\n",
      "\t\tRecall\t\t0.56\t0.0\t0.56\t0.56\n",
      "\n",
      "Statistics By Sample Space:\n",
      "\n",
      "\tSplit 0:\n",
      "\t\t\t\tAvg\tSt.Dv.\tLow\tHigh\n",
      "\t\tAccuracy\t0.54\t0.02\t0.5\t0.56\n",
      "\t\tPrecision\t0.57\t0.01\t0.55\t0.59\n",
      "\t\tRecall\t\t0.54\t0.14\t0.2\t0.71\n",
      "\n",
      "Statistics By Model Space:\n",
      "\n",
      "\tSplit 0:\n",
      "\t\t\t\tAvg\tSt.Dv.\tLow\tHigh\n",
      "\t\tAccuracy\t0.54\t0.02\t0.5\t0.56\n",
      "\t\tPrecision\t0.57\t0.01\t0.55\t0.59\n",
      "\t\tRecall\t\t0.54\t0.14\t0.2\t0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/logankelsch/ES/-ES-NN-test1/.tf_/lib/python3.12/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import _Model_Evaluation\n",
    "\n",
    "reload(_Model_Evaluation)\n",
    "\n",
    "_Model_Evaluation.evaluate_models(\n",
    "\t\tmodels=models\n",
    "\t\t,X_findx=X_find_parts\n",
    "\t\t,X_trans=X_trans_parts\n",
    "\t\t,X_train=X_train_parts\n",
    "\t\t,y_train=y_parts\n",
    "\t\t,X_test=X_val\n",
    "\t\t,y_test=y_val\n",
    "\t\t,prfm_gnrl\t=\t'all'\n",
    "\t\t,prfm_stat\t=\t'all'\n",
    "\t\t,disp_mthd\t=\t'as_value'\n",
    "\t\t,test_whch\t=\t'independent'\n",
    "\t\t,pred_type\t=\t'classification'\n",
    "        ,lstm_frmt\t=\tlstm_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-18 23:31:01.888235: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-18 23:31:02.035431: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737261062.086932  144874 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737261062.101232  144874 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-18 23:31:02.233494: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1737261064.389167  144874 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1962 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: GPU\n",
      "\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737261065.737156  145036 service.cc:148] XLA service 0x7feef400b190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1737261065.737452  145036 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 3GB, Compute Capability 6.1\n",
      "2025-01-18 23:31:05.766563: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1737261065.860935  145036 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5128 - loss: 0.7070 - precision: 0.5484 - recall: 0.6986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737261066.180332  145036 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.5091 - loss: 0.7048 - precision: 0.5341 - recall: 0.7156 - val_accuracy: 0.5167 - val_loss: 0.7015 - val_precision: 0.5294 - val_recall: 0.7605 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5095 - loss: 0.6997 - precision: 0.5064 - recall: 0.6403 - val_accuracy: 0.4992 - val_loss: 0.6973 - val_precision: 0.5239 - val_recall: 0.5602 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5242 - loss: 0.6993 - precision: 0.5227 - recall: 0.5983 - val_accuracy: 0.5231 - val_loss: 0.6944 - val_precision: 0.5392 - val_recall: 0.6627 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5617 - loss: 0.6926 - precision: 0.5527 - recall: 0.6967 - val_accuracy: 0.5231 - val_loss: 0.6924 - val_precision: 0.5388 - val_recall: 0.6687 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5606 - loss: 0.6893 - precision: 0.5657 - recall: 0.7017 - val_accuracy: 0.5254 - val_loss: 0.6913 - val_precision: 0.5405 - val_recall: 0.6732 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5863 - loss: 0.6820 - precision: 0.5931 - recall: 0.7159 - val_accuracy: 0.5294 - val_loss: 0.6907 - val_precision: 0.5443 - val_recall: 0.6657 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5702 - loss: 0.6846 - precision: 0.5681 - recall: 0.7165 - val_accuracy: 0.5302 - val_loss: 0.6896 - val_precision: 0.5445 - val_recall: 0.6732 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5563 - loss: 0.6901 - precision: 0.5348 - recall: 0.6925 - val_accuracy: 0.5270 - val_loss: 0.6893 - val_precision: 0.5429 - val_recall: 0.6581 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5746 - loss: 0.6849 - precision: 0.5697 - recall: 0.7171 - val_accuracy: 0.5278 - val_loss: 0.6882 - val_precision: 0.5430 - val_recall: 0.6657 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5419 - loss: 0.6907 - precision: 0.5458 - recall: 0.6954 - val_accuracy: 0.5278 - val_loss: 0.6879 - val_precision: 0.5430 - val_recall: 0.6657 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5647 - loss: 0.6834 - precision: 0.5536 - recall: 0.6955 - val_accuracy: 0.5453 - val_loss: 0.6877 - val_precision: 0.5669 - val_recall: 0.5873 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5661 - loss: 0.6835 - precision: 0.5833 - recall: 0.6118 - val_accuracy: 0.5493 - val_loss: 0.6872 - val_precision: 0.5698 - val_recall: 0.5964 - learning_rate: 0.0010\n",
      "Epoch 13/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5465 - loss: 0.6866 - precision: 0.5636 - recall: 0.5872 - val_accuracy: 0.5580 - val_loss: 0.6871 - val_precision: 0.5816 - val_recall: 0.5798 - learning_rate: 0.0010\n",
      "Epoch 14/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5786 - loss: 0.6801 - precision: 0.6060 - recall: 0.5958 - val_accuracy: 0.5525 - val_loss: 0.6876 - val_precision: 0.5805 - val_recall: 0.5482 - learning_rate: 0.0010\n",
      "Epoch 15/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5796 - loss: 0.6795 - precision: 0.5964 - recall: 0.5911 - val_accuracy: 0.5612 - val_loss: 0.6869 - val_precision: 0.5862 - val_recall: 0.5738 - learning_rate: 0.0010\n",
      "Epoch 16/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5665 - loss: 0.6842 - precision: 0.5762 - recall: 0.5759 - val_accuracy: 0.5525 - val_loss: 0.6873 - val_precision: 0.5805 - val_recall: 0.5482 - learning_rate: 0.0010\n",
      "Epoch 17/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6044 - loss: 0.6757 - precision: 0.6001 - recall: 0.6246 - val_accuracy: 0.5604 - val_loss: 0.6865 - val_precision: 0.5845 - val_recall: 0.5783 - learning_rate: 0.0010\n",
      "Epoch 18/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5863 - loss: 0.6782 - precision: 0.6023 - recall: 0.6160 - val_accuracy: 0.5612 - val_loss: 0.6867 - val_precision: 0.5862 - val_recall: 0.5738 - learning_rate: 0.0010\n",
      "Epoch 19/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5671 - loss: 0.6775 - precision: 0.6017 - recall: 0.5864 - val_accuracy: 0.5564 - val_loss: 0.6870 - val_precision: 0.5836 - val_recall: 0.5572 - learning_rate: 0.0010\n",
      "Epoch 20/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5660 - loss: 0.6817 - precision: 0.5720 - recall: 0.5902 - val_accuracy: 0.5564 - val_loss: 0.6871 - val_precision: 0.5836 - val_recall: 0.5572 - learning_rate: 0.0010\n",
      "Epoch 21/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5708 - loss: 0.6784 - precision: 0.5693 - recall: 0.5718 - val_accuracy: 0.5612 - val_loss: 0.6869 - val_precision: 0.5862 - val_recall: 0.5738 - learning_rate: 0.0010\n",
      "Epoch 22/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5924 - loss: 0.6746 - precision: 0.6125 - recall: 0.6396 - val_accuracy: 0.5564 - val_loss: 0.6872 - val_precision: 0.5836 - val_recall: 0.5572 - learning_rate: 0.0010\n",
      "Epoch 23/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5750 - loss: 0.6737 - precision: 0.5729 - recall: 0.5745 - val_accuracy: 0.5612 - val_loss: 0.6869 - val_precision: 0.5862 - val_recall: 0.5738 - learning_rate: 0.0010\n",
      "Epoch 24/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5688 - loss: 0.6792 - precision: 0.5846 - recall: 0.5835 - val_accuracy: 0.5612 - val_loss: 0.6873 - val_precision: 0.5862 - val_recall: 0.5738 - learning_rate: 0.0010\n",
      "Epoch 25/25\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5580 - loss: 0.6813 - precision: 0.5825 - recall: 0.5655 - val_accuracy: 0.5612 - val_loss: 0.6872 - val_precision: 0.5862 - val_recall: 0.5738 - learning_rate: 0.0010\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'y_pred' parameter of accuracy_score must be an array-like or a sparse matrix. Got None instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reload\n\u001b[1;32m      4\u001b[0m reload(_Metamodel)\n\u001b[0;32m----> 5\u001b[0m metamodel, prediction_set \u001b[38;5;241m=\u001b[39m \u001b[43m_Metamodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_test_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m\t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m\t\u001b[49m\u001b[43mmodels\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_findx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_find_parts\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_trans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_trans_parts\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m\t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m\t\u001b[49m\u001b[43mX_val\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m\t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m\t\u001b[49m\u001b[43my_val\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_size\u001b[49m\u001b[43m\t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m\t\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m\t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m\t\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmetam_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_cls_wt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ES/-ES-NN-test1/RotationalEnsemble/_Metamodel.py:113\u001b[0m, in \u001b[0;36mtrain_test_meta_model\u001b[0;34m(models, X_findx, X_trans, X_test, y_test, val_size, shuffle, metam_type, use_cls_wt, use_mm_params, metam_params, prediciton_type)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m#allowing self test to be skipped if model does not see anything\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;129;01mnot\u001b[39;00m nolearn_model):\n\u001b[1;32m    112\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMETA-MODEL SELF TEST:\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 113\u001b[0m \t\t  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_true\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mself_pred\u001b[49m\u001b[43m)\u001b[49m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    114\u001b[0m \t\t  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mPrecision:\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(precision_score(self_true,\u001b[38;5;250m \u001b[39mself_pred),\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    115\u001b[0m \t\t  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mRecall:\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(recall_score(self_true,\u001b[38;5;250m \u001b[39mself_pred),\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    116\u001b[0m \t\u001b[38;5;66;03m#Create the confusion matrix\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \tcm \u001b[38;5;241m=\u001b[39m confusion_matrix(self_true, self_pred)\n",
      "File \u001b[0;32m~/ES/-ES-NN-test1/.tf_/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:203\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m to_ignore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    201\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[0;32m--> 203\u001b[0m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_constraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__qualname__\u001b[39;49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n",
      "File \u001b[0;32m~/ES/-ES-NN-test1/.tf_/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'y_pred' parameter of accuracy_score must be an array-like or a sparse matrix. Got None instead."
     ]
    }
   ],
   "source": [
    "import _Metamodel\n",
    "from importlib import reload\n",
    "\n",
    "reload(_Metamodel)\n",
    "metamodel, prediction_set = _Metamodel.train_test_meta_model(\n",
    "\tmodels\t=\tmodels\n",
    "\t,X_findx=X_find_parts\n",
    "\t,X_trans=X_trans_parts\n",
    "\t,X_test\t=\tX_val\n",
    "\t,y_test\t=\ty_val\n",
    "\t,val_size\t=\t0.5\n",
    "\t,shuffle\t=\tTrue\n",
    "\t,metam_type = 'NN'\n",
    "    ,use_cls_wt = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot cast array data from dtype('float32') to dtype('int64') according to the rule 'safe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m zeros \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prediction_set:\n\u001b[0;32m----> 5\u001b[0m     count \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbincount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     zeros \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(zeros, count[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      8\u001b[0m y_val_zeros_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_val \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast array data from dtype('float32') to dtype('int64') according to the rule 'safe'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "zeros = np.array([])\n",
    "for p in prediction_set:\n",
    "    count = np.bincount(p)\n",
    "    zeros = np.append(zeros, count[0])\n",
    "    \n",
    "y_val_zeros_indices = np.where(y_val != 0)[0]\n",
    "\n",
    "zerocount_filtered = zeros[y_val_zeros_indices]\n",
    "zerocount_filtered = zerocount_filtered.astype(int)\n",
    "\n",
    "print((zerocount_filtered[0]))\n",
    "\n",
    "frequenct_0 = np.array([])\n",
    "frequenct_0 = np.bincount(zerocount_filtered)\n",
    "\n",
    "print(frequenct_0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(range(9),frequenct_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-18 23:19:04.872114: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-18 23:19:04.996419: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737260345.046184  127460 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737260345.060938  127460 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-18 23:19:05.189252: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/logankelsch/ES/-ES-NN-test1/.tf_/lib/python3.12/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tf_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
